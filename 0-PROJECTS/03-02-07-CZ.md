<small>Claude Sonnet 4 **(Historical Archive Explorer - RAG systém pro průzkum historických archivů)**</small>
# Historical Archive Explorer

## Klíčové koncepty projektu

### RAG (Retrieval-Augmented Generation)
Hybridní přístup kombinující vyhledávání relevantních informací z databáze s generativní AI. RAG nejprve najde související dokumenty a poté je použije jako kontext pro generování odpovědi.

### Llama 3
Open-source velký jazykový model od Meta, který poskytuje pokročilé schopnosti porozumění textu a generování odpovědí. Ideální pro lokální nasazení a práci s citlivými historickými daty.

### OCR (Optical Character Recognition)
Technologie pro rozpoznávání textu ze skenovaných dokumentů a obrázků. Klíčová pro zpracování historických novin, knih a rukopisů v digitální podobě.

### Vector Search (Vektorové vyhledávání)
Metoda vyhledávání založená na sémantické podobnosti, kde jsou texty převedeny na vektory a vyhledávání probíhá na základě vzdálenosti v multidimenzionálním prostoru.

### Timeline Generation
Automatické vytváření časových os a chronologických přehledů na základě extrahovaných dat z historických dokumentů.

## Komplexní vysvětlení projektu

Historical Archive Explorer je pokročilý RAG systém navržený pro digitalizaci, indexaci a inteligentní průzkum historických archivů. Projekt řeší problém nedostupnosti a obtížného prohledávání historických dokumentů, které jsou často uloženy pouze ve fyzické podobě nebo jako naskenované obrázky bez možnosti textového vyhledávání.

### Hlavní cíle projektu:
- **Digitalizace**: Převod fyzických dokumentů do digitální podoby pomocí OCR
- **Indexace**: Vytvoření sémantických indexů pro efektivní vyhledávání
- **Kontextuální vyhledávání**: Umožnění dotazů v přirozeném jazyce
- **Časová analýza**: Automatické vytváření chronologií a časových trendů
- **Zachování kontextu**: Udržení historického a kulturního kontextu při odpovědích

### Technické výzvy:
- Kvalita OCR pro staré a poškozené dokumenty
- Zpracování různých jazyků a historických variant češtiny
- Škálovatelnost pro velké archivy
- Přesnost sémantického vyhledávání

### Potenciální dopad:
Projekt může revolutionizovat práci historiků, novinářů a výzkumníků tím, že učiní historické prameny dostupnějšími a prohledávatelějšími.

## Komplexní implementace projektu

````python
langchain==0.1.0
llama-cpp-python==0.2.20
chromadb==0.4.18
pytesseract==0.3.10
Pillow==10.1.0
streamlit==1.29.0
pandas==2.1.4
numpy==1.25.2
python-dotenv==1.0.0
requests==2.31.0
beautifulsoup4==4.12.2
plotly==5.17.0
sentence-transformers==2.2.2
````

````python
import pytesseract
from PIL import Image
import os
import logging
from typing import List, Dict, Optional
import cv2
import numpy as np

class OCRProcessor:
    """Zpracování OCR pro historické dokumenty"""
    
    def __init__(self, tesseract_path: Optional[str] = None):
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
        
        self.logger = logging.getLogger(__name__)
        
        # Konfigurace pro české texty
        self.czech_config = '--psm 6 -l ces+eng'
        
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """Předzpracování obrázku pro lepší OCR výsledky"""
        try:
            # Načtení obrázku
            img = cv2.imread(image_path)
            
            # Převod na šedou
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # Zlepšení kontrastu
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # Odstranění šumu
            denoised = cv2.medianBlur(enhanced, 3)
            
            # Prahování
            _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            return thresh
            
        except Exception as e:
            self.logger.error(f"Chyba při předzpracování obrázku {image_path}: {e}")
            return cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    def extract_text(self, image_path: str) -> Dict[str, str]:
        """Extrakce textu z obrázku"""
        try:
            # Předzpracování
            processed_img = self.preprocess_image(image_path)
            
            # OCR s konfidencí
            data = pytesseract.image_to_data(
                processed_img, 
                config=self.czech_config, 
                output_type=pytesseract.Output.DICT
            )
            
            # Filtrování slov s nízkou konfidencí
            confident_words = []
            for i, conf in enumerate(data['conf']):
                if int(conf) > 30:  # Minimální confidence
                    word = data['text'][i].strip()
                    if word:
                        confident_words.append(word)
            
            text = ' '.join(confident_words)
            
            # Základní text z celého obrázku
            full_text = pytesseract.image_to_string(
                processed_img, 
                config=self.czech_config
            )
            
            return {
                'full_text': full_text,
                'confident_text': text,
                'source_file': os.path.basename(image_path)
            }
            
        except Exception as e:
            self.logger.error(f"Chyba při OCR zpracování {image_path}: {e}")
            return {
                'full_text': '',
                'confident_text': '',
                'source_file': os.path.basename(image_path),
                'error': str(e)
            }
    
    def batch_process(self, image_directory: str) -> List[Dict[str, str]]:
        """Dávkové zpracování obrázků"""
        results = []
        supported_formats = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp')
        
        for filename in os.listdir(image_directory):
            if filename.lower().endswith(supported_formats):
                image_path = os.path.join(image_directory, filename)
                result = self.extract_text(image_path)
                results.append(result)
                self.logger.info(f"Zpracován soubor: {filename}")
        
        return results
````

````python
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import uuid
from typing import List, Dict, Optional
import logging

class HistoricalVectorStore:
    """Vektorové úložiště pro historické dokumenty"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # České embedding modely
        self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        
        self.collection = self.client.get_or_create_collection(
            name="historical_documents",
            metadata={"description": "Historické dokumenty a noviny"}
        )
        
        self.logger = logging.getLogger(__name__)
    
    def add_documents(self, documents: List[Dict[str, str]]) -> None:
        """Přidání dokumentů do vektorového úložiště"""
        try:
            texts = []
            metadatas = []
            ids = []
            
            for doc in documents:
                if doc.get('confident_text') and len(doc['confident_text'].strip()) > 10:
                    text = doc['confident_text']
                    
                    # Vytvoření metadat
                    metadata = {
                        'source_file': doc.get('source_file', 'unknown'),
                        'full_text': doc.get('full_text', '')[:1000],  # Omezení délky
                        'length': len(text),
                        'has_error': 'error' in doc
                    }
                    
                    texts.append(text)
                    metadatas.append(metadata)
                    ids.append(str(uuid.uuid4()))
            
            if texts:
                # Generování embeddingů
                embeddings = self.embedding_model.encode(texts).tolist()
                
                # Přidání do Chroma DB
                self.collection.add(
                    embeddings=embeddings,
                    documents=texts,
                    metadatas=metadatas,
                    ids=ids
                )
                
                self.logger.info(f"Přidáno {len(texts)} dokumentů do vektorového úložiště")
            
        except Exception as e:
            self.logger.error(f"Chyba při přidávání dokumentů: {e}")
    
    def search(self, query: str, n_results: int = 5) -> List[Dict]:
        """Vyhledávání v historických dokumentech"""
        try:
            # Generování embedding pro dotaz
            query_embedding = self.embedding_model.encode([query]).tolist()
            
            # Vyhledávání
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=n_results,
                include=['documents', 'metadatas', 'distances']
            )
            
            # Formátování výsledků
            formatted_results = []
            for i in range(len(results['documents'][0])):
                formatted_results.append({
                    'document': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'similarity': 1 - results['distances'][0][i],  # Převod distance na similarity
                })
            
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"Chyba při vyhledávání: {e}")
            return []
    
    def get_statistics(self) -> Dict:
        """Statistiky úložiště"""
        try:
            count = self.collection.count()
            return {
                'total_documents': count,
                'collection_name': self.collection.name
            }
        except Exception as e:
            self.logger.error(f"Chyba při získávání statistik: {e}")
            return {'total_documents': 0}
````

````python
from llama_cpp import Llama
import json
from typing import List, Dict, Optional
import logging

class LlamaHistoricalQA:
    """Integrace Llama 3 pro historické dotazy"""
    
    def __init__(self, model_path: str, context_window: int = 4096):
        try:
            self.llm = Llama(
                model_path=model_path,
                n_ctx=context_window,
                n_threads=4,
                verbose=False
            )
            self.logger = logging.getLogger(__name__)
            self.logger.info("Llama model úspěšně načten")
            
        except Exception as e:
            self.logger.error(f"Chyba při načítání Llama modelu: {e}")
            raise
    
    def create_historical_prompt(self, query: str, context_documents: List[Dict]) -> str:
        """Vytvoření promptu pro historické dotazy"""
        
        context_text = "\n\n".join([
            f"Dokument {i+1} (ze souboru {doc['metadata']['source_file']}):\n{doc['document']}"
            for i, doc in enumerate(context_documents)
        ])
        
        prompt = f"""Jsi expert na českou historii a archivní dokumenty. Na základě poskytnutých historických dokumentů odpověz na následující dotaz v češtině.

HISTORICKÉ DOKUMENTY:
{context_text}

DOTAZ: {query}

INSTRUKCE:
- Odpověz pouze na základě poskytnutých dokumentů
- Pokud informace v dokumentech nejsou, jasně to uveď
- Zachovej historický kontext a uvádej zdroje
- Používej formální, ale srozumitelný jazyk
- Pokud jsou v dokumentech data, uveď je přesně

ODPOVĚĎ:"""
        
        return prompt
    
    def generate_answer(self, prompt: str, max_tokens: int = 512) -> str:
        """Generování odpovědi pomocí Llama"""
        try:
            response = self.llm(
                prompt,
                max_tokens=max_tokens,
                temperature=0.3,
                top_p=0.9,
                stop=["DOTAZ:", "INSTRUKCE:", "Uživatel:"],
                echo=False
            )
            
            answer = response['choices'][0]['text'].strip()
            return answer
            
        except Exception as e:
            self.logger.error(f"Chyba při generování odpovědi: {e}")
            return f"Omlouváme se, došlo k chybě při zpracování dotazu: {str(e)}"
    
    def extract_dates(self, text: str) -> List[str]:
        """Extrakce dat z textu pro timeline"""
        import re
        
        # Vzory pro česká data
        date_patterns = [
            r'\d{1,2}\.\s*\d{1,2}\.\s*\d{4}',  # DD.MM.YYYY
            r'\d{4}',  # YYYY
            r'\d{1,2}\.\s*\d{4}',  # MM.YYYY
        ]
        
        dates = []
        for pattern in date_patterns:
            matches = re.findall(pattern, text)
            dates.extend(matches)
        
        return list(set(dates))  # Odstranění duplikátů
````

````python
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import re
from typing import List, Dict, Optional
import logging

class HistoricalTimelineGenerator:
    """Generátor časových os z historických dat"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def parse_czech_date(self, date_str: str) -> Optional[datetime]:
        """Parsování českých formátů dat"""
        date_str = date_str.strip()
        
        # Různé formáty dat
        formats = [
            '%d.%m.%Y',
            '%d. %m. %Y',
            '%m.%Y',
            '%m. %Y',
            '%Y'
        ]
        
        for fmt in formats:
            try:
                if fmt == '%Y':
                    return datetime.strptime(date_str, fmt)
                elif fmt in ['%m.%Y', '%m. %Y']:
                    return datetime.strptime(date_str, fmt)
                else:
                    return datetime.strptime(date_str, fmt)
            except ValueError:
                continue
        
        return None
    
    def extract_events_from_documents(self, documents: List[Dict]) -> List[Dict]:
        """Extrakce událostí z dokumentů"""
        events = []
        
        for doc in documents:
            text = doc.get('document', '')
            source = doc.get('metadata', {}).get('source_file', 'Neznámý zdroj')
            
            # Extrakce dat
            date_pattern = r'(\d{1,2}\.\s*\d{1,2}\.\s*\d{4}|\d{4}|\d{1,2}\.\s*\d{4})'
            dates = re.findall(date_pattern, text)
            
            # Extrakce vět s daty
            sentences = text.split('.')
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 20:  # Minimální délka věty
                    for date_str in dates:
                        if date_str in sentence:
                            parsed_date = self.parse_czech_date(date_str)
                            if parsed_date:
                                events.append({
                                    'date': parsed_date,
                                    'date_str': date_str,
                                    'event': sentence[:200] + '...' if len(sentence) > 200 else sentence,
                                    'source': source,
                                    'full_text': text[:500]
                                })
                                break
        
        return events
    
    def create_timeline_chart(self, events: List[Dict]) -> go.Figure:
        """Vytvoření interaktivní časové osy"""
        if not events:
            fig = go.Figure()
            fig.add_annotation(
                text="Nebyly nalezeny žádné datované události",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
        
        # Převod na DataFrame
        df = pd.DataFrame(events)
        df = df.sort_values('date')
        
        # Vytvoření timeline grafu
        fig = go.Figure()
        
        # Přidání bodů na časovou osu
        fig.add_trace(go.Scatter(
            x=df['date'],
            y=[1] * len(df),
            mode='markers+text',
            marker=dict(
                size=12,
                color='blue',
                line=dict(width=2, color='darkblue')
            ),
            text=df['date_str'],
            textposition='top center',
            hovertemplate='<b>Datum:</b> %{text}<br>' +
                         '<b>Událost:</b> %{customdata[0]}<br>' +
                         '<b>Zdroj:</b> %{customdata[1]}<extra></extra>',
            customdata=list(zip(df['event'], df['source'])),
            name='Historické události'
        ))
        
        # Formátování grafu
        fig.update_layout(
            title='Časová osa historických událostí',
            xaxis_title='Datum',
            yaxis=dict(
                showticklabels=False,
                showgrid=False,
                zeroline=False,
                range=[0.5, 1.5]
            ),
            showlegend=False,
            height=400,
            margin=dict(t=50, b=50, l=50, r=50)
        )
        
        return fig
    
    def generate_summary_stats(self, events: List[Dict]) -> Dict:
        """Generování souhrnných statistik"""
        if not events:
            return {'total_events': 0}
        
        df = pd.DataFrame(events)
        
        # Extrakce roků
        years = [event['date'].year for event in events]
        year_counts = pd.Series(years).value_counts()
        
        return {
            'total_events': len(events),
            'date_range': f"{min(years)} - {max(years)}",
            'most_active_year': year_counts.index[0] if not year_counts.empty else None,
            'events_in_most_active_year': year_counts.iloc[0] if not year_counts.empty else 0,
            'unique_sources': len(df['source'].unique())
        }
````

````python
import streamlit as st
import os
import logging
from datetime import datetime
import pandas as pd

from ocr_processor import OCRProcessor
from vector_store import HistoricalVectorStore
from llm_integration import LlamaHistoricalQA
from timeline_generator import HistoricalTimelineGenerator

# Konfigurace loggingu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HistoricalArchiveExplorer:
    """Hlavní aplikace pro průzkum historických archivů"""
    
    def __init__(self):
        self.ocr_processor = None
        self.vector_store = None
        self.llm_qa = None
        self.timeline_generator = HistoricalTimelineGenerator()
    
    def initialize_components(self):
        """Inicializace komponent"""
        try:
            # OCR processor
            self.ocr_processor = OCRProcessor()
            
            # Vector store
            self.vector_store = HistoricalVectorStore()
            
            # LLM (pouze pokud je dostupný model)
            model_path = st.session_state.get('llm_model_path')
            if model_path and os.path.exists(model_path):
                self.llm_qa = LlamaHistoricalQA(model_path)
            
            return True
            
        except Exception as e:
            st.error(f"Chyba při inicializaci: {e}")
            return False
    
    def create_sample_data(self):
        """Vytvoření ukázkových dat pro demonstraci"""
        sample_documents = [
            {
                'confident_text': 'Dne 28. října 1918 byla vyhlášena samostatnost Československé republiky. Tomáš Garrigue Masaryk se stal prvním prezidentem.',
                'full_text': 'Dne 28. října 1918 byla vyhlášena samostatnost Československé republiky. Tomáš Garrigue Masaryk se stal prvním prezidentem nového státu.',
                'source_file': 'noviny_1918_10.jpg'
            },
            {
                'confident_text': 'Válka skončila 11. listopadu 1918 podpisem příměří v Compiègne. Pro Čechy a Slováky to znamenalo svobodu.',
                'full_text': 'První světová válka skončila 11. listopadu 1918 podpisem příměří v Compiègne. Pro Čechy a Slováky to znamenalo konečně svobodu od rakousko-uherské nadvlády.',
                'source_file': 'zpravy_1918_11.jpg'
            },
            {
                'confident_text': 'V roce 1920 byla přijata nová ústava Československé republiky. Zemi čekalo období budování demokracie.',
                'full_text': 'V roce 1920 byla přijata nová ústava Československé republiky, která ustanovila parlamentní systém. Zemi čekalo období budování moderní demokracie.',
                'source_file': 'ustava_1920.jpg'
            }
        ]
        
        return sample_documents

def main():
    st.set_page_config(
        page_title="Historical Archive Explorer",
        page_icon="📚",
        layout="wide"
    )
    
    st.title("📚 Historical Archive Explorer")
    st.subtitle("RAG systém pro průzkum historických archivů")
    
    # Inicializace session state
    if 'app' not in st.session_state:
        st.session_state.app = HistoricalArchiveExplorer()
    
    app = st.session_state.app
    
    # Sidebar pro konfiguraci
    with st.sidebar:
        st.header("⚙️ Konfigurace")
        
        # Nastavení Llama modelu
        st.subheader("LLM Model")
        model_path = st.text_input(
            "Cesta k Llama modelu (volitelné)",
            placeholder="/path/to/llama-model.gguf",
            help="Pokud máte lokální Llama model, zadejte cestu k němu"
        )
        
        if model_path:
            st.session_state.llm_model_path = model_path
        
        # Tlačítko pro inicializaci
        if st.button("🔄 Inicializovat systém"):
            with st.spinner("Inicializace komponent..."):
                if app.initialize_components():
                    st.success("✅ Systém inicializován!")
                    
                    # Načtení ukázkových dat
                    sample_data = app.create_sample_data()
                    app.vector_store.add_documents(sample_data)
                    st.info("📄 Načtena ukázková data")
        
        # Statistiky
        if app.vector_store:
            st.subheader("📊 Statistiky")
            stats = app.vector_store.get_statistics()
            st.metric("Dokumenty v databázi", stats.get('total_documents', 0))
    
    # Hlavní rozhraní
    tabs = st.tabs(["🔍 Vyhledávání", "📁 Nahrávání dokumentů", "📈 Časová osa", "ℹ️ O projektu"])
    
    # Tab 1: Vyhledávání
    with tabs[0]:
        st.header("🔍 Vyhledávání v historických archivech")
        
        if not app.vector_store:
            st.warning("⚠️ Nejprve inicializujte systém v postranním panelu")
            return
        
        # Vyhledávací formulář
        query = st.text_input(
            "Zadejte dotaz:",
            placeholder="Např: Kdy byla vyhlášena samostatnost Československa?"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            search_button = st.button("🔍 Vyhledat", type="primary")
        with col2:
            n_results = st.slider("Počet výsledků", 1, 10, 5)
        
        if search_button and query:
            with st.spinner("Vyhledávání v archivech..."):
                # Vyhledání dokumentů
                results = app.vector_store.search(query, n_results)
                
                if results:
                    st.success(f"✅ Nalezeno {len(results)} relevantních dokumentů")
                    
                    # Zobrazení výsledků
                    for i, result in enumerate(results, 1):
                        with st.expander(f"📄 Dokument {i} (podobnost: {result['similarity']:.2%})"):
                            st.write("**Obsah:**")
                            st.write(result['document'])
                            st.write(f"**Zdroj:** {result['metadata']['source_file']}")
                    
                    # Generování odpovědi pomocí LLM (pokud je k dispozici)
                    if app.llm_qa:
                        st.subheader("🤖 AI odpověď")
                        with st.spinner("Generování odpovědi..."):
                            prompt = app.llm_qa.create_historical_prompt(query, results)
                            answer = app.llm_qa.generate_answer(prompt)
                            st.write(answer)
                    else:
                        st.info("💡 Pro AI odpovědi zadejte cestu k Llama modelu v konfiguraci")
                else:
                    st.warning("🔍 Nebyly nalezeny žádné relevantní dokumenty")
    
    # Tab 2: Nahrávání dokumentů
    with tabs[1]:
        st.header("📁 Nahrávání a zpracování dokumentů")
        
        if not app.ocr_processor:
            st.warning("⚠️ Nejprve inicializujte systém v postranním panelu")
            return
        
        uploaded_files = st.file_uploader(
            "Vyberte obrázky historických dokumentů",
            type=['png', 'jpg', 'jpeg', 'tiff', 'bmp'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            if st.button("📝 Zpracovat dokumenty"):
                progress_bar = st.progress(0)
                processed_docs = []
                
                for i, uploaded_file in enumerate(uploaded_files):
                    # Uložení dočasného souboru
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # OCR zpracování
                    result = app.ocr_processor.extract_text(temp_path)
                    processed_docs.append(result)
                    
                    # Cleanup
                    os.remove(temp_path)
                    
                    # Aktualizace progress baru
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                # Přidání do vektorové databáze
                app.vector_store.add_documents(processed_docs)
                
                st.success(f"✅ Zpracováno {len(processed_docs)} dokumentů")
                
                # Zobrazení výsledků
                for doc in processed_docs:
                    if doc.get('confident_text'):
                        with st.expander(f"📄 {doc['source_file']}"):
                            st.write("**Rozpoznaný text:**")
                            st.write(doc['confident_text'])
    
    # Tab 3: Časová osa
    with tabs[2]:
        st.header("📈 Generování časové osy")
        
        if not app.vector_store:
            st.warning("⚠️ Nejprve inicializujte systém")
            return
        
        if st.button("📅 Vytvořit časovou osu"):
            with st.spinner("Analýza dokumentů a vytváření časové osy..."):
                # Získání všech dokumentů
                all_results = app.vector_store.search("", n_results=50)
                
                # Extrakce událostí
                events = app.timeline_generator.extract_events_from_documents(all_results)
                
                if events:
                    # Zobrazení časové osy
                    fig = app.timeline_generator.create_timeline_chart(events)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Statistiky
                    stats = app.timeline_generator.generate_summary_stats(events)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Celkem událostí", stats['total_events'])
                    with col2:
                        st.metric("Časové rozpětí", stats.get('date_range', 'N/A'))
                    with col3:
                        st.metric("Nejaktivnější rok", stats.get('most_active_year', 'N/A'))
                    
                    # Detail událostí
                    st.subheader("📋 Seznam událostí")
                    events_df = pd.DataFrame([
                        {
                            'Datum': event['date_str'],
                            'Událost': event['event'][:100] + '...' if len(event['event']) > 100 else event['event'],
                            'Zdroj': event['source']
                        }
                        for event in sorted(events, key=lambda x: x['date'])
                    ])
                    st.dataframe(events_df, use_container_width=True)
                else:
                    st.info("📅 V dokumentech nebyly nalezeny datované události")
    
    # Tab 4: O projektu
    with tabs[3]:
        st.header("ℹ️ O projektu Historical Archive Explorer")
        
        st.markdown("""
        ### 🎯 Účel projektu
        Historical Archive Explorer je pokročilý RAG (Retrieval-Augmented Generation) systém 
        navržený pro digitalizaci, indexaci a inteligentní průzkum historických archivů.
        
        ### 🔧 Klíčové technologie
        - **RAG architektura**: Kombinace vyhledávání a generativní AI
        - **Llama 3**: Open-source jazykový model pro lokální nasazení
        - **OCR (Tesseract)**: Rozpoznávání textu z historických dokumentů
        - **ChromaDB**: Vektorová databáze pro sémantické vyhledávání
        - **Streamlit**: Moderní webové rozhraní
        
        ### 📈 Funkce
        1. **OCR zpracování**: Převod skenovaných dokumentů na text
        2. **Vektorové vyhledávání**: Sémantické hledání v archivech
        3. **AI asistent**: Inteligentní odpovědi na historické dotazy
        4. **Časové osy**: Automatické vytváření chronologií
        
        ### 🚀 Využití
        - Historický výzkum
        - Archivní práce
        - Novinářská investigace
        - Vzdělávání
        """)

if __name__ == "__main__":
    main()
````

````python
"""
Instalační skript pro Historical Archive Explorer
"""

import subprocess
import sys
import os

def install_requirements():
    """Instalace požadovaných balíčků"""
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
        print("✅ Všechny balíčky byly úspěšně nainstalovány")
    except subprocess.CalledProcessError as e:
        print(f"❌ Chyba při instalaci balíčků: {e}")
        return False
    return True

def setup_directories():
    """Vytvoření potřebných adresářů"""
    directories = ["data", "models", "temp", "chroma_db"]
    
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"📁 Vytvořen adresář: {directory}")
    
    return True

def download_sample_model():
    """Stažení ukázkového modelu (volitelné)"""
    print("""
📥 Pro plnou funkcionalnost doporučujeme stáhnout Llama model:

1. Navštivte: https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML
2. Stáhněte soubor s příponou .gguf
3. Umístěte do složky 'models/'
4. Zadejte cestu v aplikaci

Alternativně můžete použít příkaz:
wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.q4_0.gguf -O models/llama-model.gguf
    """)

def main():
    print("🚀 Nastavení Historical Archive Explorer")
    print("=" * 50)
    
    # Instalace balíčků
    print("1. Instalace Python balíčků...")
    if not install_requirements():
        return
    
    # Vytvoření adresářů
    print("\n2. Vytváření adresářové struktury...")
    setup_directories()
    
    # Informace o modelu
    print("\n3. Informace o jazykovém modelu...")
    download_sample_model()
    
    print("\n✅ Nastavení dokončeno!")
    print("\n🚀 Spuštění aplikace:")
    print("streamlit run src/main_app.py")

if __name__ == "__main__":
    main()
````

## Shrnutí projektu

Historical Archive Explorer představuje pokročilé řešení pro digitalizaci a průzkum historických archivů pomocí moderních AI technologií. Projekt kombinuje **OCR zpracování**, **vektorové vyhledávání** a **generativní AI** do komplexního systému.

### Klíčové výhody:
- **Dostupnost**: Zpřístupnění historických dokumentů širší veřejnosti
- **Efektivita**: Rychlé vyhledávání v rozsáhlých archivech
- **Přesnost**: Sémantické porozumění historickému kontextu
- **Škálovatelnost**: Možnost rozšíření na tisíce dokumentů

### Technické přednosti:
- **Lokální nasazení** s Llama 3 zajišťuje soukromí dat
- **Modulární architektura** umožňuje snadné rozšíření
- **Moderní UI** s real-time analýzou a vizualizacemi
- **Podpora češtiny** včetně historických variant

Projekt má potenciál revolutionizovat práci s historickými prameny a učinit naši minulost dostupnější pro výzkum i vzdělávání.