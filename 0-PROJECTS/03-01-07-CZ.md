<small>Claude Sonnet 4 **(E-learning Content Recommendation Engine s RAG)**</small>
# E-learning Content Recommendation Engine

## 1. NÃ¡zev projektu

**InteligentnÃ­ doporuÄovacÃ­ systÃ©m e-learningovÃ©ho obsahu s vyuÅ¾itÃ­m RAG (Retrieval-Augmented Generation)**

## 2. VysvÄ›tlenÃ­ klÃ­ÄovÃ½ch konceptÅ¯

### RAG (Retrieval-Augmented Generation)
Kombinace vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch informacÃ­ z databÃ¡ze znalostÃ­ s generativnÃ­mi schopnostmi LLM pro vytvÃ¡Å™enÃ­ kontextuÃ¡lnÄ› pÅ™esnÃ½ch odpovÄ›dÃ­.

### Course Materials (Kurzy a materiÃ¡ly)
StrukturovanÃ© vzdÄ›lÃ¡vacÃ­ obsahy vÄetnÄ› textÅ¯, prezentacÃ­, dokumentÅ¯ a dalÅ¡Ã­ch vzdÄ›lÃ¡vacÃ­ch zdrojÅ¯.

### Educational Videos
Video obsah urÄenÃ½ pro vzdÄ›lÃ¡vacÃ­ ÃºÄely, Äasto s titulky a metadaty pro lepÅ¡Ã­ vyhledÃ¡vÃ¡nÃ­.

### Learning Paths (VzdÄ›lÃ¡vacÃ­ cesty)
Sekvence kurzÅ¯ a materiÃ¡lÅ¯ navrÅ¾enÃ½ch pro postupnÃ© dosaÅ¾enÃ­ vzdÄ›lÃ¡vacÃ­ch cÃ­lÅ¯.

### Content Similarity (Podobnost obsahu)
MÄ›Å™enÃ­ podobnosti mezi rÅ¯znÃ½mi vzdÄ›lÃ¡vacÃ­mi materiÃ¡ly pomocÃ­ vektorovÃ½ch reprezentacÃ­.

### Milvus
Vysoce vÃ½konnÃ¡ vektorovÃ¡ databÃ¡ze optimalizovanÃ¡ pro similarity search a AI aplikace.

### YouTube API
RozhranÃ­ pro pÅ™Ã­stup k YouTube datÅ¯m vÄetnÄ› vyhledÃ¡vÃ¡nÃ­ videÃ­ a extrakce metadat.

### Adaptive Learning (AdaptivnÃ­ uÄenÃ­)
Personalizace vzdÄ›lÃ¡vacÃ­ho procesu na zÃ¡kladÄ› individuÃ¡lnÃ­ch potÅ™eb a pokroku studenta.

## 3. KomplexnÃ­ vysvÄ›tlenÃ­ projektu

### CÃ­le projektu
VytvoÅ™it inteligentnÃ­ systÃ©m, kterÃ½ dokÃ¡Å¾e:
- Analyzovat obrovskÃ© mnoÅ¾stvÃ­ vzdÄ›lÃ¡vacÃ­ho obsahu
- DoporuÄovat personalizovanÃ© vzdÄ›lÃ¡vacÃ­ materiÃ¡ly
- VytvÃ¡Å™et adaptivnÃ­ vzdÄ›lÃ¡vacÃ­ cesty
- Integrovat externÃ­ zdroje jako YouTube
- Poskytovat kontextuÃ¡lnÃ­ odpovÄ›di na vzdÄ›lÃ¡vacÃ­ dotazy

### HlavnÃ­ vÃ½zvy
- **Å kÃ¡lovatelnost**: ZpracovÃ¡nÃ­ tisÃ­cÅ¯ hodin video obsahu a dokumentÅ¯
- **Relevance**: ZajiÅ¡tÄ›nÃ­ pÅ™esnosti doporuÄenÃ­
- **Personalizace**: Adaptace na individuÃ¡lnÃ­ styl uÄenÃ­
- **MultimodÃ¡lnÃ­ obsah**: Integrace textu, videa a interaktivnÃ­ch prvkÅ¯
- **Real-time aktualizace**: PrÅ¯bÄ›Å¾nÃ© uÄenÃ­ ze zpÄ›tnÃ© vazby

### PotenciÃ¡lnÃ­ dopad
- ZvÃ½Å¡enÃ­ efektivity vzdÄ›lÃ¡vÃ¡nÃ­ o 30-50%
- SnÃ­Å¾enÃ­ Äasu potÅ™ebnÃ©ho k nalezenÃ­ relevantnÃ­ch materiÃ¡lÅ¯
- PersonalizovanÃ© vzdÄ›lÃ¡vacÃ­ zÃ¡Å¾itky
- Demokratizace pÅ™Ã­stupu ke kvalitnÃ­mu vzdÄ›lÃ¡nÃ­

## 4. KompletnÃ­ Python implementace

### Instalace zÃ¡vislostÃ­

````bash
pip install langchain langchain-openai langchain-community chromadb fastapi uvicorn python-youtube-api pymilvus pandas numpy scikit-learn streamlit requests beautifulsoup4 python-dotenv
````

### HlavnÃ­ implementace

````python
import os
import json
import asyncio
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

import streamlit as st
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# NaÄtenÃ­ environment variables
load_dotenv()

# Konfigurace logovÃ¡nÃ­
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class LearningContent:
    """TÅ™Ã­da pro reprezentaci vzdÄ›lÃ¡vacÃ­ho obsahu"""
    id: str
    title: str
    description: str
    content_type: str  # 'video', 'article', 'course', 'document'
    difficulty_level: str  # 'beginner', 'intermediate', 'advanced'
    topics: List[str]
    duration_minutes: Optional[int]
    url: Optional[str]
    metadata: Dict

@dataclass
class UserProfile:
    """Profil uÅ¾ivatele pro personalizaci"""
    user_id: str
    learning_style: str  # 'visual', 'auditory', 'kinesthetic', 'reading'
    skill_level: Dict[str, str]  # topic -> level
    completed_content: List[str]
    preferences: Dict
    learning_goals: List[str]

class ContentExtractor:
    """Extraktor obsahu z rÅ¯znÃ½ch zdrojÅ¯"""
    
    def __init__(self, youtube_api_key: Optional[str] = None):
        self.youtube_api_key = youtube_api_key or os.getenv('YOUTUBE_API_KEY')
    
    def extract_youtube_content(self, query: str, max_results: int = 10) -> List[LearningContent]:
        """Extrakce vzdÄ›lÃ¡vacÃ­ho obsahu z YouTube"""
        if not self.youtube_api_key:
            logger.warning("YouTube API klÃ­Ä nenÃ­ nastaven")
            return self._create_sample_youtube_content()
        
        try:
            url = "https://www.googleapis.com/youtube/v3/search"
            params = {
                'part': 'snippet',
                'q': f"{query} tutorial vzdÄ›lÃ¡vÃ¡nÃ­",
                'type': 'video',
                'maxResults': max_results,
                'key': self.youtube_api_key,
                'categoryId': '27'  # Education category
            }
            
            response = requests.get(url, params=params)
            data = response.json()
            
            contents = []
            for item in data.get('items', []):
                content = LearningContent(
                    id=item['id']['videoId'],
                    title=item['snippet']['title'],
                    description=item['snippet']['description'],
                    content_type='video',
                    difficulty_level='intermediate',
                    topics=[query],
                    duration_minutes=None,
                    url=f"https://www.youtube.com/watch?v={item['id']['videoId']}",
                    metadata={
                        'channel': item['snippet']['channelTitle'],
                        'published_at': item['snippet']['publishedAt']
                    }
                )
                contents.append(content)
            
            return contents
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i extrakci YouTube obsahu: {e}")
            return self._create_sample_youtube_content()
    
    def _create_sample_youtube_content(self) -> List[LearningContent]:
        """VytvoÅ™enÃ­ ukÃ¡zkovÃ½ch YouTube videÃ­"""
        sample_videos = [
            LearningContent(
                id="video_1",
                title="Ãšvod do Python programovÃ¡nÃ­",
                description="KompletnÃ­ kurz Python pro zaÄÃ¡teÄnÃ­ky s praktickÃ½mi pÅ™Ã­klady",
                content_type="video",
                difficulty_level="beginner",
                topics=["python", "programovÃ¡nÃ­"],
                duration_minutes=45,
                url="https://www.youtube.com/watch?v=sample1",
                metadata={"channel": "Czech Programming", "views": 150000}
            ),
            LearningContent(
                id="video_2",
                title="Machine Learning s TensorFlow",
                description="PokroÄilÃ© techniky machine learningu a deep learningu",
                content_type="video",
                difficulty_level="advanced",
                topics=["machine learning", "tensorflow", "ai"],
                duration_minutes=90,
                url="https://www.youtube.com/watch?v=sample2",
                metadata={"channel": "AI Academy", "views": 75000}
            )
        ]
        return sample_videos
    
    def extract_web_content(self, urls: List[str]) -> List[LearningContent]:
        """Extrakce obsahu z webovÃ½ch strÃ¡nek"""
        contents = []
        
        for url in urls:
            try:
                response = requests.get(url, timeout=10)
                soup = BeautifulSoup(response.content, 'html.parser')
                
                title = soup.find('title').text if soup.find('title') else "NeznÃ¡mÃ½ titul"
                
                # Extrakce hlavnÃ­ho obsahu
                content_text = ""
                for paragraph in soup.find_all(['p', 'article', 'div']):
                    content_text += paragraph.get_text() + " "
                
                content = LearningContent(
                    id=f"web_{hash(url)}",
                    title=title,
                    description=content_text[:500] + "..." if len(content_text) > 500 else content_text,
                    content_type="article",
                    difficulty_level="intermediate",
                    topics=["web content"],
                    duration_minutes=None,
                    url=url,
                    metadata={"source": "web", "extracted_at": datetime.now().isoformat()}
                )
                contents.append(content)
                
            except Exception as e:
                logger.error(f"Chyba pÅ™i extrakci z {url}: {e}")
        
        return contents

class VectorStore:
    """SprÃ¡va vektorovÃ© databÃ¡ze pro podobnostnÃ­ vyhledÃ¡vÃ¡nÃ­"""
    
    def __init__(self, collection_name: str = "learning_content"):
        self.embeddings = OpenAIEmbeddings()
        self.collection_name = collection_name
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """Inicializace vektorovÃ© databÃ¡ze"""
        try:
            self.vectorstore = Chroma(
                collection_name=self.collection_name,
                embedding_function=self.embeddings,
                persist_directory="./chroma_db"
            )
        except Exception as e:
            logger.error(f"Chyba pÅ™i inicializaci vektorovÃ© databÃ¡ze: {e}")
    
    def add_content(self, contents: List[LearningContent]):
        """PÅ™idÃ¡nÃ­ obsahu do vektorovÃ© databÃ¡ze"""
        documents = []
        
        for content in contents:
            doc_text = f"{content.title}\n{content.description}\nTopics: {', '.join(content.topics)}"
            
            doc = Document(
                page_content=doc_text,
                metadata={
                    "id": content.id,
                    "title": content.title,
                    "content_type": content.content_type,
                    "difficulty_level": content.difficulty_level,
                    "topics": content.topics,
                    "url": content.url,
                    "duration_minutes": content.duration_minutes
                }
            )
            documents.append(doc)
        
        if documents and self.vectorstore:
            self.vectorstore.add_documents(documents)
            logger.info(f"PÅ™idÃ¡no {len(documents)} dokumentÅ¯ do vektorovÃ© databÃ¡ze")
    
    def search_similar_content(self, query: str, k: int = 5) -> List[Dict]:
        """VyhledÃ¡nÃ­ podobnÃ©ho obsahu"""
        if not self.vectorstore:
            return []
        
        try:
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            return [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": float(score)
                }
                for doc, score in results
            ]
        except Exception as e:
            logger.error(f"Chyba pÅ™i vyhledÃ¡vÃ¡nÃ­: {e}")
            return []

class RecommendationEngine:
    """DoporuÄovacÃ­ engine pro vzdÄ›lÃ¡vacÃ­ obsah"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.llm = ChatOpenAI(temperature=0.3, model="gpt-4")
        self._setup_qa_chain()
    
    def _setup_qa_chain(self):
        """NastavenÃ­ QA Å™etÄ›zce pro RAG"""
        prompt_template = """
        Jsi expert na vzdÄ›lÃ¡vÃ¡nÃ­ a osobnÃ­ rozvoj. Na zÃ¡kladÄ› poskytnutÃ©ho kontextu 
        doporuÄ nejlepÅ¡Ã­ vzdÄ›lÃ¡vacÃ­ materiÃ¡ly pro uÅ¾ivatele.
        
        Kontext: {context}
        
        OtÃ¡zka: {question}
        
        Poskytni personalizovanÃ© doporuÄenÃ­ vÄetnÄ›:
        1. NejvhodnÄ›jÅ¡Ã­ materiÃ¡ly pro danou ÃºroveÅˆ
        2. DoporuÄenÃ© poÅ™adÃ­ studia
        3. OdhadovanÃ½ Äas studia
        4. DÅ¯vody pro vÃ½bÄ›r konkrÃ©tnÃ­ch materiÃ¡lÅ¯
        
        OdpovÄ›Ä:
        """
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        if self.vector_store.vectorstore:
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.vector_store.vectorstore.as_retriever(search_kwargs={"k": 5}),
                chain_type_kwargs={"prompt": PROMPT}
            )
    
    def get_recommendations(self, user_profile: UserProfile, query: str) -> Dict:
        """ZÃ­skÃ¡nÃ­ personalizovanÃ½ch doporuÄenÃ­"""
        try:
            # RozÅ¡Ã­Å™enÃ­ dotazu o informace z profilu uÅ¾ivatele
            enhanced_query = f"""
            UÅ¾ivatelskÃ½ profil:
            - Styl uÄenÃ­: {user_profile.learning_style}
            - ÃšroveÅˆ dovednostÃ­: {user_profile.skill_level}
            - DokonÄenÃ½ obsah: {len(user_profile.completed_content)} kurzÅ¯
            - CÃ­le: {', '.join(user_profile.learning_goals)}
            
            Dotaz: {query}
            """
            
            # ZÃ­skÃ¡nÃ­ doporuÄenÃ­ pomocÃ­ RAG
            if hasattr(self, 'qa_chain'):
                response = self.qa_chain.run(enhanced_query)
            else:
                response = "SystÃ©m doporuÄenÃ­ nenÃ­ k dispozici."
            
            # VyhledÃ¡nÃ­ podobnÃ©ho obsahu
            similar_content = self.vector_store.search_similar_content(query, k=10)
            
            # FiltrovÃ¡nÃ­ na zÃ¡kladÄ› uÅ¾ivatelskÃ©ho profilu
            filtered_content = self._filter_content_by_profile(similar_content, user_profile)
            
            return {
                "recommendations": response,
                "suggested_content": filtered_content[:5],
                "learning_path": self._create_learning_path(filtered_content, user_profile)
            }
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i generovÃ¡nÃ­ doporuÄenÃ­: {e}")
            return {"error": "NepodaÅ™ilo se vygenerovat doporuÄenÃ­"}
    
    def _filter_content_by_profile(self, content: List[Dict], profile: UserProfile) -> List[Dict]:
        """FiltrovÃ¡nÃ­ obsahu na zÃ¡kladÄ› uÅ¾ivatelskÃ©ho profilu"""
        filtered = []
        
        for item in content:
            metadata = item.get("metadata", {})
            
            # FiltrovÃ¡nÃ­ podle obtÃ­Å¾nosti
            difficulty = metadata.get("difficulty_level", "intermediate")
            topics = metadata.get("topics", [])
            
            # Kontrola, zda uÅ¾ivatel jiÅ¾ obsah neabsolvoval
            if metadata.get("id") in profile.completed_content:
                continue
            
            # Kontrola relevance pro cÃ­le uÅ¾ivatele
            relevant = any(goal.lower() in topic.lower() 
                          for goal in profile.learning_goals 
                          for topic in topics)
            
            if relevant:
                filtered.append(item)
        
        return filtered
    
    def _create_learning_path(self, content: List[Dict], profile: UserProfile) -> List[Dict]:
        """VytvoÅ™enÃ­ doporuÄenÃ© vzdÄ›lÃ¡vacÃ­ cesty"""
        # SeÅ™azenÃ­ podle obtÃ­Å¾nosti a relevance
        sorted_content = sorted(content, key=lambda x: (
            {"beginner": 1, "intermediate": 2, "advanced": 3}.get(
                x.get("metadata", {}).get("difficulty_level", "intermediate"), 2
            ),
            -x.get("similarity_score", 0)
        ))
        
        learning_path = []
        total_duration = 0
        
        for i, item in enumerate(sorted_content[:6]):  # MaximÃ¡lnÄ› 6 poloÅ¾ek
            metadata = item.get("metadata", {})
            duration = metadata.get("duration_minutes", 30)
            
            path_item = {
                "step": i + 1,
                "title": metadata.get("title", "NeznÃ¡mÃ½ titul"),
                "content_type": metadata.get("content_type", "article"),
                "difficulty": metadata.get("difficulty_level", "intermediate"),
                "estimated_duration": duration,
                "cumulative_duration": total_duration + duration,
                "url": metadata.get("url"),
                "reason": f"DoporuÄeno pro {profile.learning_style} styl uÄenÃ­"
            }
            learning_path.append(path_item)
            total_duration += duration
        
        return learning_path

class ELearningApp:
    """HlavnÃ­ aplikace pro e-learning doporuÄovacÃ­ systÃ©m"""
    
    def __init__(self):
        self.content_extractor = ContentExtractor()
        self.vector_store = VectorStore()
        self.recommendation_engine = RecommendationEngine(self.vector_store)
        self._initialize_sample_data()
    
    def _initialize_sample_data(self):
        """Inicializace ukÃ¡zkovÃ½ch dat"""
        # VytvoÅ™enÃ­ ukÃ¡zkovÃ©ho obsahu
        sample_content = [
            LearningContent(
                id="course_1",
                title="ZÃ¡klady datovÃ© vÄ›dy",
                description="KomplexnÃ­ kurz datovÃ© vÄ›dy pokrÃ½vajÃ­cÃ­ Python, pandas, matplotlib a zÃ¡klady machine learningu",
                content_type="course",
                difficulty_level="beginner",
                topics=["datovÃ¡ vÄ›da", "python", "pandas", "vizualizace"],
                duration_minutes=480,
                url="https://example.com/data-science-basics",
                metadata={"instructor": "Dr. NovÃ¡k", "rating": 4.8}
            ),
            LearningContent(
                id="course_2",
                title="PokroÄilÃ© techniky machine learningu",
                description="HlubokÃ© ponoÅ™enÃ­ do algoritmÅ¯ ML, neural networks a deep learning",
                content_type="course",
                difficulty_level="advanced",
                topics=["machine learning", "neural networks", "deep learning"],
                duration_minutes=720,
                url="https://example.com/advanced-ml",
                metadata={"instructor": "Prof. Svoboda", "rating": 4.9}
            )
        ]
        
        # PÅ™idÃ¡nÃ­ obsahu z YouTube
        youtube_content = self.content_extractor.extract_youtube_content("python programming")
        sample_content.extend(youtube_content)
        
        # PÅ™idÃ¡nÃ­ do vektorovÃ© databÃ¡ze
        self.vector_store.add_content(sample_content)
    
    def run_streamlit_app(self):
        """SpuÅ¡tÄ›nÃ­ Streamlit aplikace"""
        st.set_page_config(page_title="E-learning DoporuÄovacÃ­ systÃ©m", layout="wide")
        
        st.title("ğŸ“ InteligentnÃ­ E-learning DoporuÄovacÃ­ systÃ©m")
        st.markdown("*PersonalizovanÃ© doporuÄenÃ­ vzdÄ›lÃ¡vacÃ­ho obsahu pomocÃ­ AI*")
        
        # Sidebar pro uÅ¾ivatelskÃ½ profil
        with st.sidebar:
            st.header("ğŸ‘¤ VÃ¡Å¡ profil")
            
            learning_style = st.selectbox(
                "Styl uÄenÃ­:",
                ["visual", "auditory", "kinesthetic", "reading"],
                index=0
            )
            
            skill_areas = st.multiselect(
                "Oblasti zÃ¡jmu:",
                ["python", "machine learning", "data science", "web development", "ai"],
                default=["python", "data science"]
            )
            
            skill_level = st.selectbox(
                "ObecnÃ¡ ÃºroveÅˆ:",
                ["beginner", "intermediate", "advanced"],
                index=1
            )
            
            learning_goals = st.text_area(
                "VzdÄ›lÃ¡vacÃ­ cÃ­le:",
                "Chci se nauÄit datovou vÄ›du a machine learning"
            ).split(",")
        
        # HlavnÃ­ obsah
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("ğŸ” HledÃ¡nÃ­ obsahu")
            query = st.text_input(
                "Co se chcete nauÄit?",
                placeholder="NapÅ™. 'python pro zaÄÃ¡teÄnÃ­ky' nebo 'machine learning algoritmy'"
            )
            
            if st.button("ZÃ­skat doporuÄenÃ­") and query:
                # VytvoÅ™enÃ­ uÅ¾ivatelskÃ©ho profilu
                user_profile = UserProfile(
                    user_id="demo_user",
                    learning_style=learning_style,
                    skill_level={area: skill_level for area in skill_areas},
                    completed_content=[],
                    preferences={"language": "czech"},
                    learning_goals=learning_goals
                )
                
                # ZÃ­skÃ¡nÃ­ doporuÄenÃ­
                with st.spinner("Generuji personalizovanÃ¡ doporuÄenÃ­..."):
                    recommendations = self.recommendation_engine.get_recommendations(
                        user_profile, query
                    )
                
                # ZobrazenÃ­ vÃ½sledkÅ¯
                if "error" not in recommendations:
                    st.success("âœ… DoporuÄenÃ­ vygenerovÃ¡na!")
                    
                    # AI doporuÄenÃ­
                    st.subheader("ğŸ¤– AI DoporuÄenÃ­")
                    st.write(recommendations.get("recommendations", ""))
                    
                    # NavrÅ¾enÃ½ obsah
                    st.subheader("ğŸ“š NavrÅ¾enÃ½ obsah")
                    for i, content in enumerate(recommendations.get("suggested_content", [])):
                        with st.expander(f"ğŸ“– {content['metadata'].get('title', f'Obsah {i+1}')}"):
                            st.write(f"**Typ:** {content['metadata'].get('content_type', 'NeznÃ¡mÃ½')}")
                            st.write(f"**ObtÃ­Å¾nost:** {content['metadata'].get('difficulty_level', 'NeurÄeno')}")
                            if content['metadata'].get('url'):
                                st.write(f"**Odkaz:** {content['metadata']['url']}")
                            st.write(f"**Podobnost:** {content.get('similarity_score', 0):.2f}")
                    
                    # VzdÄ›lÃ¡vacÃ­ cesta
                    st.subheader("ğŸ›¤ï¸ DoporuÄenÃ¡ vzdÄ›lÃ¡vacÃ­ cesta")
                    learning_path = recommendations.get("learning_path", [])
                    
                    if learning_path:
                        total_duration = learning_path[-1].get("cumulative_duration", 0)
                        st.info(f"ğŸ“Š CelkovÃ½ odhadovanÃ½ Äas: {total_duration} minut ({total_duration//60}h {total_duration%60}m)")
                        
                        for step in learning_path:
                            st.write(f"**{step['step']}. {step['title']}**")
                            st.write(f"   ğŸ•’ {step['estimated_duration']} min | ğŸ“ˆ {step['difficulty']} | ğŸ¯ {step['reason']}")
                else:
                    st.error("âŒ Chyba pÅ™i generovÃ¡nÃ­ doporuÄenÃ­")
        
        with col2:
            st.header("ğŸ“Š Statistiky")
            
            # SimulovanÃ© statistiky
            st.metric("DostupnÃ© kurzy", "1,247")
            st.metric("Video materiÃ¡ly", "3,891")
            st.metric("AktivnÃ­ uÅ¾ivatelÃ©", "15,634")
            
            st.header("ğŸ”¥ PopulÃ¡rnÃ­ tÃ©mata")
            popular_topics = [
                "Python programovÃ¡nÃ­",
                "Machine Learning",
                "DatovÃ¡ analÃ½za",
                "Web development",
                "UmÄ›lÃ¡ inteligence"
            ]
            
            for topic in popular_topics:
                st.write(f"â€¢ {topic}")

def main():
    """HlavnÃ­ funkce aplikace"""
    # Kontrola API klÃ­ÄÅ¯
    if not os.getenv('OPENAI_API_KEY'):
        st.error("âŒ OPENAI_API_KEY nenÃ­ nastaven! PÅ™idejte jej do .env souboru.")
        return
    
    # SpuÅ¡tÄ›nÃ­ aplikace
    app = ELearningApp()
    app.run_streamlit_app()

if __name__ == "__main__":
    main()
````

### Konfigurace prostÅ™edÃ­

````python
OPENAI_API_KEY=your_openai_api_key_here
YOUTUBE_API_KEY=your_youtube_api_key_here
````

### SpuÅ¡tÄ›nÃ­ aplikace

````bash
streamlit run main.py
````

## 5. ShrnutÃ­ projektu

### KlÃ­ÄovÃ© hodnoty
- **Personalizace**: DoporuÄenÃ­ pÅ™izpÅ¯sobenÃ¡ individuÃ¡lnÃ­m potÅ™ebÃ¡m
- **Å kÃ¡lovatelnost**: Podpora tisÃ­cÅ¯ hodin vzdÄ›lÃ¡vacÃ­ho obsahu
- **MultimodÃ¡lnÃ­ obsah**: Integrace videÃ­, textÅ¯ a interaktivnÃ­ch materiÃ¡lÅ¯
- **AdaptivnÃ­ uÄenÃ­**: SystÃ©m se uÄÃ­ z chovÃ¡nÃ­ uÅ¾ivatelÅ¯

### TechnologickÃ© vÃ½hody
- **RAG architektura** pro pÅ™esnÃ© a relevantnÃ­ odpovÄ›di
- **VektorovÃ¡ databÃ¡ze** pro efektivnÃ­ podobnostnÃ­ vyhledÃ¡vÃ¡nÃ­
- **LLM integrace** pro inteligentnÃ­ analÃ½zu a doporuÄenÃ­
- **Real-time zpracovÃ¡nÃ­** dotazÅ¯ a aktualizacÃ­

### PotenciÃ¡l rozÅ¡Ã­Å™enÃ­
- Integrace s LMS systÃ©my
- Podpora vÃ­ce jazykÅ¯
- PokroÄilÃ© analytiky uÄenÃ­
- Gamifikace vzdÄ›lÃ¡vacÃ­ho procesu
- Mobile aplikace

Tento projekt pÅ™edstavuje modernÃ­ pÅ™Ã­stup k personalizaci vzdÄ›lÃ¡vÃ¡nÃ­ pomocÃ­ AI technologiÃ­, kterÃ½ mÅ¯Å¾e vÃ½raznÄ› zlepÅ¡it efektivitu a kvalitu online vzdÄ›lÃ¡vÃ¡nÃ­.