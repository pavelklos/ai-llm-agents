<small>Claude Sonnet 4 **(AI Legal Document Analyzer - Multi-Agent SystÃ©m pro AnalÃ½zu PrÃ¡vnÃ­ch DokumentÅ¯)**</small>
# AI Legal Document Analyzer

## KlÃ­ÄovÃ© Koncepty

### LLM Agents (Agenti zaloÅ¾enÃ­ na velkÃ½ch jazykovÃ½ch modelech)
SpecializovanÃ© AI agenty vyuÅ¾Ã­vajÃ­cÃ­ velkÃ© jazykovÃ© modely (LLM) pro specifickÃ© Ãºkoly. KaÅ¾dÃ½ agent mÃ¡ definovanou roli, schopnosti a znalosti zamÄ›Å™enÃ© na konkrÃ©tnÃ­ oblast prÃ¡vnÃ­ analÃ½zy.

### Document QA (OtÃ¡zky a odpovÄ›di nad dokumenty)
SystÃ©m umoÅ¾ÅˆujÃ­cÃ­ poklÃ¡dat pÅ™irozenÃ© otÃ¡zky nad obsahem dokumentÅ¯ a zÃ­skÃ¡vat pÅ™esnÃ© odpovÄ›di zaloÅ¾enÃ© na kontextu dokumentu.

### Retrieval (VyhledÃ¡vÃ¡nÃ­ informacÃ­)
Proces efektivnÃ­ho vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch ÄÃ¡stÃ­ dokumentÅ¯ na zÃ¡kladÄ› dotazu pomocÃ­ sÃ©mantickÃ©ho vyhledÃ¡vÃ¡nÃ­ a vektorovÃ½ch databÃ¡zÃ­.

### Legal NLP (ZpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka v prÃ¡vu)
SpecializovanÃ© techniky NLP zamÄ›Å™enÃ© na prÃ¡vnÃ­ terminologii, strukturu prÃ¡vnÃ­ch dokumentÅ¯ a extrakci prÃ¡vnÄ› relevantnÃ­ch informacÃ­.

### Memory Graphs (PamÄ›Å¥ovÃ© grafy)
GrafovÃ© struktury pro uklÃ¡dÃ¡nÃ­ a propojovÃ¡nÃ­ informacÃ­ z dokumentÅ¯, umoÅ¾ÅˆujÃ­cÃ­ zachycenÃ­ vztahÅ¯ mezi rÅ¯znÃ½mi prÃ¡vnÃ­mi koncepty a klauzulemi.

### Semantic Search (SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­)
VyhledÃ¡vÃ¡nÃ­ zaloÅ¾enÃ© na vÃ½znamu a kontextu, nikoli pouze na pÅ™esnÃ©m shodÄ› klÃ­ÄovÃ½ch slov.

### Claude Sonnet
PokroÄilÃ½ jazykovÃ½ model od Anthropic specializovanÃ½ na komplexnÃ­ analÃ½zy a reasoning Ãºkoly.

### LangGraph
Framework pro tvorbu komplexnÃ­ch workflow s vÃ­ce agenty, umoÅ¾ÅˆujÃ­cÃ­ orchestraci jednotlivÃ½ch krokÅ¯ analÃ½zy.

## KomplexnÃ­ VysvÄ›tlenÃ­ Projektu

### CÃ­le Projektu
AI Legal Document Analyzer je sofistikovanÃ½ multi-agent systÃ©m navrÅ¾enÃ½ pro automatizaci analÃ½zy prÃ¡vnÃ­ch dokumentÅ¯. HlavnÃ­mi cÃ­li jsou:

1. **AutomatickÃ¡ extrakce klauzulÃ­** - Identifikace a kategorizace rÅ¯znÃ½ch typÅ¯ prÃ¡vnÃ­ch klauzulÃ­
2. **Detekce rizik** - RozpoznÃ¡nÃ­ potenciÃ¡lnÄ› problematickÃ½ch ustanovenÃ­ a jejich dopadu
3. **DoporuÄenÃ­ akcÃ­** - NavrhovÃ¡nÃ­ konkrÃ©tnÃ­ch krokÅ¯ na zÃ¡kladÄ› analÃ½zy
4. **SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­** - EfektivnÃ­ vyhledÃ¡vÃ¡nÃ­ v rozsÃ¡hlÃ½ch prÃ¡vnÃ­ch databÃ¡zÃ­ch

### VÃ½zvy a ProblÃ©my
- **Komplexnost prÃ¡vnÃ­ho jazyka** - PrÃ¡vnÃ­ dokumenty obsahujÃ­ specifickou terminologii a sloÅ¾itÃ© struktury
- **KontextovÃ¡ zÃ¡vislost** - VÃ½znam klauzulÃ­ se mÅ¯Å¾e liÅ¡it v zÃ¡vislosti na typu dokumentu a jurisdikci
- **PÅ™esnost vs. Ãºplnost** - BalancovÃ¡nÃ­ mezi detailnÃ­ analÃ½zou a rychlostÃ­ zpracovÃ¡nÃ­
- **Aktualizace prÃ¡vnÃ­ch norem** - UdrÅ¾ovÃ¡nÃ­ systÃ©mu v souladu s mÄ›nÃ­cÃ­mi se prÃ¡vnÃ­mi pÅ™edpisy

### PotenciÃ¡lnÃ­ Dopad
SystÃ©m mÅ¯Å¾e vÃ½znamnÄ› zvÃ½Å¡it efektivitu prÃ¡vnÃ­kÅ¯, snÃ­Å¾it riziko pÅ™ehlÃ©dnutÃ­ dÅ¯leÅ¾itÃ½ch ustanovenÃ­ a umoÅ¾nit rychlejÅ¡Ã­ due diligence procesy.

## KomplexnÃ­ Implementace v Pythonu

````python
langchain==0.1.0
langgraph==0.0.20
chromadb==0.4.22
sentence-transformers==2.2.2
anthropic==0.8.1
streamlit==1.29.0
pypdf2==3.0.1
python-docx==0.8.11
networkx==3.2.1
plotly==5.17.0
pydantic==2.5.2
````

````python
import os
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
import json
import networkx as nx
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain_anthropic import ChatAnthropic
from langgraph.graph import Graph, StateGraph
from langgraph.prebuilt import ToolExecutor
from pydantic import BaseModel, Field
import PyPDF2
from docx import Document as DocxDocument

class RiskLevel(Enum):
    LOW = "nÃ­zkÃ©"
    MEDIUM = "stÅ™ednÃ­"
    HIGH = "vysokÃ©"
    CRITICAL = "kritickÃ©"

class ClauseType(Enum):
    TERMINATION = "ukonÄovacÃ­"
    LIABILITY = "odpovÄ›dnostnÃ­"
    PAYMENT = "platebnÃ­"
    CONFIDENTIALITY = "dÅ¯vÄ›rnostnÃ­"
    INTELLECTUAL_PROPERTY = "duÅ¡evnÃ­ vlastnictvÃ­"
    DISPUTE_RESOLUTION = "Å™eÅ¡enÃ­ sporÅ¯"
    FORCE_MAJEURE = "vyÅ¡Å¡Ã­ moc"
    OTHER = "ostatnÃ­"

@dataclass
class LegalClause:
    content: str
    clause_type: ClauseType
    risk_level: RiskLevel
    confidence: float
    page_number: int
    recommendations: List[str]

@dataclass
class LegalRisk:
    description: str
    risk_level: RiskLevel
    affected_clauses: List[str]
    mitigation_strategies: List[str]
    legal_references: List[str]

class LegalDocumentState(BaseModel):
    document_content: str = ""
    chunks: List[str] = []
    extracted_clauses: List[Dict] = []
    identified_risks: List[Dict] = []
    recommendations: List[str] = []
    analysis_complete: bool = False
    current_step: str = "initialization"

class DocumentProcessor:
    """Agent pro zpracovÃ¡nÃ­ a parsovÃ¡nÃ­ dokumentÅ¯"""
    
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def process_pdf(self, file_path: str) -> str:
        """Extrakce textu z PDF dokumentu"""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except Exception as e:
            raise Exception(f"Chyba pÅ™i zpracovÃ¡nÃ­ PDF: {str(e)}")
    
    def process_docx(self, file_path: str) -> str:
        """Extrakce textu z DOCX dokumentu"""
        try:
            doc = DocxDocument(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            raise Exception(f"Chyba pÅ™i zpracovÃ¡nÃ­ DOCX: {str(e)}")
    
    def chunk_document(self, text: str) -> List[str]:
        """RozdÄ›lenÃ­ dokumentu na menÅ¡Ã­ ÄÃ¡sti"""
        return self.text_splitter.split_text(text)

class ClauseExtractor:
    """Agent pro extrakci prÃ¡vnÃ­ch klauzulÃ­"""
    
    def __init__(self, llm):
        self.llm = llm
        self.clause_patterns = {
            ClauseType.TERMINATION: [
                "ukonÄenÃ­", "vÃ½povÄ›Ä", "zruÅ¡enÃ­", "odstoupenÃ­", "vyprÅ¡enÃ­"
            ],
            ClauseType.LIABILITY: [
                "odpovÄ›dnost", "nÃ¡hrada Å¡kody", "omezenÃ­ odpovÄ›dnosti", "Å¡koda"
            ],
            ClauseType.PAYMENT: [
                "platba", "Ãºhrada", "fakturace", "cena", "poplatek"
            ],
            ClauseType.CONFIDENTIALITY: [
                "dÅ¯vÄ›rnost", "mlÄenlivost", "obchodnÃ­ tajemstvÃ­", "nesdÄ›lovÃ¡nÃ­"
            ]
        }
    
    async def extract_clauses(self, chunks: List[str]) -> List[LegalClause]:
        """Extrakce klauzulÃ­ z textovÃ½ch ÄÃ¡stÃ­"""
        extracted_clauses = []
        
        for i, chunk in enumerate(chunks):
            prompt = f"""
            Analyzuj nÃ¡sledujÃ­cÃ­ ÄÃ¡st prÃ¡vnÃ­ho dokumentu a identifikuj vÅ¡echny prÃ¡vnÃ­ klauzule.
            Pro kaÅ¾dou klauzuli urÄi:
            1. Typ klauzule
            2. ÃšroveÅˆ rizika (nÃ­zkÃ©/stÅ™ednÃ­/vysokÃ©/kritickÃ©)
            3. MÃ­ru spolehlivosti (0-1)
            4. DoporuÄenÃ­ pro tuto klauzuli
            
            Text: {chunk}
            
            OdpovÄ›z ve formÃ¡tu JSON:
            {{
                "clauses": [
                    {{
                        "content": "text klauzule",
                        "type": "typ_klauzule",
                        "risk_level": "ÃºroveÅˆ_rizika",
                        "confidence": 0.95,
                        "recommendations": ["doporuÄenÃ­1", "doporuÄenÃ­2"]
                    }}
                ]
            }}
            """
            
            try:
                response = await self.llm.ainvoke(prompt)
                result = json.loads(response.content)
                
                for clause_data in result.get("clauses", []):
                    clause = LegalClause(
                        content=clause_data["content"],
                        clause_type=ClauseType(clause_data["type"]),
                        risk_level=RiskLevel(clause_data["risk_level"]),
                        confidence=clause_data["confidence"],
                        page_number=i + 1,
                        recommendations=clause_data["recommendations"]
                    )
                    extracted_clauses.append(clause)
                    
            except Exception as e:
                st.warning(f"Chyba pÅ™i extrakci klauzulÃ­ z ÄÃ¡sti {i+1}: {str(e)}")
                continue
        
        return extracted_clauses

class RiskAnalyzer:
    """Agent pro analÃ½zu rizik"""
    
    def __init__(self, llm):
        self.llm = llm
    
    async def analyze_risks(self, clauses: List[LegalClause]) -> List[LegalRisk]:
        """AnalÃ½za rizik na zÃ¡kladÄ› extrakovanÃ½ch klauzulÃ­"""
        risks = []
        
        # SeskupenÃ­ klauzulÃ­ podle typu pro lepÅ¡Ã­ analÃ½zu
        clauses_by_type = {}
        for clause in clauses:
            if clause.clause_type not in clauses_by_type:
                clauses_by_type[clause.clause_type] = []
            clauses_by_type[clause.clause_type].append(clause)
        
        for clause_type, type_clauses in clauses_by_type.items():
            prompt = f"""
            Analyzuj nÃ¡sledujÃ­cÃ­ klauzule typu {clause_type.value} a identifikuj potenciÃ¡lnÃ­ rizika:
            
            Klauzule:
            {[clause.content for clause in type_clauses]}
            
            Pro kaÅ¾dÃ© identifikovanÃ© riziko poskytni:
            1. Popis rizika
            2. ÃšroveÅˆ rizika
            3. Strategie pro zmÃ­rnÄ›nÃ­ rizika
            4. RelevantnÃ­ prÃ¡vnÃ­ odkazy
            
            OdpovÄ›z ve formÃ¡tu JSON.
            """
            
            try:
                response = await self.llm.ainvoke(prompt)
                # ZpracovÃ¡nÃ­ odpovÄ›di a vytvoÅ™enÃ­ LegalRisk objektÅ¯
                # Pro jednoduchost zde pouÅ¾ijeme zjednoduÅ¡enou logiku
                
                risk = LegalRisk(
                    description=f"Riziko spojenÃ© s {clause_type.value} klauzulemi",
                    risk_level=max([clause.risk_level for clause in type_clauses]),
                    affected_clauses=[clause.content[:100] for clause in type_clauses],
                    mitigation_strategies=["PrÃ¡vnÃ­ revize", "DodateÄnÃ¡ pojistka"],
                    legal_references=["ZÃ¡kon Ä. 89/2012 Sb."]
                )
                risks.append(risk)
                
            except Exception as e:
                st.warning(f"Chyba pÅ™i analÃ½ze rizik pro {clause_type.value}: {str(e)}")
                continue
        
        return risks

class RecommendationEngine:
    """Agent pro generovÃ¡nÃ­ doporuÄenÃ­"""
    
    def __init__(self, llm):
        self.llm = llm
    
    async def generate_recommendations(self, clauses: List[LegalClause], 
                                     risks: List[LegalRisk]) -> List[str]:
        """GenerovÃ¡nÃ­ doporuÄenÃ­ na zÃ¡kladÄ› analÃ½zy"""
        
        prompt = f"""
        Na zÃ¡kladÄ› analÃ½zy prÃ¡vnÃ­ho dokumentu vytvoÅ™ komplexnÃ­ doporuÄenÃ­:
        
        PoÄet identifikovanÃ½ch klauzulÃ­: {len(clauses)}
        PoÄet identifikovanÃ½ch rizik: {len(risks)}
        
        VysokÃ¡ rizika: {len([r for r in risks if r.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]])}
        
        Poskytni konkrÃ©tnÃ­, proveditelnÃ¡ doporuÄenÃ­ pro:
        1. PrÃ¡vnÃ­ revizi
        2. RizikovÃ© management
        3. SmluvnÃ­ Ãºpravy
        4. DalÅ¡Ã­ kroky
        
        OdpovÄ›z jako seznam doporuÄenÃ­ v ÄeÅ¡tinÄ›.
        """
        
        try:
            response = await self.llm.ainvoke(prompt)
            recommendations = response.content.split('\n')
            return [rec.strip() for rec in recommendations if rec.strip()]
        except Exception as e:
            return [f"Chyba pÅ™i generovÃ¡nÃ­ doporuÄenÃ­: {str(e)}"]

class MemoryGraph:
    """Graf pro uklÃ¡dÃ¡nÃ­ a propojovÃ¡nÃ­ prÃ¡vnÃ­ch konceptÅ¯"""
    
    def __init__(self):
        self.graph = nx.DiGraph()
    
    def add_clause_relationships(self, clauses: List[LegalClause]):
        """PÅ™idÃ¡nÃ­ klauzulÃ­ a jejich vztahÅ¯ do grafu"""
        for clause in clauses:
            node_id = f"clause_{hash(clause.content[:50])}"
            self.graph.add_node(
                node_id,
                content=clause.content,
                type=clause.clause_type.value,
                risk_level=clause.risk_level.value,
                confidence=clause.confidence
            )
    
    def visualize_graph(self):
        """Vizualizace pamÄ›Å¥ovÃ©ho grafu"""
        if len(self.graph.nodes()) == 0:
            return None
        
        pos = nx.spring_layout(self.graph)
        
        edge_x = []
        edge_y = []
        for edge in self.graph.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
        
        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            mode='lines'
        )
        
        node_x = []
        node_y = []
        node_text = []
        node_color = []
        
        for node in self.graph.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            
            node_info = self.graph.nodes[node]
            node_text.append(f"Typ: {node_info['type']}<br>Riziko: {node_info['risk_level']}")
            
            # Barva podle ÃºrovnÄ› rizika
            risk_colors = {
                'nÃ­zkÃ©': 'green',
                'stÅ™ednÃ­': 'yellow',
                'vysokÃ©': 'orange',
                'kritickÃ©': 'red'
            }
            node_color.append(risk_colors.get(node_info['risk_level'], 'blue'))
        
        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers',
            hoverinfo='text',
            text=node_text,
            marker=dict(
                showscale=True,
                color=node_color,
                size=10,
                line=dict(width=2)
            )
        )
        
        fig = go.Figure(data=[edge_trace, node_trace],
                       layout=go.Layout(
                           title='Graf prÃ¡vnÃ­ch konceptÅ¯',
                           titlefont_size=16,
                           showlegend=False,
                           hovermode='closest',
                           margin=dict(b=20,l=5,r=5,t=40),
                           annotations=[ dict(
                               text="Vizualizace vztahÅ¯ mezi prÃ¡vnÃ­mi klauzulemi",
                               showarrow=False,
                               xref="paper", yref="paper",
                               x=0.005, y=-0.002,
                               xanchor="left", yanchor="bottom",
                               font=dict(color="#888", size=12)
                           )],
                           xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                           yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                       ))
        
        return fig

class LegalDocumentAnalyzer:
    """HlavnÃ­ orchestrÃ¡tor multi-agent systÃ©mu"""
    
    def __init__(self):
        # Inicializace LLM
        self.llm = ChatAnthropic(
            model="claude-3-sonnet-20240229",
            api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.1
        )
        
        # Inicializace agentÅ¯
        self.document_processor = DocumentProcessor()
        self.clause_extractor = ClauseExtractor(self.llm)
        self.risk_analyzer = RiskAnalyzer(self.llm)
        self.recommendation_engine = RecommendationEngine(self.llm)
        self.memory_graph = MemoryGraph()
        
        # Inicializace vektorovÃ© databÃ¡ze
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        self.vectorstore = None
        
        # VytvoÅ™enÃ­ workflow
        self.workflow = self._create_workflow()
    
    def _create_workflow(self) -> StateGraph:
        """VytvoÅ™enÃ­ LangGraph workflow"""
        
        def process_document_step(state: LegalDocumentState) -> LegalDocumentState:
            """Krok zpracovÃ¡nÃ­ dokumentu"""
            chunks = self.document_processor.chunk_document(state.document_content)
            state.chunks = chunks
            state.current_step = "document_processed"
            return state
        
        async def extract_clauses_step(state: LegalDocumentState) -> LegalDocumentState:
            """Krok extrakce klauzulÃ­"""
            clauses = await self.clause_extractor.extract_clauses(state.chunks)
            state.extracted_clauses = [
                {
                    "content": clause.content,
                    "type": clause.clause_type.value,
                    "risk_level": clause.risk_level.value,
                    "confidence": clause.confidence,
                    "recommendations": clause.recommendations
                }
                for clause in clauses
            ]
            state.current_step = "clauses_extracted"
            return state
        
        async def analyze_risks_step(state: LegalDocumentState) -> LegalDocumentState:
            """Krok analÃ½zy rizik"""
            clauses = [
                LegalClause(
                    content=clause["content"],
                    clause_type=ClauseType(clause["type"]),
                    risk_level=RiskLevel(clause["risk_level"]),
                    confidence=clause["confidence"],
                    page_number=1,
                    recommendations=clause["recommendations"]
                )
                for clause in state.extracted_clauses
            ]
            
            risks = await self.risk_analyzer.analyze_risks(clauses)
            state.identified_risks = [
                {
                    "description": risk.description,
                    "risk_level": risk.risk_level.value,
                    "mitigation_strategies": risk.mitigation_strategies
                }
                for risk in risks
            ]
            state.current_step = "risks_analyzed"
            return state
        
        async def generate_recommendations_step(state: LegalDocumentState) -> LegalDocumentState:
            """Krok generovÃ¡nÃ­ doporuÄenÃ­"""
            clauses = [
                LegalClause(
                    content=clause["content"],
                    clause_type=ClauseType(clause["type"]),
                    risk_level=RiskLevel(clause["risk_level"]),
                    confidence=clause["confidence"],
                    page_number=1,
                    recommendations=clause["recommendations"]
                )
                for clause in state.extracted_clauses
            ]
            
            risks = [
                LegalRisk(
                    description=risk["description"],
                    risk_level=RiskLevel(risk["risk_level"]),
                    affected_clauses=[],
                    mitigation_strategies=risk["mitigation_strategies"],
                    legal_references=[]
                )
                for risk in state.identified_risks
            ]
            
            recommendations = await self.recommendation_engine.generate_recommendations(clauses, risks)
            state.recommendations = recommendations
            state.analysis_complete = True
            state.current_step = "analysis_complete"
            return state
        
        # VytvoÅ™enÃ­ grafu
        workflow = StateGraph(LegalDocumentState)
        
        # PÅ™idÃ¡nÃ­ krokÅ¯
        workflow.add_node("process_document", process_document_step)
        workflow.add_node("extract_clauses", extract_clauses_step)
        workflow.add_node("analyze_risks", analyze_risks_step)
        workflow.add_node("generate_recommendations", generate_recommendations_step)
        
        # DefinovÃ¡nÃ­ pÅ™echodÅ¯
        workflow.set_entry_point("process_document")
        workflow.add_edge("process_document", "extract_clauses")
        workflow.add_edge("extract_clauses", "analyze_risks")
        workflow.add_edge("analyze_risks", "generate_recommendations")
        
        return workflow.compile()
    
    async def analyze_document(self, file_path: str) -> Dict[str, Any]:
        """KompletnÃ­ analÃ½za prÃ¡vnÃ­ho dokumentu"""
        try:
            # NaÄtenÃ­ dokumentu
            if file_path.endswith('.pdf'):
                content = self.document_processor.process_pdf(file_path)
            elif file_path.endswith('.docx'):
                content = self.document_processor.process_docx(file_path)
            else:
                raise ValueError("NepodporovanÃ½ formÃ¡t souboru")
            
            # Inicializace stavu
            initial_state = LegalDocumentState(document_content=content)
            
            # SpuÅ¡tÄ›nÃ­ workflow
            result = await self.workflow.ainvoke(initial_state)
            
            # VytvoÅ™enÃ­ vektorovÃ© databÃ¡ze pro sÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­
            documents = [Document(page_content=chunk) for chunk in result.chunks]
            self.vectorstore = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )
            
            # PÅ™idÃ¡nÃ­ do pamÄ›Å¥ovÃ©ho grafu
            clauses = [
                LegalClause(
                    content=clause["content"],
                    clause_type=ClauseType(clause["type"]),
                    risk_level=RiskLevel(clause["risk_level"]),
                    confidence=clause["confidence"],
                    page_number=1,
                    recommendations=clause["recommendations"]
                )
                for clause in result.extracted_clauses
            ]
            self.memory_graph.add_clause_relationships(clauses)
            
            return {
                "status": "success",
                "clauses": result.extracted_clauses,
                "risks": result.identified_risks,
                "recommendations": result.recommendations,
                "total_chunks": len(result.chunks)
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": str(e)
            }
    
    def semantic_search(self, query: str, k: int = 5) -> List[Dict]:
        """SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­ v dokumentu"""
        if not self.vectorstore:
            return []
        
        try:
            results = self.vectorstore.similarity_search(query, k=k)
            return [
                {
                    "content": doc.page_content,
                    "relevance": "high"  # V reÃ¡lnÃ© aplikaci by se poÄÃ­talo skÃ³re
                }
                for doc in results
            ]
        except Exception as e:
            st.error(f"Chyba pÅ™i vyhledÃ¡vÃ¡nÃ­: {str(e)}")
            return []

# Streamlit aplikace
def create_sample_legal_document():
    """VytvoÅ™enÃ­ ukÃ¡zkovÃ©ho prÃ¡vnÃ­ho dokumentu"""
    sample_content = """
    SMLOUVA O POSKYTOVÃNÃ SLUÅ½EB
    
    ÄŒlÃ¡nek 1 - PÅ™edmÄ›t smlouvy
    Poskytovatel se zavazuje poskytovat klientovi konzultaÄnÃ­ sluÅ¾by v oblasti IT.
    
    ÄŒlÃ¡nek 2 - PlatebnÃ­ podmÃ­nky
    Klient se zavazuje uhradit odmÄ›nu ve vÃ½Å¡i 50 000 KÄ do 30 dnÅ¯ od vystavenÃ­ faktury.
    PÅ™i prodlenÃ­ s platbou se ÃºÄtuje Ãºrok z prodlenÃ­ ve vÃ½Å¡i 0,05% dennÄ›.
    
    ÄŒlÃ¡nek 3 - OdpovÄ›dnost za Å¡kodu
    Poskytovatel neodpovÃ­dÃ¡ za Å¡kody zpÅ¯sobenÃ© nesprÃ¡vnÃ½m pouÅ¾itÃ­m poskytnutÃ½ch sluÅ¾eb.
    OdpovÄ›dnost poskytovatele je omezena na vÃ½Å¡i uhrazenÃ© odmÄ›ny.
    
    ÄŒlÃ¡nek 4 - DÅ¯vÄ›rnost
    SmluvnÃ­ strany se zavazujÃ­ zachovÃ¡vat mlÄenlivost o vÅ¡ech dÅ¯vÄ›rnÃ½ch informacÃ­ch.
    PoruÅ¡enÃ­ povinnosti mlÄenlivosti je sankcionovÃ¡no smluvnÃ­ pokutou 100 000 KÄ.
    
    ÄŒlÃ¡nek 5 - UkonÄenÃ­ smlouvy
    Smlouva mÅ¯Å¾e bÃ½t ukonÄena pÃ­semnou vÃ½povÄ›dÃ­ s dvoumÄ›sÃ­ÄnÃ­ vÃ½povÄ›dnÃ­ lhÅ¯tou.
    V pÅ™Ã­padÄ› podstatnÃ©ho poruÅ¡enÃ­ mÅ¯Å¾e bÃ½t smlouva ukonÄena okamÅ¾itÄ›.
    
    ÄŒlÃ¡nek 6 - Å˜eÅ¡enÃ­ sporÅ¯
    PÅ™Ã­padnÃ© spory budou Å™eÅ¡eny RozhodÄÃ­m soudem pÅ™i HospodÃ¡Å™skÃ© komoÅ™e ÄŒR.
    """
    
    os.makedirs("sample_documents", exist_ok=True)
    with open("sample_documents/sample_contract.txt", "w", encoding="utf-8") as f:
        f.write(sample_content)
    
    return "sample_documents/sample_contract.txt"

def main():
    st.set_page_config(
        page_title="AI Legal Document Analyzer",
        page_icon="âš–ï¸",
        layout="wide"
    )
    
    st.title("âš–ï¸ AI Legal Document Analyzer")
    st.markdown("**Multi-Agent SystÃ©m pro AnalÃ½zu PrÃ¡vnÃ­ch DokumentÅ¯**")
    
    # Sidebar pro nastavenÃ­
    with st.sidebar:
        st.header("âš™ï¸ NastavenÃ­")
        
        if st.button("ğŸ”§ VytvoÅ™it ukÃ¡zkovÃ½ dokument"):
            sample_path = create_sample_legal_document()
            st.success(f"UkÃ¡zkovÃ½ dokument vytvoÅ™en: {sample_path}")
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ PodporovanÃ© formÃ¡ty")
        st.markdown("- PDF (.pdf)")
        st.markdown("- Word (.docx)")
        st.markdown("- Text (.txt)")
    
    # HlavnÃ­ rozhranÃ­
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“„ Upload dokumentu")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Vyberte prÃ¡vnÃ­ dokument",
            type=['pdf', 'docx', 'txt']
        )
        
        # MoÅ¾nost pouÅ¾Ã­t ukÃ¡zkovÃ½ dokument
        if st.button("ğŸ“‹ PouÅ¾Ã­t ukÃ¡zkovÃ½ dokument"):
            if os.path.exists("sample_documents/sample_contract.txt"):
                uploaded_file = "sample_documents/sample_contract.txt"
                st.success("UkÃ¡zkovÃ½ dokument naÄten")
            else:
                st.error("UkÃ¡zkovÃ½ dokument neexistuje. VytvoÅ™te jej nejprve.")
    
    with col2:
        st.header("ğŸ” SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­")
        search_query = st.text_input("Zadejte dotaz pro vyhledÃ¡vÃ¡nÃ­:")
        search_button = st.button("ğŸ” Vyhledat")
    
    # AnalÃ½za dokumentu
    if uploaded_file and st.button("ğŸš€ Spustit analÃ½zu"):
        with st.spinner("ProbÃ­hÃ¡ analÃ½za dokumentu..."):
            
            # Simulace inicializace (bez API klÃ­Äe)
            st.info("ğŸ’¡ Demo verze - pouÅ¾Ã­vajÃ­ se simulovanÃ¡ data")
            
            # VytvoÅ™enÃ­ ukÃ¡zkovÃ½ch vÃ½sledkÅ¯
            sample_results = {
                "status": "success",
                "clauses": [
                    {
                        "content": "Klient se zavazuje uhradit odmÄ›nu ve vÃ½Å¡i 50 000 KÄ do 30 dnÅ¯",
                        "type": "platebnÃ­",
                        "risk_level": "stÅ™ednÃ­",
                        "confidence": 0.92,
                        "recommendations": ["ZvÃ¡Å¾it kratÅ¡Ã­ splatnost", "Definovat sankce za prodlenÃ­"]
                    },
                    {
                        "content": "Poskytovatel neodpovÃ­dÃ¡ za Å¡kody zpÅ¯sobenÃ© nesprÃ¡vnÃ½m pouÅ¾itÃ­m",
                        "type": "odpovÄ›dnostnÃ­", 
                        "risk_level": "vysokÃ©",
                        "confidence": 0.88,
                        "recommendations": ["PÅ™eformulovat omezenÃ­ odpovÄ›dnosti", "Konzultace s prÃ¡vnÃ­kem"]
                    }
                ],
                "risks": [
                    {
                        "description": "Å irokÃ© omezenÃ­ odpovÄ›dnosti poskytovatele",
                        "risk_level": "vysokÃ©",
                        "mitigation_strategies": ["PrÃ¡vnÃ­ revize", "DodateÄnÃ¡ pojistka"]
                    }
                ],
                "recommendations": [
                    "DoporuÄujeme prÃ¡vnÃ­ revizi ÄlÃ¡nku o odpovÄ›dnosti",
                    "ZvaÅ¾te pÅ™idÃ¡nÃ­ klauzule o rozhodÄÃ­m Å™Ã­zenÃ­",
                    "Specifikujte podmÃ­nky force majeure"
                ],
                "total_chunks": 6
            }
            
            # ZobrazenÃ­ vÃ½sledkÅ¯
            st.success("âœ… AnalÃ½za dokonÄena!")
            
            # Metriky
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ“‹ Klauzule", len(sample_results["clauses"]))
            with col2:
                st.metric("âš ï¸ Rizika", len(sample_results["risks"]))
            with col3:
                st.metric("ğŸ’¡ DoporuÄenÃ­", len(sample_results["recommendations"]))
            with col4:
                st.metric("ğŸ“„ ÄŒÃ¡sti dokumentu", sample_results["total_chunks"])
            
            # DetailnÃ­ vÃ½sledky v zÃ¡loÅ¾kÃ¡ch
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ Klauzule", "âš ï¸ Rizika", "ğŸ’¡ DoporuÄenÃ­", "ğŸ“Š Vizualizace"])
            
            with tab1:
                st.header("IdentifikovanÃ© klauzule")
                for i, clause in enumerate(sample_results["clauses"]):
                    with st.expander(f"Klauzule {i+1}: {clause['type']} (Riziko: {clause['risk_level']})"):
                        st.write("**Obsah:**", clause["content"])
                        st.write("**Spolehlivost:**", f"{clause['confidence']:.0%}")
                        st.write("**DoporuÄenÃ­:**")
                        for rec in clause["recommendations"]:
                            st.write(f"- {rec}")
            
            with tab2:
                st.header("IdentifikovanÃ¡ rizika")
                for i, risk in enumerate(sample_results["risks"]):
                    risk_color = {
                        "nÃ­zkÃ©": "ğŸŸ¢",
                        "stÅ™ednÃ­": "ğŸŸ¡", 
                        "vysokÃ©": "ğŸŸ ",
                        "kritickÃ©": "ğŸ”´"
                    }.get(risk["risk_level"], "âšª")
                    
                    with st.expander(f"{risk_color} Riziko {i+1}: {risk['risk_level']}"):
                        st.write("**Popis:**", risk["description"])
                        st.write("**Strategie zmÃ­rnÄ›nÃ­:**")
                        for strategy in risk["mitigation_strategies"]:
                            st.write(f"- {strategy}")
            
            with tab3:
                st.header("DoporuÄenÃ­")
                for i, rec in enumerate(sample_results["recommendations"]):
                    st.write(f"{i+1}. {rec}")
            
            with tab4:
                st.header("AnalÃ½za rizik")
                
                # Graf distribuce rizik
                risk_data = [clause["risk_level"] for clause in sample_results["clauses"]]
                risk_counts = {level: risk_data.count(level) for level in set(risk_data)}
                
                fig_pie = px.pie(
                    values=list(risk_counts.values()),
                    names=list(risk_counts.keys()),
                    title="Distribuce ÃºrovnÃ­ rizika"
                )
                st.plotly_chart(fig_pie)
                
                # Graf typÅ¯ klauzulÃ­
                clause_types = [clause["type"] for clause in sample_results["clauses"]]
                type_counts = {ctype: clause_types.count(ctype) for ctype in set(clause_types)}
                
                fig_bar = px.bar(
                    x=list(type_counts.keys()),
                    y=list(type_counts.values()),
                    title="PoÄet klauzulÃ­ podle typu"
                )
                st.plotly_chart(fig_bar)
    
    # SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­
    if search_button and search_query:
        st.header("ğŸ” VÃ½sledky vyhledÃ¡vÃ¡nÃ­")
        
        # Simulace vÃ½sledkÅ¯ vyhledÃ¡vÃ¡nÃ­
        sample_search_results = [
            {
                "content": "Klient se zavazuje uhradit odmÄ›nu ve vÃ½Å¡i 50 000 KÄ do 30 dnÅ¯ od vystavenÃ­ faktury.",
                "relevance": "high"
            },
            {
                "content": "PÅ™i prodlenÃ­ s platbou se ÃºÄtuje Ãºrok z prodlenÃ­ ve vÃ½Å¡i 0,05% dennÄ›.",
                "relevance": "medium"
            }
        ]
        
        for i, result in enumerate(sample_search_results):
            relevance_color = "ğŸŸ¢" if result["relevance"] == "high" else "ğŸŸ¡"
            with st.expander(f"{relevance_color} VÃ½sledek {i+1}"):
                st.write(result["content"])

if __name__ == "__main__":
    # NastavenÃ­ promÄ›nnÃ½ch prostÅ™edÃ­ pro demo
    os.environ["ANTHROPIC_API_KEY"] = "demo-key"
    
    main()
````

## ShrnutÃ­ Projektu

AI Legal Document Analyzer pÅ™edstavuje pokroÄilÃ½ multi-agent systÃ©m, kterÃ½ revolutionizuje zpÅ¯sob analÃ½zy prÃ¡vnÃ­ch dokumentÅ¯. SystÃ©m kombinuje nÄ›kolik specializovanÃ½ch AI agentÅ¯ pro komplexnÃ­ zpracovÃ¡nÃ­ prÃ¡vnÃ­ch textÅ¯.

### KlÃ­ÄovÃ© Hodnoty
1. **Automatizace rutinnÃ­ch ÃºkolÅ¯** - ZnaÄnÃ© Ãºspory Äasu pÅ™i analÃ½ze dokumentÅ¯
2. **ZvÃ½Å¡enÃ¡ pÅ™esnost** - Minimalizace lidskÃ½ch chyb pÅ™i identifikaci rizik
3. **StrukturovanÃ© vÃ½stupy** - SystematickÃ¡ prezentace vÃ½sledkÅ¯ analÃ½zy
4. **SÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­** - InteligentnÃ­ vyhledÃ¡vÃ¡nÃ­ v prÃ¡vnÃ­ch dokumentech

### TechnologickÃ© Inovace
- **Multi-agent architektura** s vyuÅ¾itÃ­m LangGraph
- **SÃ©mantickÃ© embeddingy** pro pokroÄilÃ© vyhledÃ¡vÃ¡nÃ­
- **PamÄ›Å¥ovÃ© grafy** pro vizualizaci vztahÅ¯ mezi koncepty
- **Streamlit UI** pro intuitivnÃ­ uÅ¾ivatelskÃ© rozhranÃ­

### PotenciÃ¡l RozÅ¡Ã­Å™enÃ­
SystÃ©m lze rozÅ¡Ã­Å™it o dalÅ¡Ã­ funktionality jako automatickÃ© generovÃ¡nÃ­ smluvnÃ­ch dokumentÅ¯, integrace s prÃ¡vnÃ­mi databÃ¡zemi nebo real-time collaboration mezi prÃ¡vnÃ­ky. PÅ™edstavuje vÃ½znamnÃ½ krok smÄ›rem k inteligentnÃ­ automatizaci v prÃ¡vnickÃ© praxi.