<small>Claude Sonnet 4 **(MCP-Powered Dynamic Chatbot Framework - Advanced Conversational AI System)**</small>
# MCP-Powered Dynamic Chatbot Framework

## Key Concepts Explanation

### Model Context Protocol (MCP)
Advanced context management framework that maintains persistent conversational state, user profiles, interaction history, and dynamic context across multiple conversation sessions, enabling sophisticated memory retention and contextual understanding that evolves with each interaction while preserving conversation continuity and personalization.

### Conversational AI Architecture
Intelligent dialogue management system that orchestrates natural language understanding, intent recognition, response generation, and context-aware conversation flow through sophisticated neural language models, enabling human-like interactions that adapt to user preferences, communication styles, and conversational objectives.

### Context-Aware Dialog Management
Dynamic conversation state tracking system that maintains awareness of conversation history, user context, emotional state, topic transitions, and conversational goals, enabling coherent multi-turn dialogues that reference previous exchanges and adapt responses based on accumulated conversational context.

### Retrieval-Augmented Generation (RAG)
Hybrid AI architecture that combines parametric knowledge from language models with external knowledge retrieval from vector databases, enabling chatbots to access current information, domain-specific knowledge, and factual data while maintaining conversational fluency and contextual relevance.

### Fine-Tuning Integration
Model customization framework that adapts pre-trained language models to specific domains, communication styles, and organizational needs through targeted training on domain-specific datasets, enabling specialized conversational capabilities while maintaining general language understanding.

### LangChain Orchestration
Comprehensive framework for building complex conversational AI applications through modular components including memory management, prompt engineering, tool integration, and conversation chains, enabling sophisticated chatbot architectures with advanced reasoning and external system integration capabilities.

## Comprehensive Project Explanation

The MCP-Powered Dynamic Chatbot Framework revolutionizes conversational AI by providing a comprehensive platform for building intelligent, context-aware chatbots that maintain persistent memory, adapt to user preferences, and integrate seamlessly with external knowledge sources. This framework enables organizations to deploy sophisticated conversational agents that provide personalized, informative, and engaging user experiences across diverse applications and domains.

### Objectives
- **Persistent Context Management**: Implement advanced MCP systems that maintain comprehensive conversation history, user profiles, preferences, and contextual state across multiple sessions, enabling continuity and personalization in long-term user interactions
- **Dynamic Knowledge Integration**: Develop RAG-powered systems that seamlessly blend conversational AI with real-time knowledge retrieval, ensuring chatbots provide accurate, current, and relevant information while maintaining natural dialogue flow
- **Adaptive Conversation Flow**: Create intelligent dialog management systems that adapt conversation strategies based on user behavior, preferences, emotional state, and conversational objectives while maintaining engagement and satisfaction
- **Scalable Framework Architecture**: Build modular, extensible chatbot framework that supports multiple deployment scenarios, integration patterns, and customization requirements while maintaining performance and reliability at scale
- **Fine-Tuned Specialization**: Enable domain-specific chatbot customization through targeted model fine-tuning and knowledge base integration, allowing organizations to deploy specialized conversational agents for specific use cases and industries

### Challenges
- **Context Window Management**: Maintaining relevant conversational context while managing memory limitations and computational efficiency, especially for long-term conversations with extensive history and complex user relationships
- **Knowledge Consistency**: Ensuring coherent responses when combining parametric model knowledge with retrieved external information while preventing contradictions and maintaining factual accuracy across diverse information sources
- **Conversation Flow Optimization**: Balancing natural dialogue progression with goal-oriented conversation guidance while adapting to user communication styles and maintaining engagement throughout extended interactions
- **Scalability & Performance**: Supporting large numbers of concurrent conversations with personalized context management while maintaining response times and computational efficiency across diverse deployment environments
- **Privacy & Security**: Protecting sensitive user data in persistent memory systems while enabling personalization and maintaining compliance with data protection regulations and security requirements

### Potential Impact
This framework could transform customer service, education, healthcare, and business communication by providing intelligent conversational agents that understand context, learn from interactions, and provide personalized assistance, potentially improving user satisfaction and operational efficiency across industries.

## Comprehensive Project Example with Python Implementation

````python
import asyncio
import json
import logging
import os
import uuid
from typing import Dict, List, Optional, Any, Union, Tuple, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import pickle
import hashlib
from collections import deque
import threading
import time

# Core AI and ML libraries
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
import openai
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# LangChain components
from langchain.chat_models import ChatOpenAI, ChatAnthropic
from langchain.llms import OpenAI
from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.memory import ConversationBufferWindowMemory, ConversationSummaryBufferMemory
from langchain.memory.chat_memory import BaseChatMemory
from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain, ConversationChain, RetrievalQA
from langchain.agents import AgentExecutor, Tool, initialize_agent, AgentType
from langchain.callbacks import StreamingStdOutCallbackHandler, BaseCallbackHandler
from langchain.schema import Document

# Vector stores and embeddings
from langchain.vectorstores import Chroma, FAISS, Pinecone
from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter
from langchain.document_loaders import TextLoader, DirectoryLoader

# Database and storage
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy import Column, String, DateTime, Text, JSON, Integer, Boolean, Float
import redis
import aioredis

# Web framework and API
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
from pydantic import BaseModel

# Monitoring and utilities
import asyncio
import aiofiles
import httpx
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database Models
Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    
    id = Column(String, primary_key=True)
    username = Column(String, unique=True)
    email = Column(String, unique=True)
    profile_data = Column(JSON)
    preferences = Column(JSON)
    conversation_style = Column(String)
    topics_of_interest = Column(JSON)
    interaction_history_summary = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    last_active = Column(DateTime, default=datetime.utcnow)

class Conversation(Base):
    __tablename__ = "conversations"
    
    id = Column(String, primary_key=True)
    user_id = Column(String, nullable=False)
    title = Column(String)
    context_summary = Column(Text)
    conversation_type = Column(String)  # casual, support, educational, business
    status = Column(String)  # active, archived, completed
    start_time = Column(DateTime, default=datetime.utcnow)
    last_message_time = Column(DateTime, default=datetime.utcnow)
    message_count = Column(Integer, default=0)
    satisfaction_rating = Column(Float)
    metadata = Column(JSON)

class Message(Base):
    __tablename__ = "messages"
    
    id = Column(String, primary_key=True)
    conversation_id = Column(String, nullable=False)
    user_id = Column(String, nullable=False)
    message_type = Column(String)  # user, assistant, system
    content = Column(Text, nullable=False)
    intent = Column(String)
    sentiment = Column(String)
    confidence_score = Column(Float)
    context_used = Column(JSON)
    response_time = Column(Float)
    timestamp = Column(DateTime, default=datetime.utcnow)

class KnowledgeBase(Base):
    __tablename__ = "knowledge_base"
    
    id = Column(String, primary_key=True)
    title = Column(String, nullable=False)
    content = Column(Text, nullable=False)
    category = Column(String)
    tags = Column(JSON)
    source = Column(String)
    relevance_score = Column(Float)
    last_updated = Column(DateTime, default=datetime.utcnow)
    embedding_vector = Column(JSON)

class ConversationContext(Base):
    __tablename__ = "conversation_contexts"
    
    id = Column(String, primary_key=True)
    conversation_id = Column(String, nullable=False)
    context_type = Column(String)  # short_term, long_term, semantic, episodic
    context_data = Column(JSON)
    importance_score = Column(Float)
    created_at = Column(DateTime, default=datetime.utcnow)
    expires_at = Column(DateTime)

# Core Data Classes
@dataclass
class UserProfile:
    user_id: str
    username: str
    preferences: Dict[str, Any]
    conversation_style: str
    topics_of_interest: List[str]
    interaction_patterns: Dict[str, Any]
    context_retention_level: str = "medium"

@dataclass
class ConversationState:
    conversation_id: str
    user_id: str
    current_topic: Optional[str]
    intent_stack: List[str]
    context_window: List[Dict[str, Any]]
    emotional_state: str
    conversation_goals: List[str]
    turn_count: int = 0

@dataclass
class ResponseContext:
    retrieved_knowledge: List[Dict[str, Any]]
    conversation_history: List[Dict[str, Any]]
    user_context: Dict[str, Any]
    intent_analysis: Dict[str, Any]
    confidence_scores: Dict[str, float]

class ConversationStyle(Enum):
    CASUAL = "casual"
    PROFESSIONAL = "professional"
    EDUCATIONAL = "educational"
    SUPPORTIVE = "supportive"
    TECHNICAL = "technical"

class IntentType(Enum):
    QUESTION = "question"
    REQUEST = "request"
    CHITCHAT = "chitchat"
    COMPLAINT = "complaint"
    COMPLIMENT = "compliment"
    TASK = "task"

class MCPMemoryManager:
    """Advanced Model Context Protocol memory management system"""
    
    def __init__(self, session_factory, redis_client=None):
        self.session_factory = session_factory
        self.redis_client = redis_client
        
        # Memory components
        self.short_term_memory = {}  # Recent conversation context
        self.episodic_memory = {}    # Specific conversation episodes
        self.semantic_memory = {}    # Factual knowledge about users
        self.procedural_memory = {}  # Learned interaction patterns
        
        # Context management
        self.context_window_size = 20
        self.memory_decay_factor = 0.95
        self.importance_threshold = 0.7
    
    async def store_conversation_turn(self, conversation_id: str, user_message: str, 
                                    assistant_response: str, context: Dict[str, Any]):
        """Store a conversation turn with context"""
        try:
            turn_data = {
                "timestamp": datetime.utcnow().isoformat(),
                "user_message": user_message,
                "assistant_response": assistant_response,
                "context": context,
                "turn_id": str(uuid.uuid4())
            }
            
            # Store in short-term memory
            if conversation_id not in self.short_term_memory:
                self.short_term_memory[conversation_id] = deque(maxlen=self.context_window_size)
            
            self.short_term_memory[conversation_id].append(turn_data)
            
            # Store in Redis for fast access
            if self.redis_client:
                await self.redis_client.lpush(
                    f"conversation:{conversation_id}:turns",
                    json.dumps(turn_data)
                )
                await self.redis_client.ltrim(f"conversation:{conversation_id}:turns", 0, 49)
                
            # Store in database for persistence
            async with self.session_factory() as session:
                message = Message(
                    id=str(uuid.uuid4()),
                    conversation_id=conversation_id,
                    user_id=context.get("user_id", ""),
                    message_type="user",
                    content=user_message,
                    intent=context.get("intent", ""),
                    sentiment=context.get("sentiment", ""),
                    context_used=context
                )
                session.add(message)
                
                response_message = Message(
                    id=str(uuid.uuid4()),
                    conversation_id=conversation_id,
                    user_id=context.get("user_id", ""),
                    message_type="assistant",
                    content=assistant_response,
                    context_used=context
                )
                session.add(response_message)
                
                await session.commit()
                
        except Exception as e:
            logger.error(f"Failed to store conversation turn: {e}")
    
    async def retrieve_conversation_context(self, conversation_id: str, 
                                          context_length: int = 10) -> List[Dict[str, Any]]:
        """Retrieve relevant conversation context"""
        try:
            context = []
            
            # Get from short-term memory first
            if conversation_id in self.short_term_memory:
                recent_turns = list(self.short_term_memory[conversation_id])
                context.extend(recent_turns[-context_length:])
            
            # If not enough context, get from Redis
            if len(context) < context_length and self.redis_client:
                redis_turns = await self.redis_client.lrange(
                    f"conversation:{conversation_id}:turns", 0, context_length - 1
                )
                
                for turn_json in redis_turns:
                    if isinstance(turn_json, bytes):
                        turn_json = turn_json.decode('utf-8')
                    turn_data = json.loads(turn_json)
                    context.append(turn_data)
            
            # If still not enough, get from database
            if len(context) < context_length:
                async with self.session_factory() as session:
                    db_messages = await session.execute(
                        """SELECT content, message_type, timestamp, context_used 
                           FROM messages WHERE conversation_id = ? 
                           ORDER BY timestamp DESC LIMIT ?""",
                        (conversation_id, context_length * 2)
                    )
                    
                    for row in db_messages.fetchall():
                        context.append({
                            "content": row[0],
                            "message_type": row[1],
                            "timestamp": row[2].isoformat(),
                            "context": row[3] or {}
                        })
            
            return context[-context_length:] if context else []
            
        except Exception as e:
            logger.error(f"Failed to retrieve conversation context: {e}")
            return []
    
    async def update_user_semantic_memory(self, user_id: str, new_information: Dict[str, Any]):
        """Update long-term semantic memory about user"""
        try:
            if user_id not in self.semantic_memory:
                self.semantic_memory[user_id] = {
                    "preferences": {},
                    "interests": [],
                    "communication_style": "",
                    "factual_information": {},
                    "relationship_context": {}
                }
            
            # Merge new information
            user_memory = self.semantic_memory[user_id]
            
            for key, value in new_information.items():
                if key in user_memory:
                    if isinstance(user_memory[key], dict) and isinstance(value, dict):
                        user_memory[key].update(value)
                    elif isinstance(user_memory[key], list) and isinstance(value, list):
                        user_memory[key].extend(value)
                        user_memory[key] = list(set(user_memory[key]))  # Remove duplicates
                    else:
                        user_memory[key] = value
                else:
                    user_memory[key] = value
            
            # Store in database
            async with self.session_factory() as session:
                user_result = await session.execute(
                    "SELECT profile_data FROM users WHERE id = ?", (user_id,)
                )
                existing_user = user_result.fetchone()
                
                if existing_user:
                    current_profile = existing_user[0] or {}
                    current_profile.update(new_information)
                    
                    await session.execute(
                        "UPDATE users SET profile_data = ?, last_active = ? WHERE id = ?",
                        (json.dumps(current_profile), datetime.utcnow(), user_id)
                    )
                    await session.commit()
                    
        except Exception as e:
            logger.error(f"Failed to update semantic memory: {e}")
    
    async def get_user_context(self, user_id: str) -> Dict[str, Any]:
        """Get comprehensive user context"""
        try:
            context = {}
            
            # Get from semantic memory
            if user_id in self.semantic_memory:
                context.update(self.semantic_memory[user_id])
            
            # Get from database
            async with self.session_factory() as session:
                user_result = await session.execute(
                    "SELECT * FROM users WHERE id = ?", (user_id,)
                )
                user_data = user_result.fetchone()
                
                if user_data:
                    user_dict = dict(user_data._mapping)
                    context.update({
                        "username": user_dict.get("username", ""),
                        "preferences": user_dict.get("preferences", {}),
                        "conversation_style": user_dict.get("conversation_style", "casual"),
                        "topics_of_interest": user_dict.get("topics_of_interest", []),
                        "profile_data": user_dict.get("profile_data", {})
                    })
            
            return context
            
        except Exception as e:
            logger.error(f"Failed to get user context: {e}")
            return {}

class RAGKnowledgeSystem:
    """Retrieval-Augmented Generation knowledge integration system"""
    
    def __init__(self, vector_store_path: str = "./knowledge_vectors"):
        self.vector_store_path = Path(vector_store_path)
        self.vector_store_path.mkdir(exist_ok=True)
        
        # Initialize embeddings and vector store
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100,
            separators=["\n\n", "\n", ". ", " "]
        )
        
        # Knowledge categories
        self.knowledge_categories = {
            "general": "General knowledge and facts",
            "domain_specific": "Domain-specific expertise",
            "conversational": "Conversational patterns and responses",
            "user_specific": "User-specific information and preferences"
        }
    
    async def initialize_knowledge_base(self, knowledge_documents: List[str] = None):
        """Initialize the knowledge base with documents"""
        try:
            # Load existing vector store or create new one
            if (self.vector_store_path / "index.faiss").exists():
                self.vector_store = FAISS.load_local(
                    str(self.vector_store_path), self.embeddings
                )
                logger.info("Loaded existing knowledge base")
            else:
                # Create new vector store with sample knowledge
                if not knowledge_documents:
                    knowledge_documents = self._create_sample_knowledge()
                
                # Split documents into chunks
                documents = []
                for i, doc_text in enumerate(knowledge_documents):
                    chunks = self.text_splitter.split_text(doc_text)
                    for j, chunk in enumerate(chunks):
                        documents.append(Document(
                            page_content=chunk,
                            metadata={
                                "source": f"doc_{i}",
                                "chunk_id": f"{i}_{j}",
                                "category": "general"
                            }
                        ))
                
                # Create vector store
                self.vector_store = FAISS.from_documents(documents, self.embeddings)
                self.vector_store.save_local(str(self.vector_store_path))
                logger.info(f"Created new knowledge base with {len(documents)} chunks")
                
        except Exception as e:
            logger.error(f"Knowledge base initialization failed: {e}")
            # Create empty vector store as fallback
            sample_doc = Document(page_content="Hello world", metadata={})
            self.vector_store = FAISS.from_documents([sample_doc], self.embeddings)
    
    def _create_sample_knowledge(self) -> List[str]:
        """Create sample knowledge documents"""
        return [
            """
            Artificial Intelligence (AI) is a branch of computer science that aims to create 
            intelligent machines that can perform tasks that typically require human intelligence. 
            These tasks include learning, reasoning, problem-solving, perception, and language 
            understanding. AI systems can be categorized into narrow AI (designed for specific 
            tasks) and general AI (capable of performing any intellectual task that a human can do).
            """,
            
            """
            Machine Learning is a subset of AI that focuses on developing algorithms that can 
            learn and improve from experience without being explicitly programmed. The three 
            main types of machine learning are supervised learning (learning from labeled data), 
            unsupervised learning (finding patterns in unlabeled data), and reinforcement 
            learning (learning through interaction with an environment).
            """,
            
            """
            Natural Language Processing (NLP) is a field of AI that focuses on the interaction 
            between computers and human language. It involves developing algorithms and models 
            that can understand, interpret, and generate human language in a valuable way. 
            Applications include language translation, sentiment analysis, chatbots, and text 
            summarization.
            """,
            
            """
            Customer service best practices include active listening, empathy, clear communication, 
            and prompt response times. Effective customer service representatives should be 
            knowledgeable about products and services, patient with customers, and able to 
            resolve issues efficiently. Building rapport and maintaining a positive attitude 
            are also crucial for customer satisfaction.
            """,
            
            """
            Software development follows various methodologies including Agile, Scrum, and 
            Waterfall. Agile methodology emphasizes iterative development, customer collaboration, 
            and responding to change. Best practices include version control, code reviews, 
            testing, documentation, and continuous integration/deployment (CI/CD).
            """
        ]
    
    async def retrieve_relevant_knowledge(self, query: str, top_k: int = 5, 
                                        category_filter: str = None) -> List[Dict[str, Any]]:
        """Retrieve relevant knowledge for a query"""
        try:
            if not self.vector_store:
                return []
            
            # Perform similarity search
            relevant_docs = self.vector_store.similarity_search_with_score(query, k=top_k)
            
            knowledge_items = []
            for doc, score in relevant_docs:
                # Filter by category if specified
                if category_filter and doc.metadata.get("category") != category_filter:
                    continue
                
                knowledge_items.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "relevance_score": float(score),
                    "source": doc.metadata.get("source", "unknown")
                })
            
            return knowledge_items
            
        except Exception as e:
            logger.error(f"Knowledge retrieval failed: {e}")
            return []
    
    async def add_knowledge_document(self, content: str, metadata: Dict[str, Any] = None):
        """Add new knowledge to the knowledge base"""
        try:
            if not self.vector_store:
                await self.initialize_knowledge_base()
            
            # Split content into chunks
            chunks = self.text_splitter.split_text(content)
            
            # Create documents
            documents = []
            for i, chunk in enumerate(chunks):
                doc_metadata = metadata.copy() if metadata else {}
                doc_metadata.update({
                    "chunk_id": f"{metadata.get('source', 'new')}_{i}",
                    "added_at": datetime.utcnow().isoformat()
                })
                
                documents.append(Document(
                    page_content=chunk,
                    metadata=doc_metadata
                ))
            
            # Add to vector store
            self.vector_store.add_documents(documents)
            self.vector_store.save_local(str(self.vector_store_path))
            
            logger.info(f"Added {len(documents)} knowledge chunks")
            
        except Exception as e:
            logger.error(f"Failed to add knowledge: {e}")

class IntentClassifier:
    """Intent classification and analysis system"""
    
    def __init__(self):
        self.intent_patterns = {
            IntentType.QUESTION: [
                "what", "how", "why", "when", "where", "who", "which", "can you tell me",
                "explain", "describe", "define", "?", "help me understand"
            ],
            IntentType.REQUEST: [
                "please", "can you", "could you", "would you", "help me", "i need",
                "assist", "support", "do", "perform", "execute"
            ],
            IntentType.CHITCHAT: [
                "hello", "hi", "hey", "good morning", "good evening", "how are you",
                "nice weather", "thanks", "thank you", "bye", "goodbye", "see you"
            ],
            IntentType.COMPLAINT: [
                "problem", "issue", "error", "wrong", "not working", "frustrated",
                "disappointed", "unhappy", "terrible", "awful", "bad"
            ],
            IntentType.COMPLIMENT: [
                "great", "excellent", "wonderful", "amazing", "fantastic", "love",
                "appreciate", "thank you", "helpful", "good job", "well done"
            ],
            IntentType.TASK: [
                "create", "generate", "make", "build", "develop", "write", "compose",
                "design", "calculate", "compute", "analyze", "process"
            ]
        }
        
        # Sentiment analysis (simplified)
        self.positive_words = ["good", "great", "excellent", "love", "like", "happy", "satisfied"]
        self.negative_words = ["bad", "terrible", "hate", "dislike", "sad", "frustrated", "angry"]
    
    async def classify_intent(self, user_input: str) -> Dict[str, Any]:
        """Classify user intent from input"""
        try:
            user_input_lower = user_input.lower()
            
            # Score each intent type
            intent_scores = {}
            for intent_type, patterns in self.intent_patterns.items():
                score = 0
                for pattern in patterns:
                    if pattern in user_input_lower:
                        score += 1
                
                # Normalize score
                intent_scores[intent_type.value] = score / len(patterns)
            
            # Determine primary intent
            primary_intent = max(intent_scores, key=intent_scores.get)
            confidence = intent_scores[primary_intent]
            
            # Analyze sentiment
            sentiment = self._analyze_sentiment(user_input_lower)
            
            # Extract entities (simplified)
            entities = self._extract_entities(user_input)
            
            return {
                "primary_intent": primary_intent,
                "confidence": confidence,
                "intent_scores": intent_scores,
                "sentiment": sentiment,
                "entities": entities,
                "input_length": len(user_input.split()),
                "has_question_mark": "?" in user_input
            }
            
        except Exception as e:
            logger.error(f"Intent classification failed: {e}")
            return {
                "primary_intent": "question",
                "confidence": 0.5,
                "sentiment": "neutral",
                "entities": []
            }
    
    def _analyze_sentiment(self, text: str) -> str:
        """Simple sentiment analysis"""
        positive_count = sum(1 for word in self.positive_words if word in text)
        negative_count = sum(1 for word in self.negative_words if word in text)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
    
    def _extract_entities(self, text: str) -> List[Dict[str, str]]:
        """Simple entity extraction"""
        entities = []
        
        # Extract potential names (capitalized words)
        words = text.split()
        for word in words:
            if word.isalpha() and word[0].isupper() and len(word) > 2:
                entities.append({
                    "text": word,
                    "type": "PERSON_OR_PLACE",
                    "confidence": 0.7
                })
        
        # Extract numbers
        import re
        numbers = re.findall(r'\d+(?:\.\d+)?', text)
        for number in numbers:
            entities.append({
                "text": number,
                "type": "NUMBER",
                "confidence": 0.9
            })
        
        return entities

class DynamicChatbot:
    """Main dynamic chatbot with MCP integration"""
    
    def __init__(self, session_factory, config: Dict[str, Any]):
        self.session_factory = session_factory
        self.config = config
        
        # Core components
        self.memory_manager = MCPMemoryManager(session_factory)
        self.knowledge_system = RAGKnowledgeSystem()
        self.intent_classifier = IntentClassifier()
        
        # Language models
        self.chat_model = ChatOpenAI(
            model_name="gpt-4o",
            temperature=0.7,
            streaming=True
        )
        
        # Conversation management
        self.active_conversations = {}
        self.response_templates = self._initialize_response_templates()
        
    async def initialize(self):
        """Initialize the chatbot system"""
        try:
            # Initialize knowledge base
            await self.knowledge_system.initialize_knowledge_base()
            
            # Initialize Redis if configured
            if self.config.get('redis_url'):
                self.memory_manager.redis_client = await aioredis.from_url(
                    self.config['redis_url']
                )
            
            logger.info("Dynamic chatbot initialized successfully")
            
        except Exception as e:
            logger.error(f"Chatbot initialization failed: {e}")
            raise
    
    def _initialize_response_templates(self) -> Dict[str, str]:
        """Initialize response templates for different conversation styles"""
        return {
            "casual": {
                "greeting": "Hey there! How can I help you today?",
                "farewell": "Take care! Feel free to chat anytime.",
                "clarification": "Sorry, I'm not quite sure what you mean. Could you rephrase that?",
                "acknowledgment": "Got it! Let me help you with that."
            },
            "professional": {
                "greeting": "Good day! How may I assist you today?",
                "farewell": "Thank you for your time. Please don't hesitate to reach out if you need further assistance.",
                "clarification": "I apologize, but I need some clarification. Could you please provide more details?",
                "acknowledgment": "I understand. I'll be happy to help you with that."
            },
            "supportive": {
                "greeting": "Hello! I'm here to help and support you. What's on your mind?",
                "farewell": "I hope I was able to help. Remember, I'm always here if you need support.",
                "clarification": "I want to make sure I understand you correctly. Could you help me by explaining a bit more?",
                "acknowledgment": "I hear you, and I'm here to support you through this."
            }
        }
    
    async def process_message(self, user_id: str, message: str, 
                            conversation_id: str = None) -> Dict[str, Any]:
        """Process user message and generate response"""
        try:
            # Create or get conversation
            if not conversation_id:
                conversation_id = await self._create_conversation(user_id)
            
            # Analyze user intent
            intent_analysis = await self.intent_classifier.classify_intent(message)
            
            # Get conversation context
            conversation_context = await self.memory_manager.retrieve_conversation_context(
                conversation_id
            )
            
            # Get user context
            user_context = await self.memory_manager.get_user_context(user_id)
            
            # Retrieve relevant knowledge
            relevant_knowledge = await self.knowledge_system.retrieve_relevant_knowledge(
                message, top_k=3
            )
            
            # Generate response
            response_context = ResponseContext(
                retrieved_knowledge=relevant_knowledge,
                conversation_history=conversation_context,
                user_context=user_context,
                intent_analysis=intent_analysis,
                confidence_scores={"intent": intent_analysis.get("confidence", 0.5)}
            )
            
            response = await self._generate_response(message, response_context, user_context)
            
            # Store conversation turn
            await self.memory_manager.store_conversation_turn(
                conversation_id, message, response["content"], {
                    "user_id": user_id,
                    "intent": intent_analysis.get("primary_intent"),
                    "sentiment": intent_analysis.get("sentiment"),
                    "knowledge_used": len(relevant_knowledge),
                    "response_time": response.get("response_time", 0)
                }
            )
            
            # Update user semantic memory if needed
            if intent_analysis.get("entities") or intent_analysis.get("sentiment") != "neutral":
                memory_update = {
                    "recent_topics": [intent_analysis.get("primary_intent", "general")],
                    "communication_patterns": {
                        "message_length": len(message.split()),
                        "sentiment_trend": intent_analysis.get("sentiment")
                    }
                }
                await self.memory_manager.update_user_semantic_memory(user_id, memory_update)
            
            return {
                "response": response["content"],
                "conversation_id": conversation_id,
                "intent": intent_analysis.get("primary_intent"),
                "sentiment": intent_analysis.get("sentiment"),
                "confidence": intent_analysis.get("confidence"),
                "knowledge_sources": len(relevant_knowledge),
                "response_metadata": response.get("metadata", {})
            }
            
        except Exception as e:
            logger.error(f"Message processing failed: {e}")
            return {
                "response": "I'm sorry, I encountered an error processing your message. Could you try again?",
                "conversation_id": conversation_id,
                "error": str(e)
            }
    
    async def _generate_response(self, user_message: str, context: ResponseContext, 
                               user_context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate contextual response using LLM"""
        try:
            start_time = time.time()
            
            # Build conversation style
            conversation_style = user_context.get("conversation_style", "casual")
            
            # Build context prompt
            context_prompt = self._build_context_prompt(user_message, context, user_context)
            
            # Generate response using LLM
            messages = [
                SystemMessage(content=context_prompt),
                HumanMessage(content=user_message)
            ]
            
            response = await self.chat_model.agenerate([messages])
            response_content = response.generations[0][0].text
            
            response_time = time.time() - start_time
            
            return {
                "content": response_content,
                "response_time": response_time,
                "metadata": {
                    "style": conversation_style,
                    "context_length": len(context.conversation_history),
                    "knowledge_used": len(context.retrieved_knowledge)
                }
            }
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return {
                "content": "I'm having trouble generating a response right now. Could you please try again?",
                "response_time": 0,
                "metadata": {"error": str(e)}
            }
    
    def _build_context_prompt(self, user_message: str, context: ResponseContext, 
                            user_context: Dict[str, Any]) -> str:
        """Build comprehensive context prompt for LLM"""
        
        conversation_style = user_context.get("conversation_style", "casual")
        user_name = user_context.get("username", "User")
        
        # Build knowledge context
        knowledge_context = ""
        if context.retrieved_knowledge:
            knowledge_context = "Relevant knowledge:\n"
            for item in context.retrieved_knowledge[:3]:
                knowledge_context += f"- {item['content'][:200]}...\n"
        
        # Build conversation history
        history_context = ""
        if context.conversation_history:
            history_context = "Recent conversation:\n"
            for turn in context.conversation_history[-3:]:
                if turn.get("user_message"):
                    history_context += f"User: {turn['user_message']}\n"
                if turn.get("assistant_response"):
                    history_context += f"Assistant: {turn['assistant_response']}\n"
        
        # Build user preferences
        preferences_context = ""
        if user_context.get("preferences"):
            preferences = user_context["preferences"]
            preferences_context = f"User preferences: {json.dumps(preferences, indent=2)}\n"
        
        context_prompt = f"""
You are a helpful, intelligent chatbot with access to conversation history and relevant knowledge. 
Your conversation style should be {conversation_style}.

User Information:
- Name: {user_name}
- Intent: {context.intent_analysis.get('primary_intent', 'unknown')}
- Sentiment: {context.intent_analysis.get('sentiment', 'neutral')}

{preferences_context}

{history_context}

{knowledge_context}

Instructions:
1. Respond in a {conversation_style} manner appropriate for the user's communication style
2. Use the relevant knowledge when helpful, but don't force it into the conversation
3. Maintain context from the conversation history
4. Be helpful, accurate, and engaging
5. If you're not sure about something, say so honestly
6. Keep responses concise but informative

Current user message: "{user_message}"

Provide a helpful and contextually appropriate response:
"""
        
        return context_prompt
    
    async def _create_conversation(self, user_id: str) -> str:
        """Create new conversation record"""
        try:
            conversation_id = str(uuid.uuid4())
            
            async with self.session_factory() as session:
                conversation = Conversation(
                    id=conversation_id,
                    user_id=user_id,
                    title="New Conversation",
                    conversation_type="casual",
                    status="active"
                )
                session.add(conversation)
                await session.commit()
            
            return conversation_id
            
        except Exception as e:
            logger.error(f"Failed to create conversation: {e}")
            return str(uuid.uuid4())  # Return UUID even if DB fails
    
    async def get_conversation_history(self, conversation_id: str) -> List[Dict[str, Any]]:
        """Get formatted conversation history"""
        try:
            async with self.session_factory() as session:
                messages_result = await session.execute(
                    """SELECT message_type, content, timestamp, intent, sentiment 
                       FROM messages WHERE conversation_id = ? 
                       ORDER BY timestamp ASC""",
                    (conversation_id,)
                )
                
                history = []
                for row in messages_result.fetchall():
                    history.append({
                        "type": row[0],
                        "content": row[1],
                        "timestamp": row[2].isoformat(),
                        "intent": row[3],
                        "sentiment": row[4]
                    })
                
                return history
                
        except Exception as e:
            logger.error(f"Failed to get conversation history: {e}")
            return []
    
    async def update_user_preferences(self, user_id: str, preferences: Dict[str, Any]):
        """Update user preferences and conversation style"""
        try:
            async with self.session_factory() as session:
                await session.execute(
                    """UPDATE users SET preferences = ?, conversation_style = ?, last_active = ? 
                       WHERE id = ?""",
                    (
                        json.dumps(preferences),
                        preferences.get("conversation_style", "casual"),
                        datetime.utcnow(),
                        user_id
                    )
                )
                await session.commit()
            
            # Update memory
            await self.memory_manager.update_user_semantic_memory(user_id, {
                "preferences": preferences
            })
            
        except Exception as e:
            logger.error(f"Failed to update user preferences: {e}")

class ChatbotAPI:
    """FastAPI application for the MCP-powered chatbot"""
    
    def __init__(self, chatbot: DynamicChatbot):
        self.app = FastAPI(title="MCP-Powered Dynamic Chatbot API")
        self.chatbot = chatbot
        self.active_connections = {}
        self.setup_middleware()
        self.setup_routes()
    
    def setup_middleware(self):
        """Setup CORS middleware"""
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def setup_routes(self):
        """Setup API routes"""
        
        # Pydantic models for request validation
        class ChatMessage(BaseModel):
            message: str
            user_id: str
            conversation_id: Optional[str] = None
            
        class UserPreferences(BaseModel):
            conversation_style: str = "casual"
            preferred_topics: List[str] = []
            response_length: str = "medium"
        
        @self.app.post("/chat")
        async def chat_endpoint(chat_message: ChatMessage):
            try:
                response = await self.chatbot.process_message(
                    chat_message.user_id,
                    chat_message.message,
                    chat_message.conversation_id
                )
                return response
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/conversation/{conversation_id}/history")
        async def get_conversation_history(conversation_id: str):
            try:
                history = await self.chatbot.get_conversation_history(conversation_id)
                return {"conversation_id": conversation_id, "history": history}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.post("/user/{user_id}/preferences")
        async def update_preferences(user_id: str, preferences: UserPreferences):
            try:
                await self.chatbot.update_user_preferences(user_id, preferences.dict())
                return {"status": "success", "message": "Preferences updated"}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.websocket("/ws/{user_id}")
        async def websocket_endpoint(websocket: WebSocket, user_id: str):
            await websocket.accept()
            self.active_connections[user_id] = websocket
            
            try:
                while True:
                    # Receive message from client
                    data = await websocket.receive_json()
                    message = data.get("message", "")
                    conversation_id = data.get("conversation_id")
                    
                    # Process message
                    response = await self.chatbot.process_message(
                        user_id, message, conversation_id
                    )
                    
                    # Send response back
                    await websocket.send_json(response)
                    
            except WebSocketDisconnect:
                if user_id in self.active_connections:
                    del self.active_connections[user_id]
            except Exception as e:
                logger.error(f"WebSocket error: {e}")
                await websocket.send_json({"error": str(e)})
        
        @self.app.get("/system/status")
        async def system_status():
            return {
                "status": "operational",
                "active_connections": len(self.active_connections),
                "features": [
                    "Context-aware conversations",
                    "Long-term memory management",
                    "RAG knowledge integration", 
                    "Intent classification",
                    "Multi-style conversation support",
                    "Real-time WebSocket communication"
                ]
            }

class MCPChatbotFramework:
    """Main framework orchestrating all chatbot components"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.session_factory = None
        self.chatbot = None
        self.api = None
    
    async def initialize(self):
        """Initialize the complete chatbot framework"""
        try:
            # Initialize database
            engine = create_async_engine(self.config['database_url'])
            self.session_factory = sessionmaker(
                engine, class_=AsyncSession, expire_on_commit=False
            )
            
            # Create tables
            async with engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
            
            # Initialize chatbot
            self.chatbot = DynamicChatbot(self.session_factory, self.config)
            await self.chatbot.initialize()
            
            # Create sample user
            await self._create_sample_user()
            
            # Initialize API
            self.api = ChatbotAPI(self.chatbot)
            
            logger.info("MCP Chatbot Framework initialized successfully")
            
        except Exception as e:
            logger.error(f"Framework initialization failed: {e}")
            raise
    
    async def _create_sample_user(self):
        """Create sample user for testing"""
        try:
            async with self.session_factory() as session:
                # Check if user already exists
                existing_user = await session.execute(
                    "SELECT id FROM users WHERE username = ?", ("demo_user",)
                )
                
                if not existing_user.fetchone():
                    sample_user = User(
                        id="user_001",
                        username="demo_user",
                        email="demo@example.com",
                        profile_data={
                            "name": "Demo User",
                            "location": "Virtual World"
                        },
                        preferences={
                            "conversation_style": "casual",
                            "preferred_topics": ["technology", "ai", "science"],
                            "response_length": "medium"
                        },
                        conversation_style="casual",
                        topics_of_interest=["AI", "technology", "chatbots"]
                    )
                    session.add(sample_user)
                    await session.commit()
                    logger.info("Created sample user")
                    
        except Exception as e:
            logger.warning(f"Sample user creation failed: {e}")
    
    def launch_api(self, host: str = "0.0.0.0", port: int = 8000):
        """Launch the chatbot API"""
        try:
            if self.api:
                uvicorn.run(self.api.app, host=host, port=port)
            else:
                logger.error("API not initialized")
        except Exception as e:
            logger.error(f"API launch failed: {e}")

async def demo():
    """Demonstration of the MCP-Powered Dynamic Chatbot Framework"""
    
    print("🤖 MCP-Powered Dynamic Chatbot Framework Demo\n")
    
    config = {
        'database_url': 'sqlite+aiosqlite:///./mcp_chatbot.db',
        'redis_url': None  # Set to Redis URL if available
    }
    
    try:
        # Initialize framework
        framework = MCPChatbotFramework(config)
        await framework.initialize()
        
        print("✅ MCP-Powered Dynamic Chatbot Framework initialized")
        print("✅ Context management system configured")
        print("✅ RAG knowledge integration enabled")
        print("✅ Intent classification system ready")
        print("✅ Long-term memory system operational")
        
        # Demo conversation
        print(f"\n💬 Starting Demo Conversation...")
        
        user_id = "user_001"
        chatbot = framework.chatbot
        
        demo_messages = [
            "Hello! I'm new here. What can you help me with?",
            "I'm interested in learning about artificial intelligence",
            "Can you explain machine learning in simple terms?",
            "That's helpful! What about deep learning?",
            "I'd like to know more about practical applications of AI",
            "Thanks! You've been very helpful. I'll remember this conversation."
        ]
        
        conversation_id = None
        
        for i, message in enumerate(demo_messages, 1):
            print(f"\n👤 User: {message}")
            
            response = await chatbot.process_message(user_id, message, conversation_id)
            
            if not conversation_id:
                conversation_id = response.get("conversation_id")
            
            print(f"🤖 Chatbot: {response['response']}")
            print(f"📊 Intent: {response.get('intent')}, Sentiment: {response.get('sentiment')}")
            print(f"🧠 Knowledge sources: {response.get('knowledge_sources', 0)}")
            
            # Small delay for realism
            await asyncio.sleep(1)
        
        # Show conversation history
        print(f"\n📚 Conversation History:")
        history = await chatbot.get_conversation_history(conversation_id)
        
        for entry in history[-4:]:  # Show last 4 exchanges
            print(f"  {entry['type']}: {entry['content'][:60]}...")
        
        # Demo user preference update
        print(f"\n⚙️ Updating User Preferences...")
        new_preferences = {
            "conversation_style": "professional",
            "preferred_topics": ["AI", "machine learning", "technology"],
            "response_length": "detailed"
        }
        
        await chatbot.update_user_preferences(user_id, new_preferences)
        print(f"✅ Preferences updated to professional style")
        
        # Test with new style
        print(f"\n👤 User: Can you tell me about natural language processing?")
        response = await chatbot.process_message(
            user_id, 
            "Can you tell me about natural language processing?", 
            conversation_id
        )
        print(f"🤖 Chatbot (Professional): {response['response'][:150]}...")
        
        # Show framework capabilities
        print(f"\n🛠️ Framework Capabilities:")
        print(f"  ✅ Context-Aware Conversations")
        print(f"  ✅ Long-Term Memory Management")
        print(f"  ✅ RAG Knowledge Integration")
        print(f"  ✅ Intent Classification & Sentiment Analysis")
        print(f"  ✅ Multi-Style Conversation Support")
        print(f"  ✅ User Preference Management")
        print(f"  ✅ Persistent Conversation Storage")
        print(f"  ✅ Real-Time WebSocket Communication")
        
        print(f"\n🎯 Key Features:")
        print(f"  • Maintains conversation context across sessions")
        print(f"  • Adapts to user communication styles")
        print(f"  • Integrates external knowledge sources")
        print(f"  • Learns user preferences over time")
        print(f"  • Provides intent-aware responses")
        print(f"  • Supports multiple conversation styles")
        
        print(f"\n🌐 API Endpoints Available:")
        print(f"  POST /chat - Send chat messages")
        print(f"  GET /conversation/{{id}}/history - Get conversation history") 
        print(f"  POST /user/{{id}}/preferences - Update user preferences")
        print(f"  WS /ws/{{user_id}} - Real-time WebSocket chat")
        print(f"  GET /system/status - System status and info")
        
        print(f"\n🚀 To start the API server:")
        print(f"   framework.launch_api(host='0.0.0.0', port=8000)")
        print(f"   API will be available at: http://localhost:8000")
        print(f"   WebSocket endpoint: ws://localhost:8000/ws/user_001")
        
        print(f"\n📱 Example API Usage:")
        print(f"""
   curl -X POST "http://localhost:8000/chat" \\
        -H "Content-Type: application/json" \\
        -d '{{"message": "Hello!", "user_id": "user_001"}}'
        """)
        
        print(f"\n🤖 MCP-Powered Dynamic Chatbot Framework demo completed!")
        
    except Exception as e:
        print(f"❌ Demo error: {e}")
        logger.error(f"Demo failed: {e}")

# Dependencies information
dependencies_info = """
# Install required dependencies:
pip install openai langchain
pip install fastapi uvicorn websockets
pip install sqlalchemy aiosqlite
pip install sentence-transformers
pip install faiss-cpu chromadb
pip install redis aioredis
pip install numpy pandas
pip install transformers torch
pip install httpx aiofiles

# Environment variables:
export OPENAI_API_KEY="your-openai-api-key"
export DATABASE_URL="sqlite+aiosqlite:///./mcp_chatbot.db"
export REDIS_URL="redis://localhost:6379"  # Optional

# Additional AI libraries:
pip install anthropic  # For Claude integration
pip install pinecone-client  # For Pinecone vector store
pip install spacy  # For advanced NLP
pip install nltk  # For text processing

# For production:
pip install gunicorn  # WSGI server
pip install celery  # Background tasks
pip install prometheus-client  # Monitoring
pip install structlog  # Structured logging

# Optional UI libraries:
pip install streamlit  # For web UI
pip install gradio  # For demo interface
"""

if __name__ == "__main__":
    print(dependencies_info)
    asyncio.run(demo())
````

## Project Summary

The MCP-Powered Dynamic Chatbot Framework represents a revolutionary advancement in conversational AI technology that combines sophisticated context management, persistent memory systems, and intelligent knowledge integration to create truly adaptive and personalized chatbot experiences. This comprehensive framework addresses critical limitations in current chatbot technologies by providing continuous context awareness, long-term memory retention, and dynamic knowledge integration capabilities.

### Key Value Propositions

1. **Advanced Context Management**: Sophisticated MCP implementation that maintains comprehensive conversation state, user profiles, and interaction history across multiple sessions, enabling chatbots to provide continuity and personalization that rivals human conversation partners while adapting to individual communication styles and preferences.

2. **Intelligent Knowledge Integration**: Seamless RAG-powered system that combines parametric language model knowledge with real-time external information retrieval, ensuring chatbots provide accurate, current, and contextually relevant responses while maintaining natural dialogue flow and conversational coherence.

3. **Adaptive Conversation Intelligence**: Dynamic dialog management system that analyzes user intent, sentiment, and communication patterns to adapt conversation strategies, response styles, and content delivery, creating personalized interactions that improve user satisfaction and engagement over time.

4. **Scalable Enterprise Architecture**: Modular, extensible framework designed for production deployment with support for multiple conversation styles, user management, real-time communication, and integration with existing business systems while maintaining performance and reliability at scale.

### Key Takeaways

- **Transformative User Experience**: Enables chatbots that remember previous conversations, learn user preferences, and provide increasingly personalized interactions, fundamentally changing user expectations and satisfaction with automated conversation systems
- **Enterprise-Ready Deployment**: Provides complete infrastructure for building and deploying sophisticated conversational AI applications with support for multi-user environments, real-time communication, and business system integration
- **Continuous Learning & Adaptation**: Implements advanced memory systems that capture and utilize conversation patterns, user preferences, and interaction history to continuously improve response quality and personalization effectiveness
- **Future-Proof Framework**: Offers modular architecture that supports integration with emerging AI technologies, external knowledge sources, and specialized models while maintaining backward compatibility and scalability for growing business needs

This MCP-Powered Dynamic Chatbot Framework empowers organizations to deploy next-generation conversational AI that provides human-like interaction quality while maintaining the scalability, reliability, and cost-effectiveness required for business applications, creating opportunities for improved customer service, enhanced user engagement, and operational efficiency across diverse industries and use cases.