<small>Claude Sonnet 4 **(Enterprise Knowledge Management s MCP (Model Context Protocol))**</small>
# Enterprise Knowledge Management with MCP

## 1. Klíčové koncepty

### Model Context Protocol (MCP)
MCP je standardizovaný protokol vyvinutý společností Anthropic pro komunikaci mezi AI aplikacemi a externími zdroji dat. Umožňuje bezpečné a strukturované připojení k databázím, API a souborovým systémům.

### Vector Databases (Vektorové databáze)
Specializované databáze optimalizované pro ukládání a vyhledávání vektorových reprezentací dat. Využívají cosine similarity a další metriky pro nalezení sémanticky podobného obsahu.

### Document Embeddings (Vložení dokumentů)
Proces převodu textových dokumentů na číselné vektory pomocí transformerových modelů. Zachycuje sémantický význam textu v mnohodimenzionálním prostoru.

### Retrieval-Augmented Generation (RAG)
Architektura kombinující vyhledávání relevantních informací s generativními jazykovými modely. Zlepšuje přesnost a aktuálnost odpovědí AI asistentů.

### LlamaIndex
Framework pro budování aplikací s LLM zaměřený na indexování a dotazování nad strukturovanými i nestrukturovanými daty.

## 2. Komplexní vysvětlení projektu

### Cíle projektu
Tento projekt demonstruje vytvoření pokročilého enterprise systému pro správu znalostí, který využívá MCP protokol pro bezpečnou integraci s různými zdroji dat. Systém implementuje RAG architekturu s vektorovými databázemi pro efektivní vyhledávání a generování odpovědí.

### Hlavní výzvy
- **Škálovatelnost**: Zpracování velkých objemů dokumentů a uživatelských dotazů
- **Bezpečnost**: Implementace autentizace a autorizace přes MCP
- **Přesnost**: Zajištění relevantních a aktuálních odpovědí
- **Integrace**: Propojení s existujícími enterprise systémy

### Potenciální dopad
Systém může dramaticky zlepšit produktivitu zaměstnanců automatizací vyhledávání informací v rozsáhlých firemních databázích znalostí. Snižuje čas potřebný k nalezení relevantních informací z hodin na sekundy.

## 3. Komplexní implementace v Pythonu

### Instalace závislostí

````python
# requirements.txt
llama-index==0.9.48
langchain==0.1.4
chromadb==0.4.24
openai==1.12.0
fastapi==0.109.2
uvicorn==0.27.1
pydantic==2.6.1
python-multipart==0.0.9
aiofiles==23.2.0
sentence-transformers==2.3.1
PyPDF2==3.0.1
python-dotenv==1.0.1
````

### Hlavní aplikace

````python
import os
import asyncio
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
import uuid
from datetime import datetime

from fastapi import FastAPI, HTTPException, Depends, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import chromadb
from chromadb.config import Settings
from llama_index.core import Document, VectorStoreIndex, ServiceContext
from llama_index.core.storage.storage_context import StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from sentence_transformers import SentenceTransformer
import PyPDF2
from dotenv import load_dotenv

# Načtení konfigurace
load_dotenv()

# Konfigurace logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MCPConfig:
    """Konfigurace MCP protokolu"""
    def __init__(self):
        self.server_name = "enterprise-knowledge-mcp"
        self.version = "1.0.0"
        self.capabilities = {
            "resources": True,
            "tools": True,
            "prompts": False
        }

class DocumentMetadata(BaseModel):
    """Metadata dokumentu"""
    filename: str
    upload_date: datetime
    file_size: int
    document_type: str
    department: Optional[str] = None
    tags: List[str] = []

class QueryRequest(BaseModel):
    """Požadavek na dotaz"""
    query: str = Field(..., min_length=1, max_length=1000)
    department_filter: Optional[str] = None
    max_results: int = Field(default=5, ge=1, le=20)
    similarity_threshold: float = Field(default=0.7, ge=0.0, le=1.0)

class QueryResponse(BaseModel):
    """Odpověď na dotaz"""
    answer: str
    sources: List[Dict[str, Any]]
    confidence_score: float
    query_id: str

class EnterpriseKnowledgeManager:
    """Hlavní třída pro správu enterprise znalostí"""
    
    def __init__(self):
        self.mcp_config = MCPConfig()
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.llm = OpenAI(
            model="gpt-4",
            api_key=os.getenv("OPENAI_API_KEY"),
            temperature=0.1
        )
        self.embedding_llm = OpenAIEmbedding(
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Inicializace ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # Vytvoření kolekce
        try:
            self.collection = self.chroma_client.get_collection("enterprise_docs")
        except:
            self.collection = self.chroma_client.create_collection(
                name="enterprise_docs",
                metadata={"description": "Enterprise knowledge base"}
            )
        
        # Inicializace LlamaIndex
        self.vector_store = ChromaVectorStore(chroma_collection=self.collection)
        self.storage_context = StorageContext.from_defaults(
            vector_store=self.vector_store
        )
        
        self.service_context = ServiceContext.from_defaults(
            llm=self.llm,
            embed_model=self.embedding_llm,
            chunk_size=512,
            chunk_overlap=50
        )
        
        # Index pro dotazy
        self.index = None
        self._initialize_index()
        
        logger.info("Enterprise Knowledge Manager inicializován")

    def _initialize_index(self):
        """Inicializace vektorového indexu"""
        try:
            # Pokus o načtení existujícího indexu
            self.index = VectorStoreIndex.from_vector_store(
                self.vector_store,
                service_context=self.service_context
            )
            logger.info("Existující index načten")
        except Exception as e:
            # Vytvoření nového indexu
            self.index = VectorStoreIndex(
                [],
                storage_context=self.storage_context,
                service_context=self.service_context
            )
            logger.info("Nový index vytvořen")

    async def process_pdf_document(self, file_content: bytes, metadata: DocumentMetadata) -> str:
        """Zpracování PDF dokumentu"""
        try:
            # Extrakce textu z PDF
            import io
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            
            if not text.strip():
                raise ValueError("PDF neobsahuje extrahovatelný text")
            
            # Vytvoření dokumentu pro LlamaIndex
            document = Document(
                text=text,
                metadata={
                    "filename": metadata.filename,
                    "upload_date": metadata.upload_date.isoformat(),
                    "file_size": metadata.file_size,
                    "document_type": metadata.document_type,
                    "department": metadata.department,
                    "tags": metadata.tags,
                    "document_id": str(uuid.uuid4())
                }
            )
            
            # Přidání do indexu
            self.index.insert(document)
            
            logger.info(f"Dokument {metadata.filename} úspěšně zpracován")
            return document.metadata["document_id"]
            
        except Exception as e:
            logger.error(f"Chyba při zpracování PDF: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Chyba při zpracování PDF: {str(e)}")

    async def query_knowledge_base(self, request: QueryRequest) -> QueryResponse:
        """Dotazování do znalostní báze pomocí RAG"""
        try:
            query_id = str(uuid.uuid4())
            
            # Vytvoření query engine
            query_engine = self.index.as_query_engine(
                similarity_top_k=request.max_results,
                response_mode="compact"
            )
            
            # Rozšíření dotazu s kontextem
            enhanced_query = self._enhance_query(request.query, request.department_filter)
            
            # Provedení dotazu
            response = query_engine.query(enhanced_query)
            
            # Zpracování zdrojů
            sources = self._extract_sources(response)
            
            # Výpočet skóre spolehlivosti
            confidence_score = self._calculate_confidence(response, sources)
            
            return QueryResponse(
                answer=str(response),
                sources=sources,
                confidence_score=confidence_score,
                query_id=query_id
            )
            
        except Exception as e:
            logger.error(f"Chyba při dotazování: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Chyba při dotazování: {str(e)}")

    def _enhance_query(self, query: str, department_filter: Optional[str]) -> str:
        """Rozšíření dotazu s kontextovými informacemi"""
        enhanced = f"Basují se na firemních dokumentech, odpověz na následující otázku: {query}"
        
        if department_filter:
            enhanced += f" Zaměř se na informace z oddělení: {department_filter}"
        
        enhanced += " Pokud nejsi si jistý odpovědí, řekni to."
        
        return enhanced

    def _extract_sources(self, response) -> List[Dict[str, Any]]:
        """Extrakce zdrojových dokumentů z odpovědi"""
        sources = []
        
        if hasattr(response, 'source_nodes'):
            for node in response.source_nodes:
                source = {
                    "filename": node.metadata.get("filename", "Neznámý"),
                    "document_type": node.metadata.get("document_type", "Neznámý"),
                    "department": node.metadata.get("department"),
                    "similarity_score": getattr(node, 'score', 0.0),
                    "text_snippet": node.text[:200] + "..." if len(node.text) > 200 else node.text
                }
                sources.append(source)
        
        return sources

    def _calculate_confidence(self, response, sources: List[Dict[str, Any]]) -> float:
        """Výpočet skóre spolehlivosti odpovědi"""
        if not sources:
            return 0.0
        
        # Průměrné skóre podobnosti ze zdrojů
        similarity_scores = [s.get("similarity_score", 0.0) for s in sources]
        avg_similarity = sum(similarity_scores) / len(similarity_scores)
        
        # Délka odpovědi jako indikátor kvality
        response_length = len(str(response))
        length_factor = min(response_length / 500, 1.0)  # Normalizace na 0-1
        
        # Počet zdrojů
        source_factor = min(len(sources) / 3, 1.0)  # Normalizace na 0-1
        
        # Kombinace faktorů
        confidence = (avg_similarity * 0.5 + length_factor * 0.3 + source_factor * 0.2)
        
        return round(confidence, 3)

    async def get_statistics(self) -> Dict[str, Any]:
        """Získání statistik znalostní báze"""
        try:
            collection_info = self.collection.get()
            
            total_documents = len(collection_info["ids"]) if collection_info["ids"] else 0
            
            # Analýza oddělení
            departments = {}
            if collection_info["metadatas"]:
                for metadata in collection_info["metadatas"]:
                    dept = metadata.get("department", "Nezařazeno")
                    departments[dept] = departments.get(dept, 0) + 1
            
            return {
                "total_documents": total_documents,
                "departments": departments,
                "last_updated": datetime.now().isoformat(),
                "mcp_server": self.mcp_config.server_name,
                "version": self.mcp_config.version
            }
            
        except Exception as e:
            logger.error(f"Chyba při získávání statistik: {str(e)}")
            return {"error": str(e)}

# Globální instance
knowledge_manager = EnterpriseKnowledgeManager()

# FastAPI aplikace
app = FastAPI(
    title="Enterprise Knowledge Management MCP",
    description="Enterprise systém pro správu znalostí s MCP protokolem",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/upload", response_model=Dict[str, str])
async def upload_document(
    file: UploadFile = File(...),
    department: Optional[str] = None,
    tags: str = ""
):
    """Nahrání dokumentu do znalostní báze"""
    
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Podporovány jsou pouze PDF soubory")
    
    try:
        content = await file.read()
        
        metadata = DocumentMetadata(
            filename=file.filename,
            upload_date=datetime.now(),
            file_size=len(content),
            document_type="pdf",
            department=department,
            tags=tags.split(",") if tags else []
        )
        
        document_id = await knowledge_manager.process_pdf_document(content, metadata)
        
        return {
            "message": "Dokument úspěšně nahrán",
            "document_id": document_id,
            "filename": file.filename
        }
        
    except Exception as e:
        logger.error(f"Chyba při nahrávání: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/query", response_model=QueryResponse)
async def query_documents(request: QueryRequest):
    """Dotazování do znalostní báze"""
    return await knowledge_manager.query_knowledge_base(request)

@app.get("/statistics")
async def get_statistics():
    """Získání statistik systému"""
    return await knowledge_manager.get_statistics()

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "mcp_server": knowledge_manager.mcp_config.server_name,
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
````

### Testovací skript

````python
import asyncio
import aiohttp
import json
from pathlib import Path

class KnowledgeManagerClient:
    """Klient pro testování Knowledge Manager API"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
    
    async def upload_sample_document(self):
        """Nahrání testovacího dokumentu"""
        
        # Vytvoření ukázkového PDF obsahu (pro demo)
        sample_text = """
        FIREMNÍ POLITIKA BEZPEČNOSTI

        1. ÚVOD
        Tato politika definuje základní pravidla pro zajištění bezpečnosti informací
        v naší společnosti. Všichni zaměstnanci jsou povinni tato pravidla dodržovat.

        2. PŘÍSTUPOVÁ PRÁVA
        - Každý zaměstnanec má přidělena jedinečná přístupová práva
        - Hesla musí být změněna každých 90 dní
        - Sdílení přístupových údajů je zakázáno

        3. OCHRANA DAT
        - Citlivá data musí být šifrována
        - Pravidelné zálohování je povinné
        - Přístup k datům je logován

        4. INCIDENTY
        Jakýkoliv bezpečnostní incident musí být okamžitě hlášen na IT oddělení.
        """
        
        print("Testovací dokument vytvořen v paměti")
        print("Pro skutečné použití nahrajte PDF soubor pomocí webového rozhraní")
        
        return True

    async def test_query(self, query: str):
        """Test dotazování"""
        async with aiohttp.ClientSession() as session:
            data = {
                "query": query,
                "department_filter": None,
                "max_results": 5,
                "similarity_threshold": 0.7
            }
            
            async with session.post(f"{self.base_url}/query", json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"\n=== DOTAZ: {query} ===")
                    print(f"Odpověď: {result['answer']}")
                    print(f"Skóre spolehlivosti: {result['confidence_score']}")
                    print(f"Počet zdrojů: {len(result['sources'])}")
                    return result
                else:
                    print(f"Chyba při dotazu: {response.status}")
                    return None

    async def get_statistics(self):
        """Získání statistik"""
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{self.base_url}/statistics") as response:
                if response.status == 200:
                    stats = await response.json()
                    print("\n=== STATISTIKY SYSTÉMU ===")
                    print(f"Celkem dokumentů: {stats.get('total_documents', 0)}")
                    print(f"Oddělení: {stats.get('departments', {})}")
                    print(f"Poslední aktualizace: {stats.get('last_updated', 'N/A')}")
                    return stats
                else:
                    print(f"Chyba při získávání statistik: {response.status}")
                    return None

async def main():
    """Hlavní testovací funkce"""
    client = KnowledgeManagerClient()
    
    # Test základní funkcionality
    print("=== TESTOVÁNÍ ENTERPRISE KNOWLEDGE MANAGEMENT ===")
    
    # Vytvoření ukázkového dokumentu
    await client.upload_sample_document()
    
    # Test dotazů
    test_queries = [
        "Jak často je třeba měnit hesla?",
        "Co dělat při bezpečnostním incidentu?",
        "Jaká jsou pravidla pro sdílení přístupových údajů?",
        "Jak se zálohují data?"
    ]
    
    for query in test_queries:
        await client.test_query(query)
        await asyncio.sleep(1)  # Krátká pauza mezi dotazy
    
    # Získání statistik
    await client.get_statistics()

if __name__ == "__main__":
    print("Spuštění testovacího klienta...")
    print("Ujistěte se, že server běží na http://localhost:8000")
    asyncio.run(main())
````

### Konfigurace prostředí

````bash
OPENAI_API_KEY=your_openai_api_key_here
CHROMA_DB_PATH=./chroma_db
LOG_LEVEL=INFO
MAX_FILE_SIZE=10485760
ALLOWED_EXTENSIONS=pdf,txt,docx
DEFAULT_CHUNK_SIZE=512
DEFAULT_CHUNK_OVERLAP=50
````

### Spuštění aplikace

````bash
# Instalace závislostí
pip install -r requirements.txt

# Spuštění serveru
python main.py

# V novém terminálu - test klienta
python test_client.py
````

## 4. Shrnutí projektu

### Klíčové výhody
- **Skalabilita**: ChromaDB umožňuje zpracování milionů dokumentů
- **Přesnost**: RAG architektura zajišťuje relevantní odpovědi s odkazy na zdroje
- **Bezpečnost**: MCP protokol poskytuje strukturovaný přístup k datům
- **Rozšiřitelnost**: Modulární architektura umožňuje snadné přidání nových funkcí

### Využití v praxi
Systém je ideální pro velké organizace, které potřebují efektivně spravovat rozsáhlé znalostní báze. Může být integrován s existujícími enterprise systémy jako SharePoint, Confluence nebo vlastní dokumentové repozitáře.

### Další možnosti rozšíření
- Podpora dalších formátů dokumentů (Word, Excel, PowerPoint)
- Implementace pokročilých filtrů a vyhledávání
- Integrace s dalšími LLM providery
- Vytvoření webového rozhraní pro end-uživatele
- Implementace role-based access control (RBAC)

Tento projekt demonstruje, jak moderní AI technologie mohou transformovat způsob, jakým organizace pracují se svými znalostmi a informacemi.