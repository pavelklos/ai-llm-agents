<small>Claude Sonnet 4 **(MCP-Optimizovaná Detekce Podvodů ve Finančních Transakcích)**</small>
# MCP-Optimized Fraud Detection for Financial Transactions

## 1. Název Projektu

**MCP-Optimizovaná Detekce Podvodů ve Finančních Transakcích**
*Inteligentní systém pro detekci anomálií v real-time s využitím Model Context Protocol*

## 2. Vysvětlení Klíčových Konceptů

### Model Context Protocol (MCP)
Protokol pro sdílení kontextu mezi různými AI modely a nástroji, umožňující efektivní komunikaci a koordinaci mezi komponentami systému pro detekci podvodů.

### Detekce Anomálií
Technika strojového učení zaměřená na identifikaci neobvyklých vzorů v datech, které se odchylují od normálního chování a mohou indikovat podvodnou aktivitu.

### Graph Neural Networks (GNN)
Specializované neuronové sítě schopné analyzovat grafové struktury dat, ideální pro modelování vztahů mezi účty, transakcemi a entitami v bankovním systému.

### Explainable AI (XAI)
Přístup k umělé inteligenci zaměřený na vytváření modelů, jejichž rozhodnutí jsou transparentní a pochopitelná pro lidské uživatele.

### Syntetická Data
Uměle generovaná data, která napodobují vlastnosti reálných dat, používaná pro trénování modelů bez porušení soukromí zákazníků.

## 3. Komplexní Vysvětlení Projektu

Tento projekt implementuje pokročilý systém detekce podvodů využívající Model Context Protocol pro koordinaci mezi různými AI komponenty. Systém kombinuje několik přístupů:

**Hlavní cíle:**
- Real-time detekce podvodných transakcí s minimálními falešnými poplachy
- Explainabilní rozhodování pro compliance a regulační požadavky
- Škálovatelná architektura schopná zpracovat miliony transakcí denně
- Adaptivní učení schopné detekovat nové typy podvodů

**Výzvy:**
- Balancování mezi citlivostí detekce a uživatelskou zkušeností
- Zpracování velkých objemů dat v real-time
- Ochrana soukromí zákazníků při analýze transakcí
- Adaptace na nové podvodné techniky

**Potenciální dopad:**
- Snížení finančních ztrát bank o 30-50%
- Zlepšení zákaznické spokojenosti díky menším false positive
- Rychlejší reakce na nové podvodné trendy

## 4. Komplexní Příklad s Python Implementací

````python
import asyncio
import json
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import networkx as nx
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
import shap
import matplotlib.pyplot as plt
import seaborn as sns

# Nastavení logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Transaction:
    """Datová struktura pro transakci"""
    transaction_id: str
    user_id: str
    amount: float
    merchant: str
    timestamp: datetime
    location: str
    transaction_type: str
    device_id: str
    
@dataclass
class FraudAlert:
    """Datová struktura pro upozornění na podvod"""
    transaction_id: str
    fraud_score: float
    explanation: str
    features_importance: Dict[str, float]
    confidence: float

class MCPFraudDetectionProtocol:
    """Model Context Protocol pro koordinaci komponent"""
    
    def __init__(self):
        self.components = {}
        self.context_store = {}
        
    def register_component(self, name: str, component):
        """Registrace komponenty do MCP"""
        self.components[name] = component
        logger.info(f"Komponenta {name} zaregistrována")
    
    async def share_context(self, context_id: str, context_data: Dict):
        """Sdílení kontextu mezi komponentami"""
        self.context_store[context_id] = context_data
        
    async def get_context(self, context_id: str) -> Optional[Dict]:
        """Získání kontextu"""
        return self.context_store.get(context_id)
    
    async def coordinate_analysis(self, transaction: Transaction) -> FraudAlert:
        """Koordinace analýzy mezi komponentami"""
        context_id = f"analysis_{transaction.transaction_id}"
        
        # Sdílení kontextu transakce
        await self.share_context(context_id, asdict(transaction))
        
        # Koordinace mezi komponentami
        results = {}
        for name, component in self.components.items():
            if hasattr(component, 'analyze'):
                results[name] = await component.analyze(transaction, context_id)
        
        # Agregace výsledků
        return await self._aggregate_results(transaction, results)
    
    async def _aggregate_results(self, transaction: Transaction, results: Dict) -> FraudAlert:
        """Agregace výsledků z různých komponent"""
        fraud_scores = [r.get('fraud_score', 0) for r in results.values()]
        explanations = [r.get('explanation', '') for r in results.values()]
        
        final_score = np.mean(fraud_scores)
        combined_explanation = " | ".join(explanations)
        
        return FraudAlert(
            transaction_id=transaction.transaction_id,
            fraud_score=final_score,
            explanation=combined_explanation,
            features_importance={},
            confidence=min(fraud_scores) if fraud_scores else 0
        )

class GraphNeuralNetwork(nn.Module):
    """Graph Neural Network pro analýzu vztahů"""
    
    def __init__(self, input_dim: int, hidden_dim: int = 64, output_dim: int = 1):
        super().__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.classifier = nn.Linear(hidden_dim, output_dim)
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x, edge_index, batch):
        x = F.relu(self.conv1(x, edge_index))
        x = self.dropout(x)
        x = F.relu(self.conv2(x, edge_index))
        x = global_mean_pool(x, batch)
        return torch.sigmoid(self.classifier(x))

class GraphAnalyzer:
    """Komponenta pro analýzu grafových vztahů"""
    
    def __init__(self):
        self.model = GraphNeuralNetwork(input_dim=10)
        self.scaler = StandardScaler()
        self.graph = nx.Graph()
        
    async def analyze(self, transaction: Transaction, context_id: str) -> Dict:
        """Analýza transakce pomocí GNN"""
        try:
            # Aktualizace grafu
            self._update_graph(transaction)
            
            # Příprava dat pro GNN
            graph_data = self._prepare_graph_data(transaction)
            
            # Predikce
            with torch.no_grad():
                fraud_score = self.model(
                    graph_data.x, 
                    graph_data.edge_index, 
                    torch.zeros(graph_data.x.size(0), dtype=torch.long)
                ).item()
            
            explanation = self._generate_explanation(transaction, fraud_score)
            
            return {
                'fraud_score': fraud_score,
                'explanation': explanation,
                'component': 'GraphAnalyzer'
            }
            
        except Exception as e:
            logger.error(f"Chyba v GraphAnalyzer: {e}")
            return {'fraud_score': 0.0, 'explanation': 'Chyba analýzy', 'component': 'GraphAnalyzer'}
    
    def _update_graph(self, transaction: Transaction):
        """Aktualizace grafu vztahů"""
        # Přidání uzlů a hran
        self.graph.add_node(transaction.user_id, type='user')
        self.graph.add_node(transaction.merchant, type='merchant')
        self.graph.add_node(transaction.device_id, type='device')
        
        # Přidání hran
        self.graph.add_edge(transaction.user_id, transaction.merchant, 
                           weight=transaction.amount, type='transaction')
        self.graph.add_edge(transaction.user_id, transaction.device_id, 
                           type='device_usage')
    
    def _prepare_graph_data(self, transaction: Transaction) -> Data:
        """Příprava dat pro GNN"""
        # Simulace přípravy grafových dat
        nodes = list(self.graph.nodes())
        node_features = torch.randn(len(nodes), 10)  # Simulace feature
        
        # Příprava edge_index
        edges = list(self.graph.edges())
        edge_index = torch.tensor(
            [[nodes.index(e[0]), nodes.index(e[1])] for e in edges], 
            dtype=torch.long
        ).t()
        
        return Data(x=node_features, edge_index=edge_index)
    
    def _generate_explanation(self, transaction: Transaction, score: float) -> str:
        """Generování vysvětlení"""
        if score > 0.7:
            return f"Vysoké riziko: Neobvyklé síťové vazby pro uživatele {transaction.user_id}"
        elif score > 0.3:
            return f"Střední riziko: Podezřelé transakční vzory"
        else:
            return "Nízké riziko: Normální síťové chování"

class AnomalyDetector:
    """Komponenta pro detekci anomálií"""
    
    def __init__(self):
        self.model = IsolationForest(contamination=0.1, random_state=42)
        self.scaler = StandardScaler()
        self.is_trained = False
        
    async def analyze(self, transaction: Transaction, context_id: str) -> Dict:
        """Analýza transakce na anomálie"""
        try:
            features = self._extract_features(transaction)
            
            if not self.is_trained:
                # Pro demonstraci - v reálném použití by byl model předtrénovaný
                self._train_with_synthetic_data()
            
            # Normalizace features
            features_scaled = self.scaler.transform([features])
            
            # Predikce anomálie
            anomaly_score = self.model.decision_function(features_scaled)[0]
            is_anomaly = self.model.predict(features_scaled)[0] == -1
            
            # Převod na fraud score (0-1)
            fraud_score = max(0, min(1, (0.5 - anomaly_score) * 2))
            
            explanation = self._generate_explanation(transaction, fraud_score, is_anomaly)
            
            return {
                'fraud_score': fraud_score,
                'explanation': explanation,
                'component': 'AnomalyDetector'
            }
            
        except Exception as e:
            logger.error(f"Chyba v AnomalyDetector: {e}")
            return {'fraud_score': 0.0, 'explanation': 'Chyba detekce anomálií', 'component': 'AnomalyDetector'}
    
    def _extract_features(self, transaction: Transaction) -> List[float]:
        """Extrakce příznaků z transakce"""
        return [
            transaction.amount,
            hash(transaction.merchant) % 1000,  # Simulace kategorie obchodníka
            transaction.timestamp.hour,
            transaction.timestamp.weekday(),
            len(transaction.location),
            hash(transaction.transaction_type) % 10,
            hash(transaction.device_id) % 100
        ]
    
    def _train_with_synthetic_data(self):
        """Trénování s uměle generovanými daty"""
        # Generování syntetických dat pro trénování
        np.random.seed(42)
        normal_data = np.random.normal(0, 1, (1000, 7))
        
        self.scaler.fit(normal_data)
        self.model.fit(self.scaler.transform(normal_data))
        self.is_trained = True
        logger.info("Model natrénován na syntetických datech")
    
    def _generate_explanation(self, transaction: Transaction, score: float, is_anomaly: bool) -> str:
        """Generování vysvětlení"""
        if is_anomaly:
            return f"Detekována anomálie: Transakce {transaction.amount} Kč je neobvyklá pro tento profil"
        else:
            return "Transakce odpovídá normálním vzorům"

class ExplainableAI:
    """Komponenta pro explainabilní AI"""
    
    def __init__(self):
        self.feature_names = [
            'amount', 'merchant_category', 'hour', 'weekday', 
            'location_length', 'transaction_type', 'device_category'
        ]
    
    async def analyze(self, transaction: Transaction, context_id: str) -> Dict:
        """Analýza s vysvětlením rozhodnutí"""
        try:
            features = self._extract_features(transaction)
            
            # Simulace SHAP hodnot pro vysvětlení
            shap_values = self._calculate_shap_values(features)
            
            # Výpočet fraud score na základě příznaků
            fraud_score = self._calculate_fraud_score(features, shap_values)
            
            explanation = self._generate_detailed_explanation(shap_values, fraud_score)
            
            return {
                'fraud_score': fraud_score,
                'explanation': explanation,
                'shap_values': dict(zip(self.feature_names, shap_values)),
                'component': 'ExplainableAI'
            }
            
        except Exception as e:
            logger.error(f"Chyba v ExplainableAI: {e}")
            return {'fraud_score': 0.0, 'explanation': 'Chyba explainabilní analýzy', 'component': 'ExplainableAI'}
    
    def _extract_features(self, transaction: Transaction) -> List[float]:
        """Extrakce příznaků"""
        return [
            transaction.amount,
            hash(transaction.merchant) % 1000,
            transaction.timestamp.hour,
            transaction.timestamp.weekday(),
            len(transaction.location),
            hash(transaction.transaction_type) % 10,
            hash(transaction.device_id) % 100
        ]
    
    def _calculate_shap_values(self, features: List[float]) -> List[float]:
        """Simulace SHAP hodnot"""
        # V reálné implementaci by se použil skutečný SHAP explainer
        base_values = [0.1, 0.05, 0.15, 0.02, 0.03, 0.08, 0.06]
        shap_values = []
        
        for i, (feature, base) in enumerate(zip(features, base_values)):
            if i == 0:  # amount
                shap_val = base * (1 + feature / 1000) if feature > 10000 else base * 0.5
            elif i == 2:  # hour
                shap_val = base * 2 if feature < 6 or feature > 22 else base * 0.3
            else:
                shap_val = base * np.random.uniform(0.5, 1.5)
            
            shap_values.append(shap_val)
        
        return shap_values
    
    def _calculate_fraud_score(self, features: List[float], shap_values: List[float]) -> float:
        """Výpočet fraud score"""
        base_score = 0.1
        contribution = sum(shap_values)
        return min(1.0, max(0.0, base_score + contribution))
    
    def _generate_detailed_explanation(self, shap_values: List[float], fraud_score: float) -> str:
        """Generování detailního vysvětlení"""
        top_features = sorted(
            zip(self.feature_names, shap_values), 
            key=lambda x: abs(x[1]), 
            reverse=True
        )[:3]
        
        explanations = []
        for feature, value in top_features:
            if value > 0.1:
                explanations.append(f"{feature}: vysoký vliv (+{value:.3f})")
            elif value < -0.1:
                explanations.append(f"{feature}: snižuje riziko ({value:.3f})")
        
        return f"Fraud score: {fraud_score:.3f}. Klíčové faktory: {', '.join(explanations)}"

class SyntheticDataGenerator:
    """Generátor syntetických dat pro testování"""
    
    @staticmethod
    def generate_transactions(num_transactions: int = 100) -> List[Transaction]:
        """Generování syntetických transakcí"""
        transactions = []
        np.random.seed(42)
        
        merchants = ['Shop_A', 'Restaurant_B', 'Gas_Station_C', 'Online_Store_D', 'ATM_E']
        locations = ['Prague', 'Brno', 'Ostrava', 'Plzen', 'Ceske_Budejovice']
        transaction_types = ['purchase', 'withdrawal', 'transfer', 'payment']
        
        for i in range(num_transactions):
            # Generování normálních transakcí (90%)
            if np.random.random() < 0.9:
                amount = np.random.lognormal(mean=7, sigma=1)  # Normální částky
                hour = np.random.choice(range(8, 22))  # Běžné hodiny
            else:
                # Podezřelé transakce (10%)
                amount = np.random.lognormal(mean=10, sigma=1)  # Vysoké částky
                hour = np.random.choice(range(0, 6))  # Neobvyklé hodiny
            
            transaction = Transaction(
                transaction_id=f"TXN_{i:06d}",
                user_id=f"USER_{np.random.randint(1, 1000):04d}",
                amount=round(amount, 2),
                merchant=np.random.choice(merchants),
                timestamp=datetime.now() - timedelta(
                    days=np.random.randint(0, 30),
                    hours=hour,
                    minutes=np.random.randint(0, 60)
                ),
                location=np.random.choice(locations),
                transaction_type=np.random.choice(transaction_types),
                device_id=f"DEV_{np.random.randint(1, 500):03d}"
            )
            
            transactions.append(transaction)
        
        return transactions

class FraudDetectionSystem:
    """Hlavní systém pro detekci podvodů"""
    
    def __init__(self):
        self.mcp = MCPFraudDetectionProtocol()
        self.setup_components()
        
    def setup_components(self):
        """Nastavení komponent systému"""
        # Registrace komponent do MCP
        self.mcp.register_component('graph_analyzer', GraphAnalyzer())
        self.mcp.register_component('anomaly_detector', AnomalyDetector())
        self.mcp.register_component('explainable_ai', ExplainableAI())
        
    async def analyze_transaction(self, transaction: Transaction) -> FraudAlert:
        """Analýza transakce"""
        logger.info(f"Zahájení analýzy transakce {transaction.transaction_id}")
        
        try:
            fraud_alert = await self.mcp.coordinate_analysis(transaction)
            
            logger.info(f"Analýza dokončena: {fraud_alert.fraud_score:.3f}")
            return fraud_alert
            
        except Exception as e:
            logger.error(f"Chyba při analýze transakce: {e}")
            return FraudAlert(
                transaction_id=transaction.transaction_id,
                fraud_score=0.0,
                explanation="Chyba systému",
                features_importance={},
                confidence=0.0
            )
    
    async def batch_analysis(self, transactions: List[Transaction]) -> List[FraudAlert]:
        """Dávková analýza transakcí"""
        logger.info(f"Zahájení dávkové analýzy {len(transactions)} transakcí")
        
        results = []
        for transaction in transactions:
            result = await self.analyze_transaction(transaction)
            results.append(result)
        
        return results
    
    def generate_report(self, alerts: List[FraudAlert]) -> Dict:
        """Generování reportu"""
        fraud_transactions = [a for a in alerts if a.fraud_score > 0.5]
        
        report = {
            'total_transactions': len(alerts),
            'fraud_detected': len(fraud_transactions),
            'fraud_rate': len(fraud_transactions) / len(alerts) if alerts else 0,
            'avg_fraud_score': np.mean([a.fraud_score for a in alerts]) if alerts else 0,
            'high_risk_transactions': [
                {
                    'transaction_id': a.transaction_id,
                    'fraud_score': a.fraud_score,
                    'explanation': a.explanation
                }
                for a in sorted(fraud_transactions, key=lambda x: x.fraud_score, reverse=True)[:10]
            ]
        }
        
        return report

async def main():
    """Hlavní funkce pro demonstraci systému"""
    print("=== MCP-Optimizovaná Detekce Podvodů ===\n")
    
    # Inicializace systému
    fraud_system = FraudDetectionSystem()
    
    # Generování testovacích dat
    print("Generování syntetických transakcí...")
    transactions = SyntheticDataGenerator.generate_transactions(50)
    
    # Analýza transakcí
    print("Zahájení analýzy transakcí...\n")
    alerts = await fraud_system.batch_analysis(transactions)
    
    # Generování reportu
    report = fraud_system.generate_report(alerts)
    
    # Výpis výsledků
    print("=== VÝSLEDKY ANALÝZY ===")
    print(f"Celkem transakcí: {report['total_transactions']}")
    print(f"Detekované podvody: {report['fraud_detected']}")
    print(f"Míra podvodů: {report['fraud_rate']:.2%}")
    print(f"Průměrné fraud score: {report['avg_fraud_score']:.3f}")
    
    print("\n=== TOP 5 RIZIKOVÝCH TRANSAKCÍ ===")
    for i, tx in enumerate(report['high_risk_transactions'][:5], 1):
        print(f"{i}. {tx['transaction_id']}: {tx['fraud_score']:.3f}")
        print(f"   Vysvětlení: {tx['explanation']}")
    
    # Demonstrace real-time analýzy
    print("\n=== REAL-TIME ANALÝZA ===")
    test_transaction = transactions[0]
    print(f"Analyzuji transakci: {test_transaction.transaction_id}")
    print(f"Částka: {test_transaction.amount} Kč")
    print(f"Obchodník: {test_transaction.merchant}")
    
    alert = await fraud_system.analyze_transaction(test_transaction)
    print(f"Fraud score: {alert.fraud_score:.3f}")
    print(f"Vysvětlení: {alert.explanation}")

if __name__ == "__main__":
    asyncio.run(main())
````

## 5. Instalace Závislostí

````bash
pandas>=1.5.0
numpy>=1.24.0
scikit-learn>=1.3.0
torch>=2.0.0
torch-geometric>=2.3.0
networkx>=3.0
shap>=0.42.0
matplotlib>=3.6.0
seaborn>=0.12.0
asyncio
logging
dataclasses
typing
datetime
````

````bash
# Instalace závislostí
pip install -r requirements.txt
````

## 6. Shrnutí Projektu

Tento projekt představuje pokročilý systém detekce podvodů využívající Model Context Protocol pro koordinaci mezi různými AI komponentami. 

**Klíčové hodnoty:**
- **Modulární architektura**: Systém je navržen s oddělenými komponentami pro různé typy analýz
- **Real-time zpracování**: Schopnost analyzovat transakce v reálném čase
- **Explainabilní rozhodování**: Každé rozhodnutí je podložené vysvětlením
- **Škálovatelnost**: Architektura umožňuje snadné přidání nových komponent

**Technologické inovace:**
- Využití Graph Neural Networks pro analýzu vztahů
- Kombinace více detekčních metod pro vyšší přesnost
- MCP protokol pro efektivní koordinaci komponent
- Syntetická data pro bezpečné testování

**Praktické benefity:**
- Snížení finančních ztrát způsobených podvody
- Zlepšení zákaznické zkušenosti díky menším false positive
- Rychlejší adaptace na nové podvodné techniky
- Compliance s regulačními požadavky díky explainabilnímu AI

Systém je připraven pro nasazení v produkčním prostředí s možností dalšího rozšíření a optimalizace podle specifických potřeb finanční instituce.