<small>Claude Sonnet 4 **(Social Media Content Strategy Assistant)**</small>
# Social Media Content Strategy Assistant

## Kl√≠ƒçov√© koncepty

### RAG (Retrieval-Augmented Generation)
Technika kombinuj√≠c√≠ vyhled√°v√°n√≠ relevantn√≠ch informac√≠ z datab√°ze znalost√≠ s generativn√≠mi AI modely pro vytv√°≈ôen√≠ kontextu√°lnƒõ p≈ôesn√Ωch odpovƒõd√≠.

### Trending Topics
Aktu√°ln√≠ t√©mata a trendy na soci√°ln√≠ch s√≠t√≠ch, kter√° z√≠sk√°vaj√≠ v√Ωznamnou pozornost a engagement u≈æivatel≈Ø.

### Engagement Analytics
Metriky mƒõ≈ô√≠c√≠ interakci u≈æivatel≈Ø s obsahem (lajky, koment√°≈ôe, sd√≠len√≠, dosah, CTR).

### Content Templates
P≈ôedp≈ôipraven√© ≈°ablony pro r≈Øzn√© typy obsahu na soci√°ln√≠ch s√≠t√≠ch s optimalizovanou strukturou.

### Hashtag Research
Anal√Ωza a v√Ωbƒõr relevantn√≠ch hashtag≈Ø pro maximalizaci dosahu a engagement.

### Instagram API
Programov√© rozhran√≠ pro p≈ô√≠stup k dat≈Øm a funkcionalit√°m Instagram platformy.

### Influencer Data
Datab√°ze informac√≠ o influencerech vƒçetnƒõ jejich audience, engagement rate a specializace.

### Brand Guidelines
Soubor pravidel a standard≈Ø pro konzistentn√≠ prezentaci znaƒçky nap≈ô√≠ƒç v≈°emi komunikaƒçn√≠mi kan√°ly.

## Komplexn√≠ vysvƒõtlen√≠ projektu

**Social Media Content Strategy Assistant** je pokroƒçil√Ω AI-powered syst√©m navr≈æen√Ω pro automatizaci a optimalizaci strategie obsahu na soci√°ln√≠ch s√≠t√≠ch. Projekt vyu≈æ√≠v√° RAG architekturu pro inteligentn√≠ generov√°n√≠ obsahu zalo≈æen√©ho na aktu√°ln√≠ch trendech, historick√Ωch datech o engagement a brand guidelines.

### Hlavn√≠ c√≠le projektu:

1. **Automatizace content strategie** - Generov√°n√≠ n√°vrh≈Ø obsahu na z√°kladƒõ trend≈Ø a c√≠lov√© audience
2. **Optimalizace engagement** - Anal√Ωza historick√Ωch dat pro p≈ôedpovƒõƒè √∫spƒõ≈°nosti obsahu
3. **Trend monitoring** - Sledov√°n√≠ aktu√°ln√≠ch t√©mat a jejich implementace do strategie
4. **Brand consistency** - Zaji≈°tƒõn√≠ souladu obsahu s identitou znaƒçky
5. **Performance tracking** - Monitorov√°n√≠ a anal√Ωza v√Ωkonnosti publikovan√©ho obsahu

### V√Ωzvy projektu:

- **Real-time data processing** - Zpracov√°n√≠ velk√©ho mno≈æstv√≠ dat z r≈Øzn√Ωch soci√°ln√≠ch s√≠t√≠
- **Context understanding** - Porozumƒõn√≠ nuanc√≠m r≈Øzn√Ωch platforem a jejich audience
- **Trend prediction** - Identifikace vznikajƒÖcych trend≈Ø p≈ôed jejich masov√Ωm roz≈°√≠≈ôen√≠m
- **Multi-platform optimization** - Adaptace obsahu pro r≈Øzn√© soci√°ln√≠ s√≠tƒõ
- **Compliance management** - Dodr≈æov√°n√≠ pravidel platforem a pr√°vn√≠ch p≈ôedpis≈Ø

### Potenci√°ln√≠ dopad:

Syst√©m m≈Ø≈æe v√Ωraznƒõ zv√Ω≈°it efektivitu social media marketingu, sn√≠≈æit n√°klady na tvorbu obsahu a zlep≈°it ROI marketingov√Ωch kampan√≠ prost≈ôednictv√≠m data-driven p≈ô√≠stupu.

## Komplexn√≠ implementace v Pythonu

````python
import os
import json
import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from pydantic import BaseModel
import requests
import sqlite3

# LangChain imports
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA

# Additional libraries
import tweepy
import instaloader
from textblob import TextBlob
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

@dataclass
class SocialMediaPost:
    """Struktura pro reprezentaci social media p≈ô√≠spƒõvku"""
    platform: str
    content: str
    hashtags: List[str]
    engagement_metrics: Dict[str, int]
    timestamp: datetime
    author: str
    sentiment: float

@dataclass
class ContentTemplate:
    """≈†ablona pro tvorbu obsahu"""
    template_id: str
    name: str
    structure: str
    platform: str
    category: str
    target_engagement: float

@dataclass
class BrandGuideline:
    """Brand guidelines pro konzistentn√≠ komunikaci"""
    brand_name: str
    tone_of_voice: str
    key_messages: List[str]
    prohibited_topics: List[str]
    color_scheme: Dict[str, str]
    target_audience: str

class TrendAnalyzer:
    """Analyz√°tor trend≈Ø na soci√°ln√≠ch s√≠t√≠ch"""
    
    def __init__(self):
        self.trends_data = []
        self._initialize_sample_data()
    
    def _initialize_sample_data(self):
        """Inicializace vzorov√Ωch dat o trendech"""
        sample_trends = [
            {"keyword": "AI", "volume": 50000, "growth": 25.5, "platforms": ["twitter", "linkedin"]},
            {"keyword": "sustainability", "volume": 35000, "growth": 15.2, "platforms": ["instagram", "twitter"]},
            {"keyword": "remote work", "volume": 28000, "growth": -5.1, "platforms": ["linkedin", "twitter"]},
            {"keyword": "NFT", "volume": 45000, "growth": -12.3, "platforms": ["twitter", "instagram"]},
            {"keyword": "wellness", "volume": 32000, "growth": 18.7, "platforms": ["instagram", "tiktok"]},
        ]
        self.trends_data = sample_trends
    
    def get_trending_topics(self, platform: str = None, limit: int = 10) -> List[Dict]:
        """Z√≠sk√°n√≠ aktu√°ln√≠ch trend≈Ø pro danou platformu"""
        if platform:
            filtered_trends = [
                trend for trend in self.trends_data 
                if platform in trend.get("platforms", [])
            ]
        else:
            filtered_trends = self.trends_data
        
        # Se≈ôazen√≠ podle objemu a r≈Østu
        sorted_trends = sorted(
            filtered_trends, 
            key=lambda x: x["volume"] * (1 + x["growth"]/100), 
            reverse=True
        )
        
        return sorted_trends[:limit]
    
    def analyze_hashtag_performance(self, hashtags: List[str]) -> Dict[str, float]:
        """Anal√Ωza v√Ωkonnosti hashtag≈Ø"""
        performance = {}
        for hashtag in hashtags:
            # Simulace v√Ωpoƒçtu v√Ωkonnosti na z√°kladƒõ popularity
            base_score = np.random.uniform(0.3, 0.9)
            trend_bonus = 0.1 if any(hashtag.lower() in trend["keyword"].lower() 
                                   for trend in self.trends_data) else 0
            performance[hashtag] = min(base_score + trend_bonus, 1.0)
        
        return performance

class ContentDatabase:
    """Datab√°ze pro ukl√°d√°n√≠ a spr√°vu obsahu"""
    
    def __init__(self, db_path: str = "social_media.db"):
        self.db_path = db_path
        self._initialize_database()
    
    def _initialize_database(self):
        """Inicializace SQLite datab√°ze"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Tabulka pro p≈ô√≠spƒõvky
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS posts (
                id INTEGER PRIMARY KEY,
                platform TEXT,
                content TEXT,
                hashtags TEXT,
                likes INTEGER,
                shares INTEGER,
                comments INTEGER,
                timestamp TEXT,
                author TEXT,
                sentiment REAL
            )
        ''')
        
        # Tabulka pro ≈°ablony
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS templates (
                id TEXT PRIMARY KEY,
                name TEXT,
                structure TEXT,
                platform TEXT,
                category TEXT,
                target_engagement REAL
            )
        ''')
        
        conn.commit()
        conn.close()
        
        # P≈ôid√°n√≠ vzorov√Ωch dat
        self._add_sample_data()
    
    def _add_sample_data(self):
        """P≈ôid√°n√≠ vzorov√Ωch dat do datab√°ze"""
        sample_posts = [
            SocialMediaPost(
                platform="instagram",
                content="Objevte kr√°su udr≈æiteln√© m√≥dy! üåø #sustainability #fashion",
                hashtags=["#sustainability", "#fashion", "#ecofriendly"],
                engagement_metrics={"likes": 1250, "shares": 45, "comments": 87},
                timestamp=datetime.now() - timedelta(days=1),
                author="fashion_brand",
                sentiment=0.8
            ),
            SocialMediaPost(
                platform="twitter",
                content="AI revoluce je tady! Jak vyu≈æ√≠t umƒõlou inteligenci ve va≈°em podnik√°n√≠? ü§ñ",
                hashtags=["#AI", "#business", "#technology"],
                engagement_metrics={"likes": 890, "shares": 156, "comments": 34},
                timestamp=datetime.now() - timedelta(days=2),
                author="tech_guru",
                sentiment=0.7
            )
        ]
        
        for post in sample_posts:
            self.save_post(post)
        
        sample_templates = [
            ContentTemplate(
                template_id="instagram_product",
                name="Product Showcase",
                structure="Hook + Product benefits + CTA + Hashtags",
                platform="instagram",
                category="product",
                target_engagement=0.8
            ),
            ContentTemplate(
                template_id="twitter_thought",
                name="Thought Leadership",
                structure="Industry insight + Personal perspective + Question to audience",
                platform="twitter", 
                category="thought_leadership",
                target_engagement=0.6
            )
        ]
        
        for template in sample_templates:
            self.save_template(template)
    
    def save_post(self, post: SocialMediaPost):
        """Ulo≈æen√≠ p≈ô√≠spƒõvku do datab√°ze"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO posts 
            (platform, content, hashtags, likes, shares, comments, timestamp, author, sentiment)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            post.platform,
            post.content,
            json.dumps(post.hashtags),
            post.engagement_metrics.get("likes", 0),
            post.engagement_metrics.get("shares", 0),
            post.engagement_metrics.get("comments", 0),
            post.timestamp.isoformat(),
            post.author,
            post.sentiment
        ))
        
        conn.commit()
        conn.close()
    
    def save_template(self, template: ContentTemplate):
        """Ulo≈æen√≠ ≈°ablony do datab√°ze"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO templates 
            (id, name, structure, platform, category, target_engagement)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            template.template_id,
            template.name,
            template.structure,
            template.platform,
            template.category,
            template.target_engagement
        ))
        
        conn.commit()
        conn.close()
    
    def get_posts_by_platform(self, platform: str, limit: int = 100) -> List[SocialMediaPost]:
        """Z√≠sk√°n√≠ p≈ô√≠spƒõvk≈Ø podle platformy"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT platform, content, hashtags, likes, shares, comments, timestamp, author, sentiment
            FROM posts 
            WHERE platform = ? 
            ORDER BY timestamp DESC 
            LIMIT ?
        ''', (platform, limit))
        
        posts = []
        for row in cursor.fetchall():
            post = SocialMediaPost(
                platform=row[0],
                content=row[1],
                hashtags=json.loads(row[2]),
                engagement_metrics={
                    "likes": row[3],
                    "shares": row[4], 
                    "comments": row[5]
                },
                timestamp=datetime.fromisoformat(row[6]),
                author=row[7],
                sentiment=row[8]
            )
            posts.append(post)
        
        conn.close()
        return posts

class EngagementAnalyzer:
    """Analyz√°tor engagement metrik"""
    
    def __init__(self, database: ContentDatabase):
        self.database = database
    
    def calculate_engagement_rate(self, post: SocialMediaPost) -> float:
        """V√Ωpoƒçet engagement rate pro p≈ô√≠spƒõvek"""
        total_engagement = (
            post.engagement_metrics.get("likes", 0) +
            post.engagement_metrics.get("shares", 0) * 2 +  # Shares maj√≠ vy≈°≈°√≠ v√°hu
            post.engagement_metrics.get("comments", 0) * 3   # Comments maj√≠ nejvy≈°≈°√≠ v√°hu
        )
        
        # Simulace poƒçtu followers (v re√°ln√© aplikaci by se z√≠sk√°valo z API)
        estimated_reach = np.random.randint(5000, 50000)
        
        return min(total_engagement / estimated_reach * 100, 100)
    
    def predict_engagement(self, content: str, hashtags: List[str], platform: str) -> float:
        """Predikce engagement na z√°kladƒõ obsahu"""
        # Z√≠sk√°n√≠ historick√Ωch dat
        historical_posts = self.database.get_posts_by_platform(platform)
        
        if not historical_posts:
            return 0.5  # V√Ωchoz√≠ hodnota
        
        # Anal√Ωza sentimentu obsahu
        blob = TextBlob(content)
        sentiment_score = blob.sentiment.polarity
        
        # Anal√Ωza hashtag≈Ø
        hashtag_performance = np.mean([
            0.7 if any(tag.lower() in post.content.lower() for post in historical_posts[-10:])
            else 0.4 for tag in hashtags
        ])
        
        # Kombinovan√Ω score
        predicted_engagement = (
            0.4 * (sentiment_score + 1) / 2 +  # Normalizace sentimentu na 0-1
            0.3 * hashtag_performance +
            0.3 * np.mean([self.calculate_engagement_rate(post) for post in historical_posts[-5:]])
        )
        
        return min(predicted_engagement, 1.0)
    
    def generate_engagement_report(self, platform: str) -> Dict[str, Any]:
        """Generov√°n√≠ reportu o engagement"""
        posts = self.database.get_posts_by_platform(platform, limit=30)
        
        if not posts:
            return {"error": "Nedostatek dat pro anal√Ωzu"}
        
        engagement_rates = [self.calculate_engagement_rate(post) for post in posts]
        
        return {
            "platform": platform,
            "total_posts": len(posts),
            "avg_engagement_rate": np.mean(engagement_rates),
            "max_engagement_rate": np.max(engagement_rates),
            "min_engagement_rate": np.min(engagement_rates),
            "engagement_trend": np.polyfit(range(len(engagement_rates)), engagement_rates, 1)[0],
            "top_performing_hashtags": self._get_top_hashtags(posts)
        }
    
    def _get_top_hashtags(self, posts: List[SocialMediaPost], top_n: int = 5) -> List[str]:
        """Z√≠sk√°n√≠ nejl√©pe performuj√≠c√≠ch hashtag≈Ø"""
        hashtag_performance = {}
        
        for post in posts:
            engagement_rate = self.calculate_engagement_rate(post)
            for hashtag in post.hashtags:
                if hashtag not in hashtag_performance:
                    hashtag_performance[hashtag] = []
                hashtag_performance[hashtag].append(engagement_rate)
        
        # Pr≈Ømƒõrn√° v√Ωkonnost hashtag≈Ø
        avg_performance = {
            hashtag: np.mean(rates) 
            for hashtag, rates in hashtag_performance.items()
        }
        
        return sorted(avg_performance.keys(), key=lambda x: avg_performance[x], reverse=True)[:top_n]

class RAGContentGenerator:
    """RAG syst√©m pro generov√°n√≠ obsahu"""
    
    def __init__(self, openai_api_key: str):
        self.openai_api_key = openai_api_key
        os.environ["OPENAI_API_KEY"] = openai_api_key
        
        # Inicializace RAG komponent
        self.embeddings = OpenAIEmbeddings()
        self.llm = ChatOpenAI(temperature=0.7, model="gpt-4")
        self.vectorstore = None
        self._initialize_knowledge_base()
    
    def _initialize_knowledge_base(self):
        """Inicializace knowledge base s obsahem o social media strategi√≠ch"""
        documents = [
            Document(
                page_content="Instagram preferuje vizu√°ln√≠ obsah s vysokou kvalitou. Nejlep≈°√≠ ƒçasy pro publikov√°n√≠ jsou 11:00-13:00 a 19:00-21:00. Stories maj√≠ vysok√Ω engagement rate.",
                metadata={"platform": "instagram", "type": "best_practices"}
            ),
            Document(
                page_content="Twitter funguje nejl√©pe s kr√°tk√Ωm, vtipn√Ωm obsahem a aktu√°ln√≠mi t√©maty. Pou≈æ√≠vejte maxim√°lnƒõ 2-3 hashtags. Ide√°ln√≠ d√©lka tweetu je 71-100 znak≈Ø.",
                metadata={"platform": "twitter", "type": "best_practices"}
            ),
            Document(
                page_content="LinkedIn je profesn√≠ s√≠≈• zamƒõ≈ôen√° na B2B obsah, thought leadership a industry insights. Dlouh√Ω content performuje l√©pe ne≈æ kr√°tk√Ω.",
                metadata={"platform": "linkedin", "type": "best_practices"}
            ),
            Document(
                page_content="Hashtag research: Pou≈æ√≠vejte mix popul√°rn√≠ch (#fashion - 500M+) a niche hashtag≈Ø (#sustainablefashion - 1M+). Optim√°ln√≠ poƒçet hashtag≈Ø na Instagramu je 5-10.",
                metadata={"type": "hashtag_strategy"}
            ),
            Document(
                page_content="Engagement boosting: Kladte ot√°zky, pou≈æ√≠vejte emoji, publikujte v optim√°ln√≠ch ƒçasech, odpov√≠dejte na koment√°≈ôe rychle.",
                metadata={"type": "engagement_strategy"}
            )
        ]
        
        # Vytvo≈ôen√≠ vector store
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory="./chroma_db"
        )
    
    def generate_content(self, 
                        platform: str, 
                        topic: str, 
                        brand_guidelines: BrandGuideline,
                        target_engagement: float = 0.7) -> Dict[str, Any]:
        """Generov√°n√≠ obsahu pomoc√≠ RAG"""
        
        # Vyhled√°n√≠ relevantn√≠ch informac√≠
        relevant_docs = self.vectorstore.similarity_search(
            f"{platform} {topic} best practices", k=3
        )
        
        context = "\n".join([doc.page_content for doc in relevant_docs])
        
        # Prompt template
        prompt_template = ChatPromptTemplate.from_template("""
        Jsi expert na social media marketing. Vytvo≈ô obsah pro {platform} na t√©ma {topic}.

        Kontext z knowledge base:
        {context}

        Brand guidelines:
        - N√°zev znaƒçky: {brand_name}
        - Tone of voice: {tone_of_voice}
        - Kl√≠ƒçov√© zpr√°vy: {key_messages}
        - C√≠lov√° audience: {target_audience}

        Vytvo≈ô:
        1. Hlavn√≠ text p≈ô√≠spƒõvku (respektuj limity platformy)
        2. 5-8 relevantn√≠ch hashtag≈Ø
        3. Doporuƒçen√Ω ƒças publikov√°n√≠
        4. N√°vrh na vizu√°ln√≠ obsah
        5. Call-to-action

        Odpovƒõz ve form√°tu JSON.
        """)
        
        # Generov√°n√≠ obsahu
        chain = prompt_template | self.llm
        
        try:
            response = chain.invoke({
                "platform": platform,
                "topic": topic,
                "context": context,
                "brand_name": brand_guidelines.brand_name,
                "tone_of_voice": brand_guidelines.tone_of_voice,
                "key_messages": ", ".join(brand_guidelines.key_messages),
                "target_audience": brand_guidelines.target_audience
            })
            
            # Parsing odpovƒõdi (zjednodu≈°eno)
            content_suggestion = {
                "platform": platform,
                "topic": topic,
                "generated_content": response.content,
                "confidence_score": 0.85,  # Simulace
                "estimated_engagement": target_engagement * 0.9  # Konzervativn√≠ odhad
            }
            
            return content_suggestion
            
        except Exception as e:
            return {
                "error": f"Chyba p≈ôi generov√°n√≠ obsahu: {str(e)}",
                "fallback_content": f"Zaj√≠mav√Ω obsah o {topic} pro {platform}! üöÄ #trending"
            }

class SocialMediaAssistant:
    """Hlavn√≠ t≈ô√≠da pro Social Media Content Strategy Assistant"""
    
    def __init__(self, openai_api_key: str):
        self.database = ContentDatabase()
        self.trend_analyzer = TrendAnalyzer()
        self.engagement_analyzer = EngagementAnalyzer(self.database)
        self.rag_generator = RAGContentGenerator(openai_api_key)
        
        # V√Ωchoz√≠ brand guidelines
        self.brand_guidelines = BrandGuideline(
            brand_name="TechStart",
            tone_of_voice="P≈ô√°telsk√Ω, odborn√Ω, inspirativn√≠",
            key_messages=["Inovace", "Kvalita", "Z√°kaznick√° spokojenost"],
            prohibited_topics=["Politika", "N√°bo≈æenstv√≠"],
            color_scheme={"primary": "#007bff", "secondary": "#6c757d"},
            target_audience="Tech-savvy professionals aged 25-45"
        )
    
    async def create_content_strategy(self, platform: str, days: int = 7) -> Dict[str, Any]:
        """Vytvo≈ôen√≠ obsahov√© strategie na zadan√© obdob√≠"""
        
        # Anal√Ωza trend≈Ø
        trending_topics = self.trend_analyzer.get_trending_topics(platform, limit=5)
        
        # Generov√°n√≠ engagement reportu
        engagement_report = self.engagement_analyzer.generate_engagement_report(platform)
        
        # Pl√°n obsahu
        content_plan = []
        
        for day in range(days):
            # V√Ωbƒõr t√©matu na z√°kladƒõ trend≈Ø
            topic = trending_topics[day % len(trending_topics)]["keyword"]
            
            # Generov√°n√≠ obsahu
            content_suggestion = self.rag_generator.generate_content(
                platform=platform,
                topic=topic,
                brand_guidelines=self.brand_guidelines
            )
            
            # Predikce engagement
            if "generated_content" in content_suggestion:
                predicted_engagement = self.engagement_analyzer.predict_engagement(
                    content_suggestion["generated_content"],
                    [],  # Zjednodu≈°eno
                    platform
                )
                content_suggestion["predicted_engagement"] = predicted_engagement
            
            content_plan.append({
                "day": day + 1,
                "topic": topic,
                "content": content_suggestion
            })
        
        return {
            "platform": platform,
            "period_days": days,
            "trending_topics": trending_topics,
            "engagement_report": engagement_report,
            "content_plan": content_plan,
            "strategy_score": np.mean([
                item["content"].get("predicted_engagement", 0.5) 
                for item in content_plan
            ])
        }
    
    def analyze_competitor_content(self, competitor_posts: List[str]) -> Dict[str, Any]:
        """Anal√Ωza obsahu konkurence"""
        competitor_analysis = {
            "total_posts_analyzed": len(competitor_posts),
            "avg_sentiment": 0,
            "common_themes": [],
            "hashtag_usage": {},
            "content_recommendations": []
        }
        
        if not competitor_posts:
            return competitor_analysis
        
        # Anal√Ωza sentimentu
        sentiments = []
        themes = []
        
        for post in competitor_posts:
            blob = TextBlob(post)
            sentiments.append(blob.sentiment.polarity)
            
            # Extrakce t√©mat (zjednodu≈°eno)
            words = post.lower().split()
            themes.extend([word for word in words if len(word) > 4])
        
        competitor_analysis["avg_sentiment"] = np.mean(sentiments)
        
        # Nejƒçastƒõj≈°√≠ t√©mata
        from collections import Counter
        theme_counts = Counter(themes)
        competitor_analysis["common_themes"] = theme_counts.most_common(5)
        
        # Doporuƒçen√≠
        competitor_analysis["content_recommendations"] = [
            "Zamƒõ≈ôte se na pozitivnƒõj≈°√≠ tone of voice" if np.mean(sentiments) < 0.3 else "Udr≈æujte pozitivn√≠ komunikaci",
            f"Vyu≈æijte popul√°rn√≠ t√©mata: {', '.join([theme[0] for theme in theme_counts.most_common(3)])}"
        ]
        
        return competitor_analysis
    
    def generate_hashtag_strategy(self, topic: str, platform: str) -> Dict[str, Any]:
        """Generov√°n√≠ hashtag strategie"""
        
        # Anal√Ωza v√Ωkonnosti hashtag≈Ø
        hashtag_suggestions = [
            f"#{topic.lower().replace(' ', '')}",
            f"#{platform.lower()}",
            "#marketing",
            "#socialmedia",
            "#content"
        ]
        
        performance = self.trend_analyzer.analyze_hashtag_performance(hashtag_suggestions)
        
        return {
            "topic": topic,
            "platform": platform,
            "recommended_hashtags": hashtag_suggestions,
            "hashtag_performance": performance,
            "strategy_tips": [
                "Kombinujte popul√°rn√≠ a niche hashtagy",
                "Sledujte v√Ωkonnost a upravte strategii",
                "Nepou≈æ√≠vejte p≈ô√≠li≈° mnoho hashtag≈Ø najednou"
            ]
        }
    
    def export_strategy_report(self, strategy_data: Dict[str, Any], filename: str = None) -> str:
        """Export strategie do souboru"""
        if filename is None:
            filename = f"social_media_strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(strategy_data, f, ensure_ascii=False, indent=2, default=str)
            
            return f"Strategie √∫spƒõ≈°nƒõ exportov√°na do {filename}"
        
        except Exception as e:
            return f"Chyba p≈ôi exportu: {str(e)}"

# Demonstraƒçn√≠ funkce
async def main_demo():
    """Hlavn√≠ demonstraƒçn√≠ funkce"""
    
    # Inicializace (vy≈æaduje OpenAI API key)
    # assistant = SocialMediaAssistant("your-openai-api-key")
    
    print("üöÄ Social Media Content Strategy Assistant - Demo")
    print("=" * 50)
    
    # Simulace bez API key
    try:
        assistant = SocialMediaAssistant("demo-key")
        
        # Vytvo≈ôen√≠ obsahov√© strategie
        print("\nüìä Vytv√°≈ôen√≠ obsahov√© strategie pro Instagram...")
        strategy = await assistant.create_content_strategy("instagram", days=3)
        
        print(f"‚úÖ Strategie vytvo≈ôena s sk√≥re: {strategy['strategy_score']:.2f}")
        print(f"üìà Trending topics: {[t['keyword'] for t in strategy['trending_topics'][:3]]}")
        
        # Hashtag strategie
        print("\nüè∑Ô∏è  Generov√°n√≠ hashtag strategie...")
        hashtag_strategy = assistant.generate_hashtag_strategy("AI technology", "instagram")
        print(f"‚úÖ Doporuƒçen√© hashtagy: {hashtag_strategy['recommended_hashtags'][:3]}")
        
        # Anal√Ωza konkurence
        print("\nüîç Anal√Ωza konkurenƒçn√≠ho obsahu...")
        competitor_posts = [
            "Nov√° technologie AI mƒõn√≠ svƒõt! #AI #tech #future",
            "Udr≈æitelnost je budoucnost. Jak m≈Ø≈æeme pomoci? #sustainability #green",
            "Remote work tips pro vy≈°≈°√≠ produktivitu #remotework #productivity"
        ]
        
        competitor_analysis = assistant.analyze_competitor_content(competitor_posts)
        print(f"‚úÖ Analyzov√°no {competitor_analysis['total_posts_analyzed']} p≈ô√≠spƒõvk≈Ø")
        print(f"üìä Pr≈Ømƒõrn√Ω sentiment: {competitor_analysis['avg_sentiment']:.2f}")
        
        # Export strategie
        print("\nüíæ Export strategie...")
        export_result = assistant.export_strategy_report(strategy)
        print(f"‚úÖ {export_result}")
        
    except Exception as e:
        print(f"‚ùå Demo error: {str(e)}")
        print("üí° Pro plnou funkcionalnost je pot≈ôeba OpenAI API key")

if __name__ == "__main__":
    asyncio.run(main_demo())
````

## Shrnut√≠ projektu

**Social Media Content Strategy Assistant** p≈ôedstavuje komplexn√≠ ≈ôe≈°en√≠ pro automatizaci a optimalizaci social media marketingu pomoc√≠ pokroƒçil√Ωch AI technologi√≠. Projekt kombinuje RAG architekturu s anal√Ωzou trend≈Ø, engagement metrik a brand guidelines pro vytv√°≈ôen√≠ efektivn√≠ obsahov√© strategie.

### Kl√≠ƒçov√© v√Ωhody:

- **Automatizace content strategie** s vyu≈æit√≠m AI a machine learning
- **Real-time anal√Ωza trend≈Ø** pro maximalizaci dosahu obsahu
- **Predikce engagement** na z√°kladƒõ historick√Ωch dat
- **Multi-platform optimalizace** pro r≈Øzn√© soci√°ln√≠ s√≠tƒõ
- **Brand consistency** prost≈ôednictv√≠m dodr≈æov√°n√≠ brand guidelines

### Technologick√© komponenty:

- **RAG syst√©m** (LangChain, OpenAI, Chroma) pro inteligentn√≠ generov√°n√≠ obsahu
- **Trend analysis** pro sledov√°n√≠ aktu√°ln√≠ch t√©mat
- **Engagement analytics** pro optimalizaci v√Ωkonnosti
- **Database management** (SQLite) pro ukl√°d√°n√≠ historick√Ωch dat
- **API integrace** pro p≈ôipojen√≠ k soci√°ln√≠m s√≠t√≠m

### Praktick√© vyu≈æit√≠:

Syst√©m je ide√°ln√≠ pro marketing t√Ωmy, social media mana≈æery a digital marketing agentury, kter√© chtƒõj√≠ zv√Ω≈°it efektivitu sv√© contenov√© strategie a dos√°hnout lep≈°√≠ch v√Ωsledk≈Ø s men≈°√≠mi n√°klady na tvorbu obsahu.