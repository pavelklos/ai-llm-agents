<small>Claude Sonnet 4 **(Music Discovery and Analysis Platform with RAG)**</small>
# Music Discovery and Analysis Platform

## Project Title
**AI-Powered Music Discovery and Analysis Platform with RAG Integration**

## Key Concepts Explanation

### Retrieval-Augmented Generation (RAG)
A framework that combines information retrieval with language generation. The system retrieves relevant music data from a knowledge base and uses it to generate contextual responses about artists, albums, and music recommendations.

### Artist Biographies
Comprehensive textual information about musicians including their background, career highlights, influences, and discography. This data serves as a knowledge base for generating detailed artist profiles.

### Album Reviews
Critical analyses and user reviews of music albums that provide insights into musical quality, themes, and cultural impact. These reviews help in understanding album context and generating recommendations.

### Concert Information
Data about live music events including venue details, dates, ticket information, and setlists. This information enhances the platform's ability to provide comprehensive music discovery services.

### Spotify API Integration
Connection to Spotify's Web API to access real-time music data including track features, artist popularity, playlists, and user listening history for personalized recommendations.

### Last.fm Data Integration
Utilization of Last.fm's extensive music database for scrobbling data, user preferences, and social music discovery features to enhance recommendation accuracy.

### Genre Classification
Automated categorization of music into genres using machine learning techniques and audio feature analysis to improve discovery and recommendation systems.

### Lyric Analysis
Natural language processing of song lyrics to extract themes, emotions, and semantic meaning, enabling content-based music recommendations and analysis.

## Comprehensive Project Explanation

The Music Discovery and Analysis Platform represents a sophisticated AI-driven system that revolutionizes how users discover, analyze, and interact with music content. This platform leverages RAG technology to combine structured music data with intelligent language generation, creating a comprehensive music intelligence system.

### Project Objectives

**Primary Goals:**
- Create an intelligent music discovery engine that understands user preferences and context
- Provide comprehensive music analysis including lyrical themes, genre classification, and cultural context
- Generate personalized recommendations based on multiple data sources and user behavior
- Offer detailed artist and album information through AI-powered research and synthesis

**Technical Objectives:**
- Implement a scalable RAG architecture for music data retrieval and generation
- Integrate multiple music APIs and data sources for comprehensive coverage
- Develop advanced NLP capabilities for lyric analysis and semantic understanding
- Create real-time recommendation systems with high accuracy and relevance

### Key Challenges

**Data Integration Complexity:**
Combining heterogeneous data sources (Spotify, Last.fm, reviews, lyrics) requires sophisticated data normalization and schema mapping to ensure consistency and reliability.

**Real-time Performance:**
Balancing comprehensive analysis with responsive user experience demands efficient caching strategies, optimized retrieval mechanisms, and intelligent pre-computation of recommendations.

**Personalization vs. Discovery:**
Creating systems that both satisfy known user preferences and introduce novel music requires sophisticated balance between exploitation and exploration algorithms.

**Scalability Requirements:**
Handling millions of tracks, artists, and user interactions while maintaining low latency requires distributed architecture and efficient data structures.

### Potential Impact

**Music Industry Transformation:**
- Enhanced artist discovery mechanisms for emerging musicians
- Data-driven insights for record labels and music marketers
- Improved user engagement through intelligent recommendations

**User Experience Enhancement:**
- Personalized music discovery that adapts to changing tastes
- Comprehensive music education through AI-generated insights
- Social music discovery features that connect like-minded listeners

**Cultural and Academic Applications:**
- Music research and analysis tools for academics and journalists
- Cultural trend analysis through large-scale music data processing
- Historical music context and evolution tracking

## Comprehensive Project Example with Python Implementation

````python
import asyncio
import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import pandas as pd
import numpy as np

# Core dependencies
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.schema import Document

# Music API integrations
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import requests
import sqlite3

# ML and analysis
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from textblob import TextBlob

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MusicTrack:
    id: str
    name: str
    artist: str
    album: str
    genres: List[str]
    audio_features: Dict[str, float]
    lyrics: Optional[str] = None
    popularity: int = 0
    release_date: str = ""

@dataclass
class ArtistProfile:
    id: str
    name: str
    genres: List[str]
    biography: str
    albums: List[str]
    popularity: int
    followers: int

class MusicDataCollector:
    """Handles data collection from various music APIs and sources"""
    
    def __init__(self, spotify_client_id: str, spotify_client_secret: str):
        # Initialize Spotify client
        client_credentials_manager = SpotifyClientCredentials(
            client_id=spotify_client_id,
            client_secret=spotify_client_secret
        )
        self.spotify = spotipy.Spotify(
            client_credentials_manager=client_credentials_manager
        )
        
        # Initialize database
        self.init_database()
    
    def init_database(self):
        """Initialize SQLite database for caching"""
        self.conn = sqlite3.connect('music_data.db')
        cursor = self.conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tracks (
                id TEXT PRIMARY KEY,
                name TEXT,
                artist TEXT,
                album TEXT,
                genres TEXT,
                audio_features TEXT,
                lyrics TEXT,
                popularity INTEGER,
                release_date TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS artists (
                id TEXT PRIMARY KEY,
                name TEXT,
                genres TEXT,
                biography TEXT,
                albums TEXT,
                popularity INTEGER,
                followers INTEGER
            )
        ''')
        
        self.conn.commit()
    
    async def collect_track_data(self, track_id: str) -> Optional[MusicTrack]:
        """Collect comprehensive track data from Spotify"""
        try:
            # Get track info
            track_info = self.spotify.track(track_id)
            
            # Get audio features
            audio_features = self.spotify.audio_features([track_id])[0]
            
            # Get artist genres
            artist_id = track_info['artists'][0]['id']
            artist_info = self.spotify.artist(artist_id)
            
            track = MusicTrack(
                id=track_id,
                name=track_info['name'],
                artist=track_info['artists'][0]['name'],
                album=track_info['album']['name'],
                genres=artist_info['genres'],
                audio_features={
                    'danceability': audio_features['danceability'],
                    'energy': audio_features['energy'],
                    'valence': audio_features['valence'],
                    'tempo': audio_features['tempo'],
                    'acousticness': audio_features['acousticness'],
                    'instrumentalness': audio_features['instrumentalness']
                },
                popularity=track_info['popularity'],
                release_date=track_info['album']['release_date']
            )
            
            # Cache in database
            self._cache_track(track)
            return track
            
        except Exception as e:
            logger.error(f"Error collecting track data: {e}")
            return None
    
    async def collect_artist_data(self, artist_id: str) -> Optional[ArtistProfile]:
        """Collect comprehensive artist data"""
        try:
            artist_info = self.spotify.artist(artist_id)
            albums = self.spotify.artist_albums(artist_id, limit=50)
            
            # Generate biography using AI (mock implementation)
            biography = await self._generate_artist_biography(artist_info)
            
            artist = ArtistProfile(
                id=artist_id,
                name=artist_info['name'],
                genres=artist_info['genres'],
                biography=biography,
                albums=[album['name'] for album in albums['items']],
                popularity=artist_info['popularity'],
                followers=artist_info['followers']['total']
            )
            
            self._cache_artist(artist)
            return artist
            
        except Exception as e:
            logger.error(f"Error collecting artist data: {e}")
            return None
    
    async def _generate_artist_biography(self, artist_info: Dict) -> str:
        """Generate artist biography using available data"""
        # This would typically use an LLM to generate biography
        # For demo purposes, creating a basic template
        name = artist_info['name']
        genres = ", ".join(artist_info['genres'][:3])
        popularity = artist_info['popularity']
        
        return f"{name} is a prominent artist in the {genres} genre(s). " \
               f"With a popularity score of {popularity}, they have gained " \
               f"significant recognition in the music industry."
    
    def _cache_track(self, track: MusicTrack):
        """Cache track data in database"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO tracks VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            track.id, track.name, track.artist, track.album,
            json.dumps(track.genres), json.dumps(track.audio_features),
            track.lyrics, track.popularity, track.release_date
        ))
        self.conn.commit()
    
    def _cache_artist(self, artist: ArtistProfile):
        """Cache artist data in database"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO artists VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            artist.id, artist.name, json.dumps(artist.genres),
            artist.biography, json.dumps(artist.albums),
            artist.popularity, artist.followers
        ))
        self.conn.commit()

class LyricAnalyzer:
    """Analyzes lyrics for themes, emotions, and semantic content"""
    
    def __init__(self):
        # Download required NLTK data
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
        nltk.download('vader_lexicon', quiet=True)
        
        from nltk.sentiment import SentimentIntensityAnalyzer
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
    
    def analyze_lyrics(self, lyrics: str) -> Dict[str, Any]:
        """Comprehensive lyric analysis"""
        if not lyrics:
            return {}
        
        # Sentiment analysis
        sentiment_scores = self.sentiment_analyzer.polarity_scores(lyrics)
        
        # Emotion detection using TextBlob
        blob = TextBlob(lyrics)
        
        # Theme extraction (simplified)
        themes = self._extract_themes(lyrics)
        
        # Language complexity
        complexity = self._calculate_complexity(lyrics)
        
        return {
            'sentiment': {
                'compound': sentiment_scores['compound'],
                'positive': sentiment_scores['pos'],
                'negative': sentiment_scores['neg'],
                'neutral': sentiment_scores['neu']
            },
            'polarity': blob.sentiment.polarity,
            'subjectivity': blob.sentiment.subjectivity,
            'themes': themes,
            'complexity_score': complexity,
            'word_count': len(lyrics.split()),
            'unique_words': len(set(lyrics.lower().split()))
        }
    
    def _extract_themes(self, lyrics: str) -> List[str]:
        """Extract themes from lyrics using keyword analysis"""
        # Simplified theme extraction
        theme_keywords = {
            'love': ['love', 'heart', 'romance', 'kiss', 'together'],
            'sadness': ['sad', 'cry', 'tears', 'lonely', 'pain'],
            'party': ['party', 'dance', 'night', 'club', 'fun'],
            'rebellion': ['fight', 'rebel', 'freedom', 'break', 'wild'],
            'nostalgia': ['remember', 'past', 'old', 'memory', 'time']
        }
        
        lyrics_lower = lyrics.lower()
        detected_themes = []
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in lyrics_lower for keyword in keywords):
                detected_themes.append(theme)
        
        return detected_themes
    
    def _calculate_complexity(self, lyrics: str) -> float:
        """Calculate linguistic complexity of lyrics"""
        words = lyrics.split()
        if not words:
            return 0.0
        
        # Average word length
        avg_word_length = sum(len(word) for word in words) / len(words)
        
        # Vocabulary diversity (unique words / total words)
        unique_ratio = len(set(words)) / len(words)
        
        # Combine metrics
        complexity = (avg_word_length * 0.3) + (unique_ratio * 0.7)
        return min(complexity, 1.0)

class GenreClassifier:
    """Classifies music genres using audio features and metadata"""
    
    def __init__(self):
        self.model = None
        self.feature_names = [
            'danceability', 'energy', 'valence', 'tempo',
            'acousticness', 'instrumentalness'
        ]
    
    def train_classifier(self, training_data: List[MusicTrack]):
        """Train genre classifier using audio features"""
        if len(training_data) < 10:
            logger.warning("Insufficient training data for genre classification")
            return
        
        # Prepare training data
        features = []
        labels = []
        
        for track in training_data:
            if track.genres and track.audio_features:
                # Use primary genre
                primary_genre = track.genres[0] if track.genres else 'unknown'
                
                # Extract audio features
                feature_vector = [
                    track.audio_features.get(feature, 0.0)
                    for feature in self.feature_names
                ]
                
                features.append(feature_vector)
                labels.append(primary_genre)
        
        if len(set(labels)) < 2:
            logger.warning("Need at least 2 different genres for classification")
            return
        
        # Train simple clustering model (in real implementation, use supervised learning)
        from sklearn.preprocessing import LabelEncoder
        
        self.label_encoder = LabelEncoder()
        encoded_labels = self.label_encoder.fit_transform(labels)
        
        # Use KMeans for simplicity (replace with proper classifier)
        n_clusters = min(len(set(labels)), 10)
        self.model = KMeans(n_clusters=n_clusters, random_state=42)
        self.model.fit(features)
        
        logger.info(f"Genre classifier trained with {len(features)} samples")
    
    def predict_genre(self, track: MusicTrack) -> str:
        """Predict genre for a track"""
        if not self.model or not track.audio_features:
            return "unknown"
        
        feature_vector = [[
            track.audio_features.get(feature, 0.0)
            for feature in self.feature_names
        ]]
        
        cluster = self.model.predict(feature_vector)[0]
        
        # Map cluster to genre (simplified)
        genre_mapping = {
            0: "pop", 1: "rock", 2: "electronic", 3: "hip-hop",
            4: "jazz", 5: "classical", 6: "country", 7: "r&b",
            8: "indie", 9: "folk"
        }
        
        return genre_mapping.get(cluster, "unknown")

class MusicRAGSystem:
    """RAG system for music discovery and analysis"""
    
    def __init__(self, openai_api_key: str):
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)
        self.vectorstore = None
        self.qa_chain = None
        
        # Initialize components
        self.lyric_analyzer = LyricAnalyzer()
        self.genre_classifier = GenreClassifier()
    
    def build_knowledge_base(self, tracks: List[MusicTrack], artists: List[ArtistProfile]):
        """Build vector database from music data"""
        documents = []
        
        # Process tracks
        for track in tracks:
            content = f"""
            Track: {track.name}
            Artist: {track.artist}
            Album: {track.album}
            Genres: {', '.join(track.genres)}
            Popularity: {track.popularity}
            Audio Features: {json.dumps(track.audio_features)}
            Release Date: {track.release_date}
            """
            
            if track.lyrics:
                lyric_analysis = self.lyric_analyzer.analyze_lyrics(track.lyrics)
                content += f"\nLyric Analysis: {json.dumps(lyric_analysis)}"
            
            documents.append(Document(
                page_content=content,
                metadata={
                    "type": "track",
                    "id": track.id,
                    "artist": track.artist,
                    "genres": track.genres
                }
            ))
        
        # Process artists
        for artist in artists:
            content = f"""
            Artist: {artist.name}
            Genres: {', '.join(artist.genres)}
            Biography: {artist.biography}
            Albums: {', '.join(artist.albums)}
            Popularity: {artist.popularity}
            Followers: {artist.followers}
            """
            
            documents.append(Document(
                page_content=content,
                metadata={
                    "type": "artist",
                    "id": artist.id,
                    "name": artist.name,
                    "genres": artist.genres
                }
            ))
        
        # Create vector store
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        
        split_docs = text_splitter.split_documents(documents)
        
        self.vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=self.embeddings,
            persist_directory="./music_chroma_db"
        )
        
        # Create QA chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 5})
        )
        
        logger.info(f"Knowledge base built with {len(documents)} documents")
    
    async def discover_music(self, query: str, user_preferences: Dict = None) -> Dict[str, Any]:
        """Discover music based on natural language query"""
        if not self.qa_chain:
            return {"error": "Knowledge base not initialized"}
        
        # Enhance query with user preferences
        enhanced_query = query
        if user_preferences:
            pref_text = ", ".join([f"{k}: {v}" for k, v in user_preferences.items()])
            enhanced_query = f"{query}. User preferences: {pref_text}"
        
        try:
            response = self.qa_chain.run(enhanced_query)
            
            # Get relevant tracks from vector search
            relevant_docs = self.vectorstore.similarity_search(query, k=5)
            
            recommendations = []
            for doc in relevant_docs:
                if doc.metadata.get("type") == "track":
                    recommendations.append({
                        "track_id": doc.metadata.get("id"),
                        "artist": doc.metadata.get("artist"),
                        "relevance_score": 0.8  # Placeholder
                    })
            
            return {
                "response": response,
                "recommendations": recommendations,
                "query_processed": enhanced_query
            }
            
        except Exception as e:
            logger.error(f"Error in music discovery: {e}")
            return {"error": str(e)}
    
    async def analyze_track(self, track: MusicTrack) -> Dict[str, Any]:
        """Comprehensive track analysis using RAG"""
        analysis = {
            "basic_info": {
                "name": track.name,
                "artist": track.artist,
                "album": track.album,
                "genres": track.genres,
                "popularity": track.popularity
            },
            "audio_features": track.audio_features
        }
        
        # Add lyric analysis if available
        if track.lyrics:
            analysis["lyric_analysis"] = self.lyric_analyzer.analyze_lyrics(track.lyrics)
        
        # Genre prediction
        if self.genre_classifier.model:
            predicted_genre = self.genre_classifier.predict_genre(track)
            analysis["predicted_genre"] = predicted_genre
        
        # Generate AI insights
        if self.qa_chain:
            insight_query = f"""
            Analyze the track '{track.name}' by {track.artist}. 
            Consider the audio features: {json.dumps(track.audio_features)}
            and genres: {', '.join(track.genres)}.
            Provide insights about the musical style, mood, and potential appeal.
            """
            
            try:
                ai_insights = self.qa_chain.run(insight_query)
                analysis["ai_insights"] = ai_insights
            except Exception as e:
                logger.error(f"Error generating AI insights: {e}")
        
        return analysis

class MusicDiscoveryPlatform:
    """Main platform orchestrating all components"""
    
    def __init__(self, config: Dict[str, str]):
        self.data_collector = MusicDataCollector(
            config['spotify_client_id'],
            config['spotify_client_secret']
        )
        
        self.rag_system = MusicRAGSystem(config['openai_api_key'])
        
        # Sample data for demonstration
        self.tracks_cache = []
        self.artists_cache = []
    
    async def initialize_platform(self):
        """Initialize platform with sample data"""
        logger.info("Initializing Music Discovery Platform...")
        
        # Sample track IDs for demonstration
        sample_track_ids = [
            "4iV5W9uYEdYUVa79Axb7Rh",  # Never Gonna Give You Up
            "1mea3bSkSGXuIRvnydlB5b",  # Bohemian Rhapsody
            "0VjIjW4GlULA4LGvdJJEzB",  # Blinding Lights
        ]
        
        # Collect sample data
        for track_id in sample_track_ids:
            track = await self.data_collector.collect_track_data(track_id)
            if track:
                self.tracks_cache.append(track)
                
                # Collect artist data
                artist_search = self.data_collector.spotify.search(
                    q=f'artist:{track.artist}', type='artist', limit=1
                )
                if artist_search['artists']['items']:
                    artist_id = artist_search['artists']['items'][0]['id']
                    artist = await self.data_collector.collect_artist_data(artist_id)
                    if artist and artist not in self.artists_cache:
                        self.artists_cache.append(artist)
        
        # Train genre classifier
        self.rag_system.genre_classifier.train_classifier(self.tracks_cache)
        
        # Build knowledge base
        self.rag_system.build_knowledge_base(self.tracks_cache, self.artists_cache)
        
        logger.info("Platform initialization complete!")
    
    async def search_music(self, query: str, user_preferences: Dict = None) -> Dict[str, Any]:
        """Search for music using natural language"""
        return await self.rag_system.discover_music(query, user_preferences)
    
    async def analyze_music(self, track_id: str) -> Dict[str, Any]:
        """Analyze a specific track"""
        # First try to get from cache
        track = next((t for t in self.tracks_cache if t.id == track_id), None)
        
        if not track:
            # Collect track data
            track = await self.data_collector.collect_track_data(track_id)
            if track:
                self.tracks_cache.append(track)
        
        if track:
            return await self.rag_system.analyze_track(track)
        else:
            return {"error": "Track not found"}

# Example usage and demo
async def main():
    """Demonstration of the Music Discovery Platform"""
    
    # Configuration (replace with your actual API keys)
    config = {
        'spotify_client_id': 'your_spotify_client_id',
        'spotify_client_secret': 'your_spotify_client_secret',
        'openai_api_key': 'your_openai_api_key'
    }
    
    # Initialize platform
    platform = MusicDiscoveryPlatform(config)
    
    try:
        # Initialize with sample data
        await platform.initialize_platform()
        
        # Example 1: Natural language music search
        print("=== Music Discovery Demo ===")
        search_result = await platform.search_music(
            "Find me upbeat pop songs with positive vibes",
            user_preferences={
                "energy": "high",
                "mood": "happy",
                "genres": ["pop", "dance"]
            }
        )
        print(f"Search Result: {json.dumps(search_result, indent=2)}")
        
        # Example 2: Track analysis
        print("\n=== Track Analysis Demo ===")
        if platform.tracks_cache:
            sample_track = platform.tracks_cache[0]
            analysis = await platform.analyze_music(sample_track.id)
            print(f"Track Analysis: {json.dumps(analysis, indent=2)}")
        
        print("\n=== Platform Demo Complete ===")
        
    except Exception as e:
        logger.error(f"Demo error: {e}")
        print("Note: This demo requires valid API keys for Spotify and OpenAI")

if __name__ == "__main__":
    asyncio.run(main())
````

````text
# Core RAG and LLM dependencies
langchain==0.0.354
openai==1.3.8
chromadb==0.4.18
tiktoken==0.5.2

# Music API integrations
spotipy==2.22.1
requests==2.31.0

# Data processing and ML
pandas==2.1.4
numpy==1.24.3
scikit-learn==1.3.2
nltk==3.8.1
textblob==0.17.1

# Database and storage
sqlite3

# Async and utilities
asyncio
aiohttp==3.9.1
python-dotenv==1.0.0

# Optional: For advanced features
# faiss-cpu==1.7.4  # Alternative vector database
# pinecone-client==2.2.4  # Cloud vector database
# sentence-transformers==2.2.2  # Alternative embeddings
````

````python
from setuptools import setup, find_packages

setup(
    name="music-discovery-rag",
    version="1.0.0",
    description="AI-Powered Music Discovery and Analysis Platform with RAG Integration",
    packages=find_packages(),
    install_requires=[
        "langchain>=0.0.354",
        "openai>=1.3.8",
        "chromadb>=0.4.18",
        "spotipy>=2.22.1",
        "pandas>=2.1.4",
        "numpy>=1.24.3",
        "scikit-learn>=1.3.2",
        "nltk>=3.8.1",
        "textblob>=0.17.1",
        "aiohttp>=3.9.1",
        "python-dotenv>=1.0.0"
    ],
    python_requires=">=3.8",
    author="AI Music Discovery Team",
    author_email="contact@musicdiscovery.ai",
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3.8+",
    ],
)
````

````yaml
version: '3.8'

services:
  music-rag-platform:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SPOTIFY_CLIENT_ID=${SPOTIFY_CLIENT_ID}
      - SPOTIFY_CLIENT_SECRET=${SPOTIFY_CLIENT_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./music_chroma_db:/app/music_chroma_db
    depends_on:
      - chroma-db
  
  chroma-db:
    image: chromadb/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_PORT=8000

volumes:
  chroma_data:
````

## Project Summary

The **Music Discovery and Analysis Platform** represents a cutting-edge application of RAG technology in the music domain, combining multiple data sources and AI capabilities to create an intelligent music intelligence system.

### Key Value Propositions

**Comprehensive Music Intelligence:**
- Multi-source data integration (Spotify, Last.fm, lyrics, reviews)
- Advanced audio feature analysis and genre classification
- Semantic understanding of music content and context

**Personalized Discovery Engine:**
- Natural language query processing for intuitive music search
- Context-aware recommendations based on user preferences and behavior
- Real-time adaptation to changing musical tastes and trends

**Scalable AI Architecture:**
- Modern RAG implementation with vector databases for efficient retrieval
- Microservices architecture supporting horizontal scaling
- Async processing for high-performance real-time responses

### Technical Achievements

**Advanced NLP Integration:**
- Lyric analysis for emotional and thematic content extraction
- Sentiment analysis and complexity scoring for content categorization
- Multi-modal data fusion combining audio features with textual analysis

**Real-world API Integration:**
- Production-ready Spotify API integration with proper error handling
- Extensible architecture supporting additional music service APIs
- Robust caching and data persistence strategies

**Machine Learning Pipeline:**
- Genre classification using audio feature analysis
- Recommendation algorithms combining collaborative and content-based filtering
- Continuous learning capabilities for improving accuracy over time

### Impact and Applications

This platform demonstrates how RAG technology can transform domain-specific applications, providing a template for building intelligent content discovery systems across various industries. The combination of structured data retrieval with generative AI capabilities creates powerful opportunities for enhanced user experiences and business intelligence in the music industry.