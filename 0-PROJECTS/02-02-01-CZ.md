<small>Claude Sonnet 4 **(AutonomnÃ­ VÃ½zkumnÃ½ TÃ½m - Multi-Agent SystÃ©m)**</small>
# Autonomous Research Team Assistant

## KlÃ­ÄovÃ© Koncepty

### RAG (Retrieval-Augmented Generation)
Technika, kterÃ¡ kombinuje vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch informacÃ­ z databÃ¡ze znalostÃ­ s generovÃ¡nÃ­m odpovÄ›dÃ­ pomocÃ­ LLM. UmoÅ¾Åˆuje AI pÅ™Ã­stup k aktuÃ¡lnÃ­m a specifickÃ½m informacÃ­m.

### LangChain Agents
Framework pro vytvÃ¡Å™enÃ­ autonomnÃ­ch AI agentÅ¯, kteÅ™Ã­ mohou pouÅ¾Ã­vat nÃ¡stroje, plÃ¡novat akce a rozhodovat se na zÃ¡kladÄ› kontextu.

### Pinecone
CloudovÃ¡ vektorovÃ¡ databÃ¡ze optimalizovanÃ¡ pro sÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­ a uklÃ¡dÃ¡nÃ­ embeddings.

### Task Decomposition
Proces rozdÄ›lenÃ­ sloÅ¾itÃ©ho Ãºkolu na menÅ¡Ã­, zvlÃ¡dnutelnÃ© podÃºkoly, kterÃ© mohou bÃ½t Å™eÅ¡eny paralelnÄ› nebo sekvenÄnÄ›.

### Memory
SystÃ©m pro uklÃ¡dÃ¡nÃ­ a vyuÅ¾Ã­vÃ¡nÃ­ kontextu z pÅ™edchozÃ­ch interakcÃ­ a vÃ½sledkÅ¯ prÃ¡ce agentÅ¯.

### Tool Use
Schopnost agentÅ¯ vyuÅ¾Ã­vat externÃ­ nÃ¡stroje jako jsou API, databÃ¡ze, webovÃ© vyhledÃ¡vaÄe pro splnÄ›nÃ­ ÃºkolÅ¯.

## KomplexnÃ­ VysvÄ›tlenÃ­ Projektu

### CÃ­le Projektu
VytvoÅ™enÃ­ inteligentnÃ­ho multi-agent systÃ©mu, kterÃ½ dokÃ¡Å¾e autonomnÄ› provÃ¡dÄ›t akademickÃ½ vÃ½zkum. SystÃ©m rozdÄ›luje vÃ½zkumnÃ© Ãºkoly mezi specializovanÃ© agenty, kaÅ¾dÃ½ s vlastnÃ­ rolÃ­ a expertÃ­zou.

### HlavnÃ­ VÃ½zvy
- **Koordinace agentÅ¯**: ZajiÅ¡tÄ›nÃ­ efektivnÃ­ komunikace a spoluprÃ¡ce mezi agenty
- **Kvalita vÃ½zkumu**: OvÄ›Å™ovÃ¡nÃ­ faktÅ¯ a zajiÅ¡tÄ›nÃ­ relevantnosti informacÃ­
- **Å kÃ¡lovatelnost**: Schopnost zvlÃ¡dnout rozsÃ¡hlÃ© vÃ½zkumnÃ© projekty
- **Citace a vÄ›rohodnost**: SprÃ¡vnÃ© odkazovÃ¡nÃ­ na zdroje

### PotenciÃ¡lnÃ­ Dopad
Automatizace vÃ½zkumnÃ©ho procesu mÅ¯Å¾e vÃ½raznÄ› urychlit akademickou prÃ¡ci, snÃ­Å¾it lidskÃ© chyby a umoÅ¾nit zpracovÃ¡nÃ­ vÄ›tÅ¡Ã­ho mnoÅ¾stvÃ­ informacÃ­.

## Implementace v Pythonu

````python
langchain==0.1.0
langchain-openai==0.0.5
langchain-pinecone==0.0.3
pinecone-client==3.0.0
openai==1.3.0
requests==2.31.0
beautifulsoup4==4.12.2
python-dotenv==1.0.0
pydantic==2.5.0
````

````python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
    PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT", "gcp-starter")
    PINECONE_INDEX_NAME = "research-knowledge"
    
    # Model konfigurace
    LLM_MODEL = "gpt-4"
    EMBEDDING_MODEL = "text-embedding-ada-002"
    TEMPERATURE = 0.1
    MAX_TOKENS = 2000
````

````python
from typing import Dict, List, Any
from datetime import datetime
import json

class ResearchMemory:
    def __init__(self):
        self.conversation_history: List[Dict] = []
        self.research_findings: Dict[str, Any] = {}
        self.verified_facts: List[Dict] = []
        self.citations: List[Dict] = []
    
    def add_finding(self, agent_id: str, finding: str, source: str, confidence: float):
        """PÅ™idÃ¡ vÃ½zkumnÃ½ nÃ¡lez do pamÄ›ti"""
        self.research_findings[f"{agent_id}_{datetime.now().isoformat()}"] = {
            "agent_id": agent_id,
            "finding": finding,
            "source": source,
            "confidence": confidence,
            "timestamp": datetime.now().isoformat()
        }
    
    def add_citation(self, title: str, authors: List[str], url: str, relevance_score: float):
        """PÅ™idÃ¡ citaci do pamÄ›ti"""
        self.citations.append({
            "title": title,
            "authors": authors,
            "url": url,
            "relevance_score": relevance_score,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_relevant_findings(self, query: str, top_k: int = 5) -> List[Dict]:
        """ZÃ­skÃ¡ relevantnÃ­ nÃ¡lezy na zÃ¡kladÄ› dotazu"""
        # ZjednoduÅ¡enÃ¡ implementace - v praxi by pouÅ¾Ã­vala embeddings
        relevant = []
        for finding_id, finding in self.research_findings.items():
            if any(word in finding["finding"].lower() for word in query.lower().split()):
                relevant.append(finding)
        
        return sorted(relevant, key=lambda x: x["confidence"], reverse=True)[:top_k]
````

````python
import requests
from bs4 import BeautifulSoup
from typing import List, Dict
import time

class WebSearchTool:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def search_google_scholar(self, query: str, max_results: int = 10) -> List[Dict]:
        """Simulace vyhledÃ¡vÃ¡nÃ­ v Google Scholar"""
        # V reÃ¡lnÃ© implementaci by se pouÅ¾Ã­valo Google Scholar API
        mock_results = [
            {
                "title": f"VÃ½zkum tÃ©matu: {query}",
                "authors": ["Dr. Jan NovÃ¡k", "Prof. Marie SvobodovÃ¡"],
                "url": f"https://scholar.google.com/citations?q={query.replace(' ', '+')}",
                "abstract": f"Tato studie se zabÃ½vÃ¡ {query} a jeho dopady na modernÃ­ technologie.",
                "year": 2023,
                "citations": 45
            }
        ]
        return mock_results[:max_results]
    
    def extract_webpage_content(self, url: str) -> str:
        """Extrahuje obsah z webovÃ© strÃ¡nky"""
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # OdstranÄ›nÃ­ skriptÅ¯ a stylÅ¯
            for script in soup(["script", "style"]):
                script.decompose()
            
            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)
            
            return text[:5000]  # OmezenÃ­ dÃ©lky
        except Exception as e:
            return f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ obsahu: {str(e)}"
````

````python
_store.py
import pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
from typing import List, Dict
from config import Config

class VectorStore:
    def __init__(self):
        pinecone.init(
            api_key=Config.PINECONE_API_KEY,
            environment=Config.PINECONE_ENVIRONMENT
        )
        
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=Config.OPENAI_API_KEY,
            model=Config.EMBEDDING_MODEL
        )
        
        # VytvoÅ™enÃ­ indexu pokud neexistuje
        if Config.PINECONE_INDEX_NAME not in pinecone.list_indexes():
            pinecone.create_index(
                name=Config.PINECONE_INDEX_NAME,
                dimension=1536,
                metric="cosine"
            )
        
        self.vectorstore = Pinecone.from_existing_index(
            index_name=Config.PINECONE_INDEX_NAME,
            embedding=self.embeddings
        )
    
    def add_documents(self, texts: List[str], metadatas: List[Dict]):
        """PÅ™idÃ¡ dokumenty do vektorovÃ© databÃ¡ze"""
        self.vectorstore.add_texts(texts=texts, metadatas=metadatas)
    
    def similarity_search(self, query: str, k: int = 5) -> List[Dict]:
        """VyhledÃ¡ podobnÃ© dokumenty"""
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        return [{"content": doc.page_content, "metadata": doc.metadata, "score": score} 
                for doc, score in results]
````

````python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from config import Config

class BaseAgent(ABC):
    def __init__(self, name: str, role: str, system_prompt: str):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.llm = ChatOpenAI(
            openai_api_key=Config.OPENAI_API_KEY,
            model_name=Config.LLM_MODEL,
            temperature=Config.TEMPERATURE,
            max_tokens=Config.MAX_TOKENS
        )
        self.memory = []
    
    @abstractmethod
    def execute_task(self, task: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """VykonÃ¡ pÅ™iÅ™azenÃ½ Ãºkol"""
        pass
    
    def _generate_response(self, user_message: str, context: str = "") -> str:
        """Generuje odpovÄ›Ä pomocÃ­ LLM"""
        messages = [
            SystemMessage(content=f"{self.system_prompt}\n\nKontext: {context}"),
            HumanMessage(content=user_message)
        ]
        
        response = self.llm(messages)
        return response.content
    
    def add_to_memory(self, interaction: Dict[str, Any]):
        """PÅ™idÃ¡ interakci do pamÄ›ti agenta"""
        self.memory.append(interaction)
        if len(self.memory) > 50:  # OmezenÃ­ velikosti pamÄ›ti
            self.memory.pop(0)
````

````python
from agents.base_agent import BaseAgent
from web_search_tool import WebSearchTool
from typing import Dict, Any, List

class ResearcherAgent(BaseAgent):
    def __init__(self):
        system_prompt = """
        Jsi expertnÃ­ vÃ½zkumnÃ½ agent specializujÃ­cÃ­ se na vyhledÃ¡vÃ¡nÃ­ a analÃ½zu akademickÃ½ch zdrojÅ¯.
        TvÃ½m Ãºkolem je najÃ­t relevantnÃ­ informace k danÃ©mu tÃ©matu, ovÄ›Å™it jejich vÄ›rohodnost
        a poskytnout strukturovanÃ© shrnutÃ­ s citacemi.
        
        VÅ¾dy:
        - OvÄ›Å™uj fakta z vÃ­ce zdrojÅ¯
        - UvÃ¡dÄ›j pÅ™esnÃ© citace
        - HodnoÅ¥ kvalitu zdrojÅ¯
        - Strukturuj informace logicky
        """
        super().__init__("Researcher", "VÃ½zkumnÃ­k", system_prompt)
        self.search_tool = WebSearchTool()
    
    def execute_task(self, task: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Provede vÃ½zkumnÃ½ Ãºkol"""
        try:
            # VyhledÃ¡nÃ­ zdrojÅ¯
            search_results = self.search_tool.search_google_scholar(task, max_results=5)
            
            # AnalÃ½za zdrojÅ¯
            analysis_prompt = f"""
            Analyzuj nÃ¡sledujÃ­cÃ­ vÃ½zkumnÃ© zdroje k tÃ©matu: {task}
            
            Zdroje: {search_results}
            
            Poskytni:
            1. ShrnutÃ­ klÃ­ÄovÃ½ch nÃ¡lezÅ¯
            2. HodnocenÃ­ kvality zdrojÅ¯
            3. Identifikaci mezer ve vÃ½zkumu
            4. DoporuÄenÃ­ pro dalÅ¡Ã­ vÃ½zkum
            """
            
            analysis = self._generate_response(analysis_prompt)
            
            result = {
                "agent": self.name,
                "task": task,
                "sources": search_results,
                "analysis": analysis,
                "confidence": 0.8,
                "status": "completed"
            }
            
            self.add_to_memory(result)
            return result
            
        except Exception as e:
            return {
                "agent": self.name,
                "task": task,
                "error": str(e),
                "status": "failed"
            }
````

````python
from agents.base_agent import BaseAgent
from typing import Dict, Any, List

class FactCheckerAgent(BaseAgent):
    def __init__(self):
        system_prompt = """
        Jsi expertnÃ­ fact-checker agent specializujÃ­cÃ­ se na ovÄ›Å™ovÃ¡nÃ­ faktickÃ½ch tvrzenÃ­.
        TvÃ½m Ãºkolem je ovÄ›Å™it vÄ›rohodnost informacÃ­, identifikovat potenciÃ¡lnÃ­ nepÅ™esnosti
        a poskytnout hodnocenÃ­ spolehlivosti.
        
        PÅ™i ovÄ›Å™ovÃ¡nÃ­:
        - PorovnÃ¡vej s vÃ­ce nezÃ¡vislÃ½mi zdroji
        - Hledej protichÅ¯dnÃ© informace
        - HodnoÅ¥ credibilitu zdrojÅ¯
        - OznaÄuj nejistÃ© nebo spornÃ© tvrzenÃ­
        """
        super().__init__("FactChecker", "OvÄ›Å™ovatel faktÅ¯", system_prompt)
    
    def execute_task(self, task: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """OvÄ›Å™Ã­ fakta v poskytnutÃ½ch informacÃ­ch"""
        try:
            # Extrakce tvrzenÃ­ k ovÄ›Å™enÃ­
            claims = self._extract_claims(context.get("content", ""))
            
            # OvÄ›Å™enÃ­ kaÅ¾dÃ©ho tvrzenÃ­
            verified_claims = []
            for claim in claims:
                verification = self._verify_claim(claim, context)
                verified_claims.append(verification)
            
            # CelkovÃ© hodnocenÃ­
            overall_reliability = self._calculate_reliability(verified_claims)
            
            result = {
                "agent": self.name,
                "task": task,
                "verified_claims": verified_claims,
                "overall_reliability": overall_reliability,
                "recommendations": self._generate_recommendations(verified_claims),
                "status": "completed"
            }
            
            self.add_to_memory(result)
            return result
            
        except Exception as e:
            return {
                "agent": self.name,
                "task": task,
                "error": str(e),
                "status": "failed"
            }
    
    def _extract_claims(self, content: str) -> List[str]:
        """Extrahuje ovÄ›Å™itelnÃ¡ tvrzenÃ­ z obsahu"""
        extraction_prompt = f"""
        Extrahuj z nÃ¡sledujÃ­cÃ­ho textu vÅ¡echna faktickÃ¡ tvrzenÃ­, kterÃ¡ lze ovÄ›Å™it:
        
        {content}
        
        VraÅ¥ seznam tvrzenÃ­ ve formÃ¡tu:
        1. TvrzenÃ­ 1
        2. TvrzenÃ­ 2
        ...
        """
        
        response = self._generate_response(extraction_prompt)
        claims = [line.strip() for line in response.split('\n') 
                 if line.strip() and line.strip()[0].isdigit()]
        return claims
    
    def _verify_claim(self, claim: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """OvÄ›Å™Ã­ jednotlivÃ© tvrzenÃ­"""
        verification_prompt = f"""
        OvÄ›Å™ nÃ¡sledujÃ­cÃ­ tvrzenÃ­: {claim}
        
        Kontext: {context}
        
        Poskytni:
        1. HodnocenÃ­ pravdivosti (0-1)
        2. ZdÅ¯vodnÄ›nÃ­
        3. PodpÅ¯rnÃ© zdroje
        4. PotenciÃ¡lnÃ­ protichÅ¯dnÃ© informace
        """
        
        verification = self._generate_response(verification_prompt)
        
        return {
            "claim": claim,
            "verification": verification,
            "confidence": 0.7  # ZjednoduÅ¡enÃ© hodnocenÃ­
        }
    
    def _calculate_reliability(self, verified_claims: List[Dict]) -> float:
        """VypoÄÃ­tÃ¡ celkovou spolehlivost"""
        if not verified_claims:
            return 0.0
        
        total_confidence = sum(claim["confidence"] for claim in verified_claims)
        return total_confidence / len(verified_claims)
    
    def _generate_recommendations(self, verified_claims: List[Dict]) -> List[str]:
        """Generuje doporuÄenÃ­ na zÃ¡kladÄ› ovÄ›Å™enÃ­"""
        low_confidence_claims = [claim for claim in verified_claims 
                               if claim["confidence"] < 0.6]
        
        recommendations = []
        if low_confidence_claims:
            recommendations.append("DoporuÄuje se dalÅ¡Ã­ ovÄ›Å™enÃ­ u mÃ©nÄ› spolehlivÃ½ch tvrzenÃ­")
            recommendations.append("Vyhledejte dodateÄnÃ© zdroje pro potvrzenÃ­")
        
        return recommendations
````

````python
from agents.base_agent import BaseAgent
from typing import Dict, Any, List

class CitationAgent(BaseAgent):
    def __init__(self):
        system_prompt = """
        Jsi expertnÃ­ citaÄnÃ­ agent specializujÃ­cÃ­ se na sprÃ¡vnÃ© formÃ¡tovÃ¡nÃ­ citacÃ­
        a sprÃ¡vu bibliografickÃ½ch zÃ¡znamÅ¯ podle akademickÃ½ch standardÅ¯.
        
        TvÃ© Ãºkoly:
        - FormÃ¡tovat citace podle poÅ¾adovanÃ©ho stylu (APA, MLA, IEEE)
        - OvÄ›Å™ovat Ãºplnost bibliografickÃ½ch ÃºdajÅ¯
        - Detekovat duplicitnÃ­ citace
        - Generovat seznam literatury
        """
        super().__init__("CitationManager", "SprÃ¡vce citacÃ­", system_prompt)
    
    def execute_task(self, task: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Zpracuje citace a vytvoÅ™Ã­ bibliografii"""
        try:
            sources = context.get("sources", [])
            citation_style = context.get("citation_style", "APA")
            
            # FormÃ¡tovÃ¡nÃ­ citacÃ­
            formatted_citations = []
            for source in sources:
                citation = self._format_citation(source, citation_style)
                formatted_citations.append(citation)
            
            # OdstranÄ›nÃ­ duplicit
            unique_citations = self._remove_duplicates(formatted_citations)
            
            # GenerovÃ¡nÃ­ bibliografie
            bibliography = self._generate_bibliography(unique_citations, citation_style)
            
            result = {
                "agent": self.name,
                "task": task,
                "formatted_citations": unique_citations,
                "bibliography": bibliography,
                "citation_count": len(unique_citations),
                "status": "completed"
            }
            
            self.add_to_memory(result)
            return result
            
        except Exception as e:
            return {
                "agent": self.name,
                "task": task,
                "error": str(e),
                "status": "failed"
            }
    
    def _format_citation(self, source: Dict[str, Any], style: str) -> str:
        """FormÃ¡tuje citaci podle poÅ¾adovanÃ©ho stylu"""
        if style.upper() == "APA":
            return self._format_apa(source)
        elif style.upper() == "MLA":
            return self._format_mla(source)
        else:
            return self._format_apa(source)  # VÃ½chozÃ­ APA
    
    def _format_apa(self, source: Dict[str, Any]) -> str:
        """FormÃ¡tuje citaci v APA stylu"""
        authors = ", ".join(source.get("authors", ["NeznÃ¡mÃ½ autor"]))
        year = source.get("year", "b.r.")
        title = source.get("title", "Bez nÃ¡zvu")
        url = source.get("url", "")
        
        citation = f"{authors} ({year}). {title}."
        if url:
            citation += f" DostupnÃ© z: {url}"
        
        return citation
    
    def _format_mla(self, source: Dict[str, Any]) -> str:
        """FormÃ¡tuje citaci v MLA stylu"""
        authors = source.get("authors", ["NeznÃ¡mÃ½ autor"])
        if authors:
            author_str = authors[0] if len(authors) == 1 else f"{authors[0]} et al."
        title = source.get("title", "Bez nÃ¡zvu")
        url = source.get("url", "")
        
        citation = f'{author_str}. "{title}." Web.'
        if url:
            citation += f" {url}."
        
        return citation
    
    def _remove_duplicates(self, citations: List[str]) -> List[str]:
        """OdstranÃ­ duplicitnÃ­ citace"""
        return list(set(citations))
    
    def _generate_bibliography(self, citations: List[str], style: str) -> str:
        """Generuje kompletnÃ­ bibliografii"""
        sorted_citations = sorted(citations)
        
        bibliography = f"# Seznam literatury ({style})\n\n"
        for i, citation in enumerate(sorted_citations, 1):
            bibliography += f"{i}. {citation}\n"
        
        return bibliography
````

````python
from typing import Dict, Any, List
from agents.researcher_agent import ResearcherAgent
from agents.fact_checker_agent import FactCheckerAgent
from agents.citation_agent import CitationAgent
from memory_manager import ResearchMemory
from vector_store import VectorStore
import asyncio

class MultiAgentCoordinator:
    def __init__(self):
        self.agents = {
            "researcher": ResearcherAgent(),
            "fact_checker": FactCheckerAgent(),
            "citation_manager": CitationAgent()
        }
        self.memory = ResearchMemory()
        self.vector_store = VectorStore()
    
    async def execute_research_project(self, research_query: str) -> Dict[str, Any]:
        """SpustÃ­ kompletnÃ­ vÃ½zkumnÃ½ projekt"""
        print(f"ğŸš€ SpouÅ¡tÃ­m vÃ½zkumnÃ½ projekt: {research_query}")
        
        # FÃ¡ze 1: VÃ½zkum
        print("ğŸ“š FÃ¡ze 1: ProvÃ¡dÃ­m vÃ½zkum...")
        research_result = self.agents["researcher"].execute_task(
            research_query, 
            {"query": research_query}
        )
        
        # UloÅ¾enÃ­ vÃ½sledkÅ¯ do pamÄ›ti
        if research_result["status"] == "completed":
            for source in research_result.get("sources", []):
                self.memory.add_citation(
                    title=source.get("title", ""),
                    authors=source.get("authors", []),
                    url=source.get("url", ""),
                    relevance_score=0.8
                )
        
        # FÃ¡ze 2: OvÄ›Å™enÃ­ faktÅ¯
        print("ğŸ” FÃ¡ze 2: OvÄ›Å™uji fakta...")
        fact_check_result = self.agents["fact_checker"].execute_task(
            "OvÄ›Å™ fakta", 
            {"content": research_result.get("analysis", "")}
        )
        
        # FÃ¡ze 3: SprÃ¡va citacÃ­
        print("ğŸ“– FÃ¡ze 3: ZpracovÃ¡vÃ¡m citace...")
        citation_result = self.agents["citation_manager"].execute_task(
            "Zpracuj citace",
            {
                "sources": research_result.get("sources", []),
                "citation_style": "APA"
            }
        )
        
        # Kombinace vÃ½sledkÅ¯
        final_report = self._compile_final_report(
            research_query,
            research_result,
            fact_check_result,
            citation_result
        )
        
        print("âœ… VÃ½zkumnÃ½ projekt dokonÄen!")
        return final_report
    
    def _compile_final_report(self, query: str, research: Dict, fact_check: Dict, 
                            citations: Dict) -> Dict[str, Any]:
        """SestavÃ­ finÃ¡lnÃ­ zprÃ¡vu"""
        report = {
            "research_query": query,
            "executive_summary": self._generate_executive_summary(research, fact_check),
            "research_findings": research.get("analysis", ""),
            "fact_verification": {
                "reliability_score": fact_check.get("overall_reliability", 0),
                "verified_claims": fact_check.get("verified_claims", []),
                "recommendations": fact_check.get("recommendations", [])
            },
            "bibliography": citations.get("bibliography", ""),
            "metadata": {
                "sources_count": len(research.get("sources", [])),
                "citations_count": citations.get("citation_count", 0),
                "confidence_score": self._calculate_overall_confidence(research, fact_check)
            }
        }
        return report
    
    def _generate_executive_summary(self, research: Dict, fact_check: Dict) -> str:
        """Generuje exekutivnÃ­ shrnutÃ­"""
        reliability = fact_check.get("overall_reliability", 0)
        sources_count = len(research.get("sources", []))
        
        summary = f"""
        ## ExekutivnÃ­ shrnutÃ­
        
        VÃ½zkum byl proveden analÃ½zou {sources_count} zdrojÅ¯ s celkovou spolehlivostÃ­ {reliability:.1%}.
        
        **KlÃ­ÄovÃ© nÃ¡lezy:**
        {research.get("analysis", "Nebyla nalezena analÃ½za")[:500]}...
        
        **HodnocenÃ­ spolehlivosti:** {reliability:.1%}
        """
        return summary
    
    def _calculate_overall_confidence(self, research: Dict, fact_check: Dict) -> float:
        """VypoÄÃ­tÃ¡ celkovou spolehlivost projektu"""
        research_confidence = research.get("confidence", 0)
        fact_check_reliability = fact_check.get("overall_reliability", 0)
        
        return (research_confidence + fact_check_reliability) / 2

    def get_research_history(self) -> Dict[str, Any]:
        """VrÃ¡tÃ­ historii vÃ½zkumu"""
        return {
            "findings": self.memory.research_findings,
            "citations": self.memory.citations,
            "verified_facts": self.memory.verified_facts
        }
````

````python
import asyncio
from multi_agent_coordinator import MultiAgentCoordinator
import json

async def main():
    """HlavnÃ­ funkce pro spuÅ¡tÄ›nÃ­ vÃ½zkumnÃ©ho projektu"""
    
    # Inicializace koordinÃ¡tora
    coordinator = MultiAgentCoordinator()
    
    # Definice vÃ½zkumnÃ½ch dotazÅ¯
    research_queries = [
        "Dopady umÄ›lÃ© inteligence na vzdÄ›lÃ¡vacÃ­ systÃ©my",
        "EtickÃ© aspekty autonomnÃ­ch vozidel",
        "KlimatickÃ© zmÄ›ny a obnovitelnÃ© zdroje energie"
    ]
    
    print("ğŸ¯ Multi-Agent VÃ½zkumnÃ½ SystÃ©m")
    print("=" * 50)
    
    # InteraktivnÃ­ vÃ½bÄ›r tÃ©matu
    print("\nDostupnÃ¡ vÃ½zkumnÃ¡ tÃ©mata:")
    for i, query in enumerate(research_queries, 1):
        print(f"{i}. {query}")
    
    try:
        choice = int(input("\nVyberte tÃ©ma (1-3): ")) - 1
        if 0 <= choice < len(research_queries):
            selected_query = research_queries[choice]
        else:
            selected_query = research_queries[0]
            print("NeplatnÃ½ vÃ½bÄ›r, pouÅ¾Ã­vÃ¡m vÃ½chozÃ­ tÃ©ma.")
    except ValueError:
        selected_query = research_queries[0]
        print("NeplatnÃ½ vstup, pouÅ¾Ã­vÃ¡m vÃ½chozÃ­ tÃ©ma.")
    
    print(f"\nğŸ”¬ Zahajuji vÃ½zkum tÃ©matu: {selected_query}")
    print("-" * 50)
    
    # SpuÅ¡tÄ›nÃ­ vÃ½zkumnÃ©ho projektu
    try:
        result = await coordinator.execute_research_project(selected_query)
        
        # ZobrazenÃ­ vÃ½sledkÅ¯
        print("\n" + "=" * 50)
        print("ğŸ“Š VÃSLEDKY VÃZKUMU")
        print("=" * 50)
        
        print(f"\n**TÃ©ma:** {result['research_query']}")
        print(f"**CelkovÃ¡ spolehlivost:** {result['metadata']['confidence_score']:.1%}")
        print(f"**PoÄet zdrojÅ¯:** {result['metadata']['sources_count']}")
        print(f"**PoÄet citacÃ­:** {result['metadata']['citations_count']}")
        
        print(result['executive_summary'])
        
        print("\nğŸ“š **Bibliografie:**")
        print(result['bibliography'])
        
        # UloÅ¾enÃ­ vÃ½sledkÅ¯
        with open(f"research_report_{selected_query.replace(' ', '_')}.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ VÃ½sledky uloÅ¾eny do souboru: research_report_{selected_query.replace(' ', '_')}.json")
        
        # ZobrazenÃ­ historie vÃ½zkumu
        history = coordinator.get_research_history()
        print(f"\nğŸ“ˆ Celkem vÃ½zkumnÃ½ch nÃ¡lezÅ¯ v pamÄ›ti: {len(history['findings'])}")
        print(f"ğŸ“– Celkem citacÃ­ v pamÄ›ti: {len(history['citations'])}")
        
    except Exception as e:
        print(f"\nâŒ Chyba pÅ™i provÃ¡dÄ›nÃ­ vÃ½zkumu: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())
````

````python
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone Configuration  
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=gcp-starter

# Optional: Custom model configurations
LLM_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-ada-002
````

## ShrnutÃ­ Projektu

### Hodnota Projektu
AutonomnÃ­ vÃ½zkumnÃ½ tÃ½m pÅ™edstavuje pokroÄilÃ½ multi-agent systÃ©m, kterÃ½ automatizuje celÃ½ proces akademickÃ©ho vÃ½zkumu od vyhledÃ¡vÃ¡nÃ­ zdrojÅ¯ aÅ¾ po ovÄ›Å™ovÃ¡nÃ­ faktÅ¯ a formÃ¡tovÃ¡nÃ­ citacÃ­.

### KlÃ­ÄovÃ© VÃ½hody
- **Efektivita**: ParalelnÃ­ zpracovÃ¡nÃ­ ÃºkolÅ¯ vÃ­ce agenty
- **Kvalita**: AutomatickÃ© ovÄ›Å™ovÃ¡nÃ­ faktÅ¯ a kvality zdrojÅ¯  
- **Standardizace**: KonzistentnÃ­ formÃ¡tovÃ¡nÃ­ citacÃ­ podle akademickÃ½ch standardÅ¯
- **Å kÃ¡lovatelnost**: Schopnost zpracovat rozsÃ¡hlÃ© vÃ½zkumnÃ© projekty

### TechnickÃ© VÃ½hody
- ModulÃ¡rnÃ­ architektura umoÅ¾ÅˆujÃ­cÃ­ snadnÃ© rozÅ¡Ã­Å™enÃ­
- PouÅ¾itÃ­ modernÃ­ch frameworkÅ¯ (LangChain, Pinecone)
- RobustnÃ­ error handling a pamÄ›Å¥ovÃ½ systÃ©m
- Podpora rÅ¯znÃ½ch citaÄnÃ­ch stylÅ¯

### BudoucÃ­ RozÅ¡Ã­Å™enÃ­
- Integrace s akademickÃ½mi databÃ¡zemi
- PokroÄilÃ© NLP analÃ½zy
- Vizualizace vÃ½zkumnÃ½ch nÃ¡lezÅ¯
- KolaborativnÃ­ funkce pro tÃ½my vÃ½zkumnÃ­kÅ¯