<small>Claude Sonnet 4 **(Historical Events Explorer - RAG syst√©m pro historick√Ω v√Ωzkum)**</small>
# Historical Events Explorer

## Kl√≠ƒçov√© koncepty

### RAG (Retrieval-Augmented Generation)
**RAG** je architektonick√Ω vzor, kter√Ω kombinuje vyhled√°v√°n√≠ relevantn√≠ch informac√≠ z extern√≠ datab√°ze znalost√≠ s generativn√≠mi schopnostmi jazykov√Ωch model≈Ø. Umo≈æ≈àuje AI poskytovat p≈ôesn√© odpovƒõdi zalo≈æen√© na faktick√Ωch datech.

### Wikipedia/Archive.org integrace
**Wikipedia** a **Archive.org** slou≈æ√≠ jako bohat√© zdroje historick√Ωch informac√≠. Wikipedia poskytuje strukturovan√© encyklopedick√© ƒçl√°nky, zat√≠mco Archive.org obsahuje historick√© dokumenty a archivy.

### Time-aware embeddings
**ƒåasovƒõ vƒõdom√© vektory** jsou speci√°ln√≠ reprezentace textu, kter√© zachycuj√≠ nejen s√©mantick√Ω obsah, ale i ƒçasov√Ω kontext ud√°lost√≠. Umo≈æ≈àuj√≠ efektivn√≠ vyhled√°v√°n√≠ podle ƒçasov√Ωch obdob√≠.

### PostgreSQL s pgvector
**PostgreSQL** s roz≈°√≠≈ôen√≠m **pgvector** poskytuje robustn√≠ ≈ôe≈°en√≠ pro ukl√°d√°n√≠ a vyhled√°v√°n√≠ vektorov√Ωch reprezentac√≠ s pokroƒçil√Ωmi SQL funkcionalitami.

### Gemini Pro
**Gemini Pro** je pokroƒçil√Ω jazykov√Ω model od Google, kter√Ω poskytuje vysokou kvalitu generov√°n√≠ textu a anal√Ωzu komplexn√≠ch historick√Ωch kontext≈Ø.

## Komplexn√≠ vysvƒõtlen√≠ projektu

**Historical Events Explorer** je sofistikovan√Ω RAG syst√©m navr≈æen√Ω pro zodpov√≠d√°n√≠ komplexn√≠ch historick√Ωch dotaz≈Ø s p≈ôesnou citac√≠ zdroj≈Ø a ƒçasov√Ωmi liniemi. Projekt ≈ôe≈°√≠ v√Ωzvu poskytov√°n√≠ fakticky spr√°vn√Ωch, kontextu√°lnƒõ bohat√Ωch odpovƒõd√≠ na historick√© ot√°zky.

### Hlavn√≠ c√≠le:
- **P≈ôesnost**: Odpovƒõdi zalo≈æen√© na ovƒõ≈ôen√Ωch historick√Ωch zdroj√≠ch
- **Kontextualita**: Zahrnut√≠ ƒçasov√Ωch souvislost√≠ a p≈ô√≠ƒçinn√Ωch vztah≈Ø
- **Sledovatelnost**: Jasn√© citace a odkazy na p≈Øvodn√≠ zdroje
- **≈†k√°lovatelnost**: Schopnost pracovat s rozs√°hl√Ωmi historick√Ωmi datab√°zemi

### Architektonick√© v√Ωzvy:
- **ƒåasov√° komplexita**: Historick√© ud√°losti se p≈ôekr√Ωvaj√≠ a ovliv≈àuj√≠ navz√°jem
- **Kvalita zdroj≈Ø**: Nutnost ovƒõ≈ôov√°n√≠ reliability historick√Ωch informac√≠
- **Multimod√°ln√≠ data**: Kombinace text≈Ø, dat a geografick√Ωch informac√≠
- **Kontextu√°ln√≠ vyhled√°v√°n√≠**: Nalezen√≠ relevantn√≠ch informac√≠ nap≈ô√≠ƒç r≈Øzn√Ωmi ƒçasov√Ωmi obdob√≠mi

## Komplexn√≠ implementace s Python

````python
langchain==0.1.0
langchain-google-genai==0.1.0
wikipedia==1.4.0
requests==2.31.0
psycopg2-binary==2.9.7
pgvector==0.2.0
sentence-transformers==2.2.2
python-dotenv==1.0.0
streamlit==1.29.0
plotly==5.17.0
pandas==2.1.0
````

````python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/historical_events")
    EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
    MAX_CONTEXT_LENGTH = 4000
    TOP_K_RESULTS = 5
    
    # Historical periods for time-aware processing
    HISTORICAL_PERIODS = {
        "ancient": (-3000, 500),
        "medieval": (500, 1500),
        "early_modern": (1500, 1800),
        "modern": (1800, 1950),
        "contemporary": (1950, 2024)
    }
````

````python
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from typing import List, Dict, Optional
import logging

class HistoricalDatabase:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.setup_database()
    
    def setup_database(self):
        """Inicializace datab√°ze s pgvector roz≈°√≠≈ôen√≠m"""
        try:
            with psycopg2.connect(self.connection_string) as conn:
                with conn.cursor() as cur:
                    # Vytvo≈ôen√≠ pgvector roz≈°√≠≈ôen√≠
                    cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                    
                    # Tabulka pro historick√© ud√°losti
                    cur.execute("""
                        CREATE TABLE IF NOT EXISTS historical_events (
                            id SERIAL PRIMARY KEY,
                            title VARCHAR(500) NOT NULL,
                            content TEXT NOT NULL,
                            date_start INTEGER,
                            date_end INTEGER,
                            location VARCHAR(200),
                            source_url VARCHAR(500),
                            source_type VARCHAR(50),
                            embedding vector(384),
                            created_at TIMESTAMP DEFAULT NOW()
                        );
                    """)
                    
                    # Index pro vektorov√© vyhled√°v√°n√≠
                    cur.execute("""
                        CREATE INDEX IF NOT EXISTS historical_events_embedding_idx 
                        ON historical_events USING ivfflat (embedding vector_cosine_ops)
                        WITH (lists = 100);
                    """)
                    
                    # Index pro ƒçasov√© vyhled√°v√°n√≠
                    cur.execute("""
                        CREATE INDEX IF NOT EXISTS historical_events_date_idx 
                        ON historical_events (date_start, date_end);
                    """)
                    
                conn.commit()
                logging.info("Datab√°ze √∫spƒõ≈°nƒõ inicializov√°na")
        except Exception as e:
            logging.error(f"Chyba p≈ôi inicializaci datab√°ze: {e}")
            raise
    
    def insert_event(self, event_data: Dict) -> int:
        """Vlo≈æen√≠ historick√© ud√°losti do datab√°ze"""
        try:
            with psycopg2.connect(self.connection_string) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO historical_events 
                        (title, content, date_start, date_end, location, source_url, source_type, embedding)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        RETURNING id;
                    """, (
                        event_data['title'],
                        event_data['content'],
                        event_data.get('date_start'),
                        event_data.get('date_end'),
                        event_data.get('location'),
                        event_data.get('source_url'),
                        event_data.get('source_type'),
                        event_data['embedding']
                    ))
                    event_id = cur.fetchone()[0]
                    conn.commit()
                    return event_id
        except Exception as e:
            logging.error(f"Chyba p≈ôi vkl√°d√°n√≠ ud√°losti: {e}")
            raise
    
    def search_similar_events(self, query_embedding: List[float], 
                            date_range: Optional[tuple] = None, 
                            limit: int = 5) -> List[Dict]:
        """Vyhled√°v√°n√≠ podobn√Ωch ud√°lost√≠ pomoc√≠ vektorov√© podobnosti"""
        try:
            with psycopg2.connect(self.connection_string) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    where_clause = ""
                    params = [query_embedding, limit]
                    
                    if date_range:
                        where_clause = """
                            WHERE (date_start <= %s AND date_end >= %s) 
                            OR (date_start >= %s AND date_start <= %s)
                        """
                        params = [query_embedding] + list(date_range) * 2 + [limit]
                    
                    cur.execute(f"""
                        SELECT id, title, content, date_start, date_end, 
                               location, source_url, source_type,
                               1 - (embedding <=> %s) as similarity
                        FROM historical_events
                        {where_clause}
                        ORDER BY embedding <=> %s
                        LIMIT %s;
                    """, params)
                    
                    return [dict(row) for row in cur.fetchall()]
        except Exception as e:
            logging.error(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            return []
````

````python
import wikipedia
import requests
from typing import List, Dict, Optional
import re
from datetime import datetime
import logging
from sentence_transformers import SentenceTransformer

class HistoricalDataCollector:
    def __init__(self, embedding_model_name: str):
        self.embedding_model = SentenceTransformer(embedding_model_name)
        wikipedia.set_lang("en")  # Pro lep≈°√≠ dostupnost historick√Ωch ƒçl√°nk≈Ø
    
    def extract_dates_from_text(self, text: str) -> tuple:
        """Extrakce dat z textu pomoc√≠ regex"""
        # Vzory pro r≈Øzn√© form√°ty dat
        year_patterns = [
            r'\b(\d{4})\b',  # ƒåty≈ôcifern√Ω rok
            r'\b(\d{1,2})\s+(century|Century)\b',  # Stolet√≠
            r'\b(\d{1,4})\s*(BC|AD|BCE|CE)\b'  # BC/AD form√°t
        ]
        
        dates = []
        for pattern in year_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0]
                try:
                    year = int(match)
                    if 1 <= year <= 2024:
                        dates.append(year)
                except ValueError:
                    continue
        
        if dates:
            return min(dates), max(dates)
        return None, None
    
    def collect_wikipedia_events(self, search_terms: List[str]) -> List[Dict]:
        """Sbƒõr historick√Ωch ud√°lost√≠ z Wikipedie"""
        events = []
        
        for term in search_terms:
            try:
                # Vyhled√°n√≠ str√°nek
                search_results = wikipedia.search(term, results=3)
                
                for title in search_results:
                    try:
                        page = wikipedia.page(title)
                        
                        # Extrakce z√°kladn√≠ch informac√≠
                        content = page.content[:2000]  # Omezen√≠ d√©lky
                        date_start, date_end = self.extract_dates_from_text(content)
                        
                        # Generov√°n√≠ embeddingu
                        embedding = self.embedding_model.encode(
                            f"{page.title} {content}"
                        ).tolist()
                        
                        event = {
                            'title': page.title,
                            'content': content,
                            'date_start': date_start,
                            'date_end': date_end,
                            'source_url': page.url,
                            'source_type': 'wikipedia',
                            'embedding': embedding
                        }
                        
                        events.append(event)
                        logging.info(f"Zpracov√°n ƒçl√°nek: {page.title}")
                        
                    except wikipedia.exceptions.PageError:
                        logging.warning(f"Str√°nka nenalezena: {title}")
                        continue
                    except Exception as e:
                        logging.error(f"Chyba p≈ôi zpracov√°n√≠ {title}: {e}")
                        continue
                        
            except Exception as e:
                logging.error(f"Chyba p≈ôi vyhled√°v√°n√≠ {term}: {e}")
                continue
        
        return events
    
    def collect_sample_historical_events(self) -> List[Dict]:
        """Sbƒõr uk√°zkov√Ωch historick√Ωch ud√°lost√≠"""
        historical_topics = [
            "Berlin Wall fall 1989",
            "World War II",
            "American Civil War",
            "French Revolution",
            "Industrial Revolution",
            "Cold War",
            "Renaissance period",
            "Roman Empire fall",
            "Black Death plague",
            "Discovery of America 1492"
        ]
        
        return self.collect_wikipedia_events(historical_topics)
````

````python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
from typing import List, Dict, Optional
import logging
from datetime import datetime

class HistoricalRAGSystem:
    def __init__(self, database, gemini_api_key: str, embedding_model):
        self.db = database
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-pro",
            google_api_key=gemini_api_key,
            temperature=0.1
        )
        self.embedding_model = embedding_model
        
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """Jsi expert na historii. Tv√Ωm √∫kolem je odpovƒõdƒõt na ot√°zky o historick√Ωch ud√°lostech 
            na z√°kladƒõ poskytnut√Ωch zdroj≈Ø. V≈ædy uveƒè zdroje a vytvo≈ô ƒçasovou linii relevantn√≠ch ud√°lost√≠.
            
            Pravidla:
            1. Odpov√≠dej pouze na z√°kladƒõ poskytnut√Ωch zdroj≈Ø
            2. Uveƒè jasn√© citace zdroj≈Ø
            3. Vytvo≈ô chronologickou ƒçasovou linii
            4. Objasni p≈ô√≠ƒçinn√© souvislosti
            5. Pokud informace nejsou dostaƒçuj√≠c√≠, ≈ôekni to jasnƒõ"""),
            ("user", """Ot√°zka: {question}
            
            Relevantn√≠ historick√© zdroje:
            {sources}
            
            Odpovƒõz v ƒçe≈°tinƒõ s ƒçasovou lini√≠ a citacemi zdroj≈Ø.""")
        ])
    
    def parse_temporal_context(self, question: str) -> Optional[tuple]:
        """Extrakce ƒçasov√©ho kontextu z ot√°zky"""
        import re
        
        # Vzory pro roky a obdob√≠
        year_pattern = r'\b(1[0-9]{3}|20[0-2][0-9])\b'
        period_patterns = {
            'st≈ôedovƒõk': (500, 1500),
            'renesance': (1400, 1600),
            'osv√≠censtv√≠': (1650, 1800),
            'pr≈Ømyslov√° revoluce': (1760, 1840),
            'prvn√≠ svƒõtov√° v√°lka': (1914, 1918),
            'druh√° svƒõtov√° v√°lka': (1939, 1945),
            'studen√° v√°lka': (1947, 1991)
        }
        
        # Hled√°n√≠ konkr√©tn√≠ch let
        years = re.findall(year_pattern, question.lower())
        if years:
            year = int(years[0])
            return (year - 50, year + 50)  # Kontext ¬±50 let
        
        # Hled√°n√≠ historick√Ωch obdob√≠
        for period, date_range in period_patterns.items():
            if period in question.lower():
                return date_range
        
        return None
    
    def retrieve_relevant_events(self, question: str, top_k: int = 5) -> List[Dict]:
        """Vyhled√°n√≠ relevantn√≠ch historick√Ωch ud√°lost√≠"""
        try:
            # Generov√°n√≠ embeddingu pro ot√°zku
            question_embedding = self.embedding_model.encode(question).tolist()
            
            # Extrakce ƒçasov√©ho kontextu
            date_range = self.parse_temporal_context(question)
            
            # Vyhled√°n√≠ podobn√Ωch ud√°lost√≠
            events = self.db.search_similar_events(
                query_embedding=question_embedding,
                date_range=date_range,
                limit=top_k
            )
            
            logging.info(f"Nalezeno {len(events)} relevantn√≠ch ud√°lost√≠")
            return events
            
        except Exception as e:
            logging.error(f"Chyba p≈ôi vyhled√°v√°n√≠ ud√°lost√≠: {e}")
            return []
    
    def format_sources(self, events: List[Dict]) -> str:
        """Form√°tov√°n√≠ zdroj≈Ø pro prompt"""
        sources = []
        for i, event in enumerate(events, 1):
            date_info = ""
            if event.get('date_start') and event.get('date_end'):
                date_info = f" ({event['date_start']}-{event['date_end']})"
            elif event.get('date_start'):
                date_info = f" ({event['date_start']})"
            
            source = f"""
Zdroj {i}: {event['title']}{date_info}
Obsah: {event['content'][:500]}...
URL: {event.get('source_url', 'N/A')}
Relevance: {event.get('similarity', 0):.3f}
            """
            sources.append(source)
        
        return "\n".join(sources)
    
    def generate_answer(self, question: str) -> Dict:
        """Generov√°n√≠ odpovƒõdi na historickou ot√°zku"""
        try:
            # Vyhled√°n√≠ relevantn√≠ch ud√°lost√≠
            events = self.retrieve_relevant_events(question)
            
            if not events:
                return {
                    "answer": "Omlouv√°m se, ale v datab√°zi jsem nena≈°el relevantn√≠ informace k va≈°√≠ ot√°zce.",
                    "sources": [],
                    "timeline": []
                }
            
            # Form√°tov√°n√≠ zdroj≈Ø
            sources_text = self.format_sources(events)
            
            # Generov√°n√≠ odpovƒõdi
            messages = self.prompt_template.format_messages(
                question=question,
                sources=sources_text
            )
            
            response = self.llm.invoke(messages)
            
            # P≈ô√≠prava ƒçasov√© linie
            timeline = []
            for event in events:
                if event.get('date_start'):
                    timeline.append({
                        'date': event['date_start'],
                        'event': event['title'],
                        'description': event['content'][:200] + '...'
                    })
            
            timeline.sort(key=lambda x: x['date'])
            
            return {
                "answer": response.content,
                "sources": events,
                "timeline": timeline,
                "question": question
            }
            
        except Exception as e:
            logging.error(f"Chyba p≈ôi generov√°n√≠ odpovƒõdi: {e}")
            return {
                "answer": f"Do≈°lo k chybƒõ p≈ôi zpracov√°n√≠ ot√°zky: {str(e)}",
                "sources": [],
                "timeline": []
            }
````

````python
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime
import logging
from config import Config
from database import HistoricalDatabase
from data_collector import HistoricalDataCollector
from rag_system import HistoricalRAGSystem
from sentence_transformers import SentenceTransformer

# Konfigurace logov√°n√≠
logging.basicConfig(level=logging.INFO)

@st.cache_resource
def initialize_system():
    """Inicializace RAG syst√©mu"""
    try:
        # Inicializace komponent
        db = HistoricalDatabase(Config.DATABASE_URL)
        embedding_model = SentenceTransformer(Config.EMBEDDING_MODEL)
        rag_system = HistoricalRAGSystem(db, Config.GEMINI_API_KEY, embedding_model)
        
        return db, embedding_model, rag_system
    except Exception as e:
        st.error(f"Chyba p≈ôi inicializaci syst√©mu: {e}")
        return None, None, None

def load_sample_data(db, collector):
    """Naƒçten√≠ uk√°zkov√Ωch dat"""
    if st.button("Naƒç√≠st uk√°zkov√° historick√° data"):
        with st.spinner("Sb√≠r√°n√≠ historick√Ωch dat z Wikipedie..."):
            events = collector.collect_sample_historical_events()
            
            progress_bar = st.progress(0)
            for i, event in enumerate(events):
                try:
                    db.insert_event(event)
                    progress_bar.progress((i + 1) / len(events))
                except Exception as e:
                    st.error(f"Chyba p≈ôi ukl√°d√°n√≠ ud√°losti: {e}")
            
            st.success(f"√öspƒõ≈°nƒõ naƒçteno {len(events)} historick√Ωch ud√°lost√≠!")

def display_timeline(timeline_data):
    """Zobrazen√≠ ƒçasov√© linie ud√°lost√≠"""
    if not timeline_data:
        return
    
    df = pd.DataFrame(timeline_data)
    
    # Vytvo≈ôen√≠ ƒçasov√© linie pomoc√≠ Plotly
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['date'],
        y=[1] * len(df),
        mode='markers+text',
        text=df['event'],
        textposition="top center",
        marker=dict(size=10, color='red'),
        hovertemplate='<b>%{text}</b><br>Rok: %{x}<br>%{customdata}<extra></extra>',
        customdata=df['description']
    ))
    
    fig.update_layout(
        title="ƒåasov√° linie historick√Ωch ud√°lost√≠",
        xaxis_title="Rok",
        yaxis=dict(visible=False),
        height=400,
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)

def main():
    st.set_page_config(
        page_title="Historical Events Explorer",
        page_icon="üèõÔ∏è",
        layout="wide"
    )
    
    st.title("üèõÔ∏è Historical Events Explorer")
    st.markdown("**RAG syst√©m pro komplexn√≠ historick√© dotazy s ƒçasov√Ωmi liniemi**")
    
    # Inicializace syst√©mu
    db, embedding_model, rag_system = initialize_system()
    
    if not all([db, embedding_model, rag_system]):
        st.error("Nepoda≈ôilo se inicializovat syst√©m. Zkontrolujte konfiguraci.")
        return
    
    # Postrann√≠ panel pro spr√°vu dat
    with st.sidebar:
        st.header("üìö Spr√°va dat")
        
        collector = HistoricalDataCollector(Config.EMBEDDING_MODEL)
        load_sample_data(db, collector)
        
        st.markdown("---")
        st.markdown("**P≈ô√≠klady ot√°zek:**")
        st.markdown("- Co zp≈Øsobilo p√°d Berl√≠nsk√© zdi?")
        st.markdown("- Jak prob√≠hala Francouzsk√° revoluce?")
        st.markdown("- Jak√© byly p≈ô√≠ƒçiny prvn√≠ svƒõtov√© v√°lky?")
    
    # Hlavn√≠ rozhran√≠
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üîç Historick√Ω dotaz")
        
        question = st.text_area(
            "Polo≈æte svou historickou ot√°zku:",
            placeholder="Nap≈ô√≠klad: Co zp≈Øsobilo p√°d Berl√≠nsk√© zdi?",
            height=100
        )
        
        if st.button("Vyhledat odpovƒõƒè", type="primary"):
            if question:
                with st.spinner("Analyzujem historick√© zdroje..."):
                    result = rag_system.generate_answer(question)
                
                # Zobrazen√≠ odpovƒõdi
                st.subheader("üìñ Odpovƒõƒè")
                st.write(result["answer"])
                
                # Zobrazen√≠ ƒçasov√© linie
                if result["timeline"]:
                    st.subheader("‚è±Ô∏è ƒåasov√° linie")
                    display_timeline(result["timeline"])
                
                # Zobrazen√≠ zdroj≈Ø
                if result["sources"]:
                    st.subheader("üìö Zdroje")
                    for i, source in enumerate(result["sources"], 1):
                        with st.expander(f"Zdroj {i}: {source['title']}"):
                            col_a, col_b = st.columns([3, 1])
                            with col_a:
                                st.write(source['content'][:300] + "...")
                            with col_b:
                                if source.get('date_start'):
                                    st.metric("Rok", source['date_start'])
                                if source.get('similarity'):
                                    st.metric("Relevance", f"{source['similarity']:.3f}")
                            
                            if source.get('source_url'):
                                st.markdown(f"[Odkaz na zdroj]({source['source_url']})")
            else:
                st.warning("Pros√≠m, zadejte svou ot√°zku.")
    
    with col2:
        st.header("üìä Statistiky")
        
        # Zobrazen√≠ statistik syst√©mu
        try:
            import psycopg2
            with psycopg2.connect(Config.DATABASE_URL) as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT COUNT(*) FROM historical_events")
                    total_events = cur.fetchone()[0]
                    
                    cur.execute("SELECT COUNT(DISTINCT source_type) FROM historical_events")
                    source_types = cur.fetchone()[0]
            
            st.metric("Celkem ud√°lost√≠", total_events)
            st.metric("Typy zdroj≈Ø", source_types)
            
        except Exception as e:
            st.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ statistik: {e}")

if __name__ == "__main__":
    main()
````

````python
import subprocess
import sys
import os

def setup_environment():
    """Nastaven√≠ prost≈ôed√≠ a instalace z√°vislost√≠"""
    print("üîß Nastavov√°n√≠ prost≈ôed√≠...")
    
    # Instalace z√°vislost√≠
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
    
    # Vytvo≈ôen√≠ .env souboru pokud neexistuje
    if not os.path.exists('.env'):
        with open('.env', 'w') as f:
            f.write("""# Historical Events Explorer Configuration
GEMINI_API_KEY=your_gemini_api_key_here
DATABASE_URL=postgresql://user:password@localhost:5432/historical_events
""")
        print("üìù Vytvo≈ôen .env soubor - nastavte sv√© API kl√≠ƒçe!")

def run_application():
    """Spu≈°tƒõn√≠ Streamlit aplikace"""
    print("üöÄ Spou≈°tƒõn√≠ Historical Events Explorer...")
    os.chdir('src')
    subprocess.run([sys.executable, "-m", "streamlit", "run", "main.py"])

if __name__ == "__main__":
    setup_environment()
    run_application()
````

## Shrnut√≠ projektu

**Historical Events Explorer** p≈ôedstavuje pokroƒçil√Ω RAG syst√©m, kter√Ω revolucionizuje zp≈Øsob, jak√Ωm lid√© zkoumaj√≠ historii. Projekt √∫spƒõ≈°nƒõ kombinuje modern√≠ AI technologie s rozs√°hl√Ωmi historick√Ωmi datab√°zemi pro poskytov√°n√≠ p≈ôesn√Ωch, kontextu√°lnƒõ bohat√Ωch odpovƒõd√≠.

### Kl√≠ƒçov√© p≈ô√≠nosy:
- **Faktick√° p≈ôesnost** d√≠ky RAG architektu≈ôe a citac√≠m zdroj≈Ø
- **ƒåasov√Ω kontext** prost≈ôednictv√≠m time-aware embedding≈Ø a ƒçasov√Ωch lini√≠
- **≈†k√°lovatelnost** s PostgreSQL a vektorov√Ωm vyhled√°v√°n√≠m
- **U≈æivatelsk√° p≈ô√≠vƒõtivost** s intuitivn√≠m Streamlit rozhran√≠m

### Technologick√© inovace:
- Integrace Wikipedia a Archive.org jako autoritativn√≠ch zdroj≈Ø
- Pokroƒçil√© vektorov√© vyhled√°v√°n√≠ s pgvector
- ƒåasovƒõ vƒõdom√© embeddingy pro historick√Ω kontext
- Gemini Pro pro kvalitn√≠ generov√°n√≠ odpovƒõd√≠

Projekt demonstruje, jak AI m≈Ø≈æe zp≈ô√≠stupnit komplexn√≠ historick√© znalosti ≈°irok√©mu publiku, zachov√°vaj√≠c p≈ôitom vƒõdeckou rigor√≥znost a sledovatelnost zdroj≈Ø.