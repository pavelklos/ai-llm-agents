<small>Claude Sonnet 4 **(AI Pr치vn칤 Asistent - RAG Syst칠m pro Pr치vn칤 Dokumenty)**</small>
# Legal Document Assistant

## Kl칤캜ov칠 Koncepty

### RAG (Retrieval-Augmented Generation)
**RAG** je architektonick칳 vzor, kter칳 kombinuje vyhled치v치n칤 relevantn칤ch informac칤 z datab치ze znalost칤 s generativn칤mi schopnostmi velk칳ch jazykov칳ch model콢. Syst칠m nejprve vyhled치 relevantn칤 dokumenty a pak pou쬴je tyto informace jako kontext pro generov치n칤 odpov캩di.

### LangChain
**LangChain** je framework pro v칳voj aplikac칤 vyu쮂셨aj칤c칤ch jazykov칠 modely. Poskytuje n치stroje pro 콏et캩zen칤 operac칤, spr치vu prompt콢, integraci s vektorov칳mi datab치zemi a orchestraci komplexn칤ch AI workflow.

### OpenAI GPT-4o
**GPT-4o** je multimod치ln칤 jazykov칳 model od OpenAI s pokro캜il칳mi schopnostmi porozum캩n칤 textu a generov치n칤 odpov캩d칤. Optimalizovan치 verze pro rychlej코칤 inference p콏i zachov치n칤 vysok칠 kvality.

### Pinecone
**Pinecone** je pln캩 spravovan치 vektorov치 datab치ze optimalizovan치 pro ukl치d치n칤 a vyhled치v치n칤 vysokodimenzion치ln칤ch vektor콢. Umo쮄갓je rychl칠 s칠mantick칠 vyhled치v치n칤 v rozs치hl칳ch kolekc칤ch dokument콢.

### PDF Parsing
**PDF Parsing** je proces extrakce strukturovan칠ho textu z PDF dokument콢. Zahrnuje zpracov치n칤 r콢zn칳ch form치t콢, zachov치n칤 struktury a metadata dokument콢.

### Prompt Engineering
**Prompt Engineering** je discipl칤na navrhov치n칤 efektivn칤ch instrukc칤 pro jazykov칠 modely. Zahrnuje optimalizaci prompt콢 pro specifick칠 칰koly a zlep코en칤 kvality odpov캩d칤.

### Semantic Search
**S칠mantick칠 vyhled치v치n칤** vyu쮂셨치 porozum캩n칤 v칳znamu dotaz콢 a dokument콢 nam칤sto pouh칠ho porovn치v치n칤 kl칤캜ov칳ch slov. Zalo쬰no na vektorov칳ch reprezentac칤ch textu.

## Komplexn칤 Vysv캩tlen칤 Projektu

### C칤le Projektu
Pr치vn칤 asistent p콏edstavuje pokro캜il칳 RAG syst칠m navr쬰n칳 pro automatizaci pr치vn칤ho poradenstv칤. Hlavn칤mi c칤li jsou:

- **Automatizace pr치vn칤ch dotaz콢**: Poskytov치n칤 okam쬴t칳ch odpov캩d칤 na pr치vn칤 ot치zky
- **Zv칳코en칤 efektivity**: Redukce 캜asu pot콏ebn칠ho pro vyhled치v치n칤 relevantn칤ch pr치vn칤ch precedent콢
- **Demokratizace pr치vn칤ch znalost칤**: Zp콏칤stupn캩n칤 pr치vn칤ch informac칤 코ir코칤 ve콏ejnosti
- **Podpora pr치vn칤k콢**: Asistence p콏i v칳zkumu a p콏칤prav캩 p콏칤pad콢

### Technick칠 V칳zvy
Projekt 콏e코칤 n캩kolik kritick칳ch technick칳ch v칳zev:

1. **Zpracov치n칤 pr치vn칤ch dokument콢**: PDF parsing s zachov치n칤m struktury a kontextu
2. **S칠mantick칠 porozum캩n칤**: Spr치vn치 interpretace pr치vn칤 terminologie
3. **Relevantn칤 vyhled치v치n칤**: Identifikace aplikovateln칳ch pr치vn칤ch precedent콢
4. **Kontextov치 generace**: Poskytov치n칤 p콏esn칳ch odpov캩d칤 s pr치vn칤mi odkazy

### Potenci치ln칤 Dopad
Syst칠m m콢쬰 revolucionalizovat p콏칤stup k pr치vn칤m slu쬭치m:
- Sn칤쬰n칤 n치klad콢 na pr치vn칤 poradenstv칤
- Zlep코en칤 dostupnosti pr치vn칤ch informac칤
- Standardizace pr치vn칤ch proces콢
- Podpora pr치vn칤ho vzd캩l치v치n칤

## Komplexn칤 Implementace s P콏칤kladem

### Instalace Z치vislost칤

````python
langchain==0.1.0
langchain-openai==0.0.5
langchain-pinecone==0.0.3
pinecone-client==3.0.0
openai==1.12.0
pypdf2==3.0.1
python-dotenv==1.0.0
streamlit==1.31.0
tiktoken==0.5.2
pydantic==2.5.3
````

### Hlavn칤 Implementace

````python
import os
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
import streamlit as st
from dotenv import load_dotenv

import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import pinecone
import PyPDF2

# Na캜ten칤 prost콏ed칤
load_dotenv()

# Konfigurace logov치n칤
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class LegalDocument:
    """Struktura pro pr치vn칤 dokument"""
    title: str
    content: str
    doc_type: str
    metadata: Dict

class PDFProcessor:
    """Zpracov치n칤 PDF dokument콢"""
    
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def extract_text(self, pdf_path: str) -> str:
        """Extrakce textu z PDF"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
        except Exception as e:
            logger.error(f"Chyba p콏i zpracov치n칤 PDF {pdf_path}: {e}")
            return ""
    
    def split_document(self, text: str, metadata: Dict) -> List[Document]:
        """Rozd캩len칤 dokumentu na chunky"""
        chunks = self.text_splitter.split_text(text)
        documents = []
        
        for i, chunk in enumerate(chunks):
            doc_metadata = metadata.copy()
            doc_metadata['chunk_id'] = i
            documents.append(Document(page_content=chunk, metadata=doc_metadata))
        
        return documents

class VectorStoreManager:
    """Spr치va vektorov칠 datab치ze"""
    
    def __init__(self, index_name: str = "legal-docs"):
        self.index_name = index_name
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self._initialize_pinecone()
    
    def _initialize_pinecone(self):
        """Inicializace Pinecone"""
        try:
            pinecone.init(
                api_key=os.getenv("PINECONE_API_KEY"),
                environment=os.getenv("PINECONE_ENVIRONMENT")
            )
            
            # Vytvo콏en칤 indexu pokud neexistuje
            if self.index_name not in pinecone.list_indexes():
                pinecone.create_index(
                    name=self.index_name,
                    dimension=3072,  # Dimenze pro text-embedding-3-large
                    metric="cosine"
                )
            
            self.vector_store = PineconeVectorStore(
                index_name=self.index_name,
                embedding=self.embeddings
            )
            logger.info("Pinecone 칰sp캩코n캩 inicializov치no")
            
        except Exception as e:
            logger.error(f"Chyba p콏i inicializaci Pinecone: {e}")
            raise
    
    def add_documents(self, documents: List[Document]) -> bool:
        """P콏id치n칤 dokument콢 do vektorov칠 datab치ze"""
        try:
            self.vector_store.add_documents(documents)
            logger.info(f"P콏id치no {len(documents)} dokument콢")
            return True
        except Exception as e:
            logger.error(f"Chyba p콏i p콏id치v치n칤 dokument콢: {e}")
            return False
    
    def similarity_search(self, query: str, k: int = 5) -> List[Document]:
        """Vyhled치v치n칤 podobn칳ch dokument콢"""
        try:
            return self.vector_store.similarity_search(query, k=k)
        except Exception as e:
            logger.error(f"Chyba p콏i vyhled치v치n칤: {e}")
            return []

class LegalAssistant:
    """Hlavn칤 t콏칤da pr치vn칤ho asistenta"""
    
    def __init__(self):
        self.vector_manager = VectorStoreManager()
        self.pdf_processor = PDFProcessor()
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.1,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self._setup_qa_chain()
    
    def _setup_qa_chain(self):
        """Nastaven칤 QA 콏et캩zce"""
        template = """
        Jsi zku코en칳 pr치vn칤 asistent specializuj칤c칤 se na 캜esk칠 pr치vo. 
        Na z치klad캩 poskytnut칳ch pr치vn칤ch dokument콢 odpov캩z na ot치zku u쬴vatele.
        
        PRAVIDLA:
        1. Odpov칤dej pouze na z치klad캩 poskytnut칳ch dokument콢
        2. Uve캞 konkr칠tn칤 odkazy na relevantn칤 캜치sti dokument콢
        3. Pokud informace nejsou dostupn칠, jasn캩 to 콏ekni
        4. Pou쬴j profesion치ln칤 pr치vn칤 terminologii
        5. Struktura odpov캩di mus칤 b칳t jasn치 a logick치
        
        KONTEXT Z PR츼VN칈CH DOKUMENT콡:
        {context}
        
        OT츼ZKA: {question}
        
        ODPOV캨캝:
        """
        
        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
        
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_manager.vector_store.as_retriever(
                search_kwargs={"k": 5}
            ),
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True
        )
    
    def process_legal_documents(self, pdf_files: List[str]) -> bool:
        """Zpracov치n칤 pr치vn칤ch dokument콢"""
        all_documents = []
        
        for pdf_path in pdf_files:
            try:
                # Extrakce textu
                text = self.pdf_processor.extract_text(pdf_path)
                if not text:
                    continue
                
                # Metadata
                metadata = {
                    "source": os.path.basename(pdf_path),
                    "doc_type": "legal_document",
                    "file_path": pdf_path
                }
                
                # Rozd캩len칤 na chunky
                documents = self.pdf_processor.split_document(text, metadata)
                all_documents.extend(documents)
                
                logger.info(f"Zpracov치n dokument: {pdf_path}")
                
            except Exception as e:
                logger.error(f"Chyba p콏i zpracov치n칤 {pdf_path}: {e}")
        
        # P콏id치n칤 do vektorov칠 datab치ze
        if all_documents:
            return self.vector_manager.add_documents(all_documents)
        return False
    
    def ask_question(self, question: str) -> Dict:
        """Polo쬰n칤 ot치zky asistentovi"""
        try:
            result = self.qa_chain.invoke({"query": question})
            
            return {
                "answer": result["result"],
                "source_documents": [
                    {
                        "content": doc.page_content[:200] + "...",
                        "source": doc.metadata.get("source", "Nezn치m칳"),
                        "metadata": doc.metadata
                    }
                    for doc in result["source_documents"]
                ],
                "success": True
            }
        except Exception as e:
            logger.error(f"Chyba p콏i odpov칤d치n칤 na ot치zku: {e}")
            return {
                "answer": "Omlouv치me se, do코lo k chyb캩 p콏i zpracov치n칤 va코칤 ot치zky.",
                "source_documents": [],
                "success": False
            }

# Vzorov치 data - vytvo콏en칤 uk치zkov칳ch pr치vn칤ch dokument콢
def create_sample_legal_documents():
    """Vytvo콏en칤 uk치zkov칳ch pr치vn칤ch dokument콢"""
    
    sample_docs = [
        {
            "title": "Pracovn칤 smlouva - vzor",
            "content": """
            PRACOVN칈 SMLOUVA
            
            Zam캩stnavatel: XYZ s.r.o., I캛O: 12345678
            Zam캩stnanec: Jan Nov치k, nar. 1.1.1990
            
            캛l치nek 1 - Z치kladn칤 ustanoven칤
            Zam캩stnavatel p콏ij칤m치 zam캩stnance do pracovn칤ho pom캩ru na pozici 
            softwarov칳 v칳voj치콏 s n치stupem dne 1.1.2024.
            
            캛l치nek 2 - Pracovn칤 doba
            Stanoven치 t칳denn칤 pracovn칤 doba 캜in칤 40 hodin. Zam캩stnanec je povinen 
            dodr쬺vat pracovn칤 dobu od 9:00 do 17:00 hodin.
            
            캛l치nek 3 - Odm캩켿ov치n칤
            Z치kladn칤 mzda 캜in칤 80.000 K캜 m캩s칤캜n캩. Mzda je splatn치 do 15. dne 
            n치sleduj칤c칤ho m캩s칤ce.
            
            캛l치nek 4 - V칳pov캩dn칤 doba
            V칳pov캩dn칤 doba 캜in칤 2 m캩s칤ce a za캜칤n치 b캩쬰t prvn칤m dnem m캩s칤ce 
            n치sleduj칤c칤ho po doru캜en칤 v칳pov캩di.
            """
        },
        {
            "title": "N치jemn칤 smlouva - byt",
            "content": """
            SMLOUVA O N츼JMU BYTU
            
            Pronaj칤matel: Anna Svobodov치, bytem Praha 1
            N치jemce: Pavel Dvo콏치k, bytem Praha 5
            
            캛l치nek 1 - P콏edm캩t n치jmu
            Pronaj칤matel pronaj칤m치 n치jemci byt 2+1 o v칳m캩콏e 65 m 
            v Praze 2, Vinohrady.
            
            캛l치nek 2 - N치jemn칠
            M캩s칤캜n칤 n치jemn칠 캜in칤 25.000 K캜 a je splatn칠 do 5. dne v m캩s칤ci.
            Slu쬭y spojen칠 s u쮂셨치n칤m bytu 캜in칤 3.000 K캜 m캩s칤캜n캩.
            
            캛l치nek 3 - Kauce
            N치jemce slo쮂 kauci ve v칳코i trojn치sobku m캩s칤캜n칤ho n치jemn칠ho, 
            tj. 75.000 K캜 p콏ed p콏ed치n칤m bytu.
            
            캛l치nek 4 - Doba n치jmu
            Smlouva se uzav칤r치 na dobu neur캜itou s v칳pov캩dn칤 dobou 3 m캩s칤ce.
            """
        }
    ]
    
    # Ulo쬰n칤 do soubor콢
    os.makedirs("sample_docs", exist_ok=True)
    
    for i, doc in enumerate(sample_docs):
        filename = f"sample_docs/dokument_{i+1}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {doc['title']}\n\n{doc['content']}")
        logger.info(f"Vytvo콏en uk치zkov칳 dokument: {filename}")

def main():
    """Hlavn칤 funkce pro testov치n칤"""
    # Vytvo콏en칤 uk치zkov칳ch dokument콢
    create_sample_legal_documents()
    
    # Inicializace asistenta
    assistant = LegalAssistant()
    
    # Zpracov치n칤 dokument콢 (v re치ln칠 aplikaci by byly PDF)
    # Pro demo 칰캜ely m콢쬰me simulovat
    logger.info("Syst칠m pr치vn칤ho asistenta je p콏ipraven!")
    
    # Uk치zkov칠 ot치zky
    sample_questions = [
        "Jak치 je v칳pov캩dn칤 doba v pracovn칤 smlouv캩?",
        "Kolik 캜in칤 kauce p콏i n치jmu bytu?",
        "Jak칠 jsou podm칤nky pro ukon캜en칤 pracovn칤ho pom캩ru?"
    ]
    
    for question in sample_questions:
        print(f"\nOt치zka: {question}")
        result = assistant.ask_question(question)
        print(f"Odpov캩캞: {result['answer']}")

if __name__ == "__main__":
    main()
````

### Streamlit UI

````python
import streamlit as st
import os
from legal_assistant import LegalAssistant, create_sample_legal_documents
import tempfile

st.set_page_config(
    page_title="AI Pr치vn칤 Asistent",
    page_icon="丘뒲잺",
    layout="wide"
)

def main():
    st.title("丘뒲잺 AI Pr치vn칤 Asistent")
    st.markdown("### RAG syst칠m pro pr치vn칤 dokumenty")
    
    # Sidebar pro nahr치n칤 dokument콢
    with st.sidebar:
        st.header("游늯 Spr치va dokument콢")
        
        uploaded_files = st.file_uploader(
            "Nahrajte pr치vn칤 dokumenty (PDF)",
            type=['pdf'],
            accept_multiple_files=True
        )
        
        if st.button("Vytvo콏it uk치zkov치 data"):
            create_sample_legal_documents()
            st.success("Uk치zkov치 data vytvo콏ena!")
        
        if st.button("Inicializovat syst칠m"):
            with st.spinner("Inicializace..."):
                st.session_state.assistant = LegalAssistant()
                st.success("Syst칠m inicializov치n!")
    
    # Hlavn칤 obsah
    if 'assistant' not in st.session_state:
        st.info("游녣 Nejprve inicializujte syst칠m v postrann칤m panelu")
        return
    
    # Chat rozhran칤
    st.header("游눫 Polo쬾e pr치vn칤 ot치zku")
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # Zobrazen칤 historie
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "sources" in message:
                with st.expander("游닄 Zdroje"):
                    for source in message["sources"]:
                        st.markdown(f"- **{source['source']}**: {source['content']}")
    
    # Input pro novou ot치zku
    if prompt := st.chat_input("Va코e pr치vn칤 ot치zka..."):
        # P콏id치n칤 ot치zky u쬴vatele
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generov치n칤 odpov캩di
        with st.chat_message("assistant"):
            with st.spinner("Hled치m odpov캩캞 v pr치vn칤ch dokumentech..."):
                result = st.session_state.assistant.ask_question(prompt)
                
                st.markdown(result["answer"])
                
                # P콏id치n칤 odpov캩di do historie
                assistant_message = {
                    "role": "assistant",
                    "content": result["answer"],
                    "sources": result["source_documents"]
                }
                st.session_state.messages.append(assistant_message)
                
                # Zobrazen칤 zdroj콢
                if result["source_documents"]:
                    with st.expander("游닄 Zdroje"):
                        for source in result["source_documents"]:
                            st.markdown(f"- **{source['source']}**: {source['content']}")

if __name__ == "__main__":
    main()
````

### Spu코t캩n칤 Aplikace

````bash
# Spu코t캩n칤 Streamlit aplikace
streamlit run streamlit_app.py
````

### Konfigurace Prost콏ed칤

````env
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
````

## Shrnut칤 Projektu

### Kl칤캜ov칠 V칳hody
- **Okam쬴t칠 odpov캩di**: Rychl칠 vyhled치n칤 relevantn칤ch pr치vn칤ch informac칤
- **S칠mantick칠 porozum캩n칤**: Pokro캜il칠 porozum캩n칤 pr치vn칤m dotaz콢m
- **맒치lovatelnost**: Snadn칠 p콏id치v치n칤 nov칳ch pr치vn칤ch dokument콢
- **Transparentnost**: Zobrazen칤 zdroj콢 pro ka쬯ou odpov캩캞

### Technick칠 P콏ednosti
- **Modul치rn칤 architektura**: Odd캩len칠 komponenty pro snadnou 칰dr쬭u
- **Robustn칤 zpracov치n칤 chyb**: Comprehensive error handling
- **Modern칤 tech stack**: Vyu쬴t칤 nejnov캩j코칤ch AI framework콢
- **U쬴vatelsky p콏칤v캩tiv칠 rozhran칤**: Intuitivn칤 Streamlit aplikace

### Potenci치l Roz코칤콏en칤
- Integrace s pr치vn칤mi datab치zemi
- Multijazy캜n치 podpora
- Pokro캜il치 analytika pr치vn칤ch trend콢
- API pro integraci s jin칳mi syst칠my

Tento AI pr치vn칤 asistent p콏edstavuje pokro캜il칠 콏e코en칤 pro automatizaci pr치vn칤ch slu쬰b s vysok칳m potenci치lem pro komer캜n칤 vyu쬴t칤.