<small>Claude Sonnet 4 **(Enterprise Data Analytics Dashboard (MCP))**</small>
# Enterprise Data Analytics Dashboard

## 1. N√°zev projektu

**Enterprise Data Analytics Dashboard s Model Context Protocol (MCP)**

Pokroƒçil√Ω analytick√Ω dashboard pro podnikov√© prost≈ôed√≠ vyu≈æ√≠vaj√≠c√≠ MCP protokol pro komunikaci s AI agenty, SQL datab√°zemi a business intelligence n√°stroji v re√°ln√©m ƒçase.

## 2. Vysvƒõtlen√≠ kl√≠ƒçov√Ωch koncept≈Ø

### Model Context Protocol (MCP)
Standardizovan√Ω protokol pro komunikaci mezi AI aplikacemi a extern√≠mi syst√©my. Umo≈æ≈àuje bezpeƒçn√© a efektivn√≠ sd√≠len√≠ kontextu mezi r≈Øzn√Ωmi komponentami AI syst√©mu.

### Business Intelligence (BI)
Soubor technologi√≠ a proces≈Ø pro anal√Ωzu podnikov√Ωch dat s c√≠lem podpory rozhodov√°n√≠. Zahrnuje reporting, analytics, data mining a vizualizaci.

### Data Visualization
Grafick√© zn√°zornƒõn√≠ dat pomoc√≠ graf≈Ø, map a interaktivn√≠ch prvk≈Ø pro lep≈°√≠ porozumƒõn√≠ a interpretaci informac√≠.

### Real-time Reporting
Syst√©m pro okam≈æit√© zobrazov√°n√≠ aktu√°ln√≠ch dat a trend≈Ø bez ƒçasov√©ho zpo≈ædƒõn√≠, kritick√Ω pro operativn√≠ rozhodov√°n√≠.

### PostgreSQL/MySQL
Relaƒçn√≠ datab√°zov√© syst√©my pro ukl√°d√°n√≠ a spr√°vu strukturovan√Ωch podnikov√Ωch dat s pokroƒçil√Ωmi funkcemi pro analytics.

## 3. Komprehentn√≠ vysvƒõtlen√≠ projektu

### C√≠le projektu
Tento projekt vytv√°≈ô√≠ modern√≠ analytick√Ω dashboard, kter√Ω kombinuje s√≠lu AI agent≈Ø s pokroƒçil√Ωmi datab√°zov√Ωmi technologiemi. Hlavn√≠m c√≠lem je poskytovat mana≈æer≈Øm a analytik≈Øm real-time p≈ôehled o kl√≠ƒçov√Ωch business metrik√°ch s mo≈ænost√≠ interaktivn√≠ch AI-powered anal√Ωz.

### V√Ωzvy
- **Integrace heterogenn√≠ch datov√Ωch zdroj≈Ø**: Spojen√≠ r≈Øzn√Ωch datab√°z√≠ a API
- **Real-time zpracov√°n√≠**: Zaji≈°tƒõn√≠ okam≈æit√© aktualizace dat
- **AI-powered analytics**: Implementace inteligentn√≠ch analytick√Ωch funkc√≠
- **≈†k√°lovatelnost**: Navr≈æen√≠ syst√©mu pro r≈Øst objemu dat
- **Bezpeƒçnost**: Ochrana citliv√Ωch podnikov√Ωch dat

### Potenci√°ln√≠ dopad
- Zrychlen√≠ rozhodovac√≠ch proces≈Ø o 60-80%
- Sn√≠≈æen√≠ n√°klad≈Ø na manu√°ln√≠ reporting
- Zv√Ω≈°en√≠ kvality business rozhodnut√≠ d√≠ky AI insights
- Automatizace rutinn√≠ch analytick√Ωch √∫kol≈Ø

## 4. Komprehentn√≠ p≈ô√≠klad implementace v Pythonu

### Instalace z√°vislost√≠

````python
fastapi==0.104.1
uvicorn==0.24.0
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
pandas==2.1.4
plotly==5.17.0
streamlit==1.28.2
python-dotenv==1.0.0
asyncio==3.4.3
websockets==12.0
redis==5.0.1
pydantic==2.5.2
openai==1.6.1
langchain==0.0.350
langchain-openai==0.0.2
chromadb==0.4.18
````

### Hlavn√≠ MCP Server implementace

````python
import asyncio
import json
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
import plotly.graph_objects as go
import plotly.express as px
from plotly.utils import PlotlyJSONEncoder

@dataclass
class MCPMessage:
    """MCP zpr√°va pro komunikaci mezi komponenty"""
    id: str
    method: str
    params: Dict[str, Any]
    timestamp: datetime

class MCPAnalyticsServer:
    """Hlavn√≠ MCP server pro analytics dashboard"""
    
    def __init__(self, db_url: str):
        self.db_engine = create_engine(
            db_url,
            poolclass=QueuePool,
            pool_size=10,
            max_overflow=20,
            echo=True
        )
        self.connections = {}
        self.cache = {}
        self.logger = logging.getLogger(__name__)
        
    async def handle_connection(self, websocket, path):
        """Zpracov√°n√≠ WebSocket p≈ôipojen√≠"""
        connection_id = f"conn_{datetime.now().timestamp()}"
        self.connections[connection_id] = websocket
        
        try:
            async for message in websocket:
                await self.process_message(connection_id, json.loads(message))
        except Exception as e:
            self.logger.error(f"Chyba v p≈ôipojen√≠ {connection_id}: {e}")
        finally:
            del self.connections[connection_id]
    
    async def process_message(self, connection_id: str, message_data: Dict):
        """Zpracov√°n√≠ MCP zpr√°vy"""
        try:
            message = MCPMessage(
                id=message_data.get('id'),
                method=message_data.get('method'),
                params=message_data.get('params', {}),
                timestamp=datetime.now()
            )
            
            if message.method == "get_sales_analytics":
                result = await self.get_sales_analytics(message.params)
            elif message.method == "get_customer_insights":
                result = await self.get_customer_insights(message.params)
            elif message.method == "get_financial_summary":
                result = await self.get_financial_summary(message.params)
            elif message.method == "generate_forecast":
                result = await self.generate_forecast(message.params)
            else:
                result = {"error": f"Nezn√°m√° metoda: {message.method}"}
            
            response = {
                "id": message.id,
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
            
            websocket = self.connections[connection_id]
            await websocket.send(json.dumps(response))
            
        except Exception as e:
            self.logger.error(f"Chyba p≈ôi zpracov√°n√≠ zpr√°vy: {e}")
    
    async def get_sales_analytics(self, params: Dict) -> Dict:
        """Anal√Ωza prodejn√≠ch dat"""
        try:
            query = """
            SELECT 
                DATE_TRUNC('day', order_date) as date,
                SUM(total_amount) as daily_sales,
                COUNT(*) as order_count,
                AVG(total_amount) as avg_order_value
            FROM orders 
            WHERE order_date >= %s AND order_date <= %s
            GROUP BY DATE_TRUNC('day', order_date)
            ORDER BY date
            """
            
            start_date = params.get('start_date', (datetime.now() - timedelta(days=30)).date())
            end_date = params.get('end_date', datetime.now().date())
            
            df = pd.read_sql(query, self.db_engine, params=[start_date, end_date])
            
            # Vytvo≈ôen√≠ grafu
            fig = px.line(
                df, 
                x='date', 
                y='daily_sales',
                title='Denn√≠ prodeje',
                labels={'daily_sales': 'Prodeje (CZK)', 'date': 'Datum'}
            )
            
            chart_json = json.dumps(fig, cls=PlotlyJSONEncoder)
            
            return {
                "data": df.to_dict('records'),
                "chart": chart_json,
                "summary": {
                    "total_sales": float(df['daily_sales'].sum()),
                    "avg_daily_sales": float(df['daily_sales'].mean()),
                    "total_orders": int(df['order_count'].sum())
                }
            }
            
        except Exception as e:
            return {"error": f"Chyba p≈ôi anal√Ωze prodej≈Ø: {str(e)}"}
    
    async def get_customer_insights(self, params: Dict) -> Dict:
        """Anal√Ωza z√°kaznick√Ωch dat"""
        try:
            query = """
            SELECT 
                c.customer_segment,
                COUNT(DISTINCT c.customer_id) as customer_count,
                SUM(o.total_amount) as segment_revenue,
                AVG(o.total_amount) as avg_order_value
            FROM customers c
            JOIN orders o ON c.customer_id = o.customer_id
            WHERE o.order_date >= %s
            GROUP BY c.customer_segment
            """
            
            start_date = params.get('start_date', (datetime.now() - timedelta(days=90)).date())
            df = pd.read_sql(query, self.db_engine, params=[start_date])
            
            # Pie chart pro segmenty
            fig = px.pie(
                df,
                values='segment_revenue',
                names='customer_segment',
                title='Rozdƒõlen√≠ tr≈æeb podle segment≈Ø z√°kazn√≠k≈Ø'
            )
            
            chart_json = json.dumps(fig, cls=PlotlyJSONEncoder)
            
            return {
                "data": df.to_dict('records'),
                "chart": chart_json,
                "insights": {
                    "most_valuable_segment": df.loc[df['segment_revenue'].idxmax(), 'customer_segment'],
                    "total_customers": int(df['customer_count'].sum()),
                    "total_revenue": float(df['segment_revenue'].sum())
                }
            }
            
        except Exception as e:
            return {"error": f"Chyba p≈ôi anal√Ωze z√°kazn√≠k≈Ø: {str(e)}"}
    
    async def generate_forecast(self, params: Dict) -> Dict:
        """Generov√°n√≠ predikce pomoc√≠ AI"""
        try:
            # Z√≠sk√°n√≠ historick√Ωch dat
            query = """
            SELECT 
                DATE_TRUNC('month', order_date) as month,
                SUM(total_amount) as monthly_sales
            FROM orders 
            WHERE order_date >= %s
            GROUP BY DATE_TRUNC('month', order_date)
            ORDER BY month
            """
            
            start_date = (datetime.now() - timedelta(days=365)).date()
            df = pd.read_sql(query, self.db_engine, params=[start_date])
            
            # Jednoduch√° line√°rn√≠ predikce (v re√°ln√©m projektu by se pou≈æil pokroƒçilej≈°√≠ model)
            if len(df) >= 3:
                trend = (df['monthly_sales'].iloc[-1] - df['monthly_sales'].iloc[0]) / len(df)
                forecast_months = 6
                
                forecast_data = []
                last_value = df['monthly_sales'].iloc[-1]
                last_date = df['month'].iloc[-1]
                
                for i in range(1, forecast_months + 1):
                    next_month = last_date + pd.DateOffset(months=i)
                    forecast_value = last_value + (trend * i)
                    forecast_data.append({
                        'month': next_month,
                        'forecasted_sales': forecast_value,
                        'type': 'forecast'
                    })
                
                # Kombinace historick√Ωch a predikovan√Ωch dat
                df['type'] = 'historical'
                df['forecasted_sales'] = df['monthly_sales']
                
                combined_df = pd.concat([
                    df[['month', 'forecasted_sales', 'type']],
                    pd.DataFrame(forecast_data)
                ])
                
                # Graf s predikc√≠
                fig = px.line(
                    combined_df,
                    x='month',
                    y='forecasted_sales',
                    color='type',
                    title='Predikce mƒõs√≠ƒçn√≠ch prodej≈Ø'
                )
                
                chart_json = json.dumps(fig, cls=PlotlyJSONEncoder)
                
                return {
                    "forecast": forecast_data,
                    "chart": chart_json,
                    "confidence": "medium",
                    "trend": "rostouc√≠" if trend > 0 else "klesaj√≠c√≠"
                }
            else:
                return {"error": "Nedostatek dat pro predikci"}
                
        except Exception as e:
            return {"error": f"Chyba p≈ôi generov√°n√≠ predikce: {str(e)}"}
````

### Streamlit Dashboard

````python
import streamlit as st
import asyncio
import websockets
import json
import plotly.graph_objects as go
from plotly.utils import PlotlyJSONEncoder
import pandas as pd
from datetime import datetime, timedelta
import time

class DashboardClient:
    """Klient pro komunikaci s MCP serverem"""
    
    def __init__(self, server_url: str):
        self.server_url = server_url
        self.websocket = None
    
    async def connect(self):
        """P≈ôipojen√≠ k MCP serveru"""
        try:
            self.websocket = await websockets.connect(self.server_url)
            return True
        except Exception as e:
            st.error(f"Chyba p≈ôipojen√≠: {e}")
            return False
    
    async def send_request(self, method: str, params: dict = None) -> dict:
        """Odesl√°n√≠ po≈æadavku na server"""
        if not self.websocket:
            await self.connect()
        
        message = {
            "id": f"req_{datetime.now().timestamp()}",
            "method": method,
            "params": params or {}
        }
        
        await self.websocket.send(json.dumps(message))
        response = await self.websocket.recv()
        return json.loads(response)
    
    async def close(self):
        """Uzav≈ôen√≠ spojen√≠"""
        if self.websocket:
            await self.websocket.close()

def main():
    st.set_page_config(
        page_title="Enterprise Analytics Dashboard",
        page_icon="üìä",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üè¢ Enterprise Data Analytics Dashboard")
    st.markdown("---")
    
    # Sidebar pro konfiguraci
    with st.sidebar:
        st.header("‚öôÔ∏è Konfigurace")
        
        # V√Ωbƒõr ƒçasov√©ho obdob√≠
        date_range = st.date_input(
            "Obdob√≠ anal√Ωzy",
            value=[datetime.now() - timedelta(days=30), datetime.now()],
            max_value=datetime.now()
        )
        
        # V√Ωbƒõr typu anal√Ωzy
        analysis_type = st.selectbox(
            "Typ anal√Ωzy",
            ["Prodejn√≠ analytics", "Z√°kaznick√© insights", "Finanƒçn√≠ p≈ôehled", "Predikce"]
        )
        
        # Refresh interval
        refresh_interval = st.slider("Auto-refresh (sekundy)", 30, 300, 60)
        auto_refresh = st.checkbox("Automatick√© obnovov√°n√≠")
    
    # Hlavn√≠ obsah
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if analysis_type == "Prodejn√≠ analytics":
            st.subheader("üìà Anal√Ωza prodej≈Ø")
            
            # Placeholder pro real-time data
            chart_placeholder = st.empty()
            metrics_placeholder = st.empty()
            
            # Simulace naƒç√≠t√°n√≠ dat
            with st.spinner("Naƒç√≠t√°n√≠ prodejn√≠ch dat..."):
                # V re√°ln√© aplikaci by zde byla komunikace s MCP serverem
                sample_data = {
                    "total_sales": 2450000,
                    "avg_daily_sales": 78000,
                    "total_orders": 1250,
                    "growth_rate": 12.5
                }
                
                # Metriky
                with metrics_placeholder.container():
                    met_col1, met_col2, met_col3, met_col4 = st.columns(4)
                    
                    with met_col1:
                        st.metric(
                            "Celkov√© prodeje",
                            f"{sample_data['total_sales']:,.0f} CZK",
                            f"{sample_data['growth_rate']:.1f}%"
                        )
                    
                    with met_col2:
                        st.metric(
                            "Pr≈Ømƒõrn√© denn√≠ prodeje",
                            f"{sample_data['avg_daily_sales']:,.0f} CZK"
                        )
                    
                    with met_col3:
                        st.metric(
                            "Poƒçet objedn√°vek",
                            f"{sample_data['total_orders']:,}"
                        )
                    
                    with met_col4:
                        st.metric(
                            "Pr≈Ømƒõrn√° hodnota objedn√°vky",
                            f"{sample_data['total_sales']/sample_data['total_orders']:,.0f} CZK"
                        )
                
                # Graf
                with chart_placeholder.container():
                    # Simulace dat pro graf
                    dates = pd.date_range(start=date_range[0], end=date_range[1], freq='D')
                    sales_data = pd.DataFrame({
                        'date': dates,
                        'sales': [50000 + i*1000 + (i%7)*5000 for i in range(len(dates))]
                    })
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=sales_data['date'],
                        y=sales_data['sales'],
                        mode='lines+markers',
                        name='Denn√≠ prodeje',
                        line=dict(color='#1f77b4', width=3)
                    ))
                    
                    fig.update_layout(
                        title="V√Ωvoj denn√≠ch prodej≈Ø",
                        xaxis_title="Datum",
                        yaxis_title="Prodeje (CZK)",
                        hovermode='x unified'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
        
        elif analysis_type == "Z√°kaznick√© insights":
            st.subheader("üë• Anal√Ωza z√°kazn√≠k≈Ø")
            
            # Segmentace z√°kazn√≠k≈Ø
            segment_data = {
                'Premium': {'count': 450, 'revenue': 1200000},
                'Standard': {'count': 1200, 'revenue': 800000},
                'Basic': {'count': 800, 'revenue': 300000}
            }
            
            col_seg1, col_seg2 = st.columns(2)
            
            with col_seg1:
                # Pie chart pro segmenty
                labels = list(segment_data.keys())
                values = [segment_data[k]['revenue'] for k in labels]
                
                fig = go.Figure(data=[go.Pie(labels=labels, values=values)])
                fig.update_layout(title="Rozdƒõlen√≠ tr≈æeb podle segment≈Ø")
                st.plotly_chart(fig, use_container_width=True)
            
            with col_seg2:
                # Tabulka s detaily
                st.markdown("**Detaily segment≈Ø:**")
                for segment, data in segment_data.items():
                    st.metric(
                        f"Segment {segment}",
                        f"{data['count']} z√°kazn√≠k≈Ø",
                        f"{data['revenue']:,} CZK"
                    )
    
    with col2:
        st.subheader("üîç AI Insights")
        
        # AI-powered insights
        with st.container():
            st.markdown("**ü§ñ Automatick√© pozorov√°n√≠:**")
            
            insights = [
                "üìä Prodeje rostou o 12.5% mƒõs√≠ƒçnƒõ",
                "üéØ Premium z√°kazn√≠ci generuj√≠ 52% tr≈æeb",
                "üìà Nejlep≈°√≠ den v t√Ωdnu: p√°tek",
                "‚ö†Ô∏è Pokles objedn√°vek v √∫ter√Ω",
                "üîÆ Predikce: +15% r≈Øst p≈ô√≠≈°t√≠ mƒõs√≠c"
            ]
            
            for insight in insights:
                st.markdown(f"- {insight}")
        
        st.markdown("---")
        
        # Real-time status
        st.subheader("‚ö° Real-time Status")
        
        status_data = {
            "Datab√°ze": "üü¢ Online",
            "MCP Server": "üü¢ Aktivn√≠",
            "Cache": "üü° 75% vyu≈æit√≠",
            "API": "üü¢ Dostupn√©"
        }
        
        for component, status in status_data.items():
            st.markdown(f"**{component}:** {status}")
    
    # Auto-refresh funkce
    if auto_refresh:
        time.sleep(refresh_interval)
        st.experimental_rerun()

if __name__ == "__main__":
    main()
````

### Datab√°zov√° inicializace

````python
from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, DateTime, Text
from sqlalchemy.sql import text
import pandas as pd
from datetime import datetime, timedelta
import random

def create_sample_database(db_url: str):
    """Vytvo≈ôen√≠ uk√°zkov√© datab√°ze s testovac√≠mi daty"""
    
    engine = create_engine(db_url)
    metadata = MetaData()
    
    # Tabulka z√°kazn√≠k≈Ø
    customers = Table('customers', metadata,
        Column('customer_id', Integer, primary_key=True),
        Column('customer_name', String(100)),
        Column('customer_segment', String(50)),
        Column('registration_date', DateTime),
        Column('total_spent', Float)
    )
    
    # Tabulka objedn√°vek
    orders = Table('orders', metadata,
        Column('order_id', Integer, primary_key=True),
        Column('customer_id', Integer),
        Column('order_date', DateTime),
        Column('total_amount', Float),
        Column('product_category', String(50)),
        Column('status', String(20))
    )
    
    # Vytvo≈ôen√≠ tabulek
    metadata.create_all(engine)
    
    # Vlo≈æen√≠ testovac√≠ch dat
    customers_data = []
    segments = ['Premium', 'Standard', 'Basic']
    
    for i in range(1, 1001):
        customers_data.append({
            'customer_id': i,
            'customer_name': f'Z√°kazn√≠k {i}',
            'customer_segment': random.choice(segments),
            'registration_date': datetime.now() - timedelta(days=random.randint(1, 365)),
            'total_spent': random.uniform(1000, 50000)
        })
    
    # Objedn√°vky
    orders_data = []
    categories = ['Elektronika', 'Obleƒçen√≠', 'Knihy', 'Sport', 'Dom√°cnost']
    statuses = ['Dokonƒçeno', 'Zpracov√°v√° se', 'Zru≈°eno']
    
    for i in range(1, 5001):
        orders_data.append({
            'order_id': i,
            'customer_id': random.randint(1, 1000),
            'order_date': datetime.now() - timedelta(days=random.randint(1, 90)),
            'total_amount': random.uniform(500, 25000),
            'product_category': random.choice(categories),
            'status': random.choice(statuses)
        })
    
    # Ulo≈æen√≠ do datab√°ze
    customers_df = pd.DataFrame(customers_data)
    orders_df = pd.DataFrame(orders_data)
    
    customers_df.to_sql('customers', engine, if_exists='replace', index=False)
    orders_df.to_sql('orders', engine, if_exists='replace', index=False)
    
    print("‚úÖ Uk√°zkov√° datab√°ze byla √∫spƒõ≈°nƒõ vytvo≈ôena!")

if __name__ == "__main__":
    # PostgreSQL p≈ôipojen√≠
    DB_URL = "postgresql://username:password@localhost:5432/analytics_db"
    create_sample_database(DB_URL)
````

### Spu≈°tƒõn√≠ aplikace

````python
import subprocess
import sys
import os
from pathlib import Path

def setup_environment():
    """Nastaven√≠ prost≈ôed√≠ a instalace z√°vislost√≠"""
    print("üîß Nastavov√°n√≠ prost≈ôed√≠...")
    
    # Instalace z√°vislost√≠
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
    
    # Kontrola PostgreSQL
    print("üóÑÔ∏è Kontrola datab√°zov√©ho p≈ôipojen√≠...")
    
    # Vytvo≈ôen√≠ .env souboru
    env_content = """
DATABASE_URL=postgresql://username:password@localhost:5432/analytics_db
MCP_SERVER_PORT=8765
STREAMLIT_PORT=8501
OPENAI_API_KEY=your_openai_api_key_here
"""
    
    with open('.env', 'w') as f:
        f.write(env_content)
    
    print("‚úÖ Prost≈ôed√≠ je p≈ôipraveno!")

def run_dashboard():
    """Spu≈°tƒõn√≠ cel√©ho dashboardu"""
    print("üöÄ Spou≈°tƒõn√≠ Enterprise Analytics Dashboard...")
    
    try:
        # Spu≈°tƒõn√≠ Streamlit aplikace
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", "dashboard.py",
            "--server.port", "8501",
            "--server.address", "localhost"
        ])
    except KeyboardInterrupt:
        print("\nüõë Dashboard byl zastaven.")
    except Exception as e:
        print(f"‚ùå Chyba p≈ôi spou≈°tƒõn√≠: {e}")

if __name__ == "__main__":
    setup_environment()
    run_dashboard()
````

## 5. Shrnut√≠ projektu

### Hodnota projektu
Enterprise Data Analytics Dashboard p≈ôedstavuje pokroƒçil√© ≈ôe≈°en√≠ pro modern√≠ podnikov√© prost≈ôed√≠, kter√© kombinuje:

- **AI-powered analytics** s MCP protokolem pro inteligentn√≠ anal√Ωzy
- **Real-time reporting** pro okam≈æit√© business insights
- **≈†k√°lovatelnou architekturu** podporuj√≠c√≠ r≈Øst objemu dat
- **U≈æivatelsky p≈ô√≠vƒõtiv√© rozhran√≠** pro mana≈æery v≈°ech √∫rovn√≠

### Kl√≠ƒçov√© v√Ωhody
- **Rychlost rozhodov√°n√≠**: Real-time data a automatick√© insights
- **Efektivita**: Automatizace rutinn√≠ch analytick√Ωch √∫kol≈Ø
- **≈†k√°lovatelnost**: Podpora pro velk√© objemy dat a u≈æivatel≈Ø
- **Flexibilita**: Modul√°rn√≠ architektura umo≈æ≈àuj√≠c√≠ snadn√© roz≈°√≠≈ôen√≠

### Technologick√© highlights
- Modern√≠ MCP protokol pro AI komunikaci
- Pokroƒçil√© vizualizace s Plotly
- Asynchronn√≠ zpracov√°n√≠ pro vysok√Ω v√Ωkon
- Robustn√≠ datab√°zov√° integrace s PostgreSQL

Tento projekt demonstruje, jak lze efektivnƒõ kombinovat AI technologie s tradiƒçn√≠mi business intelligence n√°stroji pro vytvo≈ôen√≠ v√Ωkonn√©ho analytick√©ho ≈ôe≈°en√≠ pro podnikov√© prost≈ôed√≠.