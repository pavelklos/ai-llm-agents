<small>Claude Sonnet 4 **(Automatizovan√Ω Analyz√°tor Pr√°vn√≠ch Dokument≈Ø s MCP)**</small>
# Automated Legal Document Analyzer with MCP

## 1. Kl√≠ƒçov√© Koncepty

### Model Context Protocol (MCP)
MCP je univerz√°ln√≠ protokol pro komunikaci mezi jazykov√Ωmi modely a extern√≠mi datov√Ωmi zdroji. Umo≈æ≈àuje model≈Øm p≈ô√≠stup k real-time informac√≠m, datab√°z√≠m a API slu≈æb√°m prost≈ôednictv√≠m standardizovan√©ho rozhran√≠.

### Natural Language Processing (NLP)
Technologie umo≈æ≈àuj√≠c√≠ poƒç√≠taƒç≈Øm porozumƒõt, interpretovat a generovat lidsk√Ω jazyk. V pr√°vn√≠m kontextu se pou≈æ√≠v√° pro anal√Ωzu smluv, extrakci kl√≠ƒçov√Ωch informac√≠ a identifikaci pr√°vn√≠ch klauzul√≠.

### Contract Review
Automatizovan√Ω proces kontroly pr√°vn√≠ch dokument≈Ø zahrnuj√≠c√≠ identifikaci rizikov√Ωch klauzul√≠, kontrolu dodr≈æov√°n√≠ standard≈Ø a vyhodnocen√≠ smluvn√≠ch podm√≠nek.

### Semantic Search
Pokroƒçil√° vyhled√°vac√≠ technologie, kter√° rozum√≠ v√Ωznamu a kontextu dotaz≈Ø, nikoli pouze kl√≠ƒçov√Ωm slov≈Øm. Umo≈æ≈àuje nalezen√≠ relevantn√≠ch dokument≈Ø na z√°kladƒõ s√©mantick√© podobnosti.

### Zero-Shot Classification
Technika strojov√©ho uƒçen√≠, kter√° umo≈æ≈àuje klasifikaci textu do kategori√≠ bez p≈ôedchoz√≠ho tr√©nov√°n√≠ na specifick√Ωch datech. Model vyu≈æ√≠v√° sv√© obecn√© znalosti k rozpozn√°n√≠ vzor≈Ø.

### Haystack
Open-source framework pro budov√°n√≠ NLP aplikac√≠, zejm√©na pro vyhled√°v√°n√≠ v dokumentech, question-answering syst√©my a semantickou anal√Ωzu.

## 2. Komplexn√≠ Vysvƒõtlen√≠ Projektu

### C√≠le Projektu
Automatizovan√Ω analyz√°tor pr√°vn√≠ch dokument≈Ø s MCP p≈ôedstavuje pokroƒçil√Ω syst√©m pro zpracov√°n√≠ a anal√Ωzu pr√°vn√≠ch text≈Ø. Hlavn√≠mi c√≠li jsou:

- **Automatizace kontroly smluv** - Rychl√° identifikace problematick√Ωch klauzul√≠
- **Extrakce kl√≠ƒçov√Ωch informac√≠** - Automatick√© z√≠sk√°v√°n√≠ d≈Øle≈æit√Ωch √∫daj≈Ø ze smluv
- **S√©mantick√© vyhled√°v√°n√≠** - Inteligentn√≠ prohled√°v√°n√≠ velk√Ωch archiv≈Ø dokument≈Ø
- **Klasifikace dokument≈Ø** - Automatick√© t≈ô√≠dƒõn√≠ podle typu a obsahu
- **Hodnocen√≠ rizik** - Identifikace potenci√°ln√≠ch pr√°vn√≠ch rizik

### V√Ωzvy a Probl√©my
1. **Komplexnost pr√°vn√≠ho jazyka** - Pr√°vn√≠ texty obsahuj√≠ specifickou terminologii
2. **Kontextov√© z√°vislosti** - V√Ωznam klauzul√≠ z√°vis√≠ na celkov√©m kontextu
3. **R≈Øznorodost dokument≈Ø** - R≈Øzn√© typy smluv maj√≠ odli≈°nou strukturu
4. **P≈ôesnost anal√Ωzy** - Vysok√© n√°roky na spr√°vnost interpretace
5. **Integrace dat** - Propojen√≠ s extern√≠mi pr√°vn√≠mi datab√°zemi

### Potenci√°ln√≠ Dopad
- **Zv√Ω≈°en√≠ efektivity** - Redukce ƒçasu pot≈ôebn√©ho na kontrolu dokument≈Ø
- **Sn√≠≈æen√≠ chyb** - Automatick√° detekce p≈ôehl√©dnut√Ωch probl√©m≈Ø
- **Standardizace proces≈Ø** - Jednotn√Ω p≈ô√≠stup k anal√Ωze dokument≈Ø
- **√öspora n√°klad≈Ø** - Sn√≠≈æen√≠ pot≈ôeby manu√°ln√≠ pr√°ce pr√°vn√≠k≈Ø
- **Lep≈°√≠ dostupnost** - Demokratizace p≈ô√≠stupu k pr√°vn√≠ anal√Ωze

## 3. Komplexn√≠ Implementace s P≈ô√≠kladem

````python
langchain==0.1.16
openai==1.23.3
haystack-ai==0.1.2
chromadb==0.4.24
python-dotenv==1.0.0
streamlit==1.32.2
PyPDF2==3.0.1
spacy==3.7.4
transformers==4.40.1
sentence-transformers==2.7.0
matplotlib==3.8.4
plotly==5.20.0
pandas==2.2.2
numpy==1.26.4
requests==2.31.0
````

````python
import os
import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import re

import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
import PyPDF2
import plotly.express as px
import plotly.graph_objects as go

# Konfigurace logov√°n√≠
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ContractClause:
    """Reprezentace smluvn√≠ klauzule"""
    text: str
    clause_type: str
    risk_level: str
    confidence: float
    page: int
    position: int

@dataclass
class DocumentAnalysis:
    """V√Ωsledek anal√Ωzy dokumentu"""
    document_id: str
    title: str
    document_type: str
    clauses: List[ContractClause]
    key_terms: Dict[str, Any]
    risk_score: float
    summary: str
    recommendations: List[str]

class MCPLegalAnalyzer:
    """Hlavn√≠ t≈ô√≠da pro anal√Ωzu pr√°vn√≠ch dokument≈Ø s MCP"""
    
    def __init__(self, openai_api_key: str):
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        # Inicializace ChromaDB
        self.chroma_client = chromadb.Client(Settings(
            persist_directory="./chroma_db",
            anonymized_telemetry=False
        ))
        
        # Kolekce pro ukl√°d√°n√≠ dokument≈Ø
        try:
            self.collection = self.chroma_client.get_collection("legal_documents")
        except:
            self.collection = self.chroma_client.create_collection("legal_documents")
        
        # Definice typ≈Ø klauzul√≠ a jejich rizikov√Ωch √∫rovn√≠
        self.clause_types = {
            "termination": "Ukonƒçen√≠ smlouvy",
            "payment": "Platebn√≠ podm√≠nky", 
            "liability": "Odpovƒõdnost za ≈°kody",
            "confidentiality": "Mlƒçenlivost",
            "intellectual_property": "Du≈°evn√≠ vlastnictv√≠",
            "dispute_resolution": "≈òe≈°en√≠ spor≈Ø",
            "force_majeure": "Vy≈°≈°√≠ moc",
            "governing_law": "Rozhodn√© pr√°vo"
        }
        
        self.risk_patterns = {
            "vysok√©": [
                r"bez omezen√≠ odpovƒõdnosti",
                r"neomezen√° z√°ruka",
                r"okam≈æit√© ukonƒçen√≠",
                r"v√Ωhradn√≠ licen[cz]e",
                r"nezru≈°iteln√© postoupen√≠"
            ],
            "st≈ôedn√≠": [
                r"omezen√° z√°ruka",
                r"v√Ωpovƒõdn√≠ lh≈Øta \d+ dn[√≠≈Ø]",
                r"smluvn√≠ pokuta",
                r"nev√Ωhradn√≠ licen[cz]e"
            ],
            "n√≠zk√©": [
                r"standardn√≠ z√°ruka",
                r"v√Ωpovƒõdn√≠ lh≈Øta \d+ mƒõs√≠c[≈Øy]",
                r"p≈ôimƒõ≈ôen√° n√°hrada"
            ]
        }

    def extract_text_from_pdf(self, pdf_file) -> str:
        """Extrakce textu z PDF souboru"""
        try:
            reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            logger.error(f"Chyba p≈ôi ƒçten√≠ PDF: {e}")
            raise

    def preprocess_text(self, text: str) -> str:
        """P≈ôedzpracov√°n√≠ textu"""
        # Odstranƒõn√≠ nadbyteƒçn√Ωch mezer a znak≈Ø
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s\.\,\;\:\!\?\-\(\)]', '', text)
        return text.strip()

    def classify_clause_type(self, text: str) -> str:
        """Klasifikace typu klauzule pomoc√≠ zero-shot classification"""
        prompt = f"""
        Klasifikuj n√°sleduj√≠c√≠ smluvn√≠ klauzuli do jedn√© z tƒõchto kategori√≠:
        - termination (ukonƒçen√≠ smlouvy)
        - payment (platebn√≠ podm√≠nky)
        - liability (odpovƒõdnost za ≈°kody)
        - confidentiality (mlƒçenlivost)
        - intellectual_property (du≈°evn√≠ vlastnictv√≠)
        - dispute_resolution (≈ôe≈°en√≠ spor≈Ø)
        - force_majeure (vy≈°≈°√≠ moc)
        - governing_law (rozhodn√© pr√°vo)
        - other (ostatn√≠)
        
        Text klauzule: {text}
        
        Odpovƒõz pouze n√°zvem kategorie.
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50,
                temperature=0.1
            )
            return response.choices[0].message.content.strip().lower()
        except Exception as e:
            logger.error(f"Chyba p≈ôi klasifikaci: {e}")
            return "other"

    def assess_risk_level(self, text: str) -> tuple[str, float]:
        """Hodnocen√≠ rizikov√© √∫rovnƒõ klauzule"""
        text_lower = text.lower()
        
        # Kontrola rizikov√Ωch vzor≈Ø
        for risk_level, patterns in self.risk_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    confidence = 0.8
                    return risk_level, confidence
        
        # Pokud nebyl nalezen vzor, pou≈æij LLM
        prompt = f"""
        Vyhodno≈• rizikovou √∫rove≈à n√°sleduj√≠c√≠ smluvn√≠ klauzule na ≈°k√°le:
        - vysok√© (m≈Ø≈æe zp≈Øsobit znaƒçn√© probl√©my)
        - st≈ôedn√≠ (standardn√≠ obchodn√≠ riziko)
        - n√≠zk√© (minim√°ln√≠ riziko)
        
        Text: {text}
        
        Odpovƒõz ve form√°tu: √∫rove≈à|d≈Øvƒõra (0.0-1.0)
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.1
            )
            
            result = response.choices[0].message.content.strip()
            parts = result.split('|')
            if len(parts) == 2:
                return parts[0].strip(), float(parts[1].strip())
            else:
                return "st≈ôedn√≠", 0.5
                
        except Exception as e:
            logger.error(f"Chyba p≈ôi hodnocen√≠ rizika: {e}")
            return "st≈ôedn√≠", 0.5

    def extract_key_terms(self, text: str) -> Dict[str, Any]:
        """Extrakce kl√≠ƒçov√Ωch √∫daj≈Ø ze smlouvy"""
        prompt = f"""
        Extrahuj z n√°sleduj√≠c√≠ smlouvy tyto kl√≠ƒçov√© informace a vra≈• je jako JSON:
        {{
            "strany": ["strana1", "strana2"],
            "datum_podpisu": "YYYY-MM-DD nebo null",
            "datum_platnosti": "YYYY-MM-DD nebo null", 
            "hodnota_smlouvy": "ƒç√°stka nebo null",
            "mena": "CZK/EUR/USD nebo null",
            "typ_smlouvy": "typ smlouvy",
            "platnost_do": "YYYY-MM-DD nebo null"
        }}
        
        Text smlouvy: {text[:2000]}...
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.1
            )
            
            result = response.choices[0].message.content.strip()
            return json.loads(result)
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi extrakci kl√≠ƒçov√Ωch √∫daj≈Ø: {e}")
            return {}

    def generate_summary(self, text: str) -> str:
        """Generov√°n√≠ shrnut√≠ dokumentu"""
        prompt = f"""
        Vytvo≈ôte struƒçn√© shrnut√≠ n√°sleduj√≠c√≠ho pr√°vn√≠ho dokumentu v ƒçe≈°tinƒõ.
        Zamƒõ≈ôte se na:
        - Typ smlouvy
        - Hlavn√≠ p≈ôedmƒõt
        - Kl√≠ƒçov√© podm√≠nky
        - D≈Øle≈æit√° data
        
        Text: {text[:1500]}...
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi generov√°n√≠ shrnut√≠: {e}")
            return "Shrnut√≠ nen√≠ k dispozici."

    def generate_recommendations(self, clauses: List[ContractClause]) -> List[str]:
        """Generov√°n√≠ doporuƒçen√≠ na z√°kladƒõ anal√Ωzy"""
        recommendations = []
        
        high_risk_clauses = [c for c in clauses if c.risk_level == "vysok√©"]
        if high_risk_clauses:
            recommendations.append(
                f"Identifikov√°no {len(high_risk_clauses)} vysoce rizikov√Ωch klauzul√≠. "
                "Doporuƒçujeme pr√°vn√≠ konzultaci p≈ôed podpisem."
            )
        
        termination_clauses = [c for c in clauses if c.clause_type == "termination"]
        if not termination_clauses:
            recommendations.append(
                "Ve smlouvƒõ nebyla nalezena klauzule o ukonƒçen√≠. "
                "Doporuƒçujeme doplnit podm√≠nky pro ukonƒçen√≠ smlouvy."
            )
        
        liability_clauses = [c for c in clauses if c.clause_type == "liability"]
        if not liability_clauses:
            recommendations.append(
                "Chyb√≠ definice odpovƒõdnosti za ≈°kody. "
                "Zva≈æte doplnƒõn√≠ klauzule o odpovƒõdnosti."
            )
            
        return recommendations

    def analyze_document(self, text: str, document_id: str, title: str) -> DocumentAnalysis:
        """Komplexn√≠ anal√Ωza dokumentu"""
        logger.info(f"Zahajuji anal√Ωzu dokumentu: {title}")
        
        # P≈ôedzpracov√°n√≠ textu
        processed_text = self.preprocess_text(text)
        
        # Rozdƒõlen√≠ na ƒç√°sti
        chunks = self.text_splitter.split_text(processed_text)
        
        # Anal√Ωza jednotliv√Ωch ƒç√°st√≠
        clauses = []
        for i, chunk in enumerate(chunks):
            if len(chunk.strip()) < 50:  # P≈ôeskoƒçit p≈ô√≠li≈° kr√°tk√© ƒç√°sti
                continue
                
            clause_type = self.classify_clause_type(chunk)
            risk_level, confidence = self.assess_risk_level(chunk)
            
            clause = ContractClause(
                text=chunk,
                clause_type=clause_type,
                risk_level=risk_level,
                confidence=confidence,
                page=i // 3 + 1,  # Odhad str√°nky
                position=i
            )
            clauses.append(clause)
        
        # Extrakce kl√≠ƒçov√Ωch √∫daj≈Ø
        key_terms = self.extract_key_terms(processed_text)
        
        # V√Ωpoƒçet celkov√©ho rizikov√©ho sk√≥re
        risk_scores = {"vysok√©": 3, "st≈ôedn√≠": 2, "n√≠zk√©": 1}
        total_risk = sum(risk_scores.get(c.risk_level, 2) * c.confidence for c in clauses)
        max_possible_risk = len(clauses) * 3
        risk_score = (total_risk / max_possible_risk) if max_possible_risk > 0 else 0
        
        # Generov√°n√≠ shrnut√≠ a doporuƒçen√≠
        summary = self.generate_summary(processed_text)
        recommendations = self.generate_recommendations(clauses)
        
        # Ulo≈æen√≠ do vektorov√© datab√°ze
        self.store_document(document_id, processed_text, {
            "title": title,
            "analysis_date": datetime.now().isoformat(),
            "risk_score": risk_score
        })
        
        return DocumentAnalysis(
            document_id=document_id,
            title=title,
            document_type=key_terms.get("typ_smlouvy", "Nezn√°m√Ω"),
            clauses=clauses,
            key_terms=key_terms,
            risk_score=risk_score,
            summary=summary,
            recommendations=recommendations
        )

    def store_document(self, doc_id: str, text: str, metadata: Dict[str, Any]):
        """Ulo≈æen√≠ dokumentu do vektorov√© datab√°ze"""
        try:
            chunks = self.text_splitter.split_text(text)
            embeddings = self.embedding_model.encode(chunks).tolist()
            
            self.collection.add(
                documents=chunks,
                embeddings=embeddings,
                metadatas=[{**metadata, "chunk_id": i} for i in range(len(chunks))],
                ids=[f"{doc_id}_chunk_{i}" for i in range(len(chunks))]
            )
            logger.info(f"Dokument {doc_id} ulo≈æen do datab√°ze")
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi ukl√°d√°n√≠ dokumentu: {e}")

    def semantic_search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """S√©mantick√© vyhled√°v√°n√≠ v dokumentech"""
        try:
            query_embedding = self.embedding_model.encode([query]).tolist()
            
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=limit
            )
            
            search_results = []
            for i in range(len(results['documents'][0])):
                search_results.append({
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "distance": results['distances'][0][i]
                })
            
            return search_results
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            return []

def create_sample_contract() -> str:
    """Vytvo≈ôen√≠ uk√°zkov√© smlouvy pro testov√°n√≠"""
    return """
    SMLOUVA O D√çLO
    
    uzav≈ôen√° podle ¬ß 2586 a n√°sl. z√°kona ƒç. 89/2012 Sb., obƒçansk√Ω z√°kon√≠k
    
    Smluvn√≠ strany:
    
    Objednatel: ABC s.r.o., IƒåO: 12345678, se s√≠dlem Praha 1, N√°rodn√≠ 123
    Zhotovitel: XYZ Software s.r.o., IƒåO: 87654321, se s√≠dlem Brno, Technick√° 456
    
    P≈ôedmƒõt smlouvy:
    Zhotovitel se zavazuje vytvo≈ôit a dodat objednateli webovou aplikaci pro spr√°vu z√°kazn√≠k≈Ø
    podle specifikace v p≈ô√≠loze ƒç. 1.
    
    Cena a platebn√≠ podm√≠nky:
    Celkov√° cena ƒçin√≠ 500.000 Kƒç bez DPH. Platba bude provedena ve dvou spl√°tk√°ch:
    - 50% p≈ôi podpisu smlouvy
    - 50% p≈ôi p≈ôed√°n√≠ a akceptaci d√≠la
    
    Term√≠n plnƒõn√≠:
    D√≠lo bude dokonƒçeno do 90 dn≈Ø od podpisu t√©to smlouvy.
    
    Odpovƒõdnost za vady:
    Zhotovitel odpov√≠d√° za vady d√≠la po dobu 24 mƒõs√≠c≈Ø od p≈ôed√°n√≠.
    
    Ukonƒçen√≠ smlouvy:
    Smlouvu lze ukonƒçit dohodou stran nebo v√Ωpovƒõd√≠ s dvoumƒõs√≠ƒçn√≠ v√Ωpovƒõdn√≠ lh≈Øtou.
    V p≈ô√≠padƒõ podstatn√©ho poru≈°en√≠ m≈Ø≈æe druh√° strana odstoupit od smlouvy okam≈æitƒõ.
    
    Mlƒçenlivost:
    Obƒõ strany se zavazuj√≠ zachov√°vat mlƒçenlivost o v≈°ech d≈Øvƒõrn√Ωch informac√≠ch.
    
    Rozhodn√© pr√°vo a ≈ôe≈°en√≠ spor≈Ø:
    Smlouva se ≈ô√≠d√≠ ƒçesk√Ωm pr√°vem. Spory budou ≈ôe≈°eny Obchodn√≠m soudem v Praze.
    
    Datum podpisu: 15.6.2025
    """

def main():
    """Hlavn√≠ Streamlit aplikace"""
    st.set_page_config(
        page_title="Analyz√°tor Pr√°vn√≠ch Dokument≈Ø",
        page_icon="‚öñÔ∏è",
        layout="wide"
    )
    
    st.title("‚öñÔ∏è Automatizovan√Ω Analyz√°tor Pr√°vn√≠ch Dokument≈Ø s MCP")
    st.markdown("*Pokroƒçil√° anal√Ωza smluv pomoc√≠ umƒõl√© inteligence*")
    
    # Inicializace analyz√°toru
    if "analyzer" not in st.session_state:
        # Pro demo pou≈æijeme mock kl√≠ƒç
        openai_api_key = st.secrets.get("OPENAI_API_KEY", "demo_key")
        if openai_api_key == "demo_key":
            st.warning("‚ö†Ô∏è Demo re≈æim - nƒõkter√© funkce nemus√≠ fungovat bez platn√©ho OpenAI API kl√≠ƒçe")
        
        try:
            st.session_state.analyzer = MCPLegalAnalyzer(openai_api_key)
        except Exception as e:
            st.error(f"Chyba p≈ôi inicializaci: {e}")
            return
    
    # Hlavn√≠ menu
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìÑ Anal√Ωza dokumentu", 
        "üîç S√©mantick√© vyhled√°v√°n√≠",
        "üìä P≈ôehled anal√Ωz",
        "üß™ Demo s uk√°zkov√Ωmi daty"
    ])
    
    with tab1:
        st.header("Anal√Ωza pr√°vn√≠ho dokumentu")
        
        # Volba zp≈Øsobu vstupu
        input_method = st.radio(
            "Vyberte zp≈Øsob zad√°n√≠ dokumentu:",
            ["Nahr√°n√≠ PDF souboru", "Zad√°n√≠ textu"]
        )
        
        text = ""
        title = ""
        
        if input_method == "Nahr√°n√≠ PDF souboru":
            uploaded_file = st.file_uploader(
                "Nahrajte PDF soubor", 
                type=["pdf"],
                help="Podporovan√© form√°ty: PDF"
            )
            
            if uploaded_file:
                title = uploaded_file.name
                try:
                    text = st.session_state.analyzer.extract_text_from_pdf(uploaded_file)
                    st.success(f"Soubor {title} byl √∫spƒõ≈°nƒõ naƒçten")
                    with st.expander("N√°hled textu"):
                        st.text(text[:1000] + "..." if len(text) > 1000 else text)
                except Exception as e:
                    st.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ souboru: {e}")
        
        else:
            title = st.text_input("N√°zev dokumentu:", value="Nov√Ω dokument")
            text = st.text_area(
                "Vlo≈æte text dokumentu:",
                height=300,
                help="Vlo≈æte cel√Ω text smlouvy nebo pr√°vn√≠ho dokumentu"
            )
        
        if st.button("üîç Analyzovat dokument", type="primary"):
            if text and title:
                with st.spinner("Prob√≠h√° anal√Ωza dokumentu..."):
                    try:
                        doc_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        analysis = st.session_state.analyzer.analyze_document(text, doc_id, title)
                        
                        # Ulo≈æen√≠ v√Ωsledku do session state
                        if "analyses" not in st.session_state:
                            st.session_state.analyses = []
                        st.session_state.analyses.append(analysis)
                        
                        # Zobrazen√≠ v√Ωsledk≈Ø
                        display_analysis_results(analysis)
                        
                    except Exception as e:
                        st.error(f"Chyba p≈ôi anal√Ωze: {e}")
            else:
                st.warning("Pros√≠m zadejte n√°zev a text dokumentu")
    
    with tab2:
        st.header("S√©mantick√© vyhled√°v√°n√≠")
        
        query = st.text_input(
            "Zadejte vyhled√°vac√≠ dotaz:",
            placeholder="nap≈ô. 'klauzule o odpovƒõdnosti za ≈°kody'"
        )
        
        if st.button("üîç Vyhledat", type="primary"):
            if query:
                with st.spinner("Vyhled√°v√°n√≠..."):
                    try:
                        results = st.session_state.analyzer.semantic_search(query)
                        display_search_results(results, query)
                    except Exception as e:
                        st.error(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            else:
                st.warning("Zadejte vyhled√°vac√≠ dotaz")
    
    with tab3:
        st.header("P≈ôehled anal√Ωz")
        
        if "analyses" in st.session_state and st.session_state.analyses:
            display_analyses_overview(st.session_state.analyses)
        else:
            st.info("Zat√≠m nebyly provedeny ≈æ√°dn√© anal√Ωzy")
    
    with tab4:
        st.header("Demo s uk√°zkov√Ωmi daty")
        st.markdown("Vyzkou≈°ejte analyz√°tor na uk√°zkov√© smlouvƒõ:")
        
        if st.button("üéÆ Spustit demo anal√Ωzu", type="primary"):
            sample_text = create_sample_contract()
            
            with st.spinner("Prob√≠h√° demo anal√Ωza..."):
                try:
                    doc_id = f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    analysis = st.session_state.analyzer.analyze_document(
                        sample_text, doc_id, "Demo smlouva o d√≠lo"
                    )
                    
                    if "analyses" not in st.session_state:
                        st.session_state.analyses = []
                    st.session_state.analyses.append(analysis)
                    
                    display_analysis_results(analysis)
                    
                except Exception as e:
                    st.error(f"Chyba p≈ôi demo anal√Ωze: {e}")

def display_analysis_results(analysis: DocumentAnalysis):
    """Zobrazen√≠ v√Ωsledk≈Ø anal√Ωzy"""
    st.success("‚úÖ Anal√Ωza dokonƒçena!")
    
    # Z√°kladn√≠ informace
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Typ dokumentu", analysis.document_type)
    
    with col2:
        risk_color = "üî¥" if analysis.risk_score > 0.7 else "üü°" if analysis.risk_score > 0.4 else "üü¢"
        st.metric("Rizikov√© sk√≥re", f"{risk_color} {analysis.risk_score:.2f}")
    
    with col3:
        st.metric("Poƒçet klauzul√≠", len(analysis.clauses))
    
    # Shrnut√≠
    st.subheader("üìù Shrnut√≠ dokumentu")
    st.write(analysis.summary)
    
    # Kl√≠ƒçov√© √∫daje
    if analysis.key_terms:
        st.subheader("üîë Kl√≠ƒçov√© √∫daje")
        col1, col2 = st.columns(2)
        
        with col1:
            if analysis.key_terms.get("strany"):
                st.write("**Smluvn√≠ strany:**")
                for strana in analysis.key_terms["strany"]:
                    st.write(f"- {strana}")
            
            if analysis.key_terms.get("hodnota_smlouvy"):
                st.write(f"**Hodnota:** {analysis.key_terms['hodnota_smlouvy']} {analysis.key_terms.get('mena', '')}")
        
        with col2:
            if analysis.key_terms.get("datum_podpisu"):
                st.write(f"**Datum podpisu:** {analysis.key_terms['datum_podpisu']}")
            
            if analysis.key_terms.get("platnost_do"):
                st.write(f"**Platnost do:** {analysis.key_terms['platnost_do']}")
    
    # Anal√Ωza klauzul√≠
    st.subheader("‚öñÔ∏è Anal√Ωza klauzul√≠")
    
    # Filtrov√°n√≠ podle rizika
    risk_filter = st.selectbox(
        "Filtrovat podle rizika:",
        ["V≈°echny", "vysok√©", "st≈ôedn√≠", "n√≠zk√©"]
    )
    
    filtered_clauses = analysis.clauses
    if risk_filter != "V≈°echny":
        filtered_clauses = [c for c in analysis.clauses if c.risk_level == risk_filter]
    
    # Zobrazen√≠ klauzul√≠
    for i, clause in enumerate(filtered_clauses):
        risk_color = {"vysok√©": "üî¥", "st≈ôedn√≠": "üü°", "n√≠zk√©": "üü¢"}.get(clause.risk_level, "‚ö™")
        
        with st.expander(f"{risk_color} {clause.clause_type.title()} (riziko: {clause.risk_level})"):
            st.write("**Text klauzule:**")
            st.write(clause.text)
            st.write(f"**D≈Øvƒõra klasifikace:** {clause.confidence:.2f}")
            st.write(f"**Pozice:** Str√°nka {clause.page}, sekce {clause.position}")
    
    # Doporuƒçen√≠
    if analysis.recommendations:
        st.subheader("üí° Doporuƒçen√≠")
        for rec in analysis.recommendations:
            st.warning(rec)
    
    # Grafick√° vizualizace
    st.subheader("üìä Vizualizace")
    
    # Graf distribuce rizik
    risk_counts = {}
    for clause in analysis.clauses:
        risk_counts[clause.risk_level] = risk_counts.get(clause.risk_level, 0) + 1
    
    if risk_counts:
        fig_pie = px.pie(
            values=list(risk_counts.values()),
            names=list(risk_counts.keys()),
            title="Distribuce rizikov√Ωch √∫rovn√≠ klauzul√≠",
            color_discrete_map={"vysok√©": "red", "st≈ôedn√≠": "orange", "n√≠zk√©": "green"}
        )
        st.plotly_chart(fig_pie, use_container_width=True)

def display_search_results(results: List[Dict[str, Any]], query: str):
    """Zobrazen√≠ v√Ωsledk≈Ø vyhled√°v√°n√≠"""
    if results:
        st.success(f"Nalezeno {len(results)} relevantn√≠ch v√Ωsledk≈Ø pro: '{query}'")
        
        for i, result in enumerate(results):
            similarity = 1 - result["distance"]
            
            with st.expander(f"V√Ωsledek {i+1} (relevance: {similarity:.2f})"):
                st.write("**Text:**")
                st.write(result["text"])
                
                if result["metadata"]:
                    st.write("**Metadata:**")
                    for key, value in result["metadata"].items():
                        st.write(f"- {key}: {value}")
    else:
        st.info("Nebyly nalezeny ≈æ√°dn√© relevantn√≠ v√Ωsledky")

def display_analyses_overview(analyses: List[DocumentAnalysis]):
    """Zobrazen√≠ p≈ôehledu v≈°ech anal√Ωz"""
    # Tabulka s p≈ôehledem
    data = []
    for analysis in analyses:
        risk_level = "Vysok√©" if analysis.risk_score > 0.7 else "St≈ôedn√≠" if analysis.risk_score > 0.4 else "N√≠zk√©"
        data.append({
            "Dokument": analysis.title,
            "Typ": analysis.document_type,
            "Rizikov√© sk√≥re": f"{analysis.risk_score:.2f}",
            "√örove≈à rizika": risk_level,
            "Poƒçet klauzul√≠": len(analysis.clauses),
            "ID": analysis.document_id
        })
    
    df = pd.DataFrame(data)
    st.dataframe(df, use_container_width=True)
    
    # Souhrnn√© statistiky
    col1, col2, col3 = st.columns(3)
    
    with col1:
        avg_risk = np.mean([a.risk_score for a in analyses])
        st.metric("Pr≈Ømƒõrn√© riziko", f"{avg_risk:.2f}")
    
    with col2:
        total_clauses = sum(len(a.clauses) for a in analyses)
        st.metric("Celkem klauzul√≠", total_clauses)
    
    with col3:
        high_risk_docs = sum(1 for a in analyses if a.risk_score > 0.7)
        st.metric("Vysoce rizikov√© dokumenty", high_risk_docs)
    
    # Graf v√Ωvoje rizikov√Ωch sk√≥re
    if len(analyses) > 1:
        risk_scores = [a.risk_score for a in analyses]
        doc_names = [a.title[:20] + "..." if len(a.title) > 20 else a.title for a in analyses]
        
        fig_bar = px.bar(
            x=doc_names,
            y=risk_scores,
            title="Rizikov√© sk√≥re dokument≈Ø",
            labels={"x": "Dokument", "y": "Rizikov√© sk√≥re"},
            color=risk_scores,
            color_continuous_scale="RdYlGn_r"
        )
        st.plotly_chart(fig_bar, use_container_width=True)

if __name__ == "__main__":
    main()
````

````python
"""
Instalaƒçn√≠ script pro Automatizovan√Ω Analyz√°tor Pr√°vn√≠ch Dokument≈Ø s MCP
"""

import subprocess
import sys
import os

def install_requirements():
    """Instalace po≈æadovan√Ωch bal√≠ƒçk≈Ø"""
    requirements = [
        "langchain==0.1.16",
        "openai==1.23.3", 
        "haystack-ai==0.1.2",
        "chromadb==0.4.24",
        "python-dotenv==1.0.0",
        "streamlit==1.32.2",
        "PyPDF2==3.0.1",
        "spacy==3.7.4",
        "transformers==4.40.1",
        "sentence-transformers==2.7.0",
        "matplotlib==3.8.4",
        "plotly==5.20.0",
        "pandas==2.2.2",
        "numpy==1.26.4",
        "requests==2.31.0"
    ]
    
    for package in requirements:
        print(f"Instaluji {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

def download_spacy_model():
    """Sta≈æen√≠ jazykov√©ho modelu pro spaCy"""
    try:
        subprocess.check_call([sys.executable, "-m", "spacy", "download", "cs_core_news_sm"])
        print("‚úÖ ƒåesk√Ω jazykov√Ω model pro spaCy byl √∫spƒõ≈°nƒõ nainstalov√°n")
    except:
        print("‚ö†Ô∏è Nepoda≈ôilo se nainstalovat ƒçesk√Ω model pro spaCy")

def create_directories():
    """Vytvo≈ôen√≠ pot≈ôebn√Ωch adres√°≈ô≈Ø"""
    directories = ["./chroma_db", "./uploads", "./exports"]
    
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"‚úÖ Vytvo≈ôen adres√°≈ô: {directory}")

def main():
    """Hlavn√≠ instalaƒçn√≠ funkce"""
    print("üöÄ Spou≈°t√≠m instalaci Automatizovan√©ho Analyz√°toru Pr√°vn√≠ch Dokument≈Ø s MCP")
    print("="*70)
    
    try:
        # Instalace Python bal√≠ƒçk≈Ø
        print("üì¶ Instaluji Python bal√≠ƒçky...")
        install_requirements()
        
        # Sta≈æen√≠ jazykov√Ωch model≈Ø
        print("\nüåê Stahuji jazykov√© modely...")
        download_spacy_model()
        
        # Vytvo≈ôen√≠ adres√°≈ô≈Ø
        print("\nüìÅ Vytv√°≈ô√≠m pot≈ôebn√© adres√°≈ôe...")
        create_directories()
        
        print("\n‚úÖ Instalace byla √∫spƒõ≈°nƒõ dokonƒçena!")
        print("\nüéØ Pro spu≈°tƒõn√≠ aplikace pou≈æijte:")
        print("   streamlit run legal_analyzer.py")
        
    except Exception as e:
        print(f"\n‚ùå Chyba p≈ôi instalaci: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
````

## 4. Shrnut√≠ Projektu

### Kl√≠ƒçov√© Hodnoty
Automatizovan√Ω analyz√°tor pr√°vn√≠ch dokument≈Ø s MCP p≈ôedstavuje v√Ωznamn√Ω pokrok v automatizaci pr√°vn√≠ch proces≈Ø. Projekt kombinuje nejmodernƒõj≈°√≠ technologie NLP, s√©mantick√©ho vyhled√°v√°n√≠ a zero-shot klasifikace pro vytvo≈ôen√≠ komplexn√≠ho ≈ôe≈°en√≠ anal√Ωzy smluv.

### Technologick√© Inovace
- **MCP integrace** - Standardizovan√© rozhran√≠ pro komunikaci s extern√≠mi syst√©my
- **S√©mantick√° anal√Ωza** - Pokroƒçil√© porozumƒõn√≠ obsahu dokument≈Ø
- **Automatick√° klasifikace** - Identifikace typ≈Ø klauzul√≠ bez p≈ôedchoz√≠ho tr√©nov√°n√≠
- **Vektorov√© vyhled√°v√°n√≠** - Rychl√© a p≈ôesn√© nalezen√≠ relevantn√≠ch informac√≠
- **Rizikov√© hodnocen√≠** - Automatick√© vyhodnocen√≠ potenci√°ln√≠ch probl√©m≈Ø

### Praktick√© P≈ô√≠nosy
1. **Efektivita** - Redukce ƒçasu anal√Ωzy z hodin na minuty
2. **P≈ôesnost** - Systematick√° kontrola v≈°ech klauzul√≠
3. **Konzistence** - Jednotn√© standardy hodnocen√≠
4. **Dostupnost** - Demokratizace p≈ô√≠stupu k pr√°vn√≠ anal√Ωze
5. **≈†k√°lovatelnost** - Mo≈ænost zpracov√°n√≠ velk√Ωch objem≈Ø dokument≈Ø

### Budouc√≠ Rozvoj
Projekt m√° potenci√°l pro roz≈°√≠≈ôen√≠ o:
- Podporu v√≠ce jazyk≈Ø
- Integrace s pr√°vn√≠mi datab√°zemi
- Pokroƒçil√© AI agenty pro komplexn√≠ anal√Ωzu
- Automatick√© generov√°n√≠ n√°vrh≈Ø √∫prav
- Prediktivn√≠ anal√Ωzu pr√°vn√≠ch rizik

Automatizovan√Ω analyz√°tor p≈ôedstavuje d≈Øle≈æit√Ω krok smƒõrem k digitalizaci pr√°vn√≠ch slu≈æeb a m≈Ø≈æe v√Ωraznƒõ zv√Ω≈°it efektivitu pr√°ce pr√°vn√≠k≈Ø, podnikatel≈Ø i bƒõ≈æn√Ωch obƒçan≈Ø p≈ôi pr√°ci s pr√°vn√≠mi dokumenty.