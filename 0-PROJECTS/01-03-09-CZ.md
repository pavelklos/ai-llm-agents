<small>Claude Sonnet 4 **(Platforma pro Dynamick√© Vypr√°vƒõn√≠ a Interaktivn√≠ Fikci s MCP)**</small>
# Dynamic Storytelling & Interactive Fiction Platform

## Kl√≠ƒçov√© Koncepty

### Model Context Protocol (MCP)
**MCP** je protokol pro komunikaci mezi AI modely a extern√≠mi syst√©my, umo≈æ≈àuj√≠c√≠ sd√≠len√≠ kontextu, pamƒõti a stav≈Ø mezi r≈Øzn√Ωmi komponentami aplikace. V kontextu vypr√°vƒõn√≠ poskytuje konzistentn√≠ narativn√≠ kontinuitu.

### Narrative Generation (Generov√°n√≠ Narativu)
Automatick√© vytv√°≈ôen√≠ p≈ô√≠bƒõhov√Ωch prvk≈Ø pomoc√≠ AI model≈Ø na z√°kladƒõ definovan√Ωch pravidel, charakter≈Ø a svƒõtov√Ωch prvk≈Ø. Zahrnuje generov√°n√≠ dialog≈Ø, popis≈Ø a dƒõjov√Ωch zvrat≈Ø.

### User-Driven Plotlines (U≈æivatelem ≈ò√≠zen√© Dƒõjov√© Linie)
Interaktivn√≠ syst√©m, kde u≈æivatelsk√© volby a akce p≈ô√≠mo ovliv≈àuj√≠ smƒõr a v√Ωvoj p≈ô√≠bƒõhu. Ka≈æd√© rozhodnut√≠ vytv√°≈ô√≠ nov√© vƒõtven√≠ v narativn√≠ struktu≈ôe.

### MCP Memory Layers (Pamƒõ≈•ov√© Vrstvy MCP)
Hierarchick√Ω syst√©m ukl√°d√°n√≠ informac√≠ o postav√°ch, svƒõtƒõ, ud√°lostech a u≈æivatelsk√Ωch volb√°ch. Umo≈æ≈àuje dlouhodobou kontinuitu a reference na minul√© ud√°losti.

### Stable Diffusion
AI model pro generov√°n√≠ obr√°zk≈Ø z textov√Ωch popis≈Ø, pou≈æ√≠van√Ω pro vytv√°≈ôen√≠ vizu√°ln√≠ch reprezentac√≠ sc√©n, postav a prost≈ôed√≠ v interaktivn√≠m p≈ô√≠bƒõhu.

## Komplexn√≠ Vysvƒõtlen√≠ Projektu

### C√≠le Projektu
Platforma vytv√°≈ô√≠ immerzivn√≠ prost≈ôed√≠ pro interaktivn√≠ vypr√°vƒõn√≠, kde AI a u≈æivatel spolupracuj√≠ na tvorbƒõ jedineƒçn√Ωch p≈ô√≠bƒõh≈Ø. Vyu≈æ√≠v√° pokroƒçil√© AI technologie pro generov√°n√≠ konzistentn√≠ho narativu, kter√Ω se p≈ôizp≈Øsobuje u≈æivatelsk√Ωm volb√°m.

### V√Ωzvy a ≈òe≈°en√≠
- **Narativn√≠ Konzistence**: MCP protokol zaji≈°≈•uje sd√≠len√≠ kontextu mezi v≈°emi komponentami
- **Komplexn√≠ Vƒõtven√≠**: Algoritmy pro sledov√°n√≠ a ≈ô√≠zen√≠ mnoha mo≈æn√Ωch p≈ô√≠bƒõhov√Ωch cest
- **Vizu√°ln√≠ Reprezentace**: Integrace Stable Diffusion pro automatick√© generov√°n√≠ ilustrac√≠
- **Dlouhodob√° Pamƒõ≈•**: V√≠cevrstv√Ω syst√©m ukl√°d√°n√≠ pro zachov√°n√≠ kontinuity

### Potenci√°ln√≠ Dopad
Revoluce v oblasti interaktivn√≠ z√°bavy, vzdƒõl√°v√°n√≠ a terapeutick√Ωch aplikac√≠. Poskytuje personalizovan√© narativn√≠ z√°≈æitky a podporuje kreativitu u≈æivatel≈Ø.

## Komplexn√≠ P≈ô√≠klad s Python Implementac√≠

````python
langchain==0.1.0
openai==1.10.0
chromadb==0.4.22
fastapi==0.108.0
uvicorn==0.25.0
pydantic==2.5.0
diffusers==0.24.0
torch==2.1.0
pillow==10.2.0
requests==2.31.0
python-multipart==0.0.6
````

````python
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from enum import Enum
import json
import uuid

class MCPMessageType(Enum):
    CONTEXT_UPDATE = "context_update"
    MEMORY_STORE = "memory_store"
    MEMORY_RETRIEVE = "memory_retrieve"
    NARRATIVE_REQUEST = "narrative_request"
    USER_ACTION = "user_action"

@dataclass
class MCPMessage:
    message_id: str
    message_type: MCPMessageType
    payload: Dict[str, Any]
    sender: str
    timestamp: float

class MCPComponent(ABC):
    def __init__(self, component_id: str):
        self.component_id = component_id
        self.connected_components: List['MCPComponent'] = []

    @abstractmethod
    async def process_message(self, message: MCPMessage) -> Optional[MCPMessage]:
        pass

    async def send_message(self, message: MCPMessage):
        for component in self.connected_components:
            await component.process_message(message)

    def connect(self, component: 'MCPComponent'):
        self.connected_components.append(component)

class MCPBus:
    def __init__(self):
        self.components: Dict[str, MCPComponent] = {}
        self.message_history: List[MCPMessage] = []

    def register_component(self, component: MCPComponent):
        self.components[component.component_id] = component

    async def broadcast_message(self, message: MCPMessage):
        self.message_history.append(message)
        for component in self.components.values():
            if component.component_id != message.sender:
                await component.process_message(message)
````

````python
import chromadb
from chromadb.config import Settings
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import json
import time

@dataclass
class MemoryLayer:
    layer_name: str
    description: str
    retention_policy: str
    importance_threshold: float

@dataclass
class StoryMemory:
    id: str
    content: str
    layer: str
    importance: float
    timestamp: float
    metadata: Dict[str, Any]

class MCPMemorySystem:
    def __init__(self, db_path: str = "./story_memory"):
        self.client = chromadb.PersistentClient(path=db_path)
        
        self.layers = {
            "character": MemoryLayer("character", "Informace o postav√°ch", "permanent", 0.8),
            "world": MemoryLayer("world", "Svƒõtov√Ω kontext", "permanent", 0.7),
            "events": MemoryLayer("events", "D≈Øle≈æit√© ud√°losti", "long_term", 0.6),
            "dialogue": MemoryLayer("dialogue", "Rozhovory", "medium_term", 0.4),
            "scene": MemoryLayer("scene", "Sc√©ny a popisy", "short_term", 0.3)
        }
        
        self._initialize_collections()

    def _initialize_collections(self):
        for layer_name in self.layers.keys():
            try:
                self.client.get_collection(layer_name)
            except:
                self.client.create_collection(
                    name=layer_name,
                    metadata={"description": self.layers[layer_name].description}
                )

    async def store_memory(self, memory: StoryMemory):
        collection = self.client.get_collection(memory.layer)
        
        collection.add(
            documents=[memory.content],
            metadatas=[{
                "importance": memory.importance,
                "timestamp": memory.timestamp,
                **memory.metadata
            }],
            ids=[memory.id]
        )

    async def retrieve_memories(self, query: str, layer: str, limit: int = 5) -> List[StoryMemory]:
        collection = self.client.get_collection(layer)
        
        results = collection.query(
            query_texts=[query],
            n_results=limit
        )
        
        memories = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                memories.append(StoryMemory(
                    id=results['ids'][0][i],
                    content=doc,
                    layer=layer,
                    importance=metadata.get('importance', 0.5),
                    timestamp=metadata.get('timestamp', time.time()),
                    metadata=metadata
                ))
        
        return memories

    async def get_story_context(self, current_scene: str) -> Dict[str, List[StoryMemory]]:
        context = {}
        
        for layer_name in self.layers.keys():
            memories = await self.retrieve_memories(current_scene, layer_name, 3)
            context[layer_name] = memories
        
        return context
````

````python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from typing import Dict, Any, List, Optional
import json
import random
from .mcp_protocol import MCPComponent, MCPMessage, MCPMessageType
from .memory_system import MCPMemorySystem, StoryMemory
import time
import uuid

class StoryChoice:
    def __init__(self, text: str, consequence: str, mood_impact: float):
        self.text = text
        self.consequence = consequence
        self.mood_impact = mood_impact

class StoryState:
    def __init__(self):
        self.current_scene = ""
        self.characters = {}
        self.world_state = {}
        self.user_choices = []
        self.story_mood = 0.5  # 0-1 (dark to light)
        self.chapter = 1

class NarrativeEngine(MCPComponent):
    def __init__(self, openai_api_key: str, memory_system: MCPMemorySystem):
        super().__init__("narrative_engine")
        self.llm = ChatOpenAI(
            api_key=openai_api_key,
            model="gpt-4",
            temperature=0.8
        )
        self.memory = memory_system
        self.story_state = StoryState()
        
        # P≈ôeddefinovan√© p≈ô√≠bƒõhov√© ≈°ablony
        self.story_templates = {
            "fantasy": {
                "setting": "Magick√Ω svƒõt pln√Ω drak≈Ø a kouzel",
                "protagonist": "Mlad√Ω m√°g objevuj√≠c√≠ sv√© schopnosti",
                "conflict": "Temn√° s√≠la ohro≈æuje kr√°lovstv√≠"
            },
            "sci_fi": {
                "setting": "Vesm√≠rn√° stanice v roce 2087",
                "protagonist": "D≈Østojn√≠k bezpeƒçnosti vy≈°et≈ôuj√≠c√≠ tajemstv√≠",
                "conflict": "AI se vzbou≈ôila proti lidsk√© pos√°dce"
            },
            "mystery": {
                "setting": "Viktori√°nsk√Ω Lond√Ωn",
                "protagonist": "Soukrom√Ω detektiv",
                "conflict": "S√©rie z√°hadn√Ωch zmizen√≠"
            }
        }

    async def process_message(self, message: MCPMessage) -> Optional[MCPMessage]:
        if message.message_type == MCPMessageType.NARRATIVE_REQUEST:
            return await self._generate_narrative(message.payload)
        elif message.message_type == MCPMessageType.USER_ACTION:
            return await self._process_user_action(message.payload)
        return None

    async def start_new_story(self, genre: str, user_preferences: Dict[str, Any]) -> Dict[str, Any]:
        template = self.story_templates.get(genre, self.story_templates["fantasy"])
        
        system_prompt = f"""
        Jsi mistrovsk√Ω vypravƒõƒç interaktivn√≠ch p≈ô√≠bƒõh≈Ø. Vytvo≈ô √∫vodn√≠ sc√©nu pro p≈ô√≠bƒõh v ≈æ√°nru {genre}.
        
        Nastaven√≠: {template['setting']}
        Hlavn√≠ postava: {template['protagonist']}
        Konflikt: {template['conflict']}
        
        U≈æivatelsk√© preference: {json.dumps(user_preferences, ensure_ascii=False)}
        
        Vytvo≈ô:
        1. Poutav√Ω √∫vod (2-3 odstavce)
        2. 3 mo≈ænosti volby pro u≈æivatele
        3. Z√°kladn√≠ informace o protagonistovi
        
        Odpovƒõz ve form√°tu JSON s kl√≠ƒçi: scene_description, choices, protagonist_info
        """
        
        response = await self.llm.ainvoke([SystemMessage(content=system_prompt)])
        
        try:
            story_data = json.loads(response.content)
            
            # Ulo≈æen√≠ do pamƒõti
            await self._store_story_beginning(story_data, genre)
            
            return {
                "scene": story_data.get("scene_description", ""),
                "choices": story_data.get("choices", []),
                "protagonist": story_data.get("protagonist_info", {}),
                "chapter": 1
            }
        except json.JSONDecodeError:
            return {"error": "Chyba p≈ôi generov√°n√≠ p≈ô√≠bƒõhu"}

    async def _generate_narrative(self, payload: Dict[str, Any]) -> MCPMessage:
        current_context = await self.memory.get_story_context(self.story_state.current_scene)
        
        # Sestaven√≠ kontextu pro LLM
        context_summary = self._build_context_summary(current_context)
        
        system_prompt = f"""
        Pokraƒçuj v interaktivn√≠m p≈ô√≠bƒõhu na z√°kladƒõ n√°sleduj√≠c√≠ho kontextu:
        
        {context_summary}
        
        Aktu√°ln√≠ n√°lada p≈ô√≠bƒõhu: {self.story_state.story_mood}
        Kapitola: {self.story_state.chapter}
        
        Vytvo≈ô dal≈°√≠ sc√©nu a 3 mo≈ænosti volby. Udr≈æuj konzistenci s p≈ôedchoz√≠mi ud√°lostmi.
        Odpovƒõz ve form√°tu JSON.
        """
        
        user_message = payload.get("prompt", "Pokraƒçuj v p≈ô√≠bƒõhu")
        
        response = await self.llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_message)
        ])
        
        try:
            narrative_data = json.loads(response.content)
            await self._store_scene(narrative_data)
            
            return MCPMessage(
                message_id=str(uuid.uuid4()),
                message_type=MCPMessageType.NARRATIVE_REQUEST,
                payload=narrative_data,
                sender=self.component_id,
                timestamp=time.time()
            )
        except json.JSONDecodeError:
            return MCPMessage(
                message_id=str(uuid.uuid4()),
                message_type=MCPMessageType.NARRATIVE_REQUEST,
                payload={"error": "Chyba p≈ôi generov√°n√≠ narativu"},
                sender=self.component_id,
                timestamp=time.time()
            )

    async def _process_user_action(self, payload: Dict[str, Any]) -> MCPMessage:
        choice_id = payload.get("choice_id")
        choice_text = payload.get("choice_text", "")
        
        # Ulo≈æen√≠ u≈æivatelsk√© volby
        choice_memory = StoryMemory(
            id=str(uuid.uuid4()),
            content=f"U≈æivatel vybral: {choice_text}",
            layer="events",
            importance=0.7,
            timestamp=time.time(),
            metadata={"type": "user_choice", "choice_id": choice_id}
        )
        
        await self.memory.store_memory(choice_memory)
        
        # Generov√°n√≠ pokraƒçov√°n√≠ na z√°kladƒõ volby
        return await self._generate_narrative({
            "prompt": f"U≈æivatel se rozhodl: {choice_text}. Pokraƒçuj v p≈ô√≠bƒõhu."
        })

    def _build_context_summary(self, context: Dict[str, List[StoryMemory]]) -> str:
        summary_parts = []
        
        for layer, memories in context.items():
            if memories:
                layer_summary = f"\n{layer.upper()}:\n"
                for memory in memories:
                    layer_summary += f"- {memory.content}\n"
                summary_parts.append(layer_summary)
        
        return "\n".join(summary_parts)

    async def _store_story_beginning(self, story_data: Dict[str, Any], genre: str):
        memories = [
            StoryMemory(
                id=str(uuid.uuid4()),
                content=story_data.get("scene_description", ""),
                layer="scene",
                importance=0.9,
                timestamp=time.time(),
                metadata={"type": "opening", "genre": genre}
            ),
            StoryMemory(
                id=str(uuid.uuid4()),
                content=json.dumps(story_data.get("protagonist_info", {})),
                layer="character",
                importance=1.0,
                timestamp=time.time(),
                metadata={"type": "protagonist", "character": "main"}
            )
        ]
        
        for memory in memories:
            await self.memory.store_memory(memory)

    async def _store_scene(self, narrative_data: Dict[str, Any]):
        scene_memory = StoryMemory(
            id=str(uuid.uuid4()),
            content=narrative_data.get("scene_description", ""),
            layer="scene",
            importance=0.6,
            timestamp=time.time(),
            metadata={"type": "scene", "chapter": self.story_state.chapter}
        )
        
        await self.memory.store_memory(scene_memory)
````

````python
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import io
import base64
from typing import Dict, Any, Optional
from .mcp_protocol import MCPComponent, MCPMessage, MCPMessageType
import uuid
import time

class VisualGenerator(MCPComponent):
    def __init__(self, model_name: str = "runwayml/stable-diffusion-v1-5"):
        super().__init__("visual_generator")
        
        # Inicializace Stable Diffusion pipeline
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        )
        self.pipe.to(self.device)
        
        # Optimalizace pro rychlej≈°√≠ inferenci
        if self.device == "cuda":
            self.pipe.enable_memory_efficient_attention()
        
        # Prompt ≈°ablony pro r≈Øzn√© typy sc√©n
        self.prompt_templates = {
            "character": "detailed character portrait, {description}, fantasy art style, high quality, detailed",
            "landscape": "beautiful landscape, {description}, fantasy environment, detailed, atmospheric",
            "scene": "detailed scene, {description}, cinematic lighting, fantasy art, high quality",
            "action": "dynamic action scene, {description}, dramatic lighting, detailed"
        }

    async def process_message(self, message: MCPMessage) -> Optional[MCPMessage]:
        if message.message_type == MCPMessageType.NARRATIVE_REQUEST:
            scene_data = message.payload
            if "scene_description" in scene_data:
                image_data = await self.generate_scene_image(scene_data["scene_description"])
                
                return MCPMessage(
                    message_id=str(uuid.uuid4()),
                    message_type=MCPMessageType.CONTEXT_UPDATE,
                    payload={"generated_image": image_data},
                    sender=self.component_id,
                    timestamp=time.time()
                )
        return None

    async def generate_scene_image(self, scene_description: str, image_type: str = "scene") -> Optional[str]:
        """Generuje obr√°zek na z√°kladƒõ popisu sc√©ny"""
        try:
            # Vyƒçi≈°tƒõn√≠ a optimalizace prompta
            optimized_prompt = self._optimize_prompt(scene_description, image_type)
            
            # Generov√°n√≠ obr√°zku
            with torch.autocast(self.device):
                image = self.pipe(
                    optimized_prompt,
                    num_inference_steps=30,
                    guidance_scale=7.5,
                    height=512,
                    width=512
                ).images[0]
            
            # Konverze na base64 pro p≈ôenos
            return self._image_to_base64(image)
            
        except Exception as e:
            print(f"Chyba p≈ôi generov√°n√≠ obr√°zku: {e}")
            return None

    def _optimize_prompt(self, description: str, image_type: str) -> str:
        """Optimalizuje prompt pro lep≈°√≠ v√Ωsledky SD"""
        template = self.prompt_templates.get(image_type, self.prompt_templates["scene"])
        
        # Odstranƒõn√≠ nevhodn√Ωch slov pro SD
        cleaned_description = description.replace("p≈ô√≠bƒõh", "").replace("sc√©na", "scene")
        
        # P≈ôid√°n√≠ kvality a stylu
        optimized = template.format(description=cleaned_description)
        optimized += ", masterpiece, best quality, detailed, 8k resolution"
        
        # Negativn√≠ prompt pro lep≈°√≠ kvalitu
        negative_prompt = "blurry, low quality, distorted, ugly, bad anatomy"
        
        return optimized

    def _image_to_base64(self, image: Image.Image) -> str:
        """Konvertuje PIL Image na base64 string"""
        buffer = io.BytesIO()
        image.save(buffer, format='PNG')
        image_bytes = buffer.getvalue()
        return base64.b64encode(image_bytes).decode('utf-8')

    async def generate_character_portrait(self, character_data: Dict[str, Any]) -> Optional[str]:
        """Specializovan√° metoda pro generov√°n√≠ portr√©t≈Ø postav"""
        character_description = self._build_character_description(character_data)
        return await self.generate_scene_image(character_description, "character")

    def _build_character_description(self, character_data: Dict[str, Any]) -> str:
        """Sestavuje popis postavy pro SD"""
        description_parts = []
        
        if "appearance" in character_data:
            description_parts.append(character_data["appearance"])
        
        if "clothing" in character_data:
            description_parts.append(f"wearing {character_data['clothing']}")
            
        if "mood" in character_data:
            description_parts.append(f"{character_data['mood']} expression")
        
        return ", ".join(description_parts)
````

````python
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
import uvicorn
import asyncio

from .narrative_engine import NarrativeEngine
from .visual_generator import VisualGenerator
from .memory_system import MCPMemorySystem
from .mcp_protocol import MCPBus, MCPMessage, MCPMessageType
import time
import uuid

# Pydantic modely pro API
class StoryRequest(BaseModel):
    genre: str
    user_preferences: Dict[str, Any] = {}

class ChoiceRequest(BaseModel):
    choice_id: int
    choice_text: str

class ContinueRequest(BaseModel):
    prompt: str = ""

class StorytellingPlatform:
    def __init__(self, openai_api_key: str):
        self.app = FastAPI(title="Platforma Dynamick√©ho Vypr√°vƒõn√≠", version="1.0.0")
        
        # Middleware pro CORS
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        # Inicializace MCP komponent
        self.memory_system = MCPMemorySystem()
        self.narrative_engine = NarrativeEngine(openai_api_key, self.memory_system)
        self.visual_generator = VisualGenerator()
        
        # MCP Bus pro komunikaci mezi komponentami
        self.mcp_bus = MCPBus()
        self.mcp_bus.register_component(self.narrative_engine)
        self.mcp_bus.register_component(self.visual_generator)
        
        # Propojen√≠ komponent
        self.narrative_engine.connect(self.visual_generator)
        
        # Registrace API routes
        self._setup_routes()
        
        # Aktivn√≠ p≈ô√≠bƒõhy (v re√°ln√© aplikaci by bylo v datab√°zi)
        self.active_stories: Dict[str, Dict[str, Any]] = {}

    def _setup_routes(self):
        @self.app.get("/", response_class=HTMLResponse)
        async def read_root():
            return """
            <!DOCTYPE html>
            <html>
            <head>
                <title>Platforma Dynamick√©ho Vypr√°vƒõn√≠</title>
                <meta charset="utf-8">
                <style>
                    body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
                    .story-container { background: #f5f5f5; padding: 20px; border-radius: 10px; margin: 20px 0; }
                    .choices { margin: 20px 0; }
                    .choice-button { background: #007bff; color: white; padding: 10px 20px; margin: 5px; border: none; border-radius: 5px; cursor: pointer; }
                    .choice-button:hover { background: #0056b3; }
                    .image-container { text-align: center; margin: 20px 0; }
                    .generated-image { max-width: 100%; border-radius: 10px; }
                </style>
            </head>
            <body>
                <h1>üé≠ Platforma Dynamick√©ho Vypr√°vƒõn√≠</h1>
                <p>Interaktivn√≠ AI-≈ô√≠zen√© vypr√°vƒõn√≠ s vizu√°ln√≠ podporou</p>
                
                <div>
                    <h3>Zaƒç√≠t nov√Ω p≈ô√≠bƒõh:</h3>
                    <select id="genre">
                        <option value="fantasy">Fantasy</option>
                        <option value="sci_fi">Sci-Fi</option>
                        <option value="mystery">Mysteri√≥zn√≠</option>
                    </select>
                    <button onclick="startStory()">Zaƒç√≠t p≈ô√≠bƒõh</button>
                </div>
                
                <div id="story-content"></div>
                
                <script>
                    let currentStoryId = null;
                    
                    async function startStory() {
                        const genre = document.getElementById('genre').value;
                        
                        const response = await fetch('/api/story/new', {
                            method: 'POST',
                            headers: {'Content-Type': 'application/json'},
                            body: JSON.stringify({genre: genre, user_preferences: {}})
                        });
                        
                        const data = await response.json();
                        currentStoryId = data.story_id;
                        displayStory(data);
                    }
                    
                    async function makeChoice(choiceId, choiceText) {
                        const response = await fetch(`/api/story/${currentStoryId}/choice`, {
                            method: 'POST',
                            headers: {'Content-Type': 'application/json'},
                            body: JSON.stringify({choice_id: choiceId, choice_text: choiceText})
                        });
                        
                        const data = await response.json();
                        displayStory(data);
                    }
                    
                    function displayStory(data) {
                        const container = document.getElementById('story-content');
                        
                        let html = `
                            <div class="story-container">
                                <h3>Kapitola ${data.chapter || 1}</h3>
                                <p>${data.scene}</p>
                        `;
                        
                        if (data.image) {
                            html += `
                                <div class="image-container">
                                    <img src="data:image/png;base64,${data.image}" class="generated-image" alt="Sc√©na">
                                </div>
                            `;
                        }
                        
                        if (data.choices) {
                            html += '<div class="choices"><h4>Va≈°e mo≈ænosti:</h4>';
                            data.choices.forEach((choice, index) => {
                                html += `<button class="choice-button" onclick="makeChoice(${index}, '${choice.replace(/'/g, "\\'")}')">${choice}</button><br>`;
                            });
                            html += '</div>';
                        }
                        
                        html += '</div>';
                        container.innerHTML = html;
                    }
                </script>
            </body>
            </html>
            """

        @self.app.post("/api/story/new")
        async def create_new_story(request: StoryRequest):
            story_id = str(uuid.uuid4())
            
            # Generov√°n√≠ √∫vodn√≠ sc√©ny
            story_data = await self.narrative_engine.start_new_story(
                request.genre, 
                request.user_preferences
            )
            
            # Generov√°n√≠ √∫vodn√≠ho obr√°zku
            if "scene" in story_data:
                image_base64 = await self.visual_generator.generate_scene_image(story_data["scene"])
                story_data["image"] = image_base64
            
            # Ulo≈æen√≠ aktivn√≠ho p≈ô√≠bƒõhu
            self.active_stories[story_id] = {
                "genre": request.genre,
                "current_data": story_data,
                "created_at": time.time()
            }
            
            return {
                "story_id": story_id,
                "chapter": 1,
                **story_data
            }

        @self.app.post("/api/story/{story_id}/choice")
        async def make_story_choice(story_id: str, request: ChoiceRequest):
            if story_id not in self.active_stories:
                raise HTTPException(status_code=404, detail="P≈ô√≠bƒõh nenalezen")
            
            # Zpracov√°n√≠ u≈æivatelsk√© volby
            choice_message = MCPMessage(
                message_id=str(uuid.uuid4()),
                message_type=MCPMessageType.USER_ACTION,
                payload={
                    "choice_id": request.choice_id,
                    "choice_text": request.choice_text
                },
                sender="user",
                timestamp=time.time()
            )
            
            # Generov√°n√≠ pokraƒçov√°n√≠
            response_message = await self.narrative_engine.process_message(choice_message)
            
            if response_message and response_message.payload:
                story_data = response_message.payload
                
                # Generov√°n√≠ obr√°zku pro novou sc√©nu
                if "scene_description" in story_data:
                    image_base64 = await self.visual_generator.generate_scene_image(
                        story_data["scene_description"]
                    )
                    story_data["image"] = image_base64
                
                # Aktualizace aktivn√≠ho p≈ô√≠bƒõhu
                self.active_stories[story_id]["current_data"] = story_data
                
                return {
                    "story_id": story_id,
                    "chapter": self.active_stories[story_id]["current_data"].get("chapter", 1),
                    "scene": story_data.get("scene_description", ""),
                    "choices": story_data.get("choices", []),
                    "image": story_data.get("image")
                }
            
            raise HTTPException(status_code=500, detail="Chyba p≈ôi generov√°n√≠ pokraƒçov√°n√≠")

        @self.app.get("/api/story/{story_id}/memory")
        async def get_story_memory(story_id: str):
            if story_id not in self.active_stories:
                raise HTTPException(status_code=404, detail="P≈ô√≠bƒõh nenalezen")
            
            current_scene = self.active_stories[story_id]["current_data"].get("scene", "")
            context = await self.memory_system.get_story_context(current_scene)
            
            return {"story_id": story_id, "memory_context": context}

        @self.app.get("/api/health")
        async def health_check():
            return {"status": "healthy", "components": ["narrative_engine", "visual_generator", "memory_system"]}

    def run(self, host: str = "0.0.0.0", port: int = 8000):
        uvicorn.run(self.app, host=host, port=port)

# Hlavn√≠ spou≈°tƒõc√≠ skript
if __name__ == "__main__":
    import os
    
    # Naƒçten√≠ API kl√≠ƒçe z environment variables
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("OPENAI_API_KEY environment variable je vy≈æadov√°na")
    
    platform = StorytellingPlatform(openai_api_key)
    platform.run()
````

````python
import asyncio
import os
from .web_api import StorytellingPlatform
from .narrative_engine import NarrativeEngine
from .memory_system import MCPMemorySystem
from .visual_generator import VisualGenerator

async def demo_interactive_story():
    """Demonstrace interaktivn√≠ho p≈ô√≠bƒõhu"""
    
    # Inicializace syst√©m≈Ø
    memory_system = MCPMemorySystem("./demo_memory")
    openai_api_key = os.getenv("OPENAI_API_KEY", "your-api-key-here")
    
    narrative_engine = NarrativeEngine(openai_api_key, memory_system)
    visual_generator = VisualGenerator()
    
    print("üé≠ Demo: Platforma Dynamick√©ho Vypr√°vƒõn√≠")
    print("=" * 50)
    
    # Zaƒç√°tek nov√©ho p≈ô√≠bƒõhu
    story_data = await narrative_engine.start_new_story(
        "fantasy", 
        {"preference": "dobrodru≈æn√Ω", "style": "epick√Ω"}
    )
    
    print(f"\nüìñ √övodn√≠ sc√©na:")
    print(story_data["scene"])
    
    print(f"\nüë§ Protagonista:")
    print(story_data["protagonist"])
    
    print(f"\nüîÄ Va≈°e mo≈ænosti:")
    for i, choice in enumerate(story_data["choices"], 1):
        print(f"{i}. {choice}")
    
    # Simulace u≈æivatelsk√© volby
    print(f"\n‚úÖ Vybr√°na volba 1: {story_data['choices'][0]}")
    
    # Generov√°n√≠ pokraƒçov√°n√≠
    continue_message = await narrative_engine._process_user_action({
        "choice_id": 0,
        "choice_text": story_data['choices'][0]
    })
    
    if continue_message and continue_message.payload:
        continuation = continue_message.payload
        print(f"\nüìñ Pokraƒçov√°n√≠:")
        print(continuation.get("scene_description", ""))
    
    # Demonstrace pamƒõ≈•ov√©ho syst√©mu
    print(f"\nüß† Kontext p≈ô√≠bƒõhu:")
    context = await memory_system.get_story_context("souƒçasn√° sc√©na")
    for layer, memories in context.items():
        if memories:
            print(f"\n{layer.upper()}:")
            for memory in memories[:2]:  # Pouze prvn√≠ 2 vzpom√≠nky
                print(f"  - {memory.content[:100]}...")

if __name__ == "__main__":
    # Spu≈°tƒõn√≠ demo
    asyncio.run(demo_interactive_story())
    
    # Nebo spu≈°tƒõn√≠ webov√© platformy
    # platform = StorytellingPlatform(os.getenv("OPENAI_API_KEY"))
    # platform.run()
````

````python
from setuptools import setup, find_packages

setup(
    name="ai-dynamic-storytelling",
    version="1.0.0",
    description="Platforma pro dynamick√© vypr√°vƒõn√≠ s MCP protokolem",
    packages=find_packages(),
    install_requires=[
        "langchain>=0.1.0",
        "openai>=1.10.0",
        "chromadb>=0.4.22",
        "fastapi>=0.108.0",
        "uvicorn>=0.25.0",
        "pydantic>=2.5.0",
        "diffusers>=0.24.0",
        "torch>=2.1.0",
        "pillow>=10.2.0",
        "requests>=2.31.0",
        "python-multipart>=0.0.6",
        "transformers>=4.35.0",
        "accelerate>=0.24.0"
    ],
    python_requires=">=3.8",
    entry_points={
        "console_scripts": [
            "storytelling-platform=src.web_api:main",
        ],
    },
    author="AI Development Team",
    author_email="dev@example.com",
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "Programming Language :: Python :: 3.8+",
    ],
)
````

## Souhrn Projektu

### Hodnota a V√Ωznam
Platforma pro Dynamick√© Vypr√°vƒõn√≠ p≈ôedstavuje pr≈Ølomovou implementaci AI-≈ô√≠zen√© interaktivn√≠ z√°bavy. Kombinuje pokroƒçil√© jazykov√© modely, vizu√°ln√≠ AI a sofistikovan√Ω pamƒõ≈•ov√Ω syst√©m pro vytv√°≈ôen√≠ personalizovan√Ωch narativn√≠ch z√°≈æitk≈Ø.

### Kl√≠ƒçov√© V√Ωhody
- **Nekoneƒçn√° Variabilita**: Ka≈æd√Ω p≈ô√≠bƒõh je jedineƒçn√Ω d√≠ky AI generov√°n√≠
- **Vizu√°ln√≠ Podpora**: Automatick√© vytv√°≈ôen√≠ ilustrac√≠ sc√©n
- **Dlouhodob√° Pamƒõ≈•**: Konzistentn√≠ narativn√≠ kontinuita
- **Modul√°rn√≠ Architektura**: Snadn√° roz≈°i≈ôitelnost a √∫dr≈æba
- **MCP Protokol**: Standardizovan√° komunikace mezi komponentami

### Technologick√© Inovace
- Implementace MCP protokolu pro AI syst√©my
- V√≠cevrstv√Ω pamƒõ≈•ov√Ω syst√©m s vektorov√Ωmi datab√°zemi
- Integrace textov√©ho a vizu√°ln√≠ho AI
- Real-time interaktivn√≠ webov√© rozhran√≠
- ≈†k√°lovateln√° architektura pro enterprise nasazen√≠

Projekt demonstruje budoucnost interaktivn√≠ z√°bavy, kde AI a lidsk√° kreativita vytv√°≈ôej√≠ spoleƒçnƒõ jedineƒçn√© narativn√≠ svƒõty p≈ôizp≈Øsoben√© ka≈æd√©mu u≈æivateli.