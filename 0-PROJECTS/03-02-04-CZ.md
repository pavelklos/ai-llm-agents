<small>Claude Sonnet 4 **(Akademick√Ω Tutor pro Studenty - RAG Syst√©m)**</small>
# Academic Tutor for Students

## 1. N√°zev Projektu

**Akademick√Ω Tutor pro Studenty** - Inteligentn√≠ studijn√≠ asistent vyu≈æ√≠vaj√≠c√≠ RAG (Retrieval-Augmented Generation) technologii pro personalizovan√© uƒçen√≠ a generov√°n√≠ kv√≠z≈Ø z uƒçebnic.

## 2. Vysvƒõtlen√≠ Kl√≠ƒçov√Ωch Koncept≈Ø

### RAG (Retrieval-Augmented Generation)
Hybridn√≠ p≈ô√≠stup kombinuj√≠c√≠ vyhled√°v√°n√≠ relevantn√≠ch informac√≠ z datab√°ze znalost√≠ s generativn√≠mi schopnostmi LLM. Umo≈æ≈àuje modelu p≈ôistupovat k aktu√°ln√≠m a specifick√Ωm informac√≠m mimo jeho tr√©ninkovou sadu.

### Claude Haiku
Rychl√Ω a efektivn√≠ model od Anthropic, optimalizovan√Ω pro √∫lohy vy≈æaduj√≠c√≠ rychl√© odpovƒõdi p≈ôi zachov√°n√≠ vysok√© kvality v√Ωstupu.

### PDF + DOCX Ingestion
Proces automatick√©ho extrahov√°n√≠ a strukturov√°n√≠ textov√©ho obsahu z dokument≈Ø v r≈Øzn√Ωch form√°tech pro n√°sledn√© indexov√°n√≠.

### Milvus
Vysoce v√Ωkonn√° vektorov√° datab√°ze navr≈æen√° pro spr√°vu a vyhled√°v√°n√≠ v rozs√°hl√Ωch kolekc√≠ch vektorov√Ωch embeddings.

### Streamlit
Python framework pro rychl√© vytv√°≈ôen√≠ interaktivn√≠ch webov√Ωch aplikac√≠ zamƒõ≈ôen√Ωch na data science a ML projekty.

### Flashcards (Kartiƒçky)
Digit√°ln√≠ studijn√≠ n√°stroj vyu≈æ√≠vaj√≠c√≠ metodu opakovan√©ho p≈ôipom√≠n√°n√≠ pro efektivn√≠ zapamatov√°n√≠ informac√≠.

### Quiz Generator
Automatizovan√Ω syst√©m pro vytv√°≈ôen√≠ testov√Ωch ot√°zek r≈Øzn√Ωch typ≈Ø na z√°kladƒõ studijn√≠ho materi√°lu.

## 3. Komplexn√≠ Vysvƒõtlen√≠ Projektu

### C√≠le Projektu
Akademick√Ω tutor p≈ôedstavuje pokroƒçil√Ω AI-asistovan√Ω vzdƒõl√°vac√≠ syst√©m, kter√Ω transformuje tradiƒçn√≠ uƒçebnice a studijn√≠ materi√°ly do interaktivn√≠ho prost≈ôed√≠. Hlavn√≠m c√≠lem je vytvo≈ôit personalizovan√©ho studijn√≠ho partnera, kter√Ω dok√°≈æe:

- Analyzovat a indexovat obsah z r≈Øzn√Ωch form√°t≈Ø dokument≈Ø
- Odpov√≠dat na konkr√©tn√≠ ot√°zky student≈Ø s kontextov√Ωmi odkazy
- Generovat kv√≠zy a testov√© ot√°zky p≈ôizp≈Øsoben√© √∫rovni studenta
- Vytv√°≈ôet flashcards pro efektivn√≠ memorov√°n√≠
- Sledovat pokrok a p≈ôizp≈Øsobovat obt√≠≈ænost

### Technick√© V√Ωzvy
1. **Multimod√°ln√≠ ingestion**: Zpracov√°n√≠ r≈Øzn√Ωch form√°t≈Ø dokument≈Ø p≈ôi zachov√°n√≠ struktury
2. **S√©mantick√© vyhled√°v√°n√≠**: Efektivn√≠ nalezen√≠ relevantn√≠ho obsahu v rozs√°hl√Ωch textech
3. **Kontextov√° generace**: Vytv√°≈ôen√≠ p≈ôesn√Ωch ot√°zek odpov√≠daj√≠c√≠ch obsahu
4. **Personalizace**: Adaptace na individu√°ln√≠ pot≈ôeby a √∫rove≈à studenta
5. **≈†k√°lov√°n√≠**: Optimalizace pro pr√°ci s velk√Ωmi objemy dokument≈Ø

### Potenci√°ln√≠ Dopad
Syst√©m m≈Ø≈æe v√Ωznamnƒõ zlep≈°it efektivitu studia, umo≈ænit samostatn√© uƒçen√≠ a poskytnout okam≈æitou zpƒõtnou vazbu. Zvl√°≈°tƒõ cenn√Ω je pro studenty s r≈Øzn√Ωmi styly uƒçen√≠ a ƒçasov√Ωmi omezen√≠mi.

## 4. Komplexn√≠ P≈ô√≠klad s Python Implementac√≠

### Z√°vislosti a Nastaven√≠

````python
streamlit>=1.28.0
langchain>=0.1.0
langchain-anthropic>=0.1.0
pymilvus>=2.3.0
PyPDF2>=3.0.0
python-docx>=0.8.11
sentence-transformers>=2.2.0
chromadb>=0.4.0
python-dotenv>=1.0.0
````

### Hlavn√≠ Aplikace

````python
import streamlit as st
import os
from dotenv import load_dotenv
from academic_tutor import AcademicTutor
from document_processor import DocumentProcessor
from quiz_generator import QuizGenerator

load_dotenv()

# Konfigurace str√°nky
st.set_page_config(
    page_title="Akademick√Ω Tutor",
    page_icon="üìö",
    layout="wide"
)

# Inicializace session state
if 'tutor' not in st.session_state:
    st.session_state.tutor = AcademicTutor()
if 'documents_loaded' not in st.session_state:
    st.session_state.documents_loaded = False

st.title("üìö Akademick√Ω Tutor - AI Studijn√≠ Asistent")

# Sidebar pro nahr√°n√≠ dokument≈Ø
with st.sidebar:
    st.header("üìÑ Spr√°va Dokument≈Ø")
    
    uploaded_files = st.file_uploader(
        "Nahrajte studijn√≠ materi√°ly",
        type=['pdf', 'docx'],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("Zpracovat dokumenty"):
        with st.spinner("Zpracov√°v√°m dokumenty..."):
            processor = DocumentProcessor()
            for file in uploaded_files:
                processor.process_file(file)
                st.session_state.tutor.add_documents(
                    processor.get_processed_content()
                )
            st.session_state.documents_loaded = True
            st.success("Dokumenty byly √∫spƒõ≈°nƒõ zpracov√°ny!")

# Hlavn√≠ rozhran√≠
if st.session_state.documents_loaded:
    tab1, tab2, tab3 = st.tabs(["üí¨ Chat", "üìù Kv√≠zy", "üÉè Kartiƒçky"])
    
    with tab1:
        st.header("Zeptejte se na cokoliv z va≈°ich materi√°l≈Ø")
        
        question = st.text_input("Va≈°e ot√°zka:")
        if question:
            with st.spinner("Hled√°m odpovƒõƒè..."):
                response = st.session_state.tutor.answer_question(question)
                st.write(response['answer'])
                
                if response['sources']:
                    st.subheader("üìö Zdroje:")
                    for source in response['sources']:
                        st.write(f"‚Ä¢ {source}")
    
    with tab2:
        st.header("Gener√°tor Kv√≠z≈Ø")
        
        col1, col2 = st.columns(2)
        with col1:
            topic = st.text_input("T√©ma kv√≠zu:")
            difficulty = st.selectbox("Obt√≠≈ænost:", ["Zaƒç√°teƒçn√≠k", "Pokroƒçil√Ω", "Expert"])
        with col2:
            question_count = st.number_input("Poƒçet ot√°zek:", min_value=1, max_value=20, value=5)
            quiz_type = st.selectbox("Typ ot√°zek:", ["V√Ωbƒõr z mo≈ænost√≠", "Pravda/Nepravda", "Sm√≠≈°en√©"])
        
        if st.button("Generovat kv√≠z") and topic:
            quiz_gen = QuizGenerator(st.session_state.tutor)
            quiz = quiz_gen.generate_quiz(topic, difficulty, question_count, quiz_type)
            
            for i, q in enumerate(quiz['questions'], 1):
                st.subheader(f"Ot√°zka {i}")
                st.write(q['question'])
                
                if q['type'] == 'multiple_choice':
                    answer = st.radio(f"Vyberte odpovƒõƒè {i}:", q['options'], key=f"q{i}")
                else:
                    answer = st.radio(f"Odpovƒõƒè {i}:", ["Pravda", "Nepravda"], key=f"q{i}")
    
    with tab3:
        st.header("Flashcards - Studijn√≠ Kartiƒçky")
        
        if st.button("Generovat kartiƒçky z materi√°l≈Ø"):
            flashcards = st.session_state.tutor.generate_flashcards()
            
            for i, card in enumerate(flashcards):
                with st.expander(f"Kartiƒçka {i+1}: {card['front'][:50]}..."):
                    st.write(f"**Ot√°zka:** {card['front']}")
                    st.write(f"**Odpovƒõƒè:** {card['back']}")

else:
    st.info("üëÜ Nejprve nahrajte studijn√≠ materi√°ly v postrann√≠m panelu.")
````

### Procesor Dokument≈Ø

````python
import PyPDF2
from docx import Document
import io
from typing import List, Dict
import re

class DocumentProcessor:
    def __init__(self):
        self.processed_content = []
    
    def process_file(self, uploaded_file) -> None:
        """Zpracuje nahran√Ω soubor podle jeho typu."""
        file_type = uploaded_file.type
        
        if file_type == "application/pdf":
            content = self._process_pdf(uploaded_file)
        elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            content = self._process_docx(uploaded_file)
        else:
            raise ValueError(f"Nepodporovan√Ω typ souboru: {file_type}")
        
        # Rozdƒõlen√≠ na chunky
        chunks = self._split_into_chunks(content, uploaded_file.name)
        self.processed_content.extend(chunks)
    
    def _process_pdf(self, file) -> str:
        """Extrahuje text z PDF souboru."""
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        
        return self._clean_text(text)
    
    def _process_docx(self, file) -> str:
        """Extrahuje text z DOCX souboru."""
        doc = Document(file)
        text = ""
        
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        
        return self._clean_text(text)
    
    def _clean_text(self, text: str) -> str:
        """Vyƒçist√≠ a normalizuje text."""
        # Odstranƒõn√≠ p≈ôebyteƒçn√Ωch b√≠l√Ωch znak≈Ø
        text = re.sub(r'\s+', ' ', text)
        # Odstranƒõn√≠ speci√°ln√≠ch znak≈Ø
        text = re.sub(r'[^\w\s\.,!?;:()\-]', '', text)
        return text.strip()
    
    def _split_into_chunks(self, content: str, filename: str, chunk_size: int = 1000) -> List[Dict]:
        """Rozdƒõl√≠ obsah na men≈°√≠ ƒç√°sti pro lep≈°√≠ vyhled√°v√°n√≠."""
        words = content.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size):
            chunk_words = words[i:i + chunk_size]
            chunk_text = ' '.join(chunk_words)
            
            chunks.append({
                'content': chunk_text,
                'source': filename,
                'chunk_id': i // chunk_size
            })
        
        return chunks
    
    def get_processed_content(self) -> List[Dict]:
        """Vrac√≠ zpracovan√Ω obsah."""
        return self.processed_content
````

### Akademick√Ω Tutor Core

````python
from langchain_anthropic import ChatAnthropic
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from typing import List, Dict
import os
import chromadb

class AcademicTutor:
    def __init__(self):
        self.llm = ChatAnthropic(
            model="claude-3-haiku-20240307",
            anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.3
        )
        
        self.embeddings = SentenceTransformerEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        
        # Inicializace Chroma datab√°ze
        self.client = chromadb.PersistentClient(path="./chroma_db")
        self.vectorstore = None
        self.qa_chain = None
        
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
    
    def add_documents(self, documents: List[Dict]) -> None:
        """P≈ôid√° dokumenty do vektorov√© datab√°ze."""
        texts = [doc['content'] for doc in documents]
        metadatas = [{'source': doc['source'], 'chunk_id': doc['chunk_id']} for doc in documents]
        
        if self.vectorstore is None:
            self.vectorstore = Chroma.from_texts(
                texts=texts,
                embedding=self.embeddings,
                metadatas=metadatas,
                client=self.client,
                collection_name="academic_documents"
            )
        else:
            self.vectorstore.add_texts(texts=texts, metadatas=metadatas)
        
        # Vytvo≈ôen√≠ QA chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            return_source_documents=True
        )
    
    def answer_question(self, question: str) -> Dict:
        """Odpov√≠d√° na ot√°zku studenta s kontextem z dokument≈Ø."""
        if not self.qa_chain:
            return {"answer": "Nejprve nahrajte studijn√≠ materi√°ly.", "sources": []}
        
        # P≈ôeklad ot√°zky do kontextu
        enhanced_question = f"""
        Na z√°kladƒõ nahran√Ωch studijn√≠ch materi√°l≈Ø odpovƒõz na n√°sleduj√≠c√≠ ot√°zku v ƒçe≈°tinƒõ.
        Buƒè konkr√©tn√≠ a pou≈æij p≈ô√≠klady z materi√°l≈Ø, pokud jsou relevantn√≠.
        
        Ot√°zka: {question}
        """
        
        try:
            result = self.qa_chain({"query": enhanced_question})
            
            sources = []
            if result.get('source_documents'):
                for doc in result['source_documents']:
                    source_info = f"{doc.metadata.get('source', 'Nezn√°m√Ω zdroj')} (ƒç√°st {doc.metadata.get('chunk_id', 0)})"
                    if source_info not in sources:
                        sources.append(source_info)
            
            return {
                "answer": result['result'],
                "sources": sources
            }
        
        except Exception as e:
            return {
                "answer": f"Nastala chyba p≈ôi zpracov√°n√≠ ot√°zky: {str(e)}",
                "sources": []
            }
    
    def generate_flashcards(self, count: int = 10) -> List[Dict]:
        """Generuje flashcards z obsahu dokument≈Ø."""
        if not self.vectorstore:
            return []
        
        # Z√≠sk√°n√≠ n√°hodn√Ωch dokument≈Ø pro generov√°n√≠ karet
        docs = self.vectorstore.similarity_search("", k=count)
        
        flashcards = []
        for doc in docs:
            prompt = f"""
            Na z√°kladƒõ n√°sleduj√≠c√≠ho textu vytvo≈ô jednu flashcard (studijn√≠ kartiƒçku).
            P≈ôedn√≠ strana (ot√°zka) by mƒõla b√Ωt kr√°tk√° a konkr√©tn√≠.
            Zadn√≠ strana (odpovƒõƒè) by mƒõla b√Ωt struƒçn√° ale informativn√≠.
            
            Text: {doc.page_content[:500]}
            
            Odpovƒõz ve form√°tu:
            P≈òEDN√ç STRANA: [ot√°zka]
            ZADN√ç STRANA: [odpovƒõƒè]
            """
            
            try:
                response = self.llm.invoke(prompt)
                content = response.content
                
                if "P≈òEDN√ç STRANA:" in content and "ZADN√ç STRANA:" in content:
                    parts = content.split("ZADN√ç STRANA:")
                    front = parts[0].replace("P≈òEDN√ç STRANA:", "").strip()
                    back = parts[1].strip()
                    
                    flashcards.append({
                        "front": front,
                        "back": back
                    })
            except Exception as e:
                continue
        
        return flashcards
````

### Gener√°tor Kv√≠z≈Ø

````python
from typing import List, Dict
import random

class QuizGenerator:
    def __init__(self, tutor):
        self.tutor = tutor
    
    def generate_quiz(self, topic: str, difficulty: str, count: int, quiz_type: str) -> Dict:
        """Generuje kv√≠z na zadan√© t√©ma."""
        if not self.tutor.vectorstore:
            return {"questions": []}
        
        # Vyhled√°n√≠ relevantn√≠ch dokument≈Ø k t√©matu
        relevant_docs = self.tutor.vectorstore.similarity_search(topic, k=count*2)
        
        questions = []
        for i, doc in enumerate(relevant_docs[:count]):
            question = self._generate_question(doc.page_content, difficulty, quiz_type)
            if question:
                questions.append(question)
        
        return {
            "topic": topic,
            "difficulty": difficulty,
            "questions": questions
        }
    
    def _generate_question(self, content: str, difficulty: str, quiz_type: str) -> Dict:
        """Generuje jednotlivou ot√°zku z obsahu."""
        difficulty_prompts = {
            "Zaƒç√°teƒçn√≠k": "z√°kladn√≠ faktick√© informace",
            "Pokroƒçil√Ω": "koncepty a jejich aplikace", 
            "Expert": "anal√Ωzu a synt√©zu informac√≠"
        }
        
        if quiz_type == "V√Ωbƒõr z mo≈ænost√≠" or quiz_type == "Sm√≠≈°en√©":
            prompt = f"""
            Na z√°kladƒõ n√°sleduj√≠c√≠ho textu vytvo≈ô ot√°zku s v√Ωbƒõrem z mo≈ænost√≠ zamƒõ≈ôenou na {difficulty_prompts[difficulty]}.
            
            Text: {content[:800]}
            
            Form√°t odpovƒõdi:
            OT√ÅZKA: [ot√°zka]
            A) [mo≈ænost A]
            B) [mo≈ænost B] 
            C) [mo≈ænost C]
            D) [mo≈ænost D]
            SPR√ÅVN√Å ODPOVƒöƒé: [p√≠smeno]
            """
        else:  # Pravda/Nepravda
            prompt = f"""
            Na z√°kladƒõ n√°sleduj√≠c√≠ho textu vytvo≈ô pravda/nepravda ot√°zku zamƒõ≈ôenou na {difficulty_prompts[difficulty]}.
            
            Text: {content[:800]}
            
            Form√°t odpovƒõdi:
            OT√ÅZKA: [tvrzen√≠]
            SPR√ÅVN√Å ODPOVƒöƒé: [PRAVDA/NEPRAVDA]
            """
        
        try:
            response = self.tutor.llm.invoke(prompt)
            return self._parse_question_response(response.content, quiz_type)
        except Exception as e:
            return None
    
    def _parse_question_response(self, response: str, quiz_type: str) -> Dict:
        """Parsuje odpovƒõƒè LLM do strukturovan√© ot√°zky."""
        try:
            if "OT√ÅZKA:" not in response:
                return None
            
            parts = response.split("OT√ÅZKA:")
            question_part = parts[1].split("SPR√ÅVN√Å ODPOVƒöƒé:")[0].strip()
            
            if quiz_type == "V√Ωbƒõr z mo≈ænost√≠" or (quiz_type == "Sm√≠≈°en√©" and "A)" in response):
                # Extrakce mo≈ænost√≠
                options = []
                for letter in ['A)', 'B)', 'C)', 'D)']:
                    if letter in question_part:
                        start = question_part.find(letter)
                        if letter != 'D)':
                            next_letter = ['B)', 'C)', 'D)', 'SPR√ÅVN√Å'][['A)', 'B)', 'C)', 'D)'].index(letter) + 1]
                            end = question_part.find(next_letter)
                        else:
                            end = len(question_part)
                        
                        option_text = question_part[start+2:end].strip()
                        options.append(option_text)
                
                # Extrakce samotn√© ot√°zky
                question_text = question_part.split('A)')[0].strip()
                
                # Spr√°vn√° odpovƒõƒè
                correct_answer = response.split("SPR√ÅVN√Å ODPOVƒöƒé:")[-1].strip()
                
                return {
                    "type": "multiple_choice",
                    "question": question_text,
                    "options": options,
                    "correct_answer": correct_answer
                }
            
            else:  # Pravda/Nepravda
                question_text = question_part.strip()
                correct_answer = response.split("SPR√ÅVN√Å ODPOVƒöƒé:")[-1].strip()
                
                return {
                    "type": "true_false",
                    "question": question_text,
                    "correct_answer": correct_answer
                }
                
        except Exception as e:
            return None
````

### Spu≈°tƒõn√≠ Aplikace

````python
import subprocess
import sys

def main():
    """Spust√≠ Streamlit aplikaci."""
    try:
        subprocess.run([sys.executable, "-m", "streamlit", "run", "main.py"], check=True)
    except subprocess.CalledProcessError as e:
        print(f"Chyba p≈ôi spu≈°tƒõn√≠ aplikace: {e}")
    except KeyboardInterrupt:
        print("\nAplikace byla ukonƒçena u≈æivatelem.")

if __name__ == "__main__":
    main()
````

### Environment Konfigurace

````bash
ANTHROPIC_API_KEY=your_api_key_here
````

## 5. Shrnut√≠ Projektu

Akademick√Ω Tutor p≈ôedstavuje komplexn√≠ ≈ôe≈°en√≠ pro modern√≠ vzdƒõl√°v√°n√≠, kter√© kombinuje nejnovƒõj≈°√≠ technologie AI s praktick√Ωmi vzdƒõl√°vac√≠mi pot≈ôebami. Syst√©m vyu≈æ√≠v√° RAG architekturu pro p≈ôesn√© odpovƒõdi zalo≈æen√© na faktick√©m obsahu, Claude Haiku pro rychl√© a kvalitn√≠ generov√°n√≠, a Streamlit pro intuitivn√≠ u≈æivatelsk√© rozhran√≠.

**Kl√≠ƒçov√© hodnoty:**
- **Personalizace**: P≈ôizp≈Øsoben√≠ obsahu individu√°ln√≠m pot≈ôeb√°m studenta
- **Efektivita**: Automatizace tvorby studijn√≠ch materi√°l≈Ø a test≈Ø
- **P≈ôesnost**: Odpovƒõdi zalo≈æen√© na konkr√©tn√≠ch zdroj√≠ch
- **≈†k√°lovatelnost**: Schopnost zpracovat rozs√°hl√© mno≈æstv√≠ dokument≈Ø
- **Interaktivita**: Okam≈æit√° zpƒõtn√° vazba a adaptivn√≠ uƒçen√≠

Projekt demonstruje praktick√© vyu≈æit√≠ modern√≠ch AI technologi√≠ ve vzdƒõl√°v√°n√≠ a poskytuje robustn√≠ z√°klad pro dal≈°√≠ roz≈°√≠≈ôen√≠ a personalizaci.