<small>Claude Sonnet 4 **(AI-Powered Translator with Cultural Context)**</small>
# AI-Powered Translator with Cultural Context

## Key Concepts Explanation

### Cultural Context-Aware Translation
Advanced translation system that goes beyond literal word conversion to understand and preserve cultural nuances, idioms, references, and social contexts. Analyzes source text for cultural markers, adapts translations to target cultural norms, and maintains appropriate levels of formality, humor, and cultural sensitivity while ensuring natural expression in the target language.

### Translation Memory System
Intelligent database that stores previously translated segments, phrases, and documents to ensure consistency and improve efficiency. Uses fuzzy matching algorithms and semantic similarity to retrieve relevant translations, maintains terminology databases for domain-specific vocabulary, and learns from human corrections to continuously improve translation quality.

### Tone and Style Detection
Sophisticated natural language processing system that identifies emotional tone, writing style, formality levels, and communicative intent in source text. Analyzes linguistic patterns, vocabulary choices, sentence structure, and contextual clues to preserve the original author's voice and adapt it appropriately for the target language and culture.

### Adaptive Language Models
Multi-layered AI system combining large language models with specialized translation engines, cultural knowledge bases, and domain-specific terminology. Dynamically adjusts translation strategies based on text type, target audience, cultural context, and quality requirements while maintaining consistency across related documents.

### Cross-Cultural Communication Bridge
Intelligent system that identifies potential cultural misunderstandings, explains cultural references, and suggests culturally appropriate alternatives. Provides context explanations for cultural concepts, warns about potential sensitivities, and offers multiple translation options with cultural adaptation levels.

### Quality Assurance Engine
Comprehensive evaluation system that assesses translation quality through multiple metrics including fluency, accuracy, cultural appropriateness, and consistency. Uses back-translation verification, confidence scoring, human feedback integration, and automated quality checks to ensure professional-grade translation output.

## Comprehensive Project Explanation

### Objectives
The AI-Powered Translator aims to revolutionize cross-cultural communication by providing translations that are not only linguistically accurate but also culturally sensitive, contextually appropriate, and stylistically consistent, bridging communication gaps in globalized business, education, and social interactions.

### Key Features
- **Multi-Engine Translation**: Combines multiple translation approaches for optimal results
- **Cultural Adaptation**: Automatic adjustment for cultural contexts and sensitivities
- **Tone Preservation**: Maintains original tone, style, and emotional impact
- **Domain Specialization**: Specialized translation for technical, legal, medical, and creative content
- **Interactive Refinement**: Human-in-the-loop feedback for continuous improvement
- **Consistency Management**: Translation memory ensures terminology and style consistency

### Challenges
- **Cultural Nuance Complexity**: Accurately interpreting and translating subtle cultural references and implications
- **Context Disambiguation**: Resolving ambiguous meanings based on broader document and cultural context
- **Style Transfer**: Maintaining author's voice and intent across different linguistic and cultural frameworks
- **Domain Expertise**: Handling specialized terminology and concepts across various professional fields
- **Quality Consistency**: Ensuring uniform translation quality across different content types and language pairs
- **Real-time Performance**: Balancing translation quality with speed requirements for interactive applications

### Potential Impact
This system can facilitate international business communications, enhance cross-cultural understanding, support global education initiatives, improve accessibility for multilingual communities, and contribute to breaking down language barriers in digital communications while preserving cultural richness and diversity.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
openai==1.6.1
langchain==0.1.0
langchain-openai==0.0.5
streamlit==1.29.0
transformers==4.36.0
sentence-transformers==2.2.2
chromadb==0.4.18
googletrans==4.0.0
deep-translator==1.11.4
langdetect==1.0.9
pandas==2.1.4
numpy==1.24.3
requests==2.31.0
plotly==5.17.0
textblob==0.17.1
spacy==3.7.2
nltk==3.8.1
pydantic==2.5.0
python-dotenv==1.0.0
sqlalchemy==2.0.23
torch==2.1.0
scikit-learn==1.3.2
json
uuid
logging
datetime
typing
dataclasses
enum
re
hashlib
asyncio
````

### Core Implementation

````python
import os
import json
import uuid
import logging
import hashlib
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import asyncio

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

# Translation libraries
from googletrans import Translator as GoogleTranslator
from deep_translator import GoogleTranslator as DeepGoogleTranslator
from langdetect import detect, LangDetectError

# NLP libraries
import spacy
import nltk
from textblob import TextBlob
from transformers import pipeline, AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer

# LangChain components
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Vector database
import chromadb

# ML libraries
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Download required NLTK data
try:
    nltk.download('punkt', quiet=True)
    nltk.download('vader_lexicon', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass

class TranslationEngine(Enum):
    GOOGLE = "google"
    OPENAI = "openai"
    HYBRID = "hybrid"
    CUSTOM = "custom"

class ToneType(Enum):
    FORMAL = "formal"
    INFORMAL = "informal"
    PROFESSIONAL = "professional"
    CASUAL = "casual"
    ACADEMIC = "academic"
    CREATIVE = "creative"
    TECHNICAL = "technical"
    EMOTIONAL = "emotional"

class CulturalContext(Enum):
    BUSINESS = "business"
    ACADEMIC = "academic"
    SOCIAL = "social"
    TECHNICAL = "technical"
    LEGAL = "legal"
    MEDICAL = "medical"
    CREATIVE = "creative"
    NEWS = "news"

class QualityLevel(Enum):
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"

@dataclass
class LanguageInfo:
    code: str
    name: str
    native_name: str
    rtl: bool = False
    formality_levels: List[str] = field(default_factory=list)
    cultural_notes: str = ""

@dataclass
class ToneAnalysis:
    tone_type: ToneType
    formality_score: float  # 0-1 scale
    emotional_intensity: float  # 0-1 scale
    confidence: float
    detected_emotions: List[str]
    style_markers: List[str]

@dataclass
class CulturalAnalysis:
    context_type: CulturalContext
    cultural_references: List[str]
    idioms_detected: List[str]
    formality_requirements: str
    sensitivity_warnings: List[str]
    adaptation_suggestions: List[str]

@dataclass
class TranslationMemoryEntry:
    entry_id: str
    source_text: str
    target_text: str
    source_lang: str
    target_lang: str
    context: str
    tone: ToneType
    quality_score: float
    created_at: datetime
    usage_count: int = 0
    last_used: Optional[datetime] = None

@dataclass
class TranslationResult:
    translation_id: str
    source_text: str
    translated_text: str
    source_language: str
    target_language: str
    engine_used: TranslationEngine
    tone_analysis: ToneAnalysis
    cultural_analysis: CulturalAnalysis
    quality_score: float
    confidence_score: float
    alternatives: List[str] = field(default_factory=list)
    cultural_notes: List[str] = field(default_factory=list)
    memory_matches: List[TranslationMemoryEntry] = field(default_factory=list)
    processing_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

class LanguageDetector:
    """Detects and analyzes source language properties."""
    
    def __init__(self):
        self.supported_languages = {
            'en': LanguageInfo('en', 'English', 'English', formality_levels=['casual', 'formal', 'academic']),
            'es': LanguageInfo('es', 'Spanish', 'Español', formality_levels=['informal', 'formal', 'very_formal']),
            'fr': LanguageInfo('fr', 'French', 'Français', formality_levels=['tu', 'vous', 'academic']),
            'de': LanguageInfo('de', 'German', 'Deutsch', formality_levels=['du', 'sie', 'academic']),
            'ja': LanguageInfo('ja', 'Japanese', '日本語', formality_levels=['casual', 'polite', 'honorific']),
            'zh': LanguageInfo('zh', 'Chinese', '中文', formality_levels=['casual', 'formal', 'classical']),
            'ar': LanguageInfo('ar', 'Arabic', 'العربية', rtl=True, formality_levels=['casual', 'formal', 'classical']),
            'ru': LanguageInfo('ru', 'Russian', 'Русский', formality_levels=['informal', 'formal', 'official']),
            'it': LanguageInfo('it', 'Italian', 'Italiano', formality_levels=['informal', 'formal', 'academic']),
            'pt': LanguageInfo('pt', 'Portuguese', 'Português', formality_levels=['informal', 'formal', 'academic'])
        }
    
    def detect_language(self, text: str) -> Tuple[str, float]:
        """Detect language of input text."""
        try:
            detected_lang = detect(text)
            
            # Simple confidence estimation based on text length and detection consistency
            confidence = min(0.8 + (len(text) / 1000) * 0.2, 0.99)
            
            # Verify with TextBlob for additional confidence
            try:
                blob = TextBlob(text)
                blob_lang = blob.detect_language()
                if blob_lang == detected_lang:
                    confidence = min(confidence + 0.1, 0.99)
            except:
                pass
            
            return detected_lang, confidence
            
        except LangDetectError:
            # Fallback to English with low confidence
            return 'en', 0.3
    
    def get_language_info(self, lang_code: str) -> Optional[LanguageInfo]:
        """Get language information."""
        return self.supported_languages.get(lang_code)
    
    def is_supported(self, lang_code: str) -> bool:
        """Check if language is supported."""
        return lang_code in self.supported_languages

class ToneAnalyzer:
    """Analyzes tone, style, and emotional content of text."""
    
    def __init__(self):
        try:
            # Initialize sentiment analysis
            self.sentiment_analyzer = pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest"
            )
        except:
            logger.warning("Sentiment analyzer not available")
            self.sentiment_analyzer = None
        
        # Tone markers for different styles
        self.tone_markers = {
            ToneType.FORMAL: [
                'furthermore', 'therefore', 'consequently', 'moreover', 'nevertheless',
                'in addition', 'it should be noted', 'as stated previously'
            ],
            ToneType.INFORMAL: [
                'hey', 'yeah', 'kinda', 'sorta', 'wanna', 'gonna', 'pretty much',
                'you know', 'like', 'totally'
            ],
            ToneType.PROFESSIONAL: [
                'pursuant to', 'in accordance with', 'we recommend', 'please find',
                'as per', 'kindly', 'regarding', 'with respect to'
            ],
            ToneType.ACADEMIC: [
                'hypothesis', 'methodology', 'empirical', 'theoretical framework',
                'research indicates', 'studies show', 'analysis reveals'
            ],
            ToneType.TECHNICAL: [
                'implementation', 'configuration', 'optimization', 'parameters',
                'algorithm', 'specification', 'protocol', 'interface'
            ]
        }
        
        # Formality indicators
        self.formality_indicators = {
            'formal': ['shall', 'ought', 'would be advisable', 'it is recommended'],
            'informal': ['gonna', 'wanna', 'kinda', 'sorta', 'yeah', 'nah']
        }
    
    def analyze_tone(self, text: str, language: str = 'en') -> ToneAnalysis:
        """Analyze tone and style of text."""
        text_lower = text.lower()
        
        # Detect tone type
        tone_scores = {}
        for tone_type, markers in self.tone_markers.items():
            score = sum(1 for marker in markers if marker in text_lower)
            tone_scores[tone_type] = score / len(markers)
        
        # Determine primary tone
        primary_tone = max(tone_scores.keys(), key=lambda k: tone_scores[k])
        if tone_scores[primary_tone] == 0:
            primary_tone = ToneType.CASUAL  # Default tone
        
        # Calculate formality score
        formality_score = self._calculate_formality(text_lower)
        
        # Analyze emotional content
        emotional_intensity, emotions = self._analyze_emotions(text)
        
        # Identify style markers
        style_markers = self._identify_style_markers(text_lower)
        
        # Calculate confidence
        confidence = min(0.7 + (len(text) / 500) * 0.2, 0.95)
        
        return ToneAnalysis(
            tone_type=primary_tone,
            formality_score=formality_score,
            emotional_intensity=emotional_intensity,
            confidence=confidence,
            detected_emotions=emotions,
            style_markers=style_markers
        )
    
    def _calculate_formality(self, text: str) -> float:
        """Calculate formality score (0=informal, 1=formal)."""
        formal_score = sum(1 for indicator in self.formality_indicators['formal'] 
                          if indicator in text)
        informal_score = sum(1 for indicator in self.formality_indicators['informal'] 
                           if indicator in text)
        
        # Additional formality indicators
        formal_score += len(re.findall(r'\b[A-Z][a-z]*ly\b', text))  # Adverbs ending in -ly
        formal_score += len(re.findall(r'\b(?:furthermore|moreover|however|therefore)\b', text))
        
        informal_score += len(re.findall(r'[!]{2,}', text))  # Multiple exclamation marks
        informal_score += len(re.findall(r'\b(?:lol|omg|wtf|tbh|btw)\b', text.lower()))
        
        total_indicators = formal_score + informal_score
        if total_indicators == 0:
            return 0.5  # Neutral
        
        return formal_score / total_indicators
    
    def _analyze_emotions(self, text: str) -> Tuple[float, List[str]]:
        """Analyze emotional content and intensity."""
        emotions = []
        intensity = 0.0
        
        if self.sentiment_analyzer:
            try:
                # Analyze sentiment
                results = self.sentiment_analyzer(text[:512])  # Limit text length
                if results:
                    result = results[0]
                    emotions.append(result['label'].lower())
                    intensity = result['score']
            except:
                pass
        
        # Simple emotion detection based on keywords
        emotion_keywords = {
            'joy': ['happy', 'excited', 'wonderful', 'amazing', 'fantastic'],
            'anger': ['angry', 'furious', 'outraged', 'mad', 'irritated'],
            'sadness': ['sad', 'depressed', 'disappointed', 'upset', 'heartbroken'],
            'fear': ['scared', 'afraid', 'terrified', 'worried', 'anxious'],
            'surprise': ['surprised', 'shocked', 'amazed', 'astonished']
        }
        
        text_lower = text.lower()
        for emotion, keywords in emotion_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                emotions.append(emotion)
        
        # Calculate intensity based on emotional markers
        emotional_markers = ['!', '?', 'very', 'extremely', 'incredibly', 'absolutely']
        marker_count = sum(text.count(marker) for marker in emotional_markers)
        intensity = max(intensity, min(marker_count / 10, 1.0))
        
        return intensity, list(set(emotions))
    
    def _identify_style_markers(self, text: str) -> List[str]:
        """Identify specific style markers in text."""
        markers = []
        
        # Check for various style indicators
        if re.search(r'\b(?:I|we) (?:believe|think|feel)\b', text):
            markers.append('subjective_opinion')
        
        if re.search(r'\b(?:research shows|studies indicate|data suggests)\b', text):
            markers.append('evidence_based')
        
        if re.search(r'[?]{2,}|[!]{2,}', text):
            markers.append('emphatic_punctuation')
        
        if len(re.findall(r'[A-Z]{2,}', text)) > 2:
            markers.append('caps_emphasis')
        
        if re.search(r'\b(?:like|you know|I mean|sort of)\b', text):
            markers.append('conversational_fillers')
        
        return markers

class CulturalAnalyzer:
    """Analyzes cultural context and provides adaptation suggestions."""
    
    def __init__(self):
        # Cultural context indicators
        self.context_indicators = {
            CulturalContext.BUSINESS: [
                'meeting', 'proposal', 'contract', 'revenue', 'client', 'stakeholder',
                'quarterly', 'market', 'strategy', 'partnership'
            ],
            CulturalContext.ACADEMIC: [
                'research', 'methodology', 'hypothesis', 'conclusion', 'bibliography',
                'peer review', 'journal', 'citation', 'analysis'
            ],
            CulturalContext.LEGAL: [
                'contract', 'agreement', 'clause', 'liability', 'jurisdiction',
                'plaintiff', 'defendant', 'court', 'legal'
            ],
            CulturalContext.MEDICAL: [
                'patient', 'diagnosis', 'treatment', 'symptoms', 'medication',
                'therapy', 'clinical', 'medical', 'health'
            ]
        }
        
        # Common idioms and cultural references (English examples)
        self.cultural_expressions = {
            'idioms': [
                'break the ice', 'piece of cake', 'hit the nail on the head',
                'cost an arm and a leg', 'spill the beans', 'let the cat out of the bag'
            ],
            'cultural_references': [
                'american dream', 'stiff upper lip', 'siesta', 'feng shui',
                'karma', 'zeitgeist', 'schadenfreude'
            ]
        }
        
        # Cultural sensitivity warnings
        self.sensitivity_topics = [
            'religion', 'politics', 'race', 'gender', 'sexuality', 'disability',
            'age', 'cultural practices', 'historical events'
        ]
    
    def analyze_cultural_context(self, text: str, source_lang: str, target_lang: str) -> CulturalAnalysis:
        """Analyze cultural context and provide adaptation guidance."""
        text_lower = text.lower()
        
        # Detect context type
        context_scores = {}
        for context_type, indicators in self.context_indicators.items():
            score = sum(1 for indicator in indicators if indicator in text_lower)
            context_scores[context_type] = score
        
        primary_context = max(context_scores.keys(), key=lambda k: context_scores[k])
        if context_scores[primary_context] == 0:
            primary_context = CulturalContext.SOCIAL  # Default context
        
        # Detect cultural expressions
        detected_idioms = [idiom for idiom in self.cultural_expressions['idioms']
                          if idiom in text_lower]
        
        cultural_refs = [ref for ref in self.cultural_expressions['cultural_references']
                        if ref in text_lower]
        
        # Check for sensitivity issues
        sensitivity_warnings = []
        for topic in self.sensitivity_topics:
            if topic in text_lower:
                sensitivity_warnings.append(f"Contains references to {topic} - consider cultural sensitivity")
        
        # Generate adaptation suggestions
        adaptation_suggestions = self._generate_adaptation_suggestions(
            primary_context, source_lang, target_lang, detected_idioms
        )
        
        # Determine formality requirements
        formality_req = self._determine_formality_requirements(primary_context, target_lang)
        
        return CulturalAnalysis(
            context_type=primary_context,
            cultural_references=cultural_refs,
            idioms_detected=detected_idioms,
            formality_requirements=formality_req,
            sensitivity_warnings=sensitivity_warnings,
            adaptation_suggestions=adaptation_suggestions
        )
    
    def _generate_adaptation_suggestions(self, context: CulturalContext, 
                                       source_lang: str, target_lang: str,
                                       idioms: List[str]) -> List[str]:
        """Generate cultural adaptation suggestions."""
        suggestions = []
        
        # Context-specific suggestions
        if context == CulturalContext.BUSINESS:
            if target_lang == 'ja':
                suggestions.append("Consider using keigo (honorific language) for business context")
            elif target_lang == 'de':
                suggestions.append("Use formal 'Sie' form for business communications")
        
        elif context == CulturalContext.ACADEMIC:
            suggestions.append("Maintain academic tone and citation standards")
            if target_lang in ['zh', 'ja']:
                suggestions.append("Consider cultural academic conventions")
        
        # Idiom handling
        if idioms:
            suggestions.append(f"Found {len(idioms)} idioms that may need cultural adaptation")
            suggestions.append("Consider replacing idioms with equivalent expressions in target culture")
        
        # Language-specific suggestions
        if target_lang == 'ar':
            suggestions.append("Consider right-to-left text direction and cultural context")
        elif target_lang == 'zh':
            suggestions.append("Consider simplified vs traditional character preferences")
        
        return suggestions
    
    def _determine_formality_requirements(self, context: CulturalContext, target_lang: str) -> str:
        """Determine formality requirements based on context and target language."""
        if context in [CulturalContext.BUSINESS, CulturalContext.LEGAL, CulturalContext.ACADEMIC]:
            if target_lang in ['ja', 'ko']:
                return "high_formality_with_honorifics"
            elif target_lang in ['de', 'fr']:
                return "formal_with_proper_pronouns"
            else:
                return "professional_formal"
        
        elif context == CulturalContext.SOCIAL:
            return "contextual_appropriateness"
        
        return "moderate_formality"

class TranslationMemory:
    """Manages translation memory for consistency and efficiency."""
    
    def __init__(self):
        self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.chroma_client = chromadb.Client()
        
        try:
            self.memory_collection = self.chroma_client.get_collection("translation_memory")
        except:
            self.memory_collection = self.chroma_client.create_collection("translation_memory")
        
        self.memory_entries = {}
        self._initialize_sample_memory()
    
    def _initialize_sample_memory(self):
        """Initialize with sample translation memory entries."""
        sample_entries = [
            {
                'source': 'Hello, how are you?',
                'target': 'Hola, ¿cómo estás?',
                'source_lang': 'en',
                'target_lang': 'es',
                'context': 'greeting',
                'tone': ToneType.CASUAL
            },
            {
                'source': 'Thank you for your attention',
                'target': 'Gracias por su atención',
                'source_lang': 'en',
                'target_lang': 'es',
                'context': 'formal_closing',
                'tone': ToneType.FORMAL
            }
        ]
        
        for entry_data in sample_entries:
            self.add_entry(
                entry_data['source'], entry_data['target'],
                entry_data['source_lang'], entry_data['target_lang'],
                entry_data['context'], entry_data['tone']
            )
    
    def add_entry(self, source_text: str, target_text: str, source_lang: str,
                  target_lang: str, context: str, tone: ToneType, quality_score: float = 0.8):
        """Add entry to translation memory."""
        try:
            entry_id = str(uuid.uuid4())
            
            entry = TranslationMemoryEntry(
                entry_id=entry_id,
                source_text=source_text,
                target_text=target_text,
                source_lang=source_lang,
                target_lang=target_lang,
                context=context,
                tone=tone,
                quality_score=quality_score,
                created_at=datetime.now()
            )
            
            self.memory_entries[entry_id] = entry
            
            # Add to vector database
            self.memory_collection.add(
                documents=[source_text],
                metadatas=[{
                    'entry_id': entry_id,
                    'source_lang': source_lang,
                    'target_lang': target_lang,
                    'context': context,
                    'tone': tone.value
                }],
                ids=[entry_id]
            )
            
            logger.info(f"Added translation memory entry: {entry_id}")
            
        except Exception as e:
            logger.error(f"Error adding memory entry: {e}")
    
    def search_matches(self, source_text: str, source_lang: str, target_lang: str,
                      similarity_threshold: float = 0.7) -> List[TranslationMemoryEntry]:
        """Search for similar translations in memory."""
        try:
            results = self.memory_collection.query(
                query_texts=[source_text],
                n_results=10,
                where={
                    "$and": [
                        {"source_lang": {"$eq": source_lang}},
                        {"target_lang": {"$eq": target_lang}}
                    ]
                }
            )
            
            matches = []
            if results['metadatas'] and results['metadatas'][0]:
                for metadata, distance in zip(results['metadatas'][0], results['distances'][0]):
                    similarity = 1 - distance
                    
                    if similarity >= similarity_threshold:
                        entry_id = metadata['entry_id']
                        if entry_id in self.memory_entries:
                            entry = self.memory_entries[entry_id]
                            entry.usage_count += 1
                            entry.last_used = datetime.now()
                            matches.append(entry)
            
            # Sort by similarity (highest first)
            return sorted(matches, key=lambda x: x.quality_score, reverse=True)
            
        except Exception as e:
            logger.error(f"Error searching memory: {e}")
            return []

class TranslationEngine:
    """Main translation engine with multiple backends."""
    
    def __init__(self, openai_api_key: str = None):
        self.google_translator = GoogleTranslator()
        
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.1,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        else:
            self.llm = None
        
        self.translation_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are a professional translator with deep cultural knowledge. Translate the given text
            while preserving meaning, tone, and cultural context.
            
            Guidelines:
            1. Maintain the original tone and style
            2. Adapt cultural references appropriately
            3. Preserve formality levels
            4. Ensure natural expression in target language
            5. Explain any cultural adaptations made
            
            Source Language: {source_lang}
            Target Language: {target_lang}
            Context: {context}
            Tone: {tone}
            Cultural Notes: {cultural_notes}
            """),
            ("human", """
            Text to translate: "{text}"
            
            Please provide:
            1. Primary translation
            2. Alternative translation (if applicable)
            3. Cultural adaptation notes
            4. Confidence level (1-10)
            
            Format your response as:
            PRIMARY: [translation]
            ALTERNATIVE: [alternative if different]
            CULTURAL_NOTES: [any cultural adaptations]
            CONFIDENCE: [1-10]
            """)
        ])
    
    def translate_with_google(self, text: str, source_lang: str, target_lang: str) -> Tuple[str, float]:
        """Translate using Google Translate."""
        try:
            result = self.google_translator.translate(text, src=source_lang, dest=target_lang)
            return result.text, 0.7  # Default confidence
        except Exception as e:
            logger.error(f"Google translation error: {e}")
            return text, 0.1
    
    def translate_with_openai(self, text: str, source_lang: str, target_lang: str,
                             context: str, tone: str, cultural_notes: str) -> Dict[str, Any]:
        """Translate using OpenAI with cultural context."""
        if not self.llm:
            return {'primary': text, 'alternative': '', 'cultural_notes': '', 'confidence': 0.1}
        
        try:
            response = self.llm.invoke(self.translation_prompt.format(
                text=text,
                source_lang=source_lang,
                target_lang=target_lang,
                context=context,
                tone=tone,
                cultural_notes=cultural_notes
            ))
            
            content = response.content
            
            # Parse response
            result = {
                'primary': text,
                'alternative': '',
                'cultural_notes': '',
                'confidence': 0.5
            }
            
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('PRIMARY:'):
                    result['primary'] = line.replace('PRIMARY:', '').strip()
                elif line.startswith('ALTERNATIVE:'):
                    result['alternative'] = line.replace('ALTERNATIVE:', '').strip()
                elif line.startswith('CULTURAL_NOTES:'):
                    result['cultural_notes'] = line.replace('CULTURAL_NOTES:', '').strip()
                elif line.startswith('CONFIDENCE:'):
                    try:
                        conf_str = line.replace('CONFIDENCE:', '').strip()
                        confidence = float(conf_str) / 10.0
                        result['confidence'] = min(max(confidence, 0.0), 1.0)
                    except:
                        pass
            
            return result
            
        except Exception as e:
            logger.error(f"OpenAI translation error: {e}")
            return {'primary': text, 'alternative': '', 'cultural_notes': '', 'confidence': 0.1}

class CulturalTranslator:
    """Main cultural translator system."""
    
    def __init__(self, openai_api_key: str = None):
        self.language_detector = LanguageDetector()
        self.tone_analyzer = ToneAnalyzer()
        self.cultural_analyzer = CulturalAnalyzer()
        self.translation_memory = TranslationMemory()
        self.translation_engine = TranslationEngine(openai_api_key)
        
        # Translation history
        self.translation_history = {}
    
    def translate(self, text: str, target_language: str, 
                 engine: TranslationEngine = TranslationEngine.HYBRID,
                 preserve_formatting: bool = True) -> TranslationResult:
        """Perform complete cultural translation."""
        start_time = datetime.now()
        
        try:
            # 1. Detect source language
            source_lang, lang_confidence = self.language_detector.detect_language(text)
            
            if not self.language_detector.is_supported(source_lang):
                logger.warning(f"Unsupported source language: {source_lang}")
            
            if not self.language_detector.is_supported(target_language):
                logger.warning(f"Unsupported target language: {target_language}")
            
            # 2. Analyze tone and style
            tone_analysis = self.tone_analyzer.analyze_tone(text, source_lang)
            
            # 3. Analyze cultural context
            cultural_analysis = self.cultural_analyzer.analyze_cultural_context(
                text, source_lang, target_language
            )
            
            # 4. Search translation memory
            memory_matches = self.translation_memory.search_matches(
                text, source_lang, target_language
            )
            
            # 5. Perform translation
            if memory_matches and len(memory_matches) > 0:
                # Use best memory match
                best_match = memory_matches[0]
                translated_text = best_match.target_text
                confidence = best_match.quality_score
                alternatives = []
                cultural_notes = ["Used translation memory match"]
                engine_used = TranslationEngine.CUSTOM
                
            elif engine == TranslationEngine.OPENAI or engine == TranslationEngine.HYBRID:
                # Use OpenAI with cultural context
                openai_result = self.translation_engine.translate_with_openai(
                    text, source_lang, target_language,
                    cultural_analysis.context_type.value,
                    tone_analysis.tone_type.value,
                    '; '.join(cultural_analysis.adaptation_suggestions)
                )
                
                translated_text = openai_result['primary']
                alternatives = [openai_result['alternative']] if openai_result['alternative'] else []
                cultural_notes = [openai_result['cultural_notes']] if openai_result['cultural_notes'] else []
                confidence = openai_result['confidence']
                engine_used = TranslationEngine.OPENAI
                
            else:
                # Use Google Translate
                translated_text, confidence = self.translation_engine.translate_with_google(
                    text, source_lang, target_language
                )
                alternatives = []
                cultural_notes = []
                engine_used = TranslationEngine.GOOGLE
            
            # 6. Calculate quality score
            quality_score = self._calculate_quality_score(
                text, translated_text, tone_analysis, cultural_analysis, confidence
            )
            
            # 7. Add to translation memory if quality is good
            if quality_score > 0.7:
                self.translation_memory.add_entry(
                    text, translated_text, source_lang, target_language,
                    cultural_analysis.context_type.value, tone_analysis.tone_type,
                    quality_score
                )
            
            # 8. Create result
            processing_time = (datetime.now() - start_time).total_seconds()
            
            result = TranslationResult(
                translation_id=str(uuid.uuid4()),
                source_text=text,
                translated_text=translated_text,
                source_language=source_lang,
                target_language=target_language,
                engine_used=engine_used,
                tone_analysis=tone_analysis,
                cultural_analysis=cultural_analysis,
                quality_score=quality_score,
                confidence_score=confidence,
                alternatives=alternatives,
                cultural_notes=cultural_notes + cultural_analysis.adaptation_suggestions,
                memory_matches=memory_matches,
                processing_time=processing_time
            )
            
            # Store in history
            self.translation_history[result.translation_id] = result
            
            return result
            
        except Exception as e:
            logger.error(f"Translation error: {e}")
            
            # Return minimal result with error
            return TranslationResult(
                translation_id=str(uuid.uuid4()),
                source_text=text,
                translated_text=f"Translation error: {str(e)}",
                source_language=source_lang if 'source_lang' in locals() else 'unknown',
                target_language=target_language,
                engine_used=TranslationEngine.GOOGLE,
                tone_analysis=ToneAnalysis(ToneType.CASUAL, 0.5, 0.0, 0.1, [], []),
                cultural_analysis=CulturalAnalysis(CulturalContext.SOCIAL, [], [], "", [], []),
                quality_score=0.0,
                confidence_score=0.0,
                processing_time=(datetime.now() - start_time).total_seconds()
            )
    
    def _calculate_quality_score(self, source_text: str, translated_text: str,
                               tone_analysis: ToneAnalysis, cultural_analysis: CulturalAnalysis,
                               base_confidence: float) -> float:
        """Calculate overall translation quality score."""
        quality_factors = []
        
        # Base confidence from translation engine
        quality_factors.append(base_confidence)
        
        # Text length factor (longer text generally more reliable)
        length_factor = min(len(source_text) / 100, 1.0)
        quality_factors.append(length_factor)
        
        # Tone analysis confidence
        quality_factors.append(tone_analysis.confidence)
        
        # Cultural analysis factor
        if cultural_analysis.sensitivity_warnings:
            quality_factors.append(0.7)  # Lower score for sensitive content
        else:
            quality_factors.append(0.9)
        
        # Translation memory factor
        if translated_text != source_text:  # Actually translated
            quality_factors.append(0.8)
        else:
            quality_factors.append(0.3)  # Likely failed translation
        
        return np.mean(quality_factors)

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="AI Cultural Translator",
        page_icon="🌍",
        layout="wide"
    )
    
    st.title("🌍 AI-Powered Translator with Cultural Context")
    st.markdown("Advanced translation with cultural sensitivity and context awareness")
    
    # Sidebar
    with st.sidebar:
        st.header("⚙️ Configuration")
        openai_api_key = st.text_input("OpenAI API Key (Optional)", type="password",
                                     help="For advanced cultural context translation")
        
        st.header("🔧 Translation Settings")
        engine_choice = st.selectbox("Translation Engine", [
            "hybrid", "openai", "google"
        ])
        
        preserve_formatting = st.checkbox("Preserve Formatting", value=True)
        show_alternatives = st.checkbox("Show Alternative Translations", value=True)
        cultural_adaptation = st.checkbox("Enable Cultural Adaptation", value=True)
    
    # Initialize translator
    if 'translator' not in st.session_state:
        with st.spinner("Initializing cultural translator..."):
            st.session_state['translator'] = CulturalTranslator(openai_api_key)
            st.success("Cultural translator ready!")
    
    translator = st.session_state['translator']
    
    # Main tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "🔤 Translation",
        "📊 Analysis Results",
        "💾 Translation Memory",
        "📈 Statistics"
    ])
    
    with tab1:
        st.header("🔤 Text Translation")
        
        # Language selection
        languages = {
            'en': 'English', 'es': 'Spanish', 'fr': 'French', 'de': 'German',
            'ja': 'Japanese', 'zh': 'Chinese', 'ar': 'Arabic', 'ru': 'Russian',
            'it': 'Italian', 'pt': 'Portuguese'
        }
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("📝 Source Text")
            
            # Auto-detect or manual selection
            detect_language = st.checkbox("Auto-detect language", value=True)
            
            if not detect_language:
                source_lang = st.selectbox("Source Language", 
                                         options=list(languages.keys()),
                                         format_func=lambda x: languages[x])
            
            # Text input
            source_text = st.text_area(
                "Enter text to translate:",
                height=300,
                placeholder="Type or paste your text here..."
            )
            
            # Quick example buttons
            st.write("**Quick Examples:**")
            example_col1, example_col2 = st.columns(2)
            
            with example_col1:
                if st.button("Business Email"):
                    st.session_state['example_text'] = """Dear colleagues,
                    
I hope this email finds you well. I wanted to follow up on our meeting yesterday regarding the quarterly results. The numbers look promising, and I believe we're on track to exceed our targets.

Please let me know if you have any questions or concerns.

Best regards,
John"""
            
            with example_col2:
                if st.button("Casual Message"):
                    st.session_state['example_text'] = """Hey! How's it going? I was thinking we could grab some coffee later and catch up. It's been way too long since we last hung out. Let me know if you're free around 3 PM!

Talk soon! 😊"""
            
            if 'example_text' in st.session_state:
                source_text = st.session_state['example_text']
                st.rerun()
        
        with col2:
            st.subheader("🎯 Translation")
            
            target_lang = st.selectbox("Target Language",
                                     options=list(languages.keys()),
                                     format_func=lambda x: languages[x],
                                     index=1)  # Default to Spanish
            
            # Translation button
            if st.button("🚀 Translate", type="primary", disabled=not source_text.strip()):
                if source_text.strip():
                    with st.spinner("Translating with cultural context..."):
                        
                        result = translator.translate(
                            text=source_text.strip(),
                            target_language=target_lang,
                            engine=TranslationEngine(engine_choice),
                            preserve_formatting=preserve_formatting
                        )
                        
                        st.session_state['current_result'] = result
                        st.success("Translation completed!")
        
        # Display translation result
        if 'current_result' in st.session_state:
            result = st.session_state['current_result']
            
            st.markdown("---")
            st.subheader("📄 Translation Result")
            
            # Main translation
            st.text_area(
                "Translated Text:",
                value=result.translated_text,
                height=200,
                disabled=True
            )
            
            # Quick metrics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Quality Score", f"{result.quality_score:.1%}")
            with col2:
                st.metric("Confidence", f"{result.confidence_score:.1%}")
            with col3:
                st.metric("Processing Time", f"{result.processing_time:.2f}s")
            with col4:
                st.metric("Engine Used", result.engine_used.value.title())
            
            # Alternative translations
            if show_alternatives and result.alternatives:
                st.subheader("🔄 Alternative Translations")
                for i, alt in enumerate(result.alternatives, 1):
                    if alt.strip():
                        st.text_area(f"Alternative {i}:", value=alt, disabled=True)
            
            # Cultural notes
            if result.cultural_notes:
                st.subheader("🌏 Cultural Adaptation Notes")
                for note in result.cultural_notes:
                    if note.strip():
                        st.info(f"💡 {note}")
    
    with tab2:
        st.header("📊 Detailed Analysis")
        
        if 'current_result' in st.session_state:
            result = st.session_state['current_result']
            
            # Language detection
            st.subheader("🔍 Language Detection")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Detected Language:** {result.source_language}")
                st.write(f"**Target Language:** {result.target_language}")
            
            with col2:
                lang_info = translator.language_detector.get_language_info(result.source_language)
                if lang_info:
                    st.write(f"**Native Name:** {lang_info.native_name}")
                    st.write(f"**RTL Script:** {'Yes' if lang_info.rtl else 'No'}")
            
            # Tone analysis
            st.subheader("🎭 Tone Analysis")
            tone = result.tone_analysis
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Detected Tone", tone.tone_type.value.title())
                st.metric("Formality Score", f"{tone.formality_score:.1%}")
            
            with col2:
                st.metric("Emotional Intensity", f"{tone.emotional_intensity:.1%}")
                st.metric("Analysis Confidence", f"{tone.confidence:.1%}")
            
            with col3:
                if tone.detected_emotions:
                    st.write("**Detected Emotions:**")
                    for emotion in tone.detected_emotions:
                        st.write(f"• {emotion.title()}")
            
            # Tone visualization
            tone_data = {
                'Aspect': ['Formality', 'Emotional Intensity', 'Confidence'],
                'Score': [tone.formality_score, tone.emotional_intensity, tone.confidence]
            }
            
            fig = px.bar(tone_data, x='Aspect', y='Score', 
                        title='Tone Analysis Scores',
                        color='Aspect')
            st.plotly_chart(fig, use_container_width=True)
            
            # Cultural analysis
            st.subheader("🌍 Cultural Context Analysis")
            cultural = result.cultural_analysis
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Context Type:** {cultural.context_type.value.title()}")
                st.write(f"**Formality Requirements:** {cultural.formality_requirements}")
                
                if cultural.idioms_detected:
                    st.write("**Idioms Detected:**")
                    for idiom in cultural.idioms_detected:
                        st.write(f"• {idiom}")
            
            with col2:
                if cultural.cultural_references:
                    st.write("**Cultural References:**")
                    for ref in cultural.cultural_references:
                        st.write(f"• {ref}")
                
                if cultural.sensitivity_warnings:
                    st.write("**⚠️ Sensitivity Warnings:**")
                    for warning in cultural.sensitivity_warnings:
                        st.warning(warning)
            
            # Adaptation suggestions
            if cultural.adaptation_suggestions:
                st.subheader("💡 Cultural Adaptation Suggestions")
                for suggestion in cultural.adaptation_suggestions:
                    st.info(f"💡 {suggestion}")
            
            # Translation memory matches
            if result.memory_matches:
                st.subheader("💾 Translation Memory Matches")
                
                for i, match in enumerate(result.memory_matches[:3], 1):
                    with st.expander(f"Match {i} - Quality: {match.quality_score:.1%}"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**Source:**")
                            st.write(match.source_text)
                        
                        with col2:
                            st.write("**Target:**")
                            st.write(match.target_text)
                        
                        st.write(f"**Context:** {match.context}")
                        st.write(f"**Tone:** {match.tone.value.title()}")
                        st.write(f"**Usage Count:** {match.usage_count}")
        else:
            st.info("No analysis results available. Please translate some text first.")
    
    with tab3:
        st.header("💾 Translation Memory Management")
        
        # Memory statistics
        memory_stats = {
            'Total Entries': len(translator.translation_memory.memory_entries),
            'Languages Covered': len(set(
                entry.source_lang + '-' + entry.target_lang 
                for entry in translator.translation_memory.memory_entries.values()
            )),
            'Avg Quality Score': np.mean([
                entry.quality_score 
                for entry in translator.translation_memory.memory_entries.values()
            ]) if translator.translation_memory.memory_entries else 0
        }
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Entries", memory_stats['Total Entries'])
        with col2:
            st.metric("Language Pairs", memory_stats['Languages Covered'])
        with col3:
            st.metric("Avg Quality", f"{memory_stats['Avg Quality Score']:.1%}")
        
        # Add new memory entry
        st.subheader("➕ Add Translation Memory Entry")
        
        with st.form("add_memory"):
            col1, col2 = st.columns(2)
            
            with col1:
                mem_source = st.text_area("Source Text")
                mem_source_lang = st.selectbox("Source Language", 
                                             options=list(languages.keys()),
                                             format_func=lambda x: languages[x])
                mem_context = st.text_input("Context")
            
            with col2:
                mem_target = st.text_area("Target Text")
                mem_target_lang = st.selectbox("Target Language",
                                             options=list(languages.keys()),
                                             format_func=lambda x: languages[x],
                                             index=1)
                mem_tone = st.selectbox("Tone", [tone.value for tone in ToneType])
            
            if st.form_submit_button("Add to Memory"):
                if mem_source and mem_target:
                    translator.translation_memory.add_entry(
                        mem_source, mem_target, mem_source_lang, mem_target_lang,
                        mem_context or "general", ToneType(mem_tone)
                    )
                    st.success("Added to translation memory!")
                    st.rerun()
                else:
                    st.error("Please provide both source and target text.")
        
        # Browse memory entries
        st.subheader("📖 Browse Memory Entries")
        
        if translator.translation_memory.memory_entries:
            memory_df = pd.DataFrame([
                {
                    'Source': entry.source_text[:50] + "..." if len(entry.source_text) > 50 else entry.source_text,
                    'Target': entry.target_text[:50] + "..." if len(entry.target_text) > 50 else entry.target_text,
                    'Lang Pair': f"{entry.source_lang} → {entry.target_lang}",
                    'Context': entry.context,
                    'Quality': f"{entry.quality_score:.1%}",
                    'Usage': entry.usage_count
                }
                for entry in translator.translation_memory.memory_entries.values()
            ])
            
            st.dataframe(memory_df, use_container_width=True)
        else:
            st.info("No translation memory entries available.")
    
    with tab4:
        st.header("📈 Translation Statistics")
        
        # Usage statistics
        if translator.translation_history:
            st.subheader("📊 Usage Overview")
            
            # Create statistics
            results = list(translator.translation_history.values())
            
            # Language usage
            lang_pairs = {}
            for result in results:
                pair = f"{result.source_language} → {result.target_language}"
                lang_pairs[pair] = lang_pairs.get(pair, 0) + 1
            
            if lang_pairs:
                fig = px.bar(
                    x=list(lang_pairs.keys()),
                    y=list(lang_pairs.values()),
                    title="Language Pair Usage",
                    labels={'x': 'Language Pair', 'y': 'Count'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Quality distribution
            quality_scores = [result.quality_score for result in results]
            
            if quality_scores:
                fig = px.histogram(
                    x=quality_scores,
                    title="Translation Quality Distribution",
                    labels={'x': 'Quality Score', 'y': 'Count'},
                    nbins=20
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Engine usage
            engine_usage = {}
            for result in results:
                engine = result.engine_used.value
                engine_usage[engine] = engine_usage.get(engine, 0) + 1
            
            if engine_usage:
                fig = px.pie(
                    values=list(engine_usage.values()),
                    names=list(engine_usage.keys()),
                    title="Translation Engine Usage"
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Performance metrics
            st.subheader("⚡ Performance Metrics")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                avg_quality = np.mean(quality_scores)
                st.metric("Avg Quality", f"{avg_quality:.1%}")
            
            with col2:
                avg_confidence = np.mean([r.confidence_score for r in results])
                st.metric("Avg Confidence", f"{avg_confidence:.1%}")
            
            with col3:
                avg_time = np.mean([r.processing_time for r in results])
                st.metric("Avg Processing Time", f"{avg_time:.2f}s")
            
            with col4:
                st.metric("Total Translations", len(results))
            
            # Recent activity
            st.subheader("🕒 Recent Translations")
            
            recent_df = pd.DataFrame([
                {
                    'Timestamp': result.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'Source': result.source_text[:30] + "..." if len(result.source_text) > 30 else result.source_text,
                    'Language': f"{result.source_language} → {result.target_language}",
                    'Quality': f"{result.quality_score:.1%}",
                    'Engine': result.engine_used.value.title()
                }
                for result in sorted(results, key=lambda x: x.timestamp, reverse=True)[:10]
            ])
            
            st.dataframe(recent_df, use_container_width=True)
        
        else:
            st.info("No translation statistics available. Perform some translations to see analytics.")

if __name__ == "__main__":
    main()
````

## Project Summary

The AI-Powered Translator with Cultural Context represents a sophisticated translation system that transcends traditional word-for-word conversion by incorporating deep cultural understanding, tone preservation, and contextual adaptation to deliver natural, culturally-appropriate translations.

### Key Value Propositions:
- **Cultural Context Intelligence**: Advanced analysis of cultural references, idioms, and social contexts with appropriate adaptation for target cultures
- **Tone and Style Preservation**: Sophisticated detection and maintenance of emotional tone, formality levels, and communicative intent across languages
- **Translation Memory System**: Intelligent storage and retrieval of previous translations ensuring consistency and efficiency with fuzzy matching capabilities
- **Multi-Engine Hybrid Approach**: Combines Google Translate, OpenAI LLMs, and custom algorithms for optimal translation quality
- **Quality Assurance Integration**: Comprehensive evaluation through confidence scoring, back-translation verification, and human feedback loops

### Technical Highlights:
- Advanced tone analysis using sentiment analysis models and linguistic pattern recognition with formality scoring
- ChromaDB-powered translation memory with semantic similarity matching for consistent terminology management
- LangChain-enhanced cultural adaptation with structured prompting for context-aware translations
- Multi-modal quality assessment combining linguistic accuracy, cultural appropriateness, and style consistency
- Real-time language detection with confidence estimation and comprehensive language support
- Interactive Streamlit interface providing translation workflow, memory management, and analytics dashboards

This system demonstrates how AI can bridge language barriers while preserving cultural nuances, making cross-cultural communication more natural and effective for business, education, and social interactions in our interconnected global society.