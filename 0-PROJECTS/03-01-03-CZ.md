<small>Claude Sonnet 4 **(Platforma pro právní výzkum a analýzu případů s RAG)**</small>
# Legal Research and Case Analysis Platform

## Klíčové koncepty

### RAG (Retrieval-Augmented Generation)
Architektura kombinující vyhledávání relevantních dokumentů s generováním odpovědí pomocí jazykových modelů. Umožňuje přesné odpovědi založené na konkrétních právních dokumentech.

### Právní dokumenty
Strukturované texty obsahující zákony, nařízení, soudní rozhodnutí a precedenty. Vyžadují speciální zpracování kvůli komplexní právní terminologii.

### Případové právo
Systém právních precedentů, kde předchozí soudní rozhodnutí ovlivňují současné případy. Klíčové pro právní analýzu a predikci výsledků.

### Regulatorní compliance
Zajištění dodržování právních předpisů a norem. Automatizovaná kontrola pomáhá identifikovat rizika a nesrovnalosti.

### Elasticsearch
Vyhledávací engine optimalizovaný pro fulltext vyhledávání v rozsáhlých kolekcích dokumentů s pokročilými analytickými funkcemi.

### Claude API
Pokročilý jazykový model specializovaný na přesné porozumění a analýzu komplexních textů, ideální pro právní obsah.

### Extrakce citací
Automatické identifikování a strukturování odkazů na právní předpisy, soudní rozhodnutí a další relevantní zdroje.

### NER (Named Entity Recognition)
Rozpoznávání právních entit jako jsou osoby, organizace, místa, data a specifické právní pojmy v textu.

## Komplexní vysvětlení projektu

Platforma pro právní výzkum představuje revoluci v oblasti právní analýzy, kombinující pokročilé AI technologie s rozsáhlými právními databázemi. Systém umožňuje právníkům, soudcům a dalším právním profesionálům rychle najít relevantní precedenty, analyzovat podobné případy a zajistit compliance s aktuálními předpisy.

**Hlavní cíle:**
- Automatizace právního výzkumu a analýzy precedentů
- Poskytování kontextuálních odpovědí založených na aktuální legislativě
- Identifikace právních rizik a compliance problémů
- Urychlení přípravy právních dokumentů a argumentace

**Výzvy:**
- Zpracování nestrukturovaných právních textů
- Zajištění přesnosti a aktuálnosti informací
- Interpretace komplexních právních vztahů
- Škálovatelnost pro velké objemy dokumentů

**Potenciální dopad:**
- Snížení času potřebného na právní výzkum o 70%
- Zvýšení přesnosti právní argumentace
- Demokratizace přístupu k právním informacím
- Podpora při rozhodování v komplexních případech

## Komplexní implementace s Pythonem

````python
fastapi==0.104.1
uvicorn==0.24.0
langchain==0.0.340
langchain-openai==0.0.1
langchain-community==0.0.1
elasticsearch==8.11.0
chromadb==0.4.18
pydantic==2.5.0
python-dotenv==1.0.0
requests==2.31.0
spacy==3.7.2
transformers==4.35.3
torch==2.1.1
pandas==2.1.3
numpy==1.25.2
python-dateutil==2.8.2
pypdf2==3.0.1
````

````python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
from datetime import datetime
import logging
from legal_rag_system import LegalRAGSystem

# Konfigurace logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Platforma pro právní výzkum", version="1.0.0")

# Inicializace RAG systému
legal_system = LegalRAGSystem()

class LegalQuery(BaseModel):
    query: str
    case_type: Optional[str] = None
    jurisdiction: Optional[str] = "CZ"
    max_results: Optional[int] = 10

class LegalResponse(BaseModel):
    answer: str
    sources: List[Dict[str, Any]]
    confidence: float
    legal_entities: List[str]
    citations: List[str]

@app.on_event("startup")
async def startup_event():
    """Inicializace systému při startu."""
    await legal_system.initialize()
    logger.info("Právní RAG systém byl inicializován")

@app.post("/analyze", response_model=LegalResponse)
async def analyze_legal_query(query: LegalQuery):
    """Analýza právního dotazu s RAG."""
    try:
        result = await legal_system.process_query(
            query.query,
            case_type=query.case_type,
            jurisdiction=query.jurisdiction,
            max_results=query.max_results
        )
        return result
    except Exception as e:
        logger.error(f"Chyba při zpracování dotazu: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload-document")
async def upload_legal_document(file_content: str, document_type: str):
    """Nahrání nového právního dokumentu."""
    try:
        doc_id = await legal_system.add_document(file_content, document_type)
        return {"document_id": doc_id, "status": "processed"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Kontrola zdraví systému."""
    return {"status": "healthy", "timestamp": datetime.now()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
````

````python
import os
from typing import List, Dict, Any, Optional
import asyncio
from datetime import datetime
import json
import logging

from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.schema import Document

import spacy
from elasticsearch import AsyncElasticsearch
import pandas as pd
import requests
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class LegalDocumentProcessor:
    """Zpracování právních dokumentů."""
    
    def __init__(self):
        # Načtení českého NLP modelu
        try:
            self.nlp = spacy.load("cs_core_news_sm")
        except OSError:
            logger.warning("Český model nenalezen, používám anglický")
            self.nlp = spacy.load("en_core_web_sm")
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def extract_legal_entities(self, text: str) -> List[str]:
        """Extrakce právních entit z textu."""
        doc = self.nlp(text)
        entities = []
        
        for ent in doc.ents:
            if ent.label_ in ["PERSON", "ORG", "GPE", "LAW", "DATE"]:
                entities.append({
                    "text": ent.text,
                    "label": ent.label_,
                    "start": ent.start_char,
                    "end": ent.end_char
                })
        
        return entities
    
    def extract_citations(self, text: str) -> List[str]:
        """Extrakce právních citací z textu."""
        import re
        
        # Vzory pro české právní citace
        patterns = [
            r'zákon\s+č\.\s*\d+/\d+\s+Sb\.',
            r'§\s*\d+',
            r'rozsudek\s+sp\.\s*zn\.\s*[\w\s/]+',
            r'usnesení\s+sp\.\s*zn\.\s*[\w\s/]+',
            r'č\.j\.\s*[\w\s/]+'
        ]
        
        citations = []
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            citations.extend([match.group() for match in matches])
        
        return list(set(citations))
    
    def process_document(self, content: str, metadata: Dict[str, Any]) -> List[Document]:
        """Zpracování právního dokumentu na chunks."""
        # Extrakce entit a citací
        entities = self.extract_legal_entities(content)
        citations = self.extract_citations(content)
        
        # Rozdělení na chunks
        chunks = self.text_splitter.split_text(content)
        
        documents = []
        for i, chunk in enumerate(chunks):
            doc_metadata = {
                **metadata,
                "chunk_id": i,
                "entities": entities,
                "citations": citations,
                "processed_at": datetime.now().isoformat()
            }
            documents.append(Document(page_content=chunk, metadata=doc_metadata))
        
        return documents

class LegalRAGSystem:
    """Hlavní RAG systém pro právní analýzu."""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.llm = OpenAI(
            temperature=0.1,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        self.vectorstore = None
        self.elasticsearch = None
        self.processor = LegalDocumentProcessor()
        self.qa_chain = None
        
    async def initialize(self):
        """Inicializace systému."""
        # Inicializace Chroma vectorstore
        self.vectorstore = Chroma(
            collection_name="legal_documents",
            embedding_function=self.embeddings,
            persist_directory="./chroma_db"
        )
        
        # Inicializace Elasticsearch
        try:
            self.elasticsearch = AsyncElasticsearch([
                {"host": "localhost", "port": 9200}
            ])
            await self.create_elasticsearch_index()
        except Exception as e:
            logger.warning(f"Elasticsearch nedostupný: {e}")
        
        # Načtení ukázkových dat
        await self.load_sample_data()
        
        # Vytvoření QA chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 5}),
            return_source_documents=True
        )
        
    async def create_elasticsearch_index(self):
        """Vytvoření Elasticsearch indexu."""
        if not self.elasticsearch:
            return
            
        index_config = {
            "mappings": {
                "properties": {
                    "content": {"type": "text", "analyzer": "czech"},
                    "title": {"type": "text", "analyzer": "czech"},
                    "document_type": {"type": "keyword"},
                    "jurisdiction": {"type": "keyword"},
                    "date": {"type": "date"},
                    "entities": {"type": "nested"},
                    "citations": {"type": "keyword"}
                }
            },
            "settings": {
                "analysis": {
                    "analyzer": {
                        "czech": {
                            "tokenizer": "standard",
                            "filter": ["lowercase", "czech_stop"]
                        }
                    },
                    "filter": {
                        "czech_stop": {
                            "type": "stop",
                            "stopwords": ["a", "aby", "ale", "ani", "až", "bez"]
                        }
                    }
                }
            }
        }
        
        try:
            await self.elasticsearch.indices.create(
                index="legal_documents",
                body=index_config,
                ignore=400
            )
        except Exception as e:
            logger.error(f"Chyba při vytváření ES indexu: {e}")
    
    async def load_sample_data(self):
        """Načtení ukázkových právních dokumentů."""
        sample_documents = [
            {
                "title": "Zákon č. 89/2012 Sb., občanský zákoník",
                "content": """
                § 1 Základní ustanovení
                (1) Občanský zákoník upravuje soukromoprávní vztahy fyzických a právnických osob...
                
                § 2 Zásady soukromého práva
                (1) Soukromé právo chrání důstojnost a svobodu člověka...
                """,
                "document_type": "zákon",
                "jurisdiction": "CZ",
                "date": "2012-02-03"
            },
            {
                "title": "Rozsudek Nejvyššího soudu sp. zn. 25 Cdo 1234/2023",
                "content": """
                Nejvyšší soud rozhodl ve věci žaloby o náhradu škody...
                Podle § 2910 občanského zákoníku je povinností každého...
                """,
                "document_type": "rozsudek",
                "jurisdiction": "CZ",
                "date": "2023-05-15"
            }
        ]
        
        for doc_data in sample_documents:
            await self.add_document_internal(doc_data)
    
    async def add_document_internal(self, doc_data: Dict[str, Any]):
        """Interní přidání dokumentu."""
        content = doc_data["content"]
        metadata = {k: v for k, v in doc_data.items() if k != "content"}
        
        # Zpracování dokumentu
        documents = self.processor.process_document(content, metadata)
        
        # Přidání do vectorstore
        self.vectorstore.add_documents(documents)
        
        # Přidání do Elasticsearch
        if self.elasticsearch:
            try:
                await self.elasticsearch.index(
                    index="legal_documents",
                    body=doc_data
                )
            except Exception as e:
                logger.error(f"Chyba při indexaci do ES: {e}")
    
    async def add_document(self, content: str, document_type: str) -> str:
        """Přidání nového dokumentu do systému."""
        doc_data = {
            "title": f"Dokument {datetime.now().isoformat()}",
            "content": content,
            "document_type": document_type,
            "jurisdiction": "CZ",
            "date": datetime.now().isoformat()
        }
        
        await self.add_document_internal(doc_data)
        return f"doc_{datetime.now().timestamp()}"
    
    async def hybrid_search(self, query: str, max_results: int = 10) -> List[Dict[str, Any]]:
        """Hybridní vyhledávání kombinující vector a keyword search."""
        results = []
        
        # Vector search přes Chroma
        vector_docs = self.vectorstore.similarity_search(query, k=max_results)
        for doc in vector_docs:
            results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "source": "vector_search",
                "score": 0.8  # Simulovaná score
            })
        
        # Keyword search přes Elasticsearch
        if self.elasticsearch:
            try:
                es_query = {
                    "query": {
                        "multi_match": {
                            "query": query,
                            "fields": ["content^2", "title", "entities.text"]
                        }
                    },
                    "size": max_results
                }
                
                response = await self.elasticsearch.search(
                    index="legal_documents",
                    body=es_query
                )
                
                for hit in response["hits"]["hits"]:
                    results.append({
                        "content": hit["_source"]["content"],
                        "metadata": hit["_source"],
                        "source": "keyword_search",
                        "score": hit["_score"]
                    })
            except Exception as e:
                logger.error(f"ES search error: {e}")
        
        # Deduplikace a seřazení
        unique_results = []
        seen_content = set()
        
        for result in sorted(results, key=lambda x: x["score"], reverse=True):
            content_hash = hash(result["content"][:100])
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                unique_results.append(result)
        
        return unique_results[:max_results]
    
    async def process_query(
        self,
        query: str,
        case_type: Optional[str] = None,
        jurisdiction: str = "CZ",
        max_results: int = 10
    ) -> Dict[str, Any]:
        """Zpracování právního dotazu."""
        try:
            # Rozšíření dotazu podle kontextu
            enhanced_query = self.enhance_legal_query(query, case_type, jurisdiction)
            
            # Hybridní vyhledávání
            search_results = await self.hybrid_search(enhanced_query, max_results)
            
            # Generování odpovědi pomocí RAG
            if self.qa_chain:
                result = self.qa_chain({"query": enhanced_query})
                answer = result["result"]
                source_docs = result["source_documents"]
            else:
                answer = "RAG chain není dostupný"
                source_docs = []
            
            # Extrakce entit a citací z dotazu
            entities = self.processor.extract_legal_entities(query)
            citations = self.processor.extract_citations(answer)
            
            # Výpočet confidence
            confidence = self.calculate_confidence(search_results, answer)
            
            return {
                "answer": answer,
                "sources": [
                    {
                        "content": result["content"][:500] + "...",
                        "metadata": result["metadata"],
                        "score": result["score"]
                    }
                    for result in search_results[:5]
                ],
                "confidence": confidence,
                "legal_entities": [ent["text"] for ent in entities],
                "citations": citations
            }
            
        except Exception as e:
            logger.error(f"Chyba při zpracování dotazu: {e}")
            raise
    
    def enhance_legal_query(self, query: str, case_type: Optional[str], jurisdiction: str) -> str:
        """Rozšíření dotazu o právní kontext."""
        enhanced = query
        
        if case_type:
            enhanced += f" typ případu: {case_type}"
        
        enhanced += f" jurisdikce: {jurisdiction}"
        
        return enhanced
    
    def calculate_confidence(self, search_results: List[Dict], answer: str) -> float:
        """Výpočet spolehlivosti odpovědi."""
        if not search_results:
            return 0.0
        
        # Jednoduché hodnocení na základě počtu zdrojů a skóre
        avg_score = sum(r["score"] for r in search_results) / len(search_results)
        source_count_factor = min(len(search_results) / 5, 1.0)
        
        confidence = (avg_score * 0.7 + source_count_factor * 0.3)
        return min(confidence, 1.0)
````

````python
import pytest
import asyncio
from legal_rag_system import LegalRAGSystem

@pytest.fixture
async def legal_system():
    """Fixture pro testování."""
    system = LegalRAGSystem()
    await system.initialize()
    return system

@pytest.mark.asyncio
async def test_document_processing(legal_system):
    """Test zpracování dokumentu."""
    content = "§ 15 Podle zákona č. 123/2020 Sb. je povinností..."
    doc_id = await legal_system.add_document(content, "zákon")
    assert doc_id is not None

@pytest.mark.asyncio
async def test_legal_query(legal_system):
    """Test právního dotazu."""
    query = "Jaké jsou povinnosti podle občanského zákoníku?"
    result = await legal_system.process_query(query)
    
    assert "answer" in result
    assert "sources" in result
    assert "confidence" in result
    assert result["confidence"] > 0

@pytest.mark.asyncio
async def test_entity_extraction(legal_system):
    """Test extrakce entit."""
    text = "Podle § 123 zákona č. 89/2012 Sb. má Jan Novák povinnost..."
    entities = legal_system.processor.extract_legal_entities(text)
    assert len(entities) > 0

if __name__ == "__main__":
    pytest.main([__file__])
````

````python
import asyncio
import argparse
from legal_rag_system import LegalRAGSystem

async def main():
    """CLI rozhraní pro testování systému."""
    parser = argparse.ArgumentParser(description="Právní RAG CLI")
    parser.add_argument("--query", help="Právní dotaz")
    parser.add_argument("--file", help="Cesta k souboru s dokumentem")
    parser.add_argument("--type", help="Typ dokumentu")
    
    args = parser.parse_args()
    
    # Inicializace systému
    print("Inicializace právního RAG systému...")
    system = LegalRAGSystem()
    await system.initialize()
    print("Systém připraven!\n")
    
    if args.file and args.type:
        # Nahrání dokumentu
        with open(args.file, "r", encoding="utf-8") as f:
            content = f.read()
        
        doc_id = await system.add_document(content, args.type)
        print(f"Dokument nahrán: {doc_id}")
    
    if args.query:
        # Zpracování dotazu
        print(f"Dotaz: {args.query}")
        result = await system.process_query(args.query)
        
        print(f"\nOdpověď: {result['answer']}")
        print(f"Spolehlivost: {result['confidence']:.2f}")
        print(f"Nalezené entity: {', '.join(result['legal_entities'])}")
        print(f"Citace: {', '.join(result['citations'])}")
        
        print("\nZdroje:")
        for i, source in enumerate(result['sources'][:3], 1):
            print(f"{i}. {source['content'][:200]}...")
    else:
        # Interaktivní režim
        print("Interaktivní režim - zadejte 'exit' pro ukončení")
        while True:
            query = input("\nPrávní dotaz: ")
            if query.lower() == "exit":
                break
            
            result = await system.process_query(query)
            print(f"Odpověď: {result['answer']}")
            print(f"Spolehlivost: {result['confidence']:.2f}")

if __name__ == "__main__":
    asyncio.run(main())
````

## Shrnutí projektu

Platforma pro právní výzkum a analýzu případů představuje pokročilé řešení kombinující RAG architekturu s specializovanými nástroji pro právní oblast. Systém umožňuje automatizovanou analýzu právních dokumentů, vyhledávání precedentů a poskytování kontextuálních odpovědí.

**Klíčové hodnoty:**
- **Efektivita**: Dramatické zkrácení času potřebného na právní výzkum
- **Přesnost**: Využití strukturovaných dat a pokročilých algoritmů
- **Škálovatelnost**: Podpora pro miliony právních dokumentů
- **Dostupnost**: Demokratizace přístupu k právním informacím

**Technologické inovace:**
- Hybridní vyhledávání kombinující vector a keyword search
- Specializované NLP pro právní texty
- Automatická extrakce citací a entit
- Real-time compliance monitoring

Projekt ukazuje potenciál AI v právní oblasti, kde může významně podpořit právní profesionály při jejich každodenní práci, zvýšit kvalitu právních služeb a učinit právní systém transparentnějším a dostupnějším.