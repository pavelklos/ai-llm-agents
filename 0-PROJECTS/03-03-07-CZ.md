<small>Claude Sonnet 4 **(Multilingvní Zpravodajský Průzkumník s RAG)**</small>
# Multilingual News Explorer

## Klíčové Koncepty

### RAG (Retrieval-Augmented Generation)
RAG architektura kombinuje vyhledávání relevantních informací z rozsáhlé databáze s generováním odpovědí pomocí jazykových modelů. Umožňuje poskytovat aktuální a fakticky přesné informace založené na konkrétních zdrojích.

### News API
Rozhraní pro přístup k aktuálním zpravodajským článkům z tisíců zdrojů po celém světě. Poskytuje strukturovaný přístup k novinkám s metadaty jako jsou datum, zdroj, kategorie a jazyk.

### Multilingvní Embeddings
Vektorové reprezentace textu, které zachycují sémantický význam napříč různými jazyky. Umožňují porovnávat a vyhledávat podobný obsah bez ohledu na jazyk původního textu.

### Milvus
Vysoce výkonná open-source vektorová databáze optimalizovaná pro ukládání a vyhledávání miliard vektorů. Podporuje distribuované nasazení a je ideální pro real-time aplikace.

### GPT-4 Turbo
Nejnovější verze OpenAI modelu s vylepšenou rychlostí, nižšími náklady a schopností zpracovávat dlouhé kontexty. Exceluje v analýze a sumarizaci komplexního obsahu.

## Komplexní Vysvětlení Projektu

### Popis a Cíle
Multilingvní zpravodajský průzkumník představuje pokročilý systém pro analýzu globálních zpráv napříč jazykovými bariérami. Hlavním cílem je poskytovat uživatelům komplexní přehled zpravodajství s automatickou detekcí předpojatosti a inteligentní sumarizací.

### Výzvy a Řešení
- **Jazyková diverzita**: Multilingvní embeddings umožňují jednotné zpracování různých jazyků
- **Objektivita**: AI analýza detekuje a upozorňuje na možnou předpojatost
- **Škálovatelnost**: Milvus zajišťuje rychlé vyhledávání v milionech článků
- **Aktuálnost**: Real-time integrace s News API pro nejnovější informace

### Technologické Inovace
Systém využívá nejmodernější NLP technologie pro cross-lingvální porozumění, automatickou detekci bias a inteligentní clustering podobných zpráv napříč různými zdroji.

### Dopad a Potenciál
Projekt může revolucionizovat způsob, jakým lidé konzumují zprávy, podporuje mediální gramotnost a pomáhá bojovat proti dezinformacím prostřednictvím transparentní analýzy zdrojů.

## Komplexní Implementace v Pythonu

### Instalace závislostí

````python
# requirements.txt
langchain==0.1.20
openai==1.12.0
pymilvus==2.3.4
sentence-transformers==2.2.2
newsapi-python==0.2.7
streamlit==1.31.0
pandas==2.1.4
numpy==1.24.3
requests==2.31.0
python-dotenv==1.0.0
feedparser==6.0.10
beautifulsoup4==4.12.2
langdetect==1.0.9
plotly==5.17.0
wordcloud==1.9.2
textblob==0.17.1
transformers==4.36.2
torch==2.1.2
````

### Hlavní implementace

````python
import os
import logging
import asyncio
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import hashlib
from concurrent.futures import ThreadPoolExecutor

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt

from newsapi import NewsApiClient
from sentence_transformers import SentenceTransformer
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langdetect import detect
from textblob import TextBlob
import requests
from bs4 import BeautifulSoup

# Konfigurace logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class NewsArticle:
    """Reprezentace zpravodajského článku"""
    id: str
    title: str
    content: str
    source: str
    author: Optional[str]
    published_at: datetime
    url: str
    language: str
    category: Optional[str]
    country: Optional[str]
    embedding: Optional[List[float]] = None
    bias_score: Optional[float] = None
    sentiment_score: Optional[float] = None

class MultilingualEmbeddings:
    """Správa multilingvních embeddingů"""
    
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"):
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()
        logger.info(f"Načten multilingvní model: {model_name}, dimenze: {self.dimension}")
    
    def encode_texts(self, texts: List[str]) -> List[List[float]]:
        """Zakóduje texty do vektorové reprezentace"""
        try:
            embeddings = self.model.encode(texts, convert_to_tensor=False)
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"Chyba při kódování textů: {e}")
            raise

class MilvusVectorStore:
    """Správa Milvus vektorové databáze"""
    
    def __init__(self, collection_name: str = "news_articles", 
                 host: str = "localhost", port: str = "19530"):
        self.collection_name = collection_name
        self.host = host
        self.port = port
        self.collection = None
        self._connect()
        self._setup_collection()
    
    def _connect(self):
        """Připojení k Milvus databázi"""
        try:
            connections.connect("default", host=self.host, port=self.port)
            logger.info(f"Připojeno k Milvus na {self.host}:{self.port}")
        except Exception as e:
            logger.error(f"Chyba při připojování k Milvus: {e}")
            raise
    
    def _setup_collection(self):
        """Vytvoří kolekci pokud neexistuje"""
        try:
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                logger.info(f"Načtena existující kolekce: {self.collection_name}")
            else:
                # Definice schématu
                fields = [
                    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=1000),
                    FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=10000),
                    FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=200),
                    FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=200),
                    FieldSchema(name="published_at", dtype=DataType.VARCHAR, max_length=50),
                    FieldSchema(name="url", dtype=DataType.VARCHAR, max_length=500),
                    FieldSchema(name="language", dtype=DataType.VARCHAR, max_length=10),
                    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50),
                    FieldSchema(name="country", dtype=DataType.VARCHAR, max_length=10),
                    FieldSchema(name="bias_score", dtype=DataType.FLOAT),
                    FieldSchema(name="sentiment_score", dtype=DataType.FLOAT),
                    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
                ]
                
                schema = CollectionSchema(fields, description="Zpravodajské články s embeddings")
                self.collection = Collection(self.collection_name, schema)
                
                # Vytvoření indexu
                index_params = {
                    "metric_type": "COSINE",
                    "index_type": "IVF_FLAT",
                    "params": {"nlist": 1024}
                }
                self.collection.create_index("embedding", index_params)
                logger.info(f"Vytvořena nová kolekce: {self.collection_name}")
        except Exception as e:
            logger.error(f"Chyba při vytváření kolekce: {e}")
            raise
    
    def insert_articles(self, articles: List[NewsArticle]):
        """Vloží články do databáze"""
        try:
            data = []
            for article in articles:
                if article.embedding:
                    data.append([
                        article.id,
                        article.title,
                        article.content[:9999],  # Omezení délky
                        article.source,
                        article.author or "",
                        article.published_at.isoformat(),
                        article.url,
                        article.language,
                        article.category or "",
                        article.country or "",
                        article.bias_score or 0.0,
                        article.sentiment_score or 0.0,
                        article.embedding
                    ])
            
            if data:
                # Transpozice dat pro Milvus formát
                transposed_data = list(map(list, zip(*data)))
                self.collection.insert(transposed_data)
                self.collection.flush()
                logger.info(f"Vloženo {len(data)} článků do databáze")
        except Exception as e:
            logger.error(f"Chyba při vkládání článků: {e}")
            raise
    
    def search_similar(self, query_vector: List[float], top_k: int = 10, 
                      filters: Optional[Dict] = None) -> List[Dict]:
        """Vyhledá podobné články"""
        try:
            self.collection.load()
            
            search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
            
            results = self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param=search_params,
                limit=top_k,
                output_fields=["id", "title", "content", "source", "published_at", 
                             "language", "bias_score", "sentiment_score", "url"]
            )
            
            articles = []
            for result in results[0]:
                article_data = {
                    "id": result.entity.get("id"),
                    "title": result.entity.get("title"),
                    "content": result.entity.get("content"),
                    "source": result.entity.get("source"),
                    "published_at": result.entity.get("published_at"),
                    "language": result.entity.get("language"),
                    "bias_score": result.entity.get("bias_score"),
                    "sentiment_score": result.entity.get("sentiment_score"),
                    "url": result.entity.get("url"),
                    "similarity_score": result.distance
                }
                articles.append(article_data)
            
            return articles
        except Exception as e:
            logger.error(f"Chyba při vyhledávání: {e}")
            return []

class NewsDataCollector:
    """Sběr zpravodajských dat"""
    
    def __init__(self, news_api_key: str):
        self.news_api = NewsApiClient(api_key=news_api_key)
        self.session = requests.Session()
    
    def fetch_top_headlines(self, language: str = "en", country: str = None, 
                          category: str = None, page_size: int = 100) -> List[Dict]:
        """Načte hlavní zprávy"""
        try:
            response = self.news_api.get_top_headlines(
                language=language,
                country=country,
                category=category,
                page_size=page_size
            )
            return response.get("articles", [])
        except Exception as e:
            logger.error(f"Chyba při načítání zpráv: {e}")
            return []
    
    def fetch_everything(self, query: str, language: str = None, 
                        from_date: datetime = None, page_size: int = 100) -> List[Dict]:
        """Vyhledá články podle dotazu"""
        try:
            response = self.news_api.get_everything(
                q=query,
                language=language,
                from_param=from_date.isoformat() if from_date else None,
                page_size=page_size,
                sort_by="publishedAt"
            )
            return response.get("articles", [])
        except Exception as e:
            logger.error(f"Chyba při vyhledávání článků: {e}")
            return []
    
    def extract_full_content(self, url: str) -> Optional[str]:
        """Extrahuje plný obsah článku z URL"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Odstranění nežádoucích elementů
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                tag.decompose()
            
            # Hledání hlavního obsahu
            content_selectors = [
                'article', '.article-content', '.post-content', 
                '.entry-content', '[role="main"]', 'main'
            ]
            
            content = ""
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content = ' '.join([elem.get_text(strip=True) for elem in elements])
                    break
            
            if not content:
                # Fallback na všechny odstavce
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text(strip=True) for p in paragraphs])
            
            return content[:5000] if content else None  # Omezení délky
            
        except Exception as e:
            logger.warning(f"Nepodařilo se extrahovat obsah z {url}: {e}")
            return None

class BiasDetector:
    """Detekce předpojatosti v textu"""
    
    def __init__(self, openai_api_key: str):
        self.llm = ChatOpenAI(
            api_key=openai_api_key,
            model="gpt-4-turbo-preview",
            temperature=0.1
        )
    
    def analyze_bias(self, text: str) -> Tuple[float, str]:
        """Analyzuje předpojatost v textu"""
        try:
            system_prompt = """Jsi expert na analýzu mediální předpojatosti. Analyzuj následující text a:
1. Ohodnoť předpojatost na škále 0-1 (0 = neutrální, 1 = silně předpojatý)
2. Identifikuj typ předpojatosti (politická, kulturní, ekonomická, atd.)
3. Uveď konkrétní příklady předpojatých formulací

Odpověz ve formátu JSON:
{
    "bias_score": 0.0-1.0,
    "bias_type": "typ předpojatosti",
    "explanation": "vysvětlení s příklady"
}"""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Text k analýze: {text[:2000]}")
            ]
            
            response = self.llm(messages)
            result = json.loads(response.content)
            
            return result.get("bias_score", 0.0), result.get("explanation", "")
            
        except Exception as e:
            logger.error(f"Chyba při analýze předpojatosti: {e}")
            return 0.0, "Analýza se nezdařila"
    
    def analyze_sentiment(self, text: str) -> float:
        """Analyzuje sentiment textu"""
        try:
            blob = TextBlob(text)
            return blob.sentiment.polarity
        except Exception as e:
            logger.warning(f"Chyba při analýze sentimentu: {e}")
            return 0.0

class GPT4Summarizer:
    """Sumarizace pomocí GPT-4 Turbo"""
    
    def __init__(self, openai_api_key: str):
        self.llm = ChatOpenAI(
            api_key=openai_api_key,
            model="gpt-4-turbo-preview",
            temperature=0.3
        )
    
    def summarize_articles(self, articles: List[Dict], query: str) -> str:
        """Sumarizuje články k danému dotazu"""
        try:
            # Příprava obsahu
            content_parts = []
            for i, article in enumerate(articles[:5], 1):  # Omezení na 5 článků
                content_parts.append(
                    f"ČLÁNEK {i}:\nZdroj: {article.get('source', 'Neznámý')}\n"
                    f"Jazyk: {article.get('language', 'Neznámý')}\n"
                    f"Názor/Předpojatost: {article.get('bias_score', 0):.2f}\n"
                    f"Obsah: {article.get('content', article.get('title', ''))[:1000]}\n"
                )
            
            combined_content = "\n\n".join(content_parts)
            
            system_prompt = f"""Jsi expert na zpravodajskou analýzu. Na základě poskytnutých článků vytvoř:

1. HLAVNÍ SHRNUTÍ (2-3 odstavce)
2. KLÍČOVÉ BODY (odrážky)
3. RŮZNÉ PERSPEKTIVY (pokud existují)
4. POTENCIÁLNÍ PŘEDPOJATOST (upozornění)

Dotaz uživatele: {query}

Zaměř se na objektivitu a uveď různé úhly pohledu."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=combined_content)
            ]
            
            response = self.llm(messages)
            return response.content
            
        except Exception as e:
            logger.error(f"Chyba při sumarizaci: {e}")
            return "Nepodařilo se vytvořit shrnutí."
    
    def translate_query(self, query: str, target_language: str = "en") -> str:
        """Přeloží dotaz do cílového jazyka"""
        try:
            if target_language == "en":
                system_prompt = "Přelož následující dotaz do angličtiny. Vrať pouze překlad bez dalších komentářů."
            else:
                system_prompt = f"Přelož následující dotaz do jazyka: {target_language}. Vrať pouze překlad."
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=query)
            ]
            
            response = self.llm(messages)
            return response.content.strip()
            
        except Exception as e:
            logger.warning(f"Chyba při překladu: {e}")
            return query

class MultilingualNewsExplorer:
    """Hlavní třída pro multilingvní zpravodajský průzkumník"""
    
    def __init__(self, news_api_key: str, openai_api_key: str):
        self.embeddings = MultilingualEmbeddings()
        self.vector_store = MilvusVectorStore()
        self.news_collector = NewsDataCollector(news_api_key)
        self.bias_detector = BiasDetector(openai_api_key)
        self.summarizer = GPT4Summarizer(openai_api_key)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
    
    def _generate_article_id(self, title: str, url: str) -> str:
        """Generuje unikátní ID článku"""
        return hashlib.md5(f"{title}{url}".encode()).hexdigest()
    
    def _detect_language(self, text: str) -> str:
        """Detekuje jazyk textu"""
        try:
            return detect(text)
        except:
            return "unknown"
    
    def process_raw_articles(self, raw_articles: List[Dict]) -> List[NewsArticle]:
        """Zpracuje surová data článků"""
        processed_articles = []
        
        for raw_article in raw_articles:
            try:
                # Extrakce základních údajů
                title = raw_article.get("title", "")
                url = raw_article.get("url", "")
                
                if not title or not url:
                    continue
                
                # Získání plného obsahu
                content = self.news_collector.extract_full_content(url)
                if not content:
                    content = raw_article.get("description", title)
                
                # Detekce jazyka
                language = self._detect_language(content)
                
                # Vytvoření článku
                article = NewsArticle(
                    id=self._generate_article_id(title, url),
                    title=title,
                    content=content,
                    source=raw_article.get("source", {}).get("name", "Unknown"),
                    author=raw_article.get("author"),
                    published_at=datetime.fromisoformat(
                        raw_article.get("publishedAt", "").replace("Z", "+00:00")
                    ),
                    url=url,
                    language=language,
                    category=None,
                    country=None
                )
                
                processed_articles.append(article)
                
            except Exception as e:
                logger.warning(f"Chyba při zpracování článku: {e}")
                continue
        
        return processed_articles
    
    def analyze_articles(self, articles: List[NewsArticle]) -> List[NewsArticle]:
        """Analyzuje články (embeddings, bias, sentiment)"""
        analyzed_articles = []
        
        # Generování embeddingů
        contents = [f"{article.title} {article.content}" for article in articles]
        embeddings = self.embeddings.encode_texts(contents)
        
        for article, embedding in zip(articles, embeddings):
            try:
                # Přiřazení embeddingu
                article.embedding = embedding
                
                # Analýza předpojatosti a sentimentu
                bias_score, _ = self.bias_detector.analyze_bias(article.content)
                sentiment_score = self.bias_detector.analyze_sentiment(article.content)
                
                article.bias_score = bias_score
                article.sentiment_score = sentiment_score
                
                analyzed_articles.append(article)
                
            except Exception as e:
                logger.warning(f"Chyba při analýze článku {article.id}: {e}")
                continue
        
        return analyzed_articles
    
    def collect_and_store_news(self, languages: List[str] = ["en", "cs", "de", "fr"], 
                              categories: List[str] = None):
        """Sbírá a ukládá zprávy z různých zdrojů"""
        all_articles = []
        
        for language in languages:
            try:
                # Získání hlavních zpráv
                raw_articles = self.news_collector.fetch_top_headlines(
                    language=language,
                    page_size=50
                )
                
                # Zpracování a analýza
                processed_articles = self.process_raw_articles(raw_articles)
                analyzed_articles = self.analyze_articles(processed_articles)
                
                all_articles.extend(analyzed_articles)
                
                logger.info(f"Zpracováno {len(analyzed_articles)} článků v jazyce {language}")
                
            except Exception as e:
                logger.error(f"Chyba při zpracování jazyka {language}: {e}")
                continue
        
        # Uložení do databáze
        if all_articles:
            self.vector_store.insert_articles(all_articles)
        
        return all_articles
    
    def explore_topic(self, query: str, languages: List[str] = None, 
                     max_results: int = 20) -> Tuple[str, List[Dict], Dict]:
        """Průzkum tématu napříč jazyky"""
        try:
            # Překlad dotazu do různých jazyků
            translated_queries = [query]
            if languages:
                for lang in languages:
                    translated_query = self.summarizer.translate_query(query, lang)
                    translated_queries.append(translated_query)
            
            # Vyhledání relevantních článků
            all_results = []
            for translated_query in translated_queries:
                query_embedding = self.embeddings.encode_texts([translated_query])[0]
                results = self.vector_store.search_similar(
                    query_vector=query_embedding,
                    top_k=max_results // len(translated_queries)
                )
                all_results.extend(results)
            
            # Odstranění duplikátů
            unique_results = {}
            for result in all_results:
                if result["id"] not in unique_results:
                    unique_results[result["id"]] = result
            
            final_results = list(unique_results.values())[:max_results]
            
            # Generování shrnutí
            summary = self.summarizer.summarize_articles(final_results, query)
            
            # Statistiky
            stats = self._generate_statistics(final_results)
            
            return summary, final_results, stats
            
        except Exception as e:
            logger.error(f"Chyba při průzkumu tématu: {e}")
            return "Chyba při zpracování dotazu.", [], {}
    
    def _generate_statistics(self, articles: List[Dict]) -> Dict:
        """Generuje statistiky o článcích"""
        if not articles:
            return {}
        
        # Jazykové rozložení
        language_counts = {}
        source_counts = {}
        bias_scores = []
        sentiment_scores = []
        
        for article in articles:
            # Jazyky
            lang = article.get("language", "unknown")
            language_counts[lang] = language_counts.get(lang, 0) + 1
            
            # Zdroje
            source = article.get("source", "Unknown")
            source_counts[source] = source_counts.get(source, 0) + 1
            
            # Skóre
            if article.get("bias_score") is not None:
                bias_scores.append(article["bias_score"])
            if article.get("sentiment_score") is not None:
                sentiment_scores.append(article["sentiment_score"])
        
        return {
            "total_articles": len(articles),
            "languages": language_counts,
            "sources": source_counts,
            "avg_bias_score": np.mean(bias_scores) if bias_scores else 0,
            "avg_sentiment_score": np.mean(sentiment_scores) if sentiment_scores else 0,
            "bias_scores": bias_scores,
            "sentiment_scores": sentiment_scores
        }

# Streamlit aplikace
def main():
    """Hlavní Streamlit aplikace"""
    st.set_page_config(
        page_title="Multilingvní Zpravodajský Průzkumník",
        page_icon="🌍",
        layout="wide"
    )
    
    st.title("🌍 Multilingvní Zpravodajský Průzkumník")
    st.markdown("*Průzkum globálních zpráv s AI analýzou předpojatosti*")
    st.markdown("---")
    
    # Načtení API klíčů
    news_api_key = st.secrets.get("NEWS_API_KEY", "")
    openai_api_key = st.secrets.get("OPENAI_API_KEY", "")
    
    if not news_api_key or not openai_api_key:
        st.error("Prosím, nastavte API klíče v Streamlit secrets")
        st.stop()
    
    # Inicializace systému
    if 'explorer' not in st.session_state:
        with st.spinner("Inicializuji systém..."):
            try:
                st.session_state.explorer = MultilingualNewsExplorer(
                    news_api_key=news_api_key,
                    openai_api_key=openai_api_key
                )
                st.success("Systém připraven!")
            except Exception as e:
                st.error(f"Chyba při inicializaci: {e}")
                st.stop()
    
    # Boční panel
    with st.sidebar:
        st.header("⚙️ Nastavení")
        
        languages = st.multiselect(
            "Jazyky:",
            ["en", "cs", "de", "fr", "es", "it", "ru", "zh"],
            default=["en", "cs"]
        )
        
        max_results = st.slider("Max. výsledků:", 5, 50, 20)
        
        st.markdown("---")
        
        if st.button("🔄 Aktualizovat databázi zpráv"):
            with st.spinner("Sbírám nové zprávy..."):
                articles = st.session_state.explorer.collect_and_store_news(languages)
                st.success(f"Zpracováno {len(articles)} nových článků")
    
    # Hlavní obsah
    st.header("🔍 Průzkum tématu")
    
    query = st.text_input(
        "Zadejte téma pro průzkum:",
        placeholder="např. klimatické změny, ekonomická krize, technologie AI..."
    )
    
    if st.button("🚀 Prozkoumat", type="primary") and query:
        with st.spinner("Analyzuji zprávy napříč jazyky..."):
            summary, articles, stats = st.session_state.explorer.explore_topic(
                query=query,
                languages=languages,
                max_results=max_results
            )
        
        if articles:
            # Zobrazení shrnutí
            st.subheader("📋 Inteligentní shrnutí")
            st.markdown(summary)
            
            # Statistiky
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Celkem článků", stats.get("total_articles", 0))
            
            with col2:
                st.metric("Průměrná předpojatost", 
                         f"{stats.get('avg_bias_score', 0):.2f}")
            
            with col3:
                st.metric("Průměrný sentiment", 
                         f"{stats.get('avg_sentiment_score', 0):.2f}")
            
            with col4:
                st.metric("Počet jazyků", len(stats.get("languages", {})))
            
            # Grafy
            col1, col2 = st.columns(2)
            
            with col1:
                if stats.get("languages"):
                    fig_lang = px.pie(
                        values=list(stats["languages"].values()),
                        names=list(stats["languages"].keys()),
                        title="Rozložení podle jazyků"
                    )
                    st.plotly_chart(fig_lang, use_container_width=True)
            
            with col2:
                if stats.get("bias_scores"):
                    fig_bias = px.histogram(
                        x=stats["bias_scores"],
                        nbins=20,
                        title="Distribuce předpojatosti"
                    )
                    st.plotly_chart(fig_bias, use_container_width=True)
            
            # Seznam článků
            st.subheader("📰 Nalezené články")
            
            for i, article in enumerate(articles):
                with st.expander(
                    f"{i+1}. {article['title'][:100]}... "
                    f"({article['language'].upper()}) - "
                    f"Předpojatost: {article.get('bias_score', 0):.2f}"
                ):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**Zdroj:** {article['source']}")
                        st.write(f"**Datum:** {article['published_at']}")
                        st.write(f"**Obsah:** {article['content'][:500]}...")
                        st.write(f"**URL:** {article['url']}")
                    
                    with col2:
                        st.metric("Podobnost", f"{article.get('similarity_score', 0):.3f}")
                        st.metric("Předpojatost", f"{article.get('bias_score', 0):.2f}")
                        st.metric("Sentiment", f"{article.get('sentiment_score', 0):.2f}")
        else:
            st.warning("Nebyli nalezeny žádné relevantní články.")

if __name__ == "__main__":
    main()
````

### Konfigurace a spuštění

````python
# .streamlit/secrets.toml
NEWS_API_KEY = "your_news_api_key_here"
OPENAI_API_KEY = "your_openai_api_key_here"
````

````bash
# Spuštění Milvus (Docker)
docker run -p 19530:19530 -p 9091:9091 milvusdb/milvus:latest

# Spuštění aplikace
streamlit run multilingual_news_explorer.py
````

## Shrnutí Projektu

Multilingvní zpravodajský průzkumník představuje pokročilé AI řešení pro globální analýzu zpravodajství. Systém kombinuje nejmodernější technologie pro překonání jazykových bariér a poskytování objektivního přehledu světových událostí.

**Klíčové inovace:**
- Cross-lingvální vyhledávání s multilingvními embeddings
- Automatická detekce předpojatosti pomocí GPT-4 Turbo
- Real-time integrace s globálními zpravodajskými zdroji
- Inteligentní sumarizace napříč různými perspektivami

**Technické výhody:**
- Škálovatelná architektura s Milvus databází
- Pokročilá NLP analýza sentimentu a biasu
- Multilingvní podpora pro desítky jazyků
- Interaktivní vizualizace výsledků

**Společenský dopad:**
Projekt může významně přispět k mediální gramotnosti, pomáhá uživatelům rozpoznat předpojatost v médiích a poskytuje komplexní pohled na globální události bez jazykových omezení.