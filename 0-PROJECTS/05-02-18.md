<small>Claude Sonnet 4 **(Scientific Research Assistant Agent)**</small>
# Scientific Research Assistant Agent

## Key Concepts Explanation

### Semantic Search for Scientific Literature
Advanced information retrieval system that uses vector embeddings and transformer models to understand the semantic meaning of research queries, enabling discovery of relevant papers based on conceptual similarity rather than just keyword matching across vast scientific databases.

### Automated Paper Summarization
AI-powered text summarization that extracts key findings, methodologies, and conclusions from complex scientific papers using abstractive and extractive techniques, creating concise, structured summaries while preserving critical technical details and research context.

### Retrieval-Augmented Generation (RAG)
Hybrid AI architecture that combines information retrieval with language generation, allowing the system to ground responses in retrieved scientific literature while maintaining factual accuracy and providing citations for generated insights and explanations.

### Citation Network Analysis
Graph-based analysis of academic paper relationships through citation patterns, enabling discovery of influential works, research trends, knowledge gaps, and emerging fields while mapping the evolution of scientific concepts over time.

### Multi-Modal Research Processing
Comprehensive document analysis that processes not only text but also figures, tables, equations, and supplementary materials to extract complete research insights and maintain scientific rigor in automated analysis workflows.

## Comprehensive Project Explanation

### Objectives
The Scientific Research Assistant Agent accelerates scientific discovery by providing intelligent literature search, automated paper analysis, and knowledge synthesis capabilities that help researchers quickly identify relevant work, extract key insights, and generate comprehensive research overviews.

### Key Features
- **Intelligent Paper Discovery**: Semantic search across multiple academic databases
- **Automated Summarization**: AI-generated abstracts and key findings extraction
- **Research Synthesis**: RAG-powered literature reviews and comparative analyses
- **Citation Analysis**: Network mapping and influence tracking
- **Trend Detection**: Emerging research area identification

### Challenges
- **Scale and Diversity**: Processing millions of papers across diverse scientific domains
- **Quality Assurance**: Maintaining accuracy in summarization and fact extraction
- **Domain Expertise**: Understanding specialized terminology and methodologies
- **Real-time Updates**: Keeping pace with rapidly evolving research landscapes

### Potential Impact
This system democratizes access to scientific knowledge, accelerates literature reviews, reduces research duplication, enables interdisciplinary discovery, and supports evidence-based decision making in academia, industry, and policy development.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
langchain==0.1.0
langchain-openai==0.0.5
chromadb==0.4.18
sentence-transformers==2.2.2
pandas==2.1.4
numpy==1.24.3
plotly==5.17.0
requests==2.31.0
beautifulsoup4==4.12.2
arxiv==2.1.0
PyPDF2==3.0.1
transformers==4.35.2
torch==2.1.0
faiss-cpu==1.7.4
networkx==3.2.1
matplotlib==3.7.2
seaborn==0.12.2
scikit-learn==1.3.2
nltk==3.8.1
spacy==3.7.2
pydantic==2.5.0
sqlite3
datetime
json
re
uuid
logging
typing
dataclasses
enum
asyncio
aiohttp
````

### Core Implementation

````python
import sqlite3
import json
import logging
import re
import uuid
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import io

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import plotly.network as net
import numpy as np
import networkx as nx

# NLP and ML
import spacy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import nltk
from transformers import pipeline, AutoTokenizer, AutoModel

# Vector databases
import chromadb
from chromadb.config import Settings
import faiss

# Document processing
import PyPDF2
import requests
from bs4 import BeautifulSoup
import arxiv

# LangChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PaperType(Enum):
    RESEARCH_ARTICLE = "research_article"
    REVIEW = "review"
    CONFERENCE = "conference"
    PREPRINT = "preprint"
    BOOK_CHAPTER = "book_chapter"

class ResearchField(Enum):
    COMPUTER_SCIENCE = "computer_science"
    PHYSICS = "physics"
    BIOLOGY = "biology"
    CHEMISTRY = "chemistry"
    MATHEMATICS = "mathematics"
    MEDICINE = "medicine"
    ENGINEERING = "engineering"
    INTERDISCIPLINARY = "interdisciplinary"

@dataclass
class Author:
    name: str
    affiliation: Optional[str] = None
    email: Optional[str] = None
    orcid: Optional[str] = None

@dataclass
class Citation:
    title: str
    authors: List[str]
    year: Optional[int] = None
    venue: Optional[str] = None
    doi: Optional[str] = None

@dataclass
class Paper:
    paper_id: str
    title: str
    authors: List[Author]
    abstract: str
    full_text: str
    paper_type: PaperType
    research_field: ResearchField
    keywords: List[str]
    publication_date: datetime
    venue: str
    doi: Optional[str] = None
    arxiv_id: Optional[str] = None
    citations: List[Citation] = field(default_factory=list)
    cited_by_count: int = 0
    pdf_url: Optional[str] = None
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class Summary:
    paper_id: str
    executive_summary: str
    key_findings: List[str]
    methodology: str
    limitations: List[str]
    future_work: List[str]
    technical_details: Dict[str, Any]
    confidence_score: float
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class SearchQuery:
    query_text: str
    research_fields: List[ResearchField]
    paper_types: List[PaperType]
    date_range: Tuple[datetime, datetime]
    max_results: int = 20
    min_citation_count: int = 0

@dataclass
class SearchResult:
    papers: List[Paper]
    total_found: int
    query_embedding: np.ndarray
    relevance_scores: List[float]
    search_time: float

class ArxivClient:
    """Client for fetching papers from arXiv."""
    
    def __init__(self):
        self.client = arxiv.Client()
    
    async def search_papers(self, query: str, max_results: int = 20) -> List[Paper]:
        """Search for papers on arXiv."""
        try:
            search = arxiv.Search(
                query=query,
                max_results=max_results,
                sort_by=arxiv.SortCriterion.Relevance
            )
            
            papers = []
            for result in self.client.results(search):
                authors = [Author(name=str(author)) for author in result.authors]
                
                # Determine research field based on categories
                research_field = self._categorize_field(result.categories)
                
                paper = Paper(
                    paper_id=str(uuid.uuid4()),
                    title=result.title,
                    authors=authors,
                    abstract=result.summary,
                    full_text="",  # Would need to download PDF for full text
                    paper_type=PaperType.PREPRINT,
                    research_field=research_field,
                    keywords=result.categories,
                    publication_date=result.published,
                    venue="arXiv",
                    arxiv_id=result.entry_id.split('/')[-1],
                    pdf_url=result.pdf_url
                )
                papers.append(paper)
            
            return papers
        
        except Exception as e:
            logger.error(f"ArXiv search error: {e}")
            return []
    
    def _categorize_field(self, categories: List[str]) -> ResearchField:
        """Categorize paper based on arXiv categories."""
        cs_categories = ['cs.', 'stat.ML']
        physics_categories = ['physics.', 'astro-ph.', 'cond-mat.', 'hep-', 'nucl-', 'quant-ph']
        math_categories = ['math.', 'math-ph']
        
        category_str = ' '.join(categories)
        
        if any(cat in category_str for cat in cs_categories):
            return ResearchField.COMPUTER_SCIENCE
        elif any(cat in category_str for cat in physics_categories):
            return ResearchField.PHYSICS
        elif any(cat in category_str for cat in math_categories):
            return ResearchField.MATHEMATICS
        else:
            return ResearchField.INTERDISCIPLINARY

class PaperProcessor:
    """Process and extract information from papers."""
    
    def __init__(self):
        # Initialize NLP models
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            logger.warning("spaCy model not found")
            self.nlp = None
        
        # Initialize summarization model
        try:
            self.summarizer = pipeline(
                "summarization",
                model="facebook/bart-large-cnn",
                device=0 if torch.cuda.is_available() else -1
            )
        except Exception as e:
            logger.warning(f"Could not load summarization model: {e}")
            self.summarizer = None
        
        # Download NLTK data
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('stopwords', quiet=True)
        except:
            pass
    
    def extract_key_information(self, paper: Paper) -> Dict[str, Any]:
        """Extract key information from paper text."""
        try:
            text = paper.abstract + " " + paper.full_text
            
            # Extract methodology section
            methodology = self._extract_methodology(text)
            
            # Extract key findings
            findings = self._extract_findings(text)
            
            # Extract technical terms
            technical_terms = self._extract_technical_terms(text)
            
            # Extract limitations
            limitations = self._extract_limitations(text)
            
            return {
                "methodology": methodology,
                "key_findings": findings,
                "technical_terms": technical_terms,
                "limitations": limitations
            }
        
        except Exception as e:
            logger.error(f"Information extraction error: {e}")
            return {}
    
    def _extract_methodology(self, text: str) -> str:
        """Extract methodology section from paper."""
        method_patterns = [
            r'methodology[:\s]+(.*?)(?=results|conclusion|discussion)',
            r'methods[:\s]+(.*?)(?=results|conclusion|discussion)',
            r'approach[:\s]+(.*?)(?=results|conclusion|discussion)'
        ]
        
        for pattern in method_patterns:
            match = re.search(pattern, text.lower(), re.DOTALL)
            if match:
                return match.group(1).strip()[:500]  # Limit length
        
        return "Methodology not clearly identified"
    
    def _extract_findings(self, text: str) -> List[str]:
        """Extract key findings from paper."""
        finding_patterns = [
            r'we found that ([^.]+)',
            r'results show that ([^.]+)',
            r'our findings indicate ([^.]+)',
            r'we demonstrate that ([^.]+)'
        ]
        
        findings = []
        for pattern in finding_patterns:
            matches = re.findall(pattern, text.lower())
            findings.extend(matches[:3])  # Limit to 3 per pattern
        
        return findings[:10]  # Max 10 findings
    
    def _extract_technical_terms(self, text: str) -> List[str]:
        """Extract technical terms using NLP."""
        if not self.nlp:
            return []
        
        doc = self.nlp(text[:10000])  # Limit text length for processing
        
        # Extract named entities and noun phrases
        technical_terms = set()
        
        for ent in doc.ents:
            if ent.label_ in ['ORG', 'PRODUCT', 'EVENT', 'WORK_OF_ART']:
                technical_terms.add(ent.text.lower())
        
        # Extract noun phrases
        for chunk in doc.noun_chunks:
            if len(chunk.text.split()) >= 2 and len(chunk.text) > 5:
                technical_terms.add(chunk.text.lower())
        
        return list(technical_terms)[:20]  # Limit to 20 terms
    
    def _extract_limitations(self, text: str) -> List[str]:
        """Extract limitations mentioned in the paper."""
        limitation_patterns = [
            r'limitation[s]?[:\s]+(.*?)(?=\.|future|conclusion)',
            r'drawback[s]?[:\s]+(.*?)(?=\.|future|conclusion)',
            r'constraint[s]?[:\s]+(.*?)(?=\.|future|conclusion)'
        ]
        
        limitations = []
        for pattern in limitation_patterns:
            matches = re.findall(pattern, text.lower(), re.DOTALL)
            limitations.extend([match.strip() for match in matches])
        
        return limitations[:5]  # Max 5 limitations
    
    def generate_summary(self, paper: Paper) -> Summary:
        """Generate comprehensive summary of the paper."""
        try:
            # Extract key information
            key_info = self.extract_key_information(paper)
            
            # Generate executive summary using abstractive summarization
            text_to_summarize = paper.abstract
            if len(text_to_summarize) > 50:
                if self.summarizer:
                    try:
                        summary_result = self.summarizer(
                            text_to_summarize,
                            max_length=150,
                            min_length=50,
                            do_sample=False
                        )
                        executive_summary = summary_result[0]['summary_text']
                    except:
                        executive_summary = text_to_summarize[:300] + "..."
                else:
                    executive_summary = text_to_summarize[:300] + "..."
            else:
                executive_summary = text_to_summarize
            
            # Calculate confidence score based on abstract quality
            confidence_score = min(1.0, len(paper.abstract) / 500)
            
            summary = Summary(
                paper_id=paper.paper_id,
                executive_summary=executive_summary,
                key_findings=key_info.get('key_findings', []),
                methodology=key_info.get('methodology', ''),
                limitations=key_info.get('limitations', []),
                future_work=[],  # Would extract from full text
                technical_details=key_info.get('technical_terms', []),
                confidence_score=confidence_score
            )
            
            return summary
        
        except Exception as e:
            logger.error(f"Summary generation error: {e}")
            return Summary(
                paper_id=paper.paper_id,
                executive_summary="Summary generation failed",
                key_findings=[],
                methodology="",
                limitations=[],
                future_work=[],
                technical_details={},
                confidence_score=0.0
            )

class SemanticSearchEngine:
    """Semantic search engine for scientific papers."""
    
    def __init__(self, embedding_model: str = "all-MiniLM-L6-v2"):
        try:
            self.sentence_transformer = SentenceTransformer(embedding_model)
        except Exception as e:
            logger.warning(f"Could not load sentence transformer: {e}")
            self.sentence_transformer = None
        
        # Initialize vector database
        self.chroma_client = chromadb.Client(
            Settings(allow_reset=True, anonymized_telemetry=False)
        )
        
        try:
            self.collection = self.chroma_client.create_collection(
                name="scientific_papers",
                metadata={"description": "Scientific paper embeddings"}
            )
        except:
            self.collection = self.chroma_client.get_collection("scientific_papers")
        
        # Initialize FAISS index for large-scale search
        self.faiss_index = None
        self.paper_ids = []
    
    def add_papers_to_index(self, papers: List[Paper]):
        """Add papers to the search index."""
        try:
            if not self.sentence_transformer:
                logger.warning("No sentence transformer available")
                return
            
            # Generate embeddings
            texts = []
            ids = []
            metadatas = []
            
            for paper in papers:
                # Combine title and abstract for embedding
                text = f"{paper.title} {paper.abstract}"
                texts.append(text)
                ids.append(paper.paper_id)
                
                metadata = {
                    "title": paper.title,
                    "authors": [author.name for author in paper.authors],
                    "research_field": paper.research_field.value,
                    "paper_type": paper.paper_type.value,
                    "publication_date": paper.publication_date.isoformat(),
                    "venue": paper.venue
                }
                metadatas.append(metadata)
            
            # Generate embeddings
            embeddings = self.sentence_transformer.encode(texts)
            
            # Add to ChromaDB
            self.collection.add(
                embeddings=embeddings.tolist(),
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            # Update FAISS index
            if self.faiss_index is None:
                dimension = embeddings.shape[1]
                self.faiss_index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity
                self.paper_ids = []
            
            # Normalize embeddings for cosine similarity
            normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
            self.faiss_index.add(normalized_embeddings.astype('float32'))
            self.paper_ids.extend(ids)
            
            logger.info(f"Added {len(papers)} papers to search index")
        
        except Exception as e:
            logger.error(f"Index update error: {e}")
    
    def search(self, query: SearchQuery) -> SearchResult:
        """Perform semantic search for papers."""
        try:
            start_time = datetime.now()
            
            if not self.sentence_transformer:
                return SearchResult([], 0, np.array([]), [], 0.0)
            
            # Generate query embedding
            query_embedding = self.sentence_transformer.encode([query.query_text])
            
            # Search using ChromaDB
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=min(query.max_results, 100),
                where={
                    "research_field": {"$in": [field.value for field in query.research_fields]}
                } if query.research_fields else None
            )
            
            # Parse results
            papers = []
            relevance_scores = []
            
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0],
                    results['distances'][0]
                )):
                    # Convert distance to similarity score
                    similarity_score = 1 - distance
                    relevance_scores.append(similarity_score)
                    
                    # Create paper object from metadata
                    authors = [Author(name=name) for name in metadata.get('authors', [])]
                    
                    paper = Paper(
                        paper_id=results['ids'][0][i],
                        title=metadata.get('title', ''),
                        authors=authors,
                        abstract=doc.split(' ', 10)[-1] if ' ' in doc else doc,  # Extract abstract part
                        full_text="",
                        paper_type=PaperType(metadata.get('paper_type', 'research_article')),
                        research_field=ResearchField(metadata.get('research_field', 'interdisciplinary')),
                        keywords=[],
                        publication_date=datetime.fromisoformat(metadata.get('publication_date', datetime.now().isoformat())),
                        venue=metadata.get('venue', '')
                    )
                    papers.append(paper)
            
            search_time = (datetime.now() - start_time).total_seconds()
            
            return SearchResult(
                papers=papers,
                total_found=len(papers),
                query_embedding=query_embedding[0],
                relevance_scores=relevance_scores,
                search_time=search_time
            )
        
        except Exception as e:
            logger.error(f"Search error: {e}")
            return SearchResult([], 0, np.array([]), [], 0.0)

class RAGSystem:
    """Retrieval-Augmented Generation system for research questions."""
    
    def __init__(self, search_engine: SemanticSearchEngine, openai_api_key: Optional[str] = None):
        self.search_engine = search_engine
        self.llm = None
        
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.3,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        
        self._initialize_prompts()
    
    def _initialize_prompts(self):
        """Initialize RAG prompts."""
        self.research_prompt = ChatPromptTemplate.from_template("""
        You are a scientific research assistant. Based on the following research papers and the user's question, 
        provide a comprehensive, accurate answer that synthesizes information from the papers.

        Research Question: {question}

        Relevant Papers:
        {papers_context}

        Instructions:
        1. Provide a clear, well-structured answer based on the scientific evidence
        2. Cite specific papers when making claims (use paper titles)
        3. Highlight any conflicting findings or limitations
        4. Suggest areas for further research if applicable
        5. Maintain scientific rigor and acknowledge uncertainties

        Answer:
        """)
        
        self.summary_prompt = ChatPromptTemplate.from_template("""
        Synthesize the key insights from these research papers on the topic: {topic}

        Papers:
        {papers_context}

        Provide:
        1. Main findings and consensus
        2. Methodological approaches used
        3. Key debates or conflicting results
        4. Research gaps and future directions
        5. Practical implications

        Synthesis:
        """)
    
    def answer_research_question(self, question: str, max_papers: int = 5) -> Dict[str, Any]:
        """Answer a research question using RAG."""
        try:
            # Create search query
            search_query = SearchQuery(
                query_text=question,
                research_fields=[],  # Search all fields
                paper_types=[],  # Search all types
                date_range=(datetime.now() - timedelta(days=3650), datetime.now()),  # Last 10 years
                max_results=max_papers
            )
            
            # Retrieve relevant papers
            search_result = self.search_engine.search(search_query)
            
            if not search_result.papers:
                return {
                    "answer": "No relevant papers found for this question.",
                    "sources": [],
                    "confidence": 0.0
                }
            
            # Prepare context from papers
            papers_context = ""
            sources = []
            
            for i, paper in enumerate(search_result.papers):
                papers_context += f"\nPaper {i+1}: {paper.title}\n"
                papers_context += f"Authors: {', '.join([author.name for author in paper.authors])}\n"
                papers_context += f"Abstract: {paper.abstract}\n"
                papers_context += f"Venue: {paper.venue}\n"
                papers_context += "---\n"
                
                sources.append({
                    "title": paper.title,
                    "authors": [author.name for author in paper.authors],
                    "venue": paper.venue,
                    "relevance_score": search_result.relevance_scores[i] if i < len(search_result.relevance_scores) else 0.0
                })
            
            # Generate answer using LLM
            if self.llm:
                prompt = self.research_prompt.format(
                    question=question,
                    papers_context=papers_context
                )
                
                response = self.llm.invoke(prompt)
                answer = response.content
                
                # Calculate confidence based on relevance scores
                avg_relevance = np.mean(search_result.relevance_scores) if search_result.relevance_scores else 0.0
                confidence = min(0.9, avg_relevance * 1.2)  # Cap at 0.9
            else:
                answer = f"Found {len(search_result.papers)} relevant papers. Please configure OpenAI API key for detailed analysis."
                confidence = 0.5
            
            return {
                "answer": answer,
                "sources": sources,
                "confidence": confidence,
                "search_time": search_result.search_time,
                "papers_found": len(search_result.papers)
            }
        
        except Exception as e:
            logger.error(f"RAG answer generation error: {e}")
            return {
                "answer": f"Error generating answer: {e}",
                "sources": [],
                "confidence": 0.0
            }
    
    def generate_literature_review(self, topic: str, max_papers: int = 10) -> Dict[str, Any]:
        """Generate a literature review on a given topic."""
        try:
            # Search for papers on the topic
            search_query = SearchQuery(
                query_text=topic,
                research_fields=[],
                paper_types=[],
                date_range=(datetime.now() - timedelta(days=1825), datetime.now()),  # Last 5 years
                max_results=max_papers
            )
            
            search_result = self.search_engine.search(search_query)
            
            if not search_result.papers:
                return {
                    "review": "No papers found for literature review.",
                    "paper_count": 0,
                    "key_themes": []
                }
            
            # Prepare context
            papers_context = ""
            for paper in search_result.papers:
                papers_context += f"Title: {paper.title}\n"
                papers_context += f"Abstract: {paper.abstract}\n"
                papers_context += f"Authors: {', '.join([author.name for author in paper.authors])}\n\n"
            
            # Generate review
            if self.llm:
                prompt = self.summary_prompt.format(
                    topic=topic,
                    papers_context=papers_context
                )
                
                response = self.llm.invoke(prompt)
                review = response.content
            else:
                review = f"Literature review requires OpenAI API key. Found {len(search_result.papers)} papers on '{topic}'."
            
            # Extract key themes (simplified)
            key_themes = self._extract_themes(search_result.papers)
            
            return {
                "review": review,
                "paper_count": len(search_result.papers),
                "key_themes": key_themes,
                "search_time": search_result.search_time
            }
        
        except Exception as e:
            logger.error(f"Literature review generation error: {e}")
            return {
                "review": f"Error generating review: {e}",
                "paper_count": 0,
                "key_themes": []
            }
    
    def _extract_themes(self, papers: List[Paper]) -> List[str]:
        """Extract key themes from papers."""
        # Simple keyword extraction
        all_keywords = []
        for paper in papers:
            all_keywords.extend(paper.keywords)
        
        # Count frequency
        from collections import Counter
        keyword_counts = Counter(all_keywords)
        
        # Return top themes
        return [keyword for keyword, count in keyword_counts.most_common(10)]

class CitationAnalyzer:
    """Analyze citation networks and research impact."""
    
    def __init__(self):
        self.citation_graph = nx.DiGraph()
    
    def build_citation_network(self, papers: List[Paper]):
        """Build citation network from papers."""
        try:
            # Add nodes for each paper
            for paper in papers:
                self.citation_graph.add_node(
                    paper.paper_id,
                    title=paper.title,
                    authors=[author.name for author in paper.authors],
                    year=paper.publication_date.year,
                    venue=paper.venue,
                    cited_by_count=paper.cited_by_count
                )
                
                # Add citation edges
                for citation in paper.citations:
                    # Find cited paper in our collection
                    cited_paper_id = self._find_paper_by_title(citation.title, papers)
                    if cited_paper_id:
                        self.citation_graph.add_edge(paper.paper_id, cited_paper_id)
            
            logger.info(f"Built citation network with {self.citation_graph.number_of_nodes()} nodes and {self.citation_graph.number_of_edges()} edges")
        
        except Exception as e:
            logger.error(f"Citation network building error: {e}")
    
    def _find_paper_by_title(self, title: str, papers: List[Paper]) -> Optional[str]:
        """Find paper ID by title."""
        for paper in papers:
            if paper.title.lower() == title.lower():
                return paper.paper_id
        return None
    
    def calculate_impact_metrics(self) -> Dict[str, Any]:
        """Calculate various impact metrics."""
        try:
            if self.citation_graph.number_of_nodes() == 0:
                return {}
            
            # PageRank scores
            pagerank_scores = nx.pagerank(self.citation_graph)
            
            # Betweenness centrality
            betweenness_scores = nx.betweenness_centrality(self.citation_graph)
            
            # Find most influential papers
            top_pagerank = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            top_betweenness = sorted(betweenness_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # Network statistics
            stats = {
                "total_papers": self.citation_graph.number_of_nodes(),
                "total_citations": self.citation_graph.number_of_edges(),
                "average_citations_per_paper": self.citation_graph.number_of_edges() / max(1, self.citation_graph.number_of_nodes()),
                "most_influential_pagerank": [
                    {
                        "paper_id": paper_id,
                        "title": self.citation_graph.nodes[paper_id].get('title', ''),
                        "score": score
                    }
                    for paper_id, score in top_pagerank
                ],
                "most_influential_betweenness": [
                    {
                        "paper_id": paper_id,
                        "title": self.citation_graph.nodes[paper_id].get('title', ''),
                        "score": score
                    }
                    for paper_id, score in top_betweenness
                ]
            }
            
            return stats
        
        except Exception as e:
            logger.error(f"Impact metrics calculation error: {e}")
            return {}

class ResearchDatabase:
    """Database for storing papers and research data."""
    
    def __init__(self, db_path: str = "research_assistant.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize database tables."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # Papers table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS papers (
                    paper_id TEXT PRIMARY KEY,
                    title TEXT,
                    authors TEXT,
                    abstract TEXT,
                    full_text TEXT,
                    paper_type TEXT,
                    research_field TEXT,
                    keywords TEXT,
                    publication_date TEXT,
                    venue TEXT,
                    doi TEXT,
                    arxiv_id TEXT,
                    cited_by_count INTEGER,
                    pdf_url TEXT,
                    created_at TEXT
                )
            """)
            
            # Summaries table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS summaries (
                    summary_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    paper_id TEXT,
                    executive_summary TEXT,
                    key_findings TEXT,
                    methodology TEXT,
                    limitations TEXT,
                    technical_details TEXT,
                    confidence_score REAL,
                    created_at TEXT,
                    FOREIGN KEY (paper_id) REFERENCES papers (paper_id)
                )
            """)
            
            # Research queries table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS research_queries (
                    query_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query_text TEXT,
                    answer TEXT,
                    sources TEXT,
                    confidence REAL,
                    created_at TEXT
                )
            """)
            
            conn.commit()
    
    def save_paper(self, paper: Paper):
        """Save paper to database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO papers 
                    (paper_id, title, authors, abstract, full_text, paper_type, research_field,
                     keywords, publication_date, venue, doi, arxiv_id, cited_by_count, pdf_url, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    paper.paper_id,
                    paper.title,
                    json.dumps([author.name for author in paper.authors]),
                    paper.abstract,
                    paper.full_text,
                    paper.paper_type.value,
                    paper.research_field.value,
                    json.dumps(paper.keywords),
                    paper.publication_date.isoformat(),
                    paper.venue,
                    paper.doi,
                    paper.arxiv_id,
                    paper.cited_by_count,
                    paper.pdf_url,
                    paper.created_at.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving paper: {e}")
    
    def save_summary(self, summary: Summary):
        """Save paper summary to database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO summaries 
                    (paper_id, executive_summary, key_findings, methodology, limitations,
                     technical_details, confidence_score, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    summary.paper_id,
                    summary.executive_summary,
                    json.dumps(summary.key_findings),
                    summary.methodology,
                    json.dumps(summary.limitations),
                    json.dumps(summary.technical_details),
                    summary.confidence_score,
                    summary.created_at.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving summary: {e}")
    
    def get_all_papers(self) -> List[Dict]:
        """Retrieve all papers from database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM papers")
                columns = [description[0] for description in cursor.description]
                results = []
                for row in cursor.fetchall():
                    results.append(dict(zip(columns, row)))
                return results
        except Exception as e:
            logger.error(f"Error retrieving papers: {e}")
            return []

class ScientificResearchAssistant:
    """Main research assistant orchestrating all components."""
    
    def __init__(self, openai_api_key: Optional[str] = None):
        self.database = ResearchDatabase()
        self.arxiv_client = ArxivClient()
        self.processor = PaperProcessor()
        self.search_engine = SemanticSearchEngine()
        self.rag_system = RAGSystem(self.search_engine, openai_api_key)
        self.citation_analyzer = CitationAnalyzer()
        
        # Load existing papers into search index
        self._load_existing_papers()
    
    def _load_existing_papers(self):
        """Load existing papers from database into search index."""
        try:
            papers_data = self.database.get_all_papers()
            papers = []
            
            for paper_data in papers_data:
                authors = [Author(name=name) for name in json.loads(paper_data['authors'])]
                
                paper = Paper(
                    paper_id=paper_data['paper_id'],
                    title=paper_data['title'],
                    authors=authors,
                    abstract=paper_data['abstract'],
                    full_text=paper_data['full_text'],
                    paper_type=PaperType(paper_data['paper_type']),
                    research_field=ResearchField(paper_data['research_field']),
                    keywords=json.loads(paper_data['keywords']),
                    publication_date=datetime.fromisoformat(paper_data['publication_date']),
                    venue=paper_data['venue'],
                    doi=paper_data['doi'],
                    arxiv_id=paper_data['arxiv_id'],
                    cited_by_count=paper_data['cited_by_count'] or 0,
                    pdf_url=paper_data['pdf_url']
                )
                papers.append(paper)
            
            if papers:
                self.search_engine.add_papers_to_index(papers)
                self.citation_analyzer.build_citation_network(papers)
                logger.info(f"Loaded {len(papers)} papers from database")
        
        except Exception as e:
            logger.error(f"Error loading existing papers: {e}")
    
    async def search_and_add_papers(self, query: str, max_results: int = 20) -> List[Paper]:
        """Search for papers and add them to the system."""
        try:
            # Search arXiv
            papers = await self.arxiv_client.search_papers(query, max_results)
            
            # Process and save papers
            for paper in papers:
                # Generate summary
                summary = self.processor.generate_summary(paper)
                
                # Save to database
                self.database.save_paper(paper)
                self.database.save_summary(summary)
            
            # Add to search index
            if papers:
                self.search_engine.add_papers_to_index(papers)
                self.citation_analyzer.build_citation_network(papers)
            
            logger.info(f"Added {len(papers)} new papers")
            return papers
        
        except Exception as e:
            logger.error(f"Error searching and adding papers: {e}")
            return []
    
    def search_papers(self, query: str, fields: List[str] = None, max_results: int = 20) -> SearchResult:
        """Search existing papers."""
        try:
            research_fields = []
            if fields:
                for field in fields:
                    try:
                        research_fields.append(ResearchField(field))
                    except ValueError:
                        pass
            
            search_query = SearchQuery(
                query_text=query,
                research_fields=research_fields,
                paper_types=[],
                date_range=(datetime.now() - timedelta(days=3650), datetime.now()),
                max_results=max_results
            )
            
            return self.search_engine.search(search_query)
        
        except Exception as e:
            logger.error(f"Paper search error: {e}")
            return SearchResult([], 0, np.array([]), [], 0.0)
    
    def ask_research_question(self, question: str) -> Dict[str, Any]:
        """Answer a research question using RAG."""
        return self.rag_system.answer_research_question(question)
    
    def generate_literature_review(self, topic: str) -> Dict[str, Any]:
        """Generate a literature review."""
        return self.rag_system.generate_literature_review(topic)
    
    def get_research_analytics(self) -> Dict[str, Any]:
        """Get analytics about the research collection."""
        try:
            papers_data = self.database.get_all_papers()
            
            if not papers_data:
                return {"error": "No papers in database"}
            
            # Basic statistics
            total_papers = len(papers_data)
            
            # Field distribution
            fields = [paper['research_field'] for paper in papers_data]
            field_counts = {field: fields.count(field) for field in set(fields)}
            
            # Venue distribution
            venues = [paper['venue'] for paper in papers_data]
            venue_counts = {venue: venues.count(venue) for venue in set(venues)}
            
            # Publication timeline
            years = []
            for paper in papers_data:
                try:
                    year = datetime.fromisoformat(paper['publication_date']).year
                    years.append(year)
                except:
                    pass
            
            year_counts = {year: years.count(year) for year in set(years)}
            
            # Citation metrics
            citation_metrics = self.citation_analyzer.calculate_impact_metrics()
            
            analytics = {
                "total_papers": total_papers,
                "field_distribution": field_counts,
                "venue_distribution": dict(sorted(venue_counts.items(), key=lambda x: x[1], reverse=True)[:10]),
                "publication_timeline": dict(sorted(year_counts.items())),
                "citation_metrics": citation_metrics
            }
            
            return analytics
        
        except Exception as e:
            logger.error(f"Analytics error: {e}")
            return {"error": str(e)}

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="Scientific Research Assistant",
        page_icon="ğŸ”¬",
        layout="wide"
    )
    
    st.title("ğŸ”¬ Scientific Research Assistant Agent")
    st.markdown("**AI-powered research discovery, summarization, and analysis**")
    
    # Initialize session state
    if 'assistant' not in st.session_state:
        st.session_state['assistant'] = None
    if 'search_results' not in st.session_state:
        st.session_state['search_results'] = None
    if 'research_answer' not in st.session_state:
        st.session_state['research_answer'] = None
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ”§ Configuration")
        
        openai_key = st.text_input("OpenAI API Key (Optional)", type="password", 
                                  help="Required for RAG and summarization features")
        
        if st.button("Initialize Assistant") or st.session_state['assistant'] is None:
            with st.spinner("Initializing Research Assistant..."):
                st.session_state['assistant'] = ScientificResearchAssistant(openai_key)
                st.success("Assistant ready!")
        
        st.header("ğŸ“š Data Sources")
        st.info("Currently integrated with:")
        st.write("â€¢ arXiv (preprints)")
        st.write("â€¢ Local database")
        st.write("â€¢ Custom paper uploads")
    
    if not st.session_state['assistant']:
        st.info("ğŸ‘ˆ Please initialize the Research Assistant")
        return
    
    assistant = st.session_state['assistant']
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ” Search", "â“ Ask Questions", "ğŸ“„ Literature Review", "ğŸ“Š Analytics", "âš™ï¸ Management"])
    
    with tab1:
        st.header("ğŸ” Paper Search & Discovery")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_query = st.text_input(
                "Search Query",
                placeholder="Enter research topic, keywords, or specific question...",
                help="Use natural language or specific technical terms"
            )
        
        with col2:
            search_fields = st.multiselect(
                "Research Fields",
                [field.value.replace('_', ' ').title() for field in ResearchField],
                help="Filter by specific research domains"
            )
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            if st.button("ğŸ” Search Existing", help="Search papers already in database"):
                if search_query:
                    with st.spinner("Searching papers..."):
                        results = assistant.search_papers(search_query, search_fields)
                        st.session_state['search_results'] = results
                        st.rerun()
        
        with col2:
            if st.button("ğŸ“¥ Search & Import", help="Search arXiv and import new papers"):
                if search_query:
                    with st.spinner("Searching arXiv and importing papers..."):
                        papers = asyncio.run(assistant.search_and_add_papers(search_query, 10))
                        if papers:
                            st.success(f"Imported {len(papers)} new papers!")
                            results = assistant.search_papers(search_query, search_fields)
                            st.session_state['search_results'] = results
                            st.rerun()
                        else:
                            st.warning("No papers found or imported")
        
        # Display search results
        if st.session_state['search_results']:
            results = st.session_state['search_results']
            
            st.subheader(f"ğŸ“‹ Search Results ({results.total_found} papers found)")
            
            if results.papers:
                # Search metrics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Papers Found", results.total_found)
                with col2:
                    st.metric("Search Time", f"{results.search_time:.2f}s")
                with col3:
                    avg_relevance = np.mean(results.relevance_scores) if results.relevance_scores else 0
                    st.metric("Avg Relevance", f"{avg_relevance:.2%}")
                
                # Paper results
                for i, (paper, score) in enumerate(zip(results.papers, results.relevance_scores)):
                    with st.expander(f"#{i+1} {paper.title} (Relevance: {score:.1%})"):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"**Authors:** {', '.join([author.name for author in paper.authors])}")
                            st.write(f"**Venue:** {paper.venue}")
                            st.write(f"**Date:** {paper.publication_date.strftime('%Y-%m-%d')}")
                            st.write(f"**Field:** {paper.research_field.value.replace('_', ' ').title()}")
                        
                        with col2:
                            if paper.arxiv_id:
                                st.write(f"**arXiv ID:** {paper.arxiv_id}")
                            if paper.doi:
                                st.write(f"**DOI:** {paper.doi}")
                            if paper.pdf_url:
                                st.link_button("ğŸ“„ View PDF", paper.pdf_url)
                        
                        st.write("**Abstract:**")
                        st.write(paper.abstract)
                        
                        if paper.keywords:
                            st.write(f"**Keywords:** {', '.join(paper.keywords[:5])}")
            else:
                st.info("No papers found. Try different keywords or import papers from arXiv.")
    
    with tab2:
        st.header("â“ Research Question Answering")
        
        research_question = st.text_area(
            "Research Question",
            placeholder="Ask a specific research question (e.g., 'What are the latest advances in transformer architectures?')",
            height=100
        )
        
        if st.button("ğŸ¤– Get Answer"):
            if research_question:
                with st.spinner("Analyzing research literature..."):
                    answer_result = assistant.ask_research_question(research_question)
                    st.session_state['research_answer'] = answer_result
                    st.rerun()
            else:
                st.warning("Please enter a research question")
        
        # Display answer
        if st.session_state['research_answer']:
            result = st.session_state['research_answer']
            
            # Answer metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Confidence", f"{result.get('confidence', 0):.1%}")
            with col2:
                st.metric("Sources", result.get('papers_found', 0))
            with col3:
                st.metric("Search Time", f"{result.get('search_time', 0):.2f}s")
            with col4:
                quality = "High" if result.get('confidence', 0) > 0.7 else "Medium" if result.get('confidence', 0) > 0.4 else "Low"
                st.metric("Answer Quality", quality)
            
            # Answer
            st.subheader("ğŸ¯ Answer")
            st.write(result['answer'])
            
            # Sources
            if result.get('sources'):
                st.subheader("ğŸ“š Sources")
                
                for i, source in enumerate(result['sources'], 1):
                    with st.expander(f"Source {i}: {source['title']} (Relevance: {source.get('relevance_score', 0):.1%})"):
                        st.write(f"**Authors:** {', '.join(source['authors'])}")
                        st.write(f"**Venue:** {source['venue']}")
    
    with tab3:
        st.header("ğŸ“„ Literature Review Generation")
        
        review_topic = st.text_input(
            "Review Topic",
            placeholder="Enter a research topic for literature review (e.g., 'machine learning in healthcare')"
        )
        
        max_papers = st.slider("Maximum Papers to Include", 5, 50, 15)
        
        if st.button("ğŸ“ Generate Review"):
            if review_topic:
                with st.spinner("Generating literature review..."):
                    review_result = assistant.generate_literature_review(review_topic)
                    
                    if review_result:
                        st.subheader(f"ğŸ“„ Literature Review: {review_topic}")
                        
                        # Review metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Papers Analyzed", review_result.get('paper_count', 0))
                        with col2:
                            st.metric("Key Themes", len(review_result.get('key_themes', [])))
                        with col3:
                            st.metric("Generation Time", f"{review_result.get('search_time', 0):.2f}s")
                        
                        # Review content
                        st.write(review_result['review'])
                        
                        # Key themes
                        if review_result.get('key_themes'):
                            st.subheader("ğŸ”‘ Key Themes")
                            
                            themes_col1, themes_col2 = st.columns(2)
                            for i, theme in enumerate(review_result['key_themes']):
                                if i % 2 == 0:
                                    themes_col1.write(f"â€¢ {theme}")
                                else:
                                    themes_col2.write(f"â€¢ {theme}")
            else:
                st.warning("Please enter a review topic")
    
    with tab4:
        st.header("ğŸ“Š Research Analytics")
        
        if st.button("ğŸ“ˆ Generate Analytics"):
            with st.spinner("Analyzing research collection..."):
                analytics = assistant.get_research_analytics()
                
                if 'error' not in analytics:
                    # Key metrics
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Total Papers", analytics.get('total_papers', 0))
                    with col2:
                        citation_metrics = analytics.get('citation_metrics', {})
                        st.metric("Total Citations", citation_metrics.get('total_citations', 0))
                    with col3:
                        avg_cites = citation_metrics.get('average_citations_per_paper', 0)
                        st.metric("Avg Citations/Paper", f"{avg_cites:.1f}")
                    
                    # Field distribution
                    if analytics.get('field_distribution'):
                        st.subheader("ğŸ“Š Research Field Distribution")
                        
                        fields_df = pd.DataFrame(
                            list(analytics['field_distribution'].items()),
                            columns=['Field', 'Count']
                        )
                        fields_df['Field'] = fields_df['Field'].str.replace('_', ' ').str.title()
                        
                        fig = px.pie(fields_df, values='Count', names='Field', 
                                   title='Papers by Research Field')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Publication timeline
                    if analytics.get('publication_timeline'):
                        st.subheader("ğŸ“… Publication Timeline")
                        
                        timeline_df = pd.DataFrame(
                            list(analytics['publication_timeline'].items()),
                            columns=['Year', 'Papers']
                        )
                        
                        fig = px.line(timeline_df, x='Year', y='Papers', 
                                    title='Papers Published Over Time',
                                    markers=True)
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Top venues
                    if analytics.get('venue_distribution'):
                        st.subheader("ğŸ›ï¸ Top Publication Venues")
                        
                        venues_df = pd.DataFrame(
                            list(analytics['venue_distribution'].items()),
                            columns=['Venue', 'Papers']
                        )
                        
                        fig = px.bar(venues_df, x='Papers', y='Venue', orientation='h',
                                   title='Most Active Publication Venues')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Impact metrics
                    citation_metrics = analytics.get('citation_metrics', {})
                    if citation_metrics.get('most_influential_pagerank'):
                        st.subheader("â­ Most Influential Papers (PageRank)")
                        
                        for i, paper in enumerate(citation_metrics['most_influential_pagerank'][:5], 1):
                            st.write(f"{i}. **{paper['title']}** (Score: {paper['score']:.4f})")
                else:
                    st.error(analytics['error'])
    
    with tab5:
        st.header("âš™ï¸ Data Management")
        
        # Database statistics
        st.subheader("ğŸ’¾ Database Status")
        
        papers_data = assistant.database.get_all_papers()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Papers in Database", len(papers_data))
        with col2:
            # Calculate total abstracts length
            total_text = sum(len(paper.get('abstract', '') + paper.get('full_text', '')) for paper in papers_data)
            st.metric("Total Text (chars)", f"{total_text:,}")
        with col3:
            # Estimate database size
            db_size = len(str(papers_data)) * 1.5  # Rough estimate
            st.metric("Est. DB Size", f"{db_size/1024/1024:.1f} MB")
        
        # Recent papers
        if papers_data:
            st.subheader("ğŸ“‹ Recent Papers")
            
            # Sort by creation date
            sorted_papers = sorted(papers_data, 
                                 key=lambda x: x.get('created_at', ''), 
                                 reverse=True)[:10]
            
            for paper in sorted_papers:
                authors = json.loads(paper.get('authors', '[]'))
                st.write(f"â€¢ **{paper['title']}** - {', '.join(authors[:2])}{'...' if len(authors) > 2 else ''}")
        
        # Data management actions
        st.subheader("ğŸ”§ Management Actions")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ—‘ï¸ Clear Database", type="secondary"):
                if st.button("Confirm Clear Database", type="primary"):
                    # Would implement database clearing
                    st.warning("Database clearing would be implemented here")
        
        with col2:
            if st.button("ğŸ“Š Rebuild Search Index"):
                with st.spinner("Rebuilding search index..."):
                    assistant._load_existing_papers()
                    st.success("Search index rebuilt!")
        
        # Import settings
        st.subheader("ğŸ“¥ Import Settings")
        
        auto_summarize = st.checkbox("Auto-generate summaries for imported papers", True)
        max_import_batch = st.number_input("Maximum papers per import batch", 1, 100, 20)
        
        # Export options
        st.subheader("ğŸ“¤ Export Options")
        
        if st.button("ğŸ“„ Export Papers as JSON"):
            if papers_data:
                json_data = json.dumps(papers_data, indent=2, default=str)
                st.download_button(
                    label="Download JSON",
                    data=json_data,
                    file_name=f"research_papers_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json"
                )
            else:
                st.info("No papers to export")

if __name__ == "__main__":
    main()
````

## Project Summary

The Scientific Research Assistant Agent revolutionizes research workflows through intelligent paper discovery, automated summarization, and RAG-powered question answering that transforms how researchers access, analyze, and synthesize scientific knowledge across domains.

### Key Value Propositions:
- **Intelligent Discovery**: Semantic search across scientific literature with relevance scoring
- **Automated Analysis**: AI-powered paper summarization and key insight extraction  
- **Knowledge Synthesis**: RAG-based question answering with source attribution
- **Research Intelligence**: Citation analysis and trend identification for strategic insights

### Technical Architecture:
The system integrates transformer-based embedding models for semantic search, ChromaDB/FAISS for scalable vector storage, LangChain for RAG workflows, and NetworkX for citation analysis, creating a comprehensive research platform that accelerates scientific discovery through intelligent automation while maintaining accuracy and scholarly rigor in knowledge extraction and synthesis processes.