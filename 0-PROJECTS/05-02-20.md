<small>Claude Sonnet 4 **(DevOps Deployment Agent)**</small>
# DevOps Deployment Agent

## Key Concepts Explanation

### CI/CD Pipeline Integration
Automated Continuous Integration and Continuous Deployment orchestration that interfaces with popular platforms like Jenkins, GitLab CI, GitHub Actions, and Azure DevOps to manage build, test, and deployment workflows while providing intelligent decision-making capabilities for deployment strategies and rollback procedures.

### Intelligent Shell Command Execution
Secure and context-aware execution of system commands, scripts, and deployment tools with proper privilege management, command validation, output parsing, and error handling that enables automated infrastructure management while maintaining security boundaries and audit trails.

### Infrastructure Monitoring and Observability
Real-time monitoring of deployed applications, infrastructure health, performance metrics, and deployment status through integration with monitoring tools like Prometheus, Grafana, DataDog, and custom health checks while providing intelligent alerting and auto-remediation capabilities.

### Deployment Strategy Automation
Intelligent management of various deployment patterns including blue-green deployments, canary releases, rolling updates, and feature flag management with automated rollback capabilities based on performance metrics, error rates, and predefined success criteria.

### Environment Management and Orchestration
Automated provisioning, configuration, and management of development, staging, and production environments using Infrastructure as Code (IaC) tools like Terraform, Ansible, and Kubernetes while ensuring consistency and compliance across all deployment targets.

## Comprehensive Project Explanation

### Objectives
The DevOps Deployment Agent streamlines and automates the entire software deployment lifecycle by providing intelligent orchestration of CI/CD pipelines, infrastructure management, and monitoring systems while reducing human error, accelerating deployment cycles, and ensuring reliable software delivery.

### Key Features
- **Pipeline Orchestration**: Automated CI/CD workflow management and optimization
- **Infrastructure Automation**: Intelligent provisioning and configuration management
- **Deployment Strategies**: Smart deployment pattern selection and execution
- **Monitoring Integration**: Real-time observability and performance tracking
- **Auto-remediation**: Intelligent incident response and rollback mechanisms

### Challenges
- **Security Management**: Ensuring secure execution of privileged operations
- **Environment Complexity**: Managing heterogeneous infrastructure and deployment targets
- **Integration Complexity**: Coordinating multiple tools and platforms in the DevOps toolchain
- **Reliability Requirements**: Maintaining high availability during deployments and operations

### Potential Impact
This system transforms DevOps practices by reducing deployment time from hours to minutes, minimizing human error through automation, enabling rapid iteration cycles, improving system reliability through intelligent monitoring, and allowing teams to focus on development rather than operational overhead.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
langchain==0.1.0
langchain-openai==0.0.5
docker==6.1.3
kubernetes==28.1.0
ansible-runner==2.3.4
paramiko==3.3.1
psutil==5.9.6
prometheus-client==0.19.0
requests==2.31.0
pydantic==2.5.0
pyyaml==6.0.1
jinja2==3.1.2
gitpython==3.1.40
pandas==2.1.4
plotly==5.17.0
schedule==1.2.0
sqlite3
subprocess
asyncio
threading
json
datetime
logging
os
pathlib
uuid
typing
dataclasses
enum
````

### Core Implementation

````python
import os
import json
import logging
import sqlite3
import subprocess
import asyncio
import threading
import uuid
import schedule
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import yaml
import docker
import paramiko
import psutil
import requests
from git import Repo
from kubernetes import client, config
from jinja2 import Template

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import BaseMessage
from pydantic import BaseModel, Field

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DeploymentStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"
    CANCELLED = "cancelled"

class DeploymentStrategy(Enum):
    ROLLING_UPDATE = "rolling_update"
    BLUE_GREEN = "blue_green"
    CANARY = "canary"
    RECREATE = "recreate"
    A_B_TESTING = "a_b_testing"

class Environment(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    TESTING = "testing"

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class DeploymentConfig:
    app_name: str
    version: str
    environment: Environment
    strategy: DeploymentStrategy
    image_url: str
    replicas: int = 3
    resources: Dict[str, Any] = field(default_factory=dict)
    environment_vars: Dict[str, str] = field(default_factory=dict)
    health_check_path: str = "/health"
    rollback_on_failure: bool = True
    max_unavailable: int = 1
    max_surge: int = 1

@dataclass
class PipelineStep:
    step_id: str
    name: str
    command: str
    environment: Dict[str, str] = field(default_factory=dict)
    timeout: int = 300
    retry_count: int = 3
    depends_on: List[str] = field(default_factory=list)
    condition: Optional[str] = None

@dataclass
class Pipeline:
    pipeline_id: str
    name: str
    repository_url: str
    branch: str
    steps: List[PipelineStep]
    triggers: List[str] = field(default_factory=list)
    environment: Environment = Environment.DEVELOPMENT
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class DeploymentRecord:
    deployment_id: str
    app_name: str
    version: str
    environment: Environment
    strategy: DeploymentStrategy
    status: DeploymentStatus
    started_at: datetime
    completed_at: Optional[datetime] = None
    logs: List[str] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)
    rollback_deployment_id: Optional[str] = None

@dataclass
class MonitoringAlert:
    alert_id: str
    service_name: str
    metric_name: str
    severity: AlertSeverity
    message: str
    threshold: float
    current_value: float
    timestamp: datetime = field(default_factory=datetime.now)
    resolved: bool = False

class CommandExecutor:
    """Secure command execution with proper error handling."""
    
    def __init__(self, working_directory: str = "/tmp"):
        self.working_directory = Path(working_directory)
        self.working_directory.mkdir(exist_ok=True)
        self.allowed_commands = {
            'git', 'docker', 'kubectl', 'terraform', 'ansible-playbook',
            'npm', 'yarn', 'pip', 'python', 'mvn', 'gradle', 'make'
        }
    
    def execute_command(self, command: str, environment: Dict[str, str] = None, 
                       timeout: int = 300) -> Tuple[bool, str, str]:
        """Execute a command securely with validation."""
        try:
            # Validate command
            cmd_parts = command.split()
            if not cmd_parts or cmd_parts[0] not in self.allowed_commands:
                return False, "", f"Command '{cmd_parts[0] if cmd_parts else 'empty'}' not allowed"
            
            # Prepare environment
            env = os.environ.copy()
            if environment:
                env.update(environment)
            
            # Execute command
            logger.info(f"Executing command: {command}")
            
            process = subprocess.Popen(
                command,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=self.working_directory,
                env=env,
                text=True
            )
            
            try:
                stdout, stderr = process.communicate(timeout=timeout)
                success = process.returncode == 0
                
                logger.info(f"Command completed with return code: {process.returncode}")
                return success, stdout, stderr
            
            except subprocess.TimeoutExpired:
                process.kill()
                return False, "", f"Command timed out after {timeout} seconds"
        
        except Exception as e:
            logger.error(f"Command execution error: {e}")
            return False, "", str(e)
    
    async def execute_command_async(self, command: str, environment: Dict[str, str] = None,
                                   timeout: int = 300) -> Tuple[bool, str, str]:
        """Execute command asynchronously."""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, self.execute_command, command, environment, timeout
        )

class DockerManager:
    """Docker container and image management."""
    
    def __init__(self):
        try:
            self.client = docker.from_env()
        except Exception as e:
            logger.error(f"Docker client initialization failed: {e}")
            self.client = None
    
    def build_image(self, dockerfile_path: str, tag: str, build_args: Dict[str, str] = None) -> bool:
        """Build Docker image."""
        try:
            if not self.client:
                return False
            
            logger.info(f"Building Docker image: {tag}")
            
            image, logs = self.client.images.build(
                path=str(Path(dockerfile_path).parent),
                dockerfile=Path(dockerfile_path).name,
                tag=tag,
                buildargs=build_args or {},
                rm=True
            )
            
            logger.info(f"Image built successfully: {image.id}")
            return True
        
        except Exception as e:
            logger.error(f"Docker image build failed: {e}")
            return False
    
    def push_image(self, tag: str, registry_auth: Dict[str, str] = None) -> bool:
        """Push image to registry."""
        try:
            if not self.client:
                return False
            
            logger.info(f"Pushing image: {tag}")
            
            # Login if auth provided
            if registry_auth:
                self.client.login(**registry_auth)
            
            self.client.images.push(tag)
            logger.info(f"Image pushed successfully: {tag}")
            return True
        
        except Exception as e:
            logger.error(f"Docker image push failed: {e}")
            return False
    
    def get_containers(self, filters: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """Get container information."""
        try:
            if not self.client:
                return []
            
            containers = self.client.containers.list(all=True, filters=filters)
            
            return [
                {
                    "id": container.id[:12],
                    "name": container.name,
                    "image": container.image.tags[0] if container.image.tags else "unknown",
                    "status": container.status,
                    "ports": container.ports,
                    "created": container.attrs['Created']
                }
                for container in containers
            ]
        
        except Exception as e:
            logger.error(f"Error getting containers: {e}")
            return []

class KubernetesManager:
    """Kubernetes cluster management."""
    
    def __init__(self, kubeconfig_path: Optional[str] = None):
        try:
            if kubeconfig_path:
                config.load_kube_config(config_file=kubeconfig_path)
            else:
                config.load_incluster_config()
            
            self.v1 = client.CoreV1Api()
            self.apps_v1 = client.AppsV1Api()
            self.available = True
        
        except Exception as e:
            logger.error(f"Kubernetes client initialization failed: {e}")
            self.available = False
    
    def deploy_application(self, deployment_config: DeploymentConfig) -> bool:
        """Deploy application to Kubernetes."""
        try:
            if not self.available:
                return False
            
            # Create deployment manifest
            deployment = self._create_deployment_manifest(deployment_config)
            
            # Create or update deployment
            try:
                existing = self.apps_v1.read_namespaced_deployment(
                    name=deployment_config.app_name,
                    namespace="default"
                )
                
                # Update existing deployment
                deployment.metadata.resource_version = existing.metadata.resource_version
                self.apps_v1.patch_namespaced_deployment(
                    name=deployment_config.app_name,
                    namespace="default",
                    body=deployment
                )
                logger.info(f"Updated deployment: {deployment_config.app_name}")
            
            except client.exceptions.ApiException as e:
                if e.status == 404:
                    # Create new deployment
                    self.apps_v1.create_namespaced_deployment(
                        namespace="default",
                        body=deployment
                    )
                    logger.info(f"Created deployment: {deployment_config.app_name}")
                else:
                    raise
            
            # Create service if it doesn't exist
            self._ensure_service_exists(deployment_config)
            
            return True
        
        except Exception as e:
            logger.error(f"Kubernetes deployment failed: {e}")
            return False
    
    def _create_deployment_manifest(self, config: DeploymentConfig) -> client.V1Deployment:
        """Create Kubernetes deployment manifest."""
        container = client.V1Container(
            name=config.app_name,
            image=config.image_url,
            ports=[client.V1ContainerPort(container_port=8080)],
            env=[
                client.V1EnvVar(name=key, value=value)
                for key, value in config.environment_vars.items()
            ],
            resources=client.V1ResourceRequirements(
                requests=config.resources.get("requests", {}),
                limits=config.resources.get("limits", {})
            ),
            liveness_probe=client.V1Probe(
                http_get=client.V1HTTPGetAction(
                    path=config.health_check_path,
                    port=8080
                ),
                initial_delay_seconds=30,
                period_seconds=10
            )
        )
        
        pod_spec = client.V1PodSpec(containers=[container])
        
        pod_template = client.V1PodTemplateSpec(
            metadata=client.V1ObjectMeta(
                labels={"app": config.app_name, "version": config.version}
            ),
            spec=pod_spec
        )
        
        deployment_spec = client.V1DeploymentSpec(
            replicas=config.replicas,
            selector=client.V1LabelSelector(
                match_labels={"app": config.app_name}
            ),
            template=pod_template,
            strategy=client.V1DeploymentStrategy(
                type="RollingUpdate",
                rolling_update=client.V1RollingUpdateDeployment(
                    max_unavailable=config.max_unavailable,
                    max_surge=config.max_surge
                )
            )
        )
        
        return client.V1Deployment(
            api_version="apps/v1",
            kind="Deployment",
            metadata=client.V1ObjectMeta(
                name=config.app_name,
                labels={"app": config.app_name}
            ),
            spec=deployment_spec
        )
    
    def _ensure_service_exists(self, config: DeploymentConfig):
        """Ensure service exists for the deployment."""
        try:
            self.v1.read_namespaced_service(
                name=f"{config.app_name}-service",
                namespace="default"
            )
        except client.exceptions.ApiException as e:
            if e.status == 404:
                # Create service
                service = client.V1Service(
                    api_version="v1",
                    kind="Service",
                    metadata=client.V1ObjectMeta(
                        name=f"{config.app_name}-service",
                        labels={"app": config.app_name}
                    ),
                    spec=client.V1ServiceSpec(
                        selector={"app": config.app_name},
                        ports=[
                            client.V1ServicePort(
                                name="http",
                                port=80,
                                target_port=8080
                            )
                        ],
                        type="ClusterIP"
                    )
                )
                
                self.v1.create_namespaced_service(
                    namespace="default",
                    body=service
                )
                logger.info(f"Created service: {config.app_name}-service")
    
    def get_deployment_status(self, app_name: str) -> Dict[str, Any]:
        """Get deployment status."""
        try:
            if not self.available:
                return {"error": "Kubernetes not available"}
            
            deployment = self.apps_v1.read_namespaced_deployment(
                name=app_name,
                namespace="default"
            )
            
            return {
                "name": deployment.metadata.name,
                "replicas": deployment.spec.replicas,
                "ready_replicas": deployment.status.ready_replicas or 0,
                "updated_replicas": deployment.status.updated_replicas or 0,
                "available_replicas": deployment.status.available_replicas or 0,
                "conditions": [
                    {
                        "type": condition.type,
                        "status": condition.status,
                        "reason": condition.reason,
                        "message": condition.message
                    }
                    for condition in (deployment.status.conditions or [])
                ]
            }
        
        except Exception as e:
            logger.error(f"Error getting deployment status: {e}")
            return {"error": str(e)}

class MonitoringSystem:
    """Application and infrastructure monitoring."""
    
    def __init__(self):
        self.metrics_store = {}
        self.alerts = []
        self.thresholds = {
            "cpu_usage": 80.0,
            "memory_usage": 85.0,
            "response_time": 1000.0,  # ms
            "error_rate": 5.0  # %
        }
    
    def collect_system_metrics(self) -> Dict[str, float]:
        """Collect system metrics."""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            metrics = {
                "cpu_usage": cpu_percent,
                "memory_usage": memory.percent,
                "disk_usage": disk.percent,
                "timestamp": datetime.now().timestamp()
            }
            
            # Store metrics
            self.metrics_store[datetime.now().isoformat()] = metrics
            
            # Check thresholds
            self._check_thresholds(metrics)
            
            return metrics
        
        except Exception as e:
            logger.error(f"Error collecting system metrics: {e}")
            return {}
    
    def collect_application_metrics(self, app_name: str, health_check_url: str) -> Dict[str, Any]:
        """Collect application-specific metrics."""
        try:
            start_time = time.time()
            
            # Health check
            response = requests.get(health_check_url, timeout=10)
            response_time = (time.time() - start_time) * 1000  # ms
            
            metrics = {
                "app_name": app_name,
                "status_code": response.status_code,
                "response_time": response_time,
                "is_healthy": response.status_code == 200,
                "timestamp": datetime.now().timestamp()
            }
            
            # Store metrics
            self.metrics_store[f"{app_name}_{datetime.now().isoformat()}"] = metrics
            
            # Check application thresholds
            if response_time > self.thresholds["response_time"]:
                self._create_alert(
                    app_name,
                    "response_time",
                    AlertSeverity.WARNING,
                    f"High response time: {response_time:.2f}ms",
                    self.thresholds["response_time"],
                    response_time
                )
            
            return metrics
        
        except Exception as e:
            logger.error(f"Error collecting application metrics for {app_name}: {e}")
            return {"error": str(e)}
    
    def _check_thresholds(self, metrics: Dict[str, float]):
        """Check metrics against thresholds and create alerts."""
        for metric_name, value in metrics.items():
            if metric_name in self.thresholds and value > self.thresholds[metric_name]:
                severity = AlertSeverity.WARNING
                if value > self.thresholds[metric_name] * 1.2:
                    severity = AlertSeverity.ERROR
                
                self._create_alert(
                    "system",
                    metric_name,
                    severity,
                    f"High {metric_name}: {value:.2f}%",
                    self.thresholds[metric_name],
                    value
                )
    
    def _create_alert(self, service_name: str, metric_name: str, severity: AlertSeverity,
                     message: str, threshold: float, current_value: float):
        """Create monitoring alert."""
        alert = MonitoringAlert(
            alert_id=str(uuid.uuid4()),
            service_name=service_name,
            metric_name=metric_name,
            severity=severity,
            message=message,
            threshold=threshold,
            current_value=current_value
        )
        
        self.alerts.append(alert)
        logger.warning(f"Alert created: {alert.message}")
    
    def get_recent_metrics(self, hours: int = 24) -> List[Dict[str, Any]]:
        """Get metrics from the last N hours."""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        recent_metrics = []
        for timestamp_str, metrics in self.metrics_store.items():
            try:
                timestamp = datetime.fromisoformat(timestamp_str.split('_')[-1])
                if timestamp > cutoff_time:
                    metrics["timestamp_str"] = timestamp_str
                    recent_metrics.append(metrics)
            except:
                continue
        
        return sorted(recent_metrics, key=lambda x: x.get("timestamp", 0))
    
    def get_active_alerts(self) -> List[MonitoringAlert]:
        """Get currently active alerts."""
        return [alert for alert in self.alerts if not alert.resolved]

class CICDPipeline:
    """CI/CD pipeline management."""
    
    def __init__(self, command_executor: CommandExecutor):
        self.command_executor = command_executor
        self.running_pipelines = {}
    
    async def execute_pipeline(self, pipeline: Pipeline) -> bool:
        """Execute a CI/CD pipeline."""
        try:
            logger.info(f"Starting pipeline: {pipeline.name}")
            
            # Clone repository
            repo_success = await self._clone_repository(pipeline.repository_url, pipeline.branch)
            if not repo_success:
                return False
            
            # Execute steps in order
            for step in pipeline.steps:
                # Check dependencies
                if not self._check_step_dependencies(step, pipeline):
                    logger.error(f"Step dependencies not met: {step.name}")
                    return False
                
                # Execute step
                step_success = await self._execute_step(step)
                if not step_success:
                    logger.error(f"Step failed: {step.name}")
                    return False
            
            logger.info(f"Pipeline completed successfully: {pipeline.name}")
            return True
        
        except Exception as e:
            logger.error(f"Pipeline execution error: {e}")
            return False
    
    async def _clone_repository(self, repository_url: str, branch: str) -> bool:
        """Clone repository for pipeline execution."""
        try:
            clone_command = f"git clone -b {branch} {repository_url} ./repo"
            success, stdout, stderr = await self.command_executor.execute_command_async(clone_command)
            
            if success:
                # Change working directory to repo
                self.command_executor.working_directory = self.command_executor.working_directory / "repo"
                return True
            else:
                logger.error(f"Repository clone failed: {stderr}")
                return False
        
        except Exception as e:
            logger.error(f"Repository clone error: {e}")
            return False
    
    async def _execute_step(self, step: PipelineStep) -> bool:
        """Execute a pipeline step with retries."""
        for attempt in range(step.retry_count + 1):
            try:
                logger.info(f"Executing step: {step.name} (attempt {attempt + 1})")
                
                success, stdout, stderr = await self.command_executor.execute_command_async(
                    step.command,
                    step.environment,
                    step.timeout
                )
                
                if success:
                    logger.info(f"Step completed: {step.name}")
                    return True
                else:
                    logger.warning(f"Step failed (attempt {attempt + 1}): {step.name} - {stderr}")
                    if attempt < step.retry_count:
                        await asyncio.sleep(5)  # Wait before retry
            
            except Exception as e:
                logger.error(f"Step execution error: {e}")
        
        return False
    
    def _check_step_dependencies(self, step: PipelineStep, pipeline: Pipeline) -> bool:
        """Check if step dependencies are satisfied."""
        # In a real implementation, this would check if dependent steps completed successfully
        return True

class DeploymentManager:
    """Main deployment orchestration."""
    
    def __init__(self, llm: Optional[ChatOpenAI] = None):
        self.llm = llm
        self.command_executor = CommandExecutor()
        self.docker_manager = DockerManager()
        self.k8s_manager = KubernetesManager()
        self.monitoring_system = MonitoringSystem()
        self.cicd_pipeline = CICDPipeline(self.command_executor)
        self.database = self._init_database()
        self._initialize_prompts()
    
    def _init_database(self) -> sqlite3.Connection:
        """Initialize deployment database."""
        db = sqlite3.connect("deployments.db", check_same_thread=False)
        cursor = db.cursor()
        
        # Deployments table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS deployments (
                deployment_id TEXT PRIMARY KEY,
                app_name TEXT,
                version TEXT,
                environment TEXT,
                strategy TEXT,
                status TEXT,
                started_at TEXT,
                completed_at TEXT,
                logs TEXT
            )
        """)
        
        # Pipelines table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pipelines (
                pipeline_id TEXT PRIMARY KEY,
                name TEXT,
                repository_url TEXT,
                branch TEXT,
                environment TEXT,
                created_at TEXT,
                config TEXT
            )
        """)
        
        db.commit()
        return db
    
    def _initialize_prompts(self):
        """Initialize AI prompts for deployment decisions."""
        if self.llm:
            self.deployment_strategy_prompt = ChatPromptTemplate.from_template("""
            You are a DevOps expert. Based on the following deployment context, recommend the best deployment strategy:
            
            Application: {app_name}
            Environment: {environment}
            Current Version: {current_version}
            New Version: {new_version}
            Risk Tolerance: {risk_tolerance}
            Traffic Pattern: {traffic_pattern}
            Rollback Requirements: {rollback_requirements}
            
            Available strategies:
            1. Rolling Update - Gradual replacement of instances
            2. Blue-Green - Complete environment switch
            3. Canary - Small percentage traffic routing
            4. Recreate - Complete shutdown and restart
            
            Recommend a strategy and explain your reasoning:
            """)
    
    async def deploy_application(self, deployment_config: DeploymentConfig) -> str:
        """Deploy application with specified configuration."""
        try:
            deployment_id = str(uuid.uuid4())
            
            # Create deployment record
            deployment_record = DeploymentRecord(
                deployment_id=deployment_id,
                app_name=deployment_config.app_name,
                version=deployment_config.version,
                environment=deployment_config.environment,
                strategy=deployment_config.strategy,
                status=DeploymentStatus.RUNNING,
                started_at=datetime.now()
            )
            
            # Save to database
            self._save_deployment_record(deployment_record)
            
            # Execute deployment based on strategy
            success = False
            
            if deployment_config.strategy == DeploymentStrategy.ROLLING_UPDATE:
                success = await self._rolling_update_deployment(deployment_config)
            elif deployment_config.strategy == DeploymentStrategy.BLUE_GREEN:
                success = await self._blue_green_deployment(deployment_config)
            elif deployment_config.strategy == DeploymentStrategy.CANARY:
                success = await self._canary_deployment(deployment_config)
            else:
                success = await self._recreate_deployment(deployment_config)
            
            # Update deployment status
            deployment_record.status = DeploymentStatus.SUCCESS if success else DeploymentStatus.FAILED
            deployment_record.completed_at = datetime.now()
            
            if not success and deployment_config.rollback_on_failure:
                await self._rollback_deployment(deployment_id)
                deployment_record.status = DeploymentStatus.ROLLED_BACK
            
            self._save_deployment_record(deployment_record)
            
            return deployment_id
        
        except Exception as e:
            logger.error(f"Deployment error: {e}")
            raise
    
    async def _rolling_update_deployment(self, config: DeploymentConfig) -> bool:
        """Execute rolling update deployment."""
        try:
            logger.info(f"Starting rolling update deployment for {config.app_name}")
            
            # Deploy to Kubernetes with rolling update strategy
            success = self.k8s_manager.deploy_application(config)
            
            if success:
                # Monitor deployment progress
                await self._monitor_deployment_progress(config.app_name)
            
            return success
        
        except Exception as e:
            logger.error(f"Rolling update deployment error: {e}")
            return False
    
    async def _blue_green_deployment(self, config: DeploymentConfig) -> bool:
        """Execute blue-green deployment."""
        try:
            logger.info(f"Starting blue-green deployment for {config.app_name}")
            
            # Create green environment
            green_config = config
            green_config.app_name = f"{config.app_name}-green"
            
            # Deploy to green environment
            success = self.k8s_manager.deploy_application(green_config)
            
            if success:
                # Wait for green environment to be ready
                await asyncio.sleep(30)
                
                # Health check green environment
                health_url = f"http://{green_config.app_name}-service{config.health_check_path}"
                metrics = self.monitoring_system.collect_application_metrics(
                    green_config.app_name, health_url
                )
                
                if metrics.get("is_healthy"):
                    # Switch traffic (in real scenario, this would update load balancer)
                    logger.info("Switching traffic to green environment")
                    return True
                else:
                    logger.error("Green environment health check failed")
                    return False
            
            return False
        
        except Exception as e:
            logger.error(f"Blue-green deployment error: {e}")
            return False
    
    async def _canary_deployment(self, config: DeploymentConfig) -> bool:
        """Execute canary deployment."""
        try:
            logger.info(f"Starting canary deployment for {config.app_name}")
            
            # Deploy canary version with reduced replicas
            canary_config = config
            canary_config.replicas = max(1, config.replicas // 5)  # 20% traffic
            canary_config.app_name = f"{config.app_name}-canary"
            
            success = self.k8s_manager.deploy_application(canary_config)
            
            if success:
                # Monitor canary for issues
                await self._monitor_canary_deployment(canary_config)
                
                # If no issues, proceed with full deployment
                return self.k8s_manager.deploy_application(config)
            
            return False
        
        except Exception as e:
            logger.error(f"Canary deployment error: {e}")
            return False
    
    async def _recreate_deployment(self, config: DeploymentConfig) -> bool:
        """Execute recreate deployment."""
        try:
            logger.info(f"Starting recreate deployment for {config.app_name}")
            
            # Simply deploy with recreate strategy
            return self.k8s_manager.deploy_application(config)
        
        except Exception as e:
            logger.error(f"Recreate deployment error: {e}")
            return False
    
    async def _monitor_deployment_progress(self, app_name: str, timeout: int = 300):
        """Monitor deployment progress."""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            status = self.k8s_manager.get_deployment_status(app_name)
            
            if "error" in status:
                break
            
            ready_replicas = status.get("ready_replicas", 0)
            desired_replicas = status.get("replicas", 0)
            
            if ready_replicas == desired_replicas and ready_replicas > 0:
                logger.info(f"Deployment completed: {app_name}")
                break
            
            logger.info(f"Deployment progress: {ready_replicas}/{desired_replicas} replicas ready")
            await asyncio.sleep(10)
    
    async def _monitor_canary_deployment(self, config: DeploymentConfig, duration: int = 300):
        """Monitor canary deployment for issues."""
        start_time = time.time()
        
        while time.time() - start_time < duration:
            # Collect metrics
            health_url = f"http://{config.app_name}-service{config.health_check_path}"
            metrics = self.monitoring_system.collect_application_metrics(config.app_name, health_url)
            
            # Check for alerts
            alerts = self.monitoring_system.get_active_alerts()
            canary_alerts = [a for a in alerts if config.app_name in a.service_name]
            
            if canary_alerts:
                logger.warning(f"Canary deployment issues detected: {len(canary_alerts)} alerts")
                break
            
            await asyncio.sleep(30)
    
    async def _rollback_deployment(self, deployment_id: str):
        """Rollback a failed deployment."""
        try:
            logger.info(f"Rolling back deployment: {deployment_id}")
            
            # In a real implementation, this would:
            # 1. Find the previous successful deployment
            # 2. Restore the previous version
            # 3. Update traffic routing
            
            # For demo purposes, just log the rollback
            logger.info("Rollback completed (simulated)")
        
        except Exception as e:
            logger.error(f"Rollback error: {e}")
    
    def _save_deployment_record(self, record: DeploymentRecord):
        """Save deployment record to database."""
        try:
            cursor = self.database.cursor()
            cursor.execute("""
                INSERT OR REPLACE INTO deployments
                (deployment_id, app_name, version, environment, strategy, status, started_at, completed_at, logs)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                record.deployment_id,
                record.app_name,
                record.version,
                record.environment.value,
                record.strategy.value,
                record.status.value,
                record.started_at.isoformat(),
                record.completed_at.isoformat() if record.completed_at else None,
                json.dumps(record.logs)
            ))
            self.database.commit()
        
        except Exception as e:
            logger.error(f"Error saving deployment record: {e}")
    
    def get_deployment_history(self) -> List[Dict[str, Any]]:
        """Get deployment history."""
        try:
            cursor = self.database.cursor()
            cursor.execute("SELECT * FROM deployments ORDER BY started_at DESC LIMIT 50")
            
            columns = [description[0] for description in cursor.description]
            results = []
            
            for row in cursor.fetchall():
                results.append(dict(zip(columns, row)))
            
            return results
        
        except Exception as e:
            logger.error(f"Error getting deployment history: {e}")
            return []

class DevOpsAgent:
    """Main DevOps agent orchestrating all operations."""
    
    def __init__(self, openai_api_key: Optional[str] = None):
        self.llm = None
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.3,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        
        self.deployment_manager = DeploymentManager(self.llm)
        
        # Start monitoring thread
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
    
    def _monitoring_loop(self):
        """Background monitoring loop."""
        schedule.every(30).seconds.do(self._collect_metrics)
        
        while True:
            schedule.run_pending()
            time.sleep(1)
    
    def _collect_metrics(self):
        """Collect system and application metrics."""
        try:
            self.deployment_manager.monitoring_system.collect_system_metrics()
        except Exception as e:
            logger.error(f"Metrics collection error: {e}")
    
    async def deploy_application(self, config: Dict[str, Any]) -> str:
        """Deploy application with configuration."""
        deployment_config = DeploymentConfig(**config)
        return await self.deployment_manager.deploy_application(deployment_config)
    
    async def execute_pipeline(self, pipeline_config: Dict[str, Any]) -> bool:
        """Execute CI/CD pipeline."""
        pipeline = Pipeline(**pipeline_config)
        return await self.deployment_manager.cicd_pipeline.execute_pipeline(pipeline)
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get overall system status."""
        try:
            # Get system metrics
            metrics = self.deployment_manager.monitoring_system.collect_system_metrics()
            
            # Get active alerts
            alerts = self.deployment_manager.monitoring_system.get_active_alerts()
            
            # Get deployment history
            recent_deployments = self.deployment_manager.get_deployment_history()[:10]
            
            # Get container status
            containers = self.deployment_manager.docker_manager.get_containers()
            
            return {
                "system_metrics": metrics,
                "active_alerts": len(alerts),
                "recent_deployments": len(recent_deployments),
                "running_containers": len([c for c in containers if c["status"] == "running"]),
                "timestamp": datetime.now().isoformat()
            }
        
        except Exception as e:
            logger.error(f"Error getting system status: {e}")
            return {"error": str(e)}

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="DevOps Deployment Agent",
        page_icon="üöÄ",
        layout="wide"
    )
    
    st.title("üöÄ DevOps Deployment Agent")
    st.markdown("**AI-powered CI/CD orchestration, deployment automation, and infrastructure monitoring**")
    
    # Initialize session state
    if 'agent' not in st.session_state:
        st.session_state['agent'] = None
    if 'deployment_status' not in st.session_state:
        st.session_state['deployment_status'] = {}
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        openai_key = st.text_input("OpenAI API Key (Optional)", type="password", 
                                  help="For AI-powered deployment decisions")
        
        if st.button("Initialize Agent"):
            try:
                st.session_state['agent'] = DevOpsAgent(openai_key)
                st.success("DevOps Agent initialized!")
            except Exception as e:
                st.error(f"Initialization failed: {e}")
        
        st.header("üîß System Status")
        if st.session_state['agent']:
            status = st.session_state['agent'].get_system_status()
            if "error" not in status:
                st.metric("CPU Usage", f"{status['system_metrics'].get('cpu_usage', 0):.1f}%")
                st.metric("Memory Usage", f"{status['system_metrics'].get('memory_usage', 0):.1f}%")
                st.metric("Active Alerts", status.get('active_alerts', 0))
                st.metric("Running Containers", status.get('running_containers', 0))
    
    if not st.session_state['agent']:
        st.info("üëà Please initialize the DevOps Agent")
        return
    
    agent = st.session_state['agent']
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üöÄ Deploy", "‚öôÔ∏è Pipelines", "üìä Monitoring", "üìã History", "üîß Management"])
    
    with tab1:
        st.header("üöÄ Application Deployment")
        
        # Deployment configuration
        col1, col2 = st.columns(2)
        
        with col1:
            app_name = st.text_input("Application Name", placeholder="my-app")
            version = st.text_input("Version", placeholder="v1.2.3")
            image_url = st.text_input("Docker Image", placeholder="nginx:latest")
            environment = st.selectbox("Environment", [e.value for e in Environment])
        
        with col2:
            strategy = st.selectbox("Deployment Strategy", [s.value for s in DeploymentStrategy])
            replicas = st.number_input("Replicas", min_value=1, max_value=20, value=3)
            health_check_path = st.text_input("Health Check Path", value="/health")
            rollback_on_failure = st.checkbox("Auto-rollback on failure", True)
        
        # Resource configuration
        st.subheader("Resource Configuration")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            cpu_request = st.text_input("CPU Request", placeholder="100m")
        with col2:
            cpu_limit = st.text_input("CPU Limit", placeholder="500m")
        with col3:
            memory_request = st.text_input("Memory Request", placeholder="128Mi")
        with col4:
            memory_limit = st.text_input("Memory Limit", placeholder="512Mi")
        
        # Environment variables
        st.subheader("Environment Variables")
        env_vars_text = st.text_area(
            "Environment Variables (KEY=VALUE, one per line)",
            placeholder="NODE_ENV=production\nPORT=8080"
        )
        
        # Deploy button
        if st.button("üöÄ Deploy Application", type="primary"):
            if not all([app_name, version, image_url]):
                st.error("Please fill in all required fields")
            else:
                # Parse environment variables
                env_vars = {}
                if env_vars_text:
                    for line in env_vars_text.strip().split('\n'):
                        if '=' in line:
                            key, value = line.split('=', 1)
                            env_vars[key.strip()] = value.strip()
                
                # Prepare deployment config
                config = {
                    "app_name": app_name,
                    "version": version,
                    "environment": Environment(environment),
                    "strategy": DeploymentStrategy(strategy),
                    "image_url": image_url,
                    "replicas": replicas,
                    "resources": {
                        "requests": {
                            "cpu": cpu_request or None,
                            "memory": memory_request or None
                        },
                        "limits": {
                            "cpu": cpu_limit or None,
                            "memory": memory_limit or None
                        }
                    },
                    "environment_vars": env_vars,
                    "health_check_path": health_check_path,
                    "rollback_on_failure": rollback_on_failure
                }
                
                with st.spinner("Deploying application..."):
                    try:
                        deployment_id = asyncio.run(agent.deploy_application(config))
                        st.session_state['deployment_status'][deployment_id] = {
                            "status": "deployed",
                            "timestamp": datetime.now()
                        }
                        st.success(f"Deployment initiated! ID: {deployment_id}")
                    except Exception as e:
                        st.error(f"Deployment failed: {e}")
        
        # Recent deployments
        if st.session_state['deployment_status']:
            st.subheader("Recent Deployments")
            for dep_id, status in list(st.session_state['deployment_status'].items())[-5:]:
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    st.write(f"**{dep_id[:8]}...**")
                with col2:
                    st.write(status['status'].title())
                with col3:
                    st.write(status['timestamp'].strftime("%H:%M:%S"))
    
    with tab2:
        st.header("‚öôÔ∏è CI/CD Pipelines")
        
        # Pipeline configuration
        st.subheader("Create New Pipeline")
        
        col1, col2 = st.columns(2)
        
        with col1:
            pipeline_name = st.text_input("Pipeline Name", placeholder="build-and-deploy")
            repository_url = st.text_input("Repository URL", placeholder="https://github.com/user/repo.git")
            branch = st.text_input("Branch", value="main")
        
        with col2:
            pipeline_env = st.selectbox("Target Environment", [e.value for e in Environment], key="pipeline_env")
            triggers = st.multiselect("Triggers", ["push", "pull_request", "schedule", "manual"])
        
        # Pipeline steps
        st.subheader("Pipeline Steps")
        
        steps_text = st.text_area(
            "Pipeline Steps (YAML format)",
            value="""steps:
  - name: "Checkout Code"
    command: "git checkout HEAD"
    timeout: 60
  - name: "Install Dependencies"
    command: "npm install"
    timeout: 300
  - name: "Run Tests"
    command: "npm test"
    timeout: 600
  - name: "Build Application"
    command: "npm run build"
    timeout: 300
  - name: "Build Docker Image"
    command: "docker build -t myapp:latest ."
    timeout: 600""",
            height=200
        )
        
        if st.button("üíæ Save Pipeline"):
            if pipeline_name and repository_url:
                try:
                    # Parse steps (simplified YAML parsing)
                    steps_data = yaml.safe_load(steps_text)
                    steps = []
                    
                    for i, step_data in enumerate(steps_data.get('steps', [])):
                        step = PipelineStep(
                            step_id=str(uuid.uuid4()),
                            name=step_data['name'],
                            command=step_data['command'],
                            timeout=step_data.get('timeout', 300)
                        )
                        steps.append(step)
                    
                    pipeline = Pipeline(
                        pipeline_id=str(uuid.uuid4()),
                        name=pipeline_name,
                        repository_url=repository_url,
                        branch=branch,
                        steps=steps,
                        triggers=triggers,
                        environment=Environment(pipeline_env)
                    )
                    
                    st.success(f"Pipeline saved: {pipeline.name}")
                
                except Exception as e:
                    st.error(f"Pipeline save failed: {e}")
            else:
                st.error("Please provide pipeline name and repository URL")
        
        # Execute pipeline
        st.subheader("Execute Pipeline")
        
        col1, col2 = st.columns(2)
        
        with col1:
            exec_pipeline_name = st.text_input("Pipeline to Execute", value=pipeline_name if 'pipeline_name' in locals() else "")
        
        with col2:
            if st.button("‚ñ∂Ô∏è Execute Pipeline"):
                if exec_pipeline_name:
                    with st.spinner("Executing pipeline..."):
                        # Create a simple pipeline for demo
                        demo_pipeline = Pipeline(
                            pipeline_id=str(uuid.uuid4()),
                            name=exec_pipeline_name,
                            repository_url="https://github.com/example/demo.git",
                            branch="main",
                            steps=[
                                PipelineStep(
                                    step_id="1",
                                    name="Demo Step",
                                    command="echo 'Pipeline executed successfully'",
                                    timeout=60
                                )
                            ]
                        )
                        
                        try:
                            success = asyncio.run(agent.execute_pipeline(demo_pipeline.__dict__))
                            if success:
                                st.success("Pipeline executed successfully!")
                            else:
                                st.error("Pipeline execution failed")
                        except Exception as e:
                            st.error(f"Pipeline execution error: {e}")
    
    with tab3:
        st.header("üìä Monitoring Dashboard")
        
        # System metrics
        st.subheader("System Metrics")
        
        if st.button("üîÑ Refresh Metrics"):
            status = agent.get_system_status()
            
            if "error" not in status:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("CPU Usage", f"{status['system_metrics'].get('cpu_usage', 0):.1f}%")
                with col2:
                    st.metric("Memory Usage", f"{status['system_metrics'].get('memory_usage', 0):.1f}%")
                with col3:
                    st.metric("Disk Usage", f"{status['system_metrics'].get('disk_usage', 0):.1f}%")
                with col4:
                    st.metric("Active Alerts", status.get('active_alerts', 0))
        
        # Metrics visualization
        st.subheader("Metrics Visualization")
        
        # Get recent metrics
        monitoring_system = agent.deployment_manager.monitoring_system
        recent_metrics = monitoring_system.get_recent_metrics(hours=1)
        
        if recent_metrics:
            # Create DataFrame for plotting
            metrics_df = pd.DataFrame(recent_metrics)
            
            if not metrics_df.empty and 'timestamp' in metrics_df.columns:
                metrics_df['datetime'] = pd.to_datetime(metrics_df['timestamp'], unit='s')
                
                # CPU Usage chart
                if 'cpu_usage' in metrics_df.columns:
                    fig_cpu = px.line(metrics_df, x='datetime', y='cpu_usage', 
                                     title='CPU Usage Over Time',
                                     labels={'cpu_usage': 'CPU Usage (%)', 'datetime': 'Time'})
                    st.plotly_chart(fig_cpu, use_container_width=True)
                
                # Memory Usage chart
                if 'memory_usage' in metrics_df.columns:
                    fig_memory = px.line(metrics_df, x='datetime', y='memory_usage',
                                        title='Memory Usage Over Time',
                                        labels={'memory_usage': 'Memory Usage (%)', 'datetime': 'Time'})
                    st.plotly_chart(fig_memory, use_container_width=True)
        
        # Active alerts
        st.subheader("Active Alerts")
        
        alerts = monitoring_system.get_active_alerts()
        
        if alerts:
            for alert in alerts[-10:]:  # Show last 10 alerts
                severity_color = {
                    AlertSeverity.INFO: "üîµ",
                    AlertSeverity.WARNING: "üü°", 
                    AlertSeverity.ERROR: "üî¥",
                    AlertSeverity.CRITICAL: "üö®"
                }
                
                st.write(f"{severity_color.get(alert.severity, '‚ö™')} **{alert.service_name}** - {alert.message}")
                st.caption(f"Threshold: {alert.threshold}, Current: {alert.current_value:.2f} - {alert.timestamp.strftime('%H:%M:%S')}")
        else:
            st.info("No active alerts")
        
        # Container status
        st.subheader("Container Status")
        
        containers = agent.deployment_manager.docker_manager.get_containers()
        
        if containers:
            container_df = pd.DataFrame(containers)
            st.dataframe(container_df, use_container_width=True)
        else:
            st.info("No containers found")
    
    with tab4:
        st.header("üìã Deployment History")
        
        # Get deployment history
        history = agent.deployment_manager.get_deployment_history()
        
        if history:
            st.subheader(f"Recent Deployments ({len(history)} total)")
            
            # Convert to DataFrame for better display
            history_df = pd.DataFrame(history)
            
            # Format columns
            if not history_df.empty:
                history_df['started_at'] = pd.to_datetime(history_df['started_at'])
                history_df['duration'] = history_df.apply(
                    lambda row: (
                        pd.to_datetime(row['completed_at']) - row['started_at']
                    ).total_seconds() if row['completed_at'] else None,
                    axis=1
                )
                
                # Display summary metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    success_rate = (history_df['status'] == 'success').mean() * 100
                    st.metric("Success Rate", f"{success_rate:.1f}%")
                
                with col2:
                    avg_duration = history_df['duration'].mean()
                    st.metric("Avg Duration", f"{avg_duration:.0f}s" if pd.notna(avg_duration) else "N/A")
                
                with col3:
                    recent_deployments = len(history_df[history_df['started_at'] > datetime.now() - timedelta(days=1)])
                    st.metric("Last 24h", recent_deployments)
                
                with col4:
                    failed_deployments = len(history_df[history_df['status'] == 'failed'])
                    st.metric("Failed", failed_deployments)
                
                # Deployment timeline
                st.subheader("Deployment Timeline")
                
                fig_timeline = px.scatter(
                    history_df.head(20), 
                    x='started_at', 
                    y='app_name',
                    color='status',
                    title='Recent Deployments Timeline',
                    labels={'started_at': 'Deployment Time', 'app_name': 'Application'}
                )
                st.plotly_chart(fig_timeline, use_container_width=True)
                
                # Detailed history table
                st.subheader("Detailed History")
                
                # Select columns to display
                display_columns = ['app_name', 'version', 'environment', 'strategy', 'status', 'started_at']
                display_df = history_df[display_columns].copy()
                display_df['started_at'] = display_df['started_at'].dt.strftime('%Y-%m-%d %H:%M:%S')
                
                st.dataframe(display_df, use_container_width=True)
        else:
            st.info("No deployment history available")
    
    with tab5:
        st.header("üîß System Management")
        
        # Service status
        st.subheader("Service Status")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            docker_available = agent.deployment_manager.docker_manager.client is not None
            st.write(f"üê≥ **Docker**: {'‚úÖ Available' if docker_available else '‚ùå Unavailable'}")
        
        with col2:
            k8s_available = agent.deployment_manager.k8s_manager.available
            st.write(f"‚ò∏Ô∏è **Kubernetes**: {'‚úÖ Available' if k8s_available else '‚ùå Unavailable'}")
        
        with col3:
            monitoring_active = len(agent.deployment_manager.monitoring_system.metrics_store) > 0
            st.write(f"üìä **Monitoring**: {'‚úÖ Active' if monitoring_active else '‚ùå Inactive'}")
        
        # Configuration
        st.subheader("Configuration")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Monitoring Thresholds**")
            cpu_threshold = st.slider("CPU Usage Threshold (%)", 50, 95, 80)
            memory_threshold = st.slider("Memory Usage Threshold (%)", 60, 95, 85)
            response_time_threshold = st.slider("Response Time Threshold (ms)", 500, 5000, 1000)
        
        with col2:
            st.write("**Deployment Settings**")
            default_strategy = st.selectbox("Default Deployment Strategy", [s.value for s in DeploymentStrategy])
            auto_rollback = st.checkbox("Enable Auto-rollback", True)
            health_check_timeout = st.number_input("Health Check Timeout (s)", 30, 300, 60)
        
        # Actions
        st.subheader("System Actions")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ Restart Monitoring"):
                st.info("Monitoring service restarted")
        
        with col2:
            if st.button("üßπ Clear Metrics"):
                agent.deployment_manager.monitoring_system.metrics_store.clear()
                st.success("Metrics cleared")
        
        with col3:
            if st.button("üìä Export Logs"):
                st.info("Log export functionality would be implemented here")
        
        # System information
        st.subheader("System Information")
        
        info_data = {
            "Python Version": "3.9+",
            "Docker API": "Available" if docker_available else "Not Available",
            "Kubernetes API": "Available" if k8s_available else "Not Available",
            "Monitoring": "Active",
            "Database": "SQLite",
            "Metrics Collected": len(agent.deployment_manager.monitoring_system.metrics_store),
            "Active Alerts": len(agent.deployment_manager.monitoring_system.get_active_alerts())
        }
        
        info_df = pd.DataFrame(list(info_data.items()), columns=['Component', 'Status'])
        st.dataframe(info_df, use_container_width=True)

if __name__ == "__main__":
    main()
````

## Project Summary

The DevOps Deployment Agent revolutionizes software delivery through intelligent CI/CD orchestration, automated deployment strategies, and comprehensive monitoring that transforms complex DevOps workflows into streamlined, reliable, and scalable operations.

### Key Value Propositions:
- **Intelligent Automation**: AI-powered deployment strategy selection and pipeline optimization
- **Multi-Strategy Deployment**: Support for rolling updates, blue-green, canary, and A/B testing
- **Comprehensive Monitoring**: Real-time observability with automated alerting and remediation
- **Secure Execution**: Controlled command execution with proper validation and audit trails

### Technical Architecture:
The system integrates Docker for containerization, Kubernetes for orchestration, monitoring systems for observability, and LangChain for intelligent decision-making, creating a unified DevOps platform that accelerates deployment cycles while maintaining reliability through automated testing, monitoring, and rollback capabilities for continuous delivery excellence.