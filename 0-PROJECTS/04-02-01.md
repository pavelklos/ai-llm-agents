<small>Claude Sonnet 4 **(Legal Document Analyzer)**</small>
# Legal Document Analyzer

## Key Concepts Explanation

### Retrieval-Augmented Generation (RAG)
RAG combines information retrieval with generative AI to provide accurate, contextual responses based on specific document collections. It retrieves relevant passages from a knowledge base and uses them to generate informed answers.

### LangChain
A framework for developing applications powered by language models, providing tools for document loading, text splitting, embedding generation, and chain orchestration.

### Vector Embeddings
Mathematical representations of text that capture semantic meaning, enabling similarity search and retrieval of relevant document sections.

### PDF Parsing
The process of extracting structured text content from PDF documents while preserving formatting and metadata.

### Document Summarization
Automated generation of concise summaries that capture the key points and essential information from lengthy legal documents.

### Vector Databases
Specialized databases optimized for storing and querying high-dimensional vector embeddings, enabling fast similarity search.

## Comprehensive Project Explanation

### Objectives
The Legal Document Analyzer aims to revolutionize how legal professionals process and analyze complex documents. It provides intelligent document summarization, clause extraction, risk assessment, and natural language querying capabilities.

### Key Features
- **Intelligent Document Processing**: Automated extraction and structuring of legal content
- **Semantic Search**: Natural language queries across document collections
- **Risk Analysis**: Identification of potential legal risks and compliance issues
- **Comparative Analysis**: Side-by-side comparison of contract terms and clauses
- **Automated Summarization**: Generation of executive summaries and key points

### Challenges
- **Legal Accuracy**: Ensuring precise interpretation of complex legal language
- **Document Variety**: Handling diverse legal document formats and structures
- **Privacy & Security**: Protecting sensitive legal information
- **Scalability**: Processing large document volumes efficiently
- **Regulatory Compliance**: Adhering to legal industry standards

### Potential Impact
This system can significantly reduce legal review time, improve accuracy in document analysis, and democratize access to legal insights for smaller firms and individuals.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
langchain==0.1.0
langchain-openai==0.0.5
langchain-chroma==0.1.0
pypdf2==3.0.1
streamlit==1.29.0
python-dotenv==1.0.0
tiktoken==0.5.2
chromadb==0.4.22
openai==1.6.1
````

### Core Implementation

````python
import os
import streamlit as st
from typing import List, Dict, Any
from dataclasses import dataclass
import PyPDF2
from io import BytesIO
import logging

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain.chains.summarize import load_summarize_chain

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AnalysisResult:
    summary: str
    key_clauses: List[str]
    risk_assessment: str
    recommendations: List[str]

class LegalDocumentAnalyzer:
    def __init__(self, openai_api_key: str):
        """Initialize the Legal Document Analyzer."""
        self.openai_api_key = openai_api_key
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.llm = ChatOpenAI(
            temperature=0.1,
            model_name="gpt-4",
            openai_api_key=openai_api_key
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " "]
        )
        self.vector_store = None
        
    def extract_text_from_pdf(self, pdf_file) -> str:
        """Extract text content from PDF file."""
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            logger.error(f"Error extracting PDF text: {e}")
            raise
    
    def create_vector_store(self, documents: List[Document]) -> Chroma:
        """Create a vector store from documents."""
        try:
            chunks = self.text_splitter.split_documents(documents)
            vector_store = Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )
            return vector_store
        except Exception as e:
            logger.error(f"Error creating vector store: {e}")
            raise
    
    def summarize_document(self, text: str) -> str:
        """Generate a comprehensive summary of the legal document."""
        prompt_template = """
        Analyze the following legal document and provide a comprehensive summary:
        
        {text}
        
        Please provide:
        1. Document type and purpose
        2. Key parties involved
        3. Main terms and conditions
        4. Important dates and deadlines
        5. Financial terms (if applicable)
        
        Summary:
        """
        
        prompt = PromptTemplate(template=prompt_template, input_variables=["text"])
        
        # Split text for large documents
        docs = [Document(page_content=text)]
        chunks = self.text_splitter.split_documents(docs)
        
        if len(chunks) > 1:
            chain = load_summarize_chain(
                self.llm,
                chain_type="map_reduce",
                map_prompt=prompt,
                combine_prompt=prompt
            )
            return chain.run(chunks)
        else:
            return self.llm.predict(prompt.format(text=text))
    
    def extract_key_clauses(self, text: str) -> List[str]:
        """Extract and categorize key legal clauses."""
        prompt = f"""
        Analyze the following legal document and extract key clauses:
        
        {text}
        
        Please identify and extract:
        1. Termination clauses
        2. Liability limitations
        3. Confidentiality provisions
        4. Payment terms
        5. Dispute resolution mechanisms
        6. Force majeure clauses
        7. Intellectual property rights
        
        Format each clause with its category and brief explanation.
        """
        
        response = self.llm.predict(prompt)
        return response.split('\n')
    
    def assess_legal_risks(self, text: str) -> str:
        """Perform risk assessment on the legal document."""
        prompt = f"""
        Perform a comprehensive legal risk assessment on the following document:
        
        {text}
        
        Please analyze:
        1. High-risk clauses or terms
        2. Missing standard protections
        3. Ambiguous language that could lead to disputes
        4. Compliance concerns
        5. Financial exposure risks
        
        Provide a risk level (Low/Medium/High) and detailed explanation for each identified risk.
        """
        
        return self.llm.predict(prompt)
    
    def generate_recommendations(self, text: str, risks: str) -> List[str]:
        """Generate actionable recommendations based on analysis."""
        prompt = f"""
        Based on the legal document analysis and identified risks, provide specific recommendations:
        
        Document: {text[:1000]}...
        Risks: {risks}
        
        Please provide:
        1. Specific clause modifications needed
        2. Additional protections to include
        3. Negotiation strategies
        4. Compliance requirements
        5. Next steps for legal review
        
        Format as numbered actionable recommendations.
        """
        
        response = self.llm.predict(prompt)
        return [rec.strip() for rec in response.split('\n') if rec.strip()]
    
    def query_document(self, query: str) -> str:
        """Answer specific questions about the document."""
        if not self.vector_store:
            raise ValueError("No document loaded. Please process a document first.")
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(search_kwargs={"k": 3}),
            return_source_documents=True
        )
        
        legal_prompt = f"""
        You are a legal AI assistant. Answer the following question based on the legal document context:
        
        Question: {query}
        
        Provide a detailed, accurate answer with specific references to relevant sections.
        """
        
        result = qa_chain({"query": legal_prompt})
        return result["result"]
    
    def analyze_document(self, pdf_file) -> AnalysisResult:
        """Perform comprehensive analysis of a legal document."""
        try:
            # Extract text from PDF
            text = self.extract_text_from_pdf(pdf_file)
            
            # Create vector store for querying
            documents = [Document(page_content=text)]
            self.vector_store = self.create_vector_store(documents)
            
            # Perform analysis
            summary = self.summarize_document(text)
            key_clauses = self.extract_key_clauses(text)
            risk_assessment = self.assess_legal_risks(text)
            recommendations = self.generate_recommendations(text, risk_assessment)
            
            return AnalysisResult(
                summary=summary,
                key_clauses=key_clauses,
                risk_assessment=risk_assessment,
                recommendations=recommendations
            )
            
        except Exception as e:
            logger.error(f"Error analyzing document: {e}")
            raise

class DocumentComparator:
    """Compare multiple legal documents for differences and similarities."""
    
    def __init__(self, analyzer: LegalDocumentAnalyzer):
        self.analyzer = analyzer
    
    def compare_documents(self, doc1_text: str, doc2_text: str) -> str:
        """Compare two legal documents."""
        prompt = f"""
        Compare the following two legal documents and provide:
        
        Document 1:
        {doc1_text[:2000]}...
        
        Document 2:
        {doc2_text[:2000]}...
        
        Analysis:
        1. Key differences in terms and conditions
        2. Similarities and common clauses
        3. Risk comparison between documents
        4. Recommendations for which terms to adopt
        
        Provide a detailed comparison report.
        """
        
        return self.analyzer.llm.predict(prompt)

# Sample legal contract for demonstration
SAMPLE_CONTRACT = """
SOFTWARE LICENSE AGREEMENT

This Software License Agreement ("Agreement") is entered into on January 1, 2024, between TechCorp Inc., a Delaware corporation ("Licensor"), and BusinessCo LLC, a California limited liability company ("Licensee").

1. GRANT OF LICENSE
Licensor hereby grants to Licensee a non-exclusive, non-transferable license to use the software product "DataManager Pro" (the "Software") subject to the terms and conditions of this Agreement.

2. TERM
This Agreement shall commence on the Effective Date and shall continue for a period of three (3) years, unless earlier terminated in accordance with the provisions hereof.

3. PAYMENT TERMS
Licensee agrees to pay Licensor a total license fee of $50,000, payable in annual installments of $16,666.67, due on the anniversary of the Effective Date.

4. LIMITATION OF LIABILITY
IN NO EVENT SHALL LICENSOR BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES, INCLUDING WITHOUT LIMITATION, LOSS OF PROFITS, DATA, OR USE, REGARDLESS OF THE THEORY OF LIABILITY.

5. TERMINATION
This Agreement may be terminated by either party upon thirty (30) days written notice to the other party in the event of a material breach that remains uncured after such notice period.

6. GOVERNING LAW
This Agreement shall be governed by and construed in accordance with the laws of the State of Delaware, without regard to its conflict of laws principles.

7. CONFIDENTIALITY
Each party acknowledges that it may receive confidential information from the other party and agrees to maintain such information in confidence for a period of five (5) years following termination of this Agreement.
"""

def save_sample_contract():
    """Save sample contract to a file for demonstration."""
    with open("sample_contract.txt", "w") as f:
        f.write(SAMPLE_CONTRACT)

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="Legal Document Analyzer",
        page_icon="‚öñÔ∏è",
        layout="wide"
    )
    
    st.title("‚öñÔ∏è Legal Document Analyzer")
    st.markdown("Upload PDF legal documents for comprehensive analysis using AI")
    
    # Sidebar for API key
    with st.sidebar:
        st.header("Configuration")
        api_key = st.text_input("OpenAI API Key", type="password")
        
        if st.button("Load Sample Contract"):
            save_sample_contract()
            st.success("Sample contract saved as 'sample_contract.txt'")
    
    if not api_key:
        st.warning("Please enter your OpenAI API key in the sidebar")
        return
    
    try:
        analyzer = LegalDocumentAnalyzer(api_key)
        
        # File upload
        uploaded_file = st.file_uploader(
            "Upload Legal Document (PDF)",
            type=['pdf'],
            help="Upload a PDF legal document for analysis"
        )
        
        if uploaded_file:
            with st.spinner("Analyzing document..."):
                try:
                    result = analyzer.analyze_document(uploaded_file)
                    
                    # Display results in tabs
                    tab1, tab2, tab3, tab4 = st.tabs([
                        "üìÑ Summary", 
                        "üîç Key Clauses", 
                        "‚ö†Ô∏è Risk Assessment", 
                        "üí° Recommendations"
                    ])
                    
                    with tab1:
                        st.header("Document Summary")
                        st.write(result.summary)
                    
                    with tab2:
                        st.header("Key Clauses")
                        for clause in result.key_clauses:
                            if clause.strip():
                                st.write(f"‚Ä¢ {clause}")
                    
                    with tab3:
                        st.header("Risk Assessment")
                        st.write(result.risk_assessment)
                    
                    with tab4:
                        st.header("Recommendations")
                        for rec in result.recommendations:
                            if rec.strip():
                                st.write(f"‚Ä¢ {rec}")
                    
                    # Query interface
                    st.header("üí¨ Ask Questions About the Document")
                    query = st.text_input("Enter your question about the document:")
                    
                    if query and st.button("Get Answer"):
                        with st.spinner("Searching document..."):
                            answer = analyzer.query_document(query)
                            st.write("**Answer:**")
                            st.write(answer)
                            
                except Exception as e:
                    st.error(f"Error analyzing document: {str(e)}")
        
        # Document comparison section
        st.header("üìä Document Comparison")
        col1, col2 = st.columns(2)
        
        with col1:
            doc1 = st.file_uploader("First Document (PDF)", type=['pdf'], key="doc1")
        
        with col2:
            doc2 = st.file_uploader("Second Document (PDF)", type=['pdf'], key="doc2")
        
        if doc1 and doc2 and st.button("Compare Documents"):
            with st.spinner("Comparing documents..."):
                try:
                    text1 = analyzer.extract_text_from_pdf(doc1)
                    text2 = analyzer.extract_text_from_pdf(doc2)
                    
                    comparator = DocumentComparator(analyzer)
                    comparison = comparator.compare_documents(text1, text2)
                    
                    st.header("Comparison Results")
                    st.write(comparison)
                    
                except Exception as e:
                    st.error(f"Error comparing documents: {str(e)}")
    
    except Exception as e:
        st.error(f"Error initializing analyzer: {str(e)}")

if __name__ == "__main__":
    main()
````

### Environment Configuration

````python
OPENAI_API_KEY=your_openai_api_key_here
````

### Usage Instructions

````python
"""
Usage instructions for the Legal Document Analyzer

1. Install dependencies:
   pip install -r requirements.txt

2. Set up environment variables:
   - Create .env file with OPENAI_API_KEY

3. Run the Streamlit application:
   streamlit run legal_analyzer.py

4. Upload PDF legal documents for analysis

5. Features available:
   - Document summarization
   - Key clause extraction
   - Risk assessment
   - Recommendations generation
   - Natural language querying
   - Document comparison
"""

import os
from dotenv import load_dotenv

def setup_environment():
    """Set up the environment for the legal analyzer."""
    load_dotenv()
    
    if not os.getenv("OPENAI_API_KEY"):
        print("Warning: OPENAI_API_KEY not found in environment variables")
        print("Please set your OpenAI API key in the .env file")
    
    print("Environment setup complete!")
    print("Run: streamlit run legal_analyzer.py")

if __name__ == "__main__":
    setup_environment()
````

## Project Summary

The Legal Document Analyzer represents a powerful application of RAG technology in the legal domain. By combining LangChain's document processing capabilities with OpenAI's language models, it provides comprehensive legal document analysis including summarization, risk assessment, and intelligent querying.

### Key Value Propositions:
- **Efficiency**: Reduces document review time from hours to minutes
- **Accuracy**: Leverages AI for consistent, thorough analysis
- **Accessibility**: Makes legal analysis tools available to smaller firms
- **Scalability**: Handles large document volumes automatically
- **Intelligence**: Provides contextual insights and recommendations

### Technical Highlights:
- Modern RAG architecture with vector similarity search
- Comprehensive error handling and logging
- Modular design for easy extension
- Interactive Streamlit interface
- Support for PDF document processing
- Comparative analysis capabilities

This system demonstrates how AI can augment legal professionals' capabilities while maintaining the precision and accuracy required in legal work.