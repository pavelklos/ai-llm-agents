<small>Claude Sonnet 4 **(AI-Powered CV Skill Gap Analyzer)**</small>
# AI-Powered CV Skill Gap Analyzer

## Key Concepts Explanation

### Resume Parsing
Automated extraction and structuring of information from resumes in various formats (PDF, DOCX, TXT) using natural language processing, optical character recognition, and machine learning techniques. This involves identifying and categorizing personal information, work experience, education, skills, certifications, and achievements while handling diverse resume formats and layouts.

### Skill Prediction
Machine learning-based identification and classification of skills from unstructured text using named entity recognition, skill taxonomies, and semantic analysis. This includes both explicit skill mentions and implicit skill inference from job descriptions, projects, and experiences, with confidence scoring and skill-level assessment.

### Upskilling Suggestions
Intelligent recommendation system that analyzes skill gaps between current competencies and target roles, providing personalized learning paths, course recommendations, and career development strategies based on industry trends, job market demands, and individual career goals.

### Skill Gap Analysis
Comprehensive comparison between existing skills and market requirements for specific roles or career paths, identifying missing competencies, skill level mismatches, and improvement opportunities through data-driven analysis of job postings and industry standards.

### Career Path Mapping
Strategic visualization of potential career progression routes based on current skills, market trends, and professional goals, including transition pathways, required skill acquisitions, and timeline estimations for career advancement.

## Comprehensive Project Explanation

### Objectives
The AI-Powered CV Skill Gap Analyzer aims to revolutionize career development by providing automated resume analysis, intelligent skill assessment, and personalized upskilling recommendations to bridge the gap between current competencies and market demands.

### Key Features
- **Intelligent Resume Parsing**: Multi-format document processing with advanced NLP
- **Comprehensive Skill Extraction**: Automated identification of technical and soft skills
- **Market-Driven Gap Analysis**: Real-time comparison with industry requirements
- **Personalized Learning Paths**: Customized upskilling recommendations
- **Career Progression Mapping**: Strategic career development guidance
- **Industry Trend Integration**: Current market demand analysis

### Challenges
- **Format Diversity**: Handling various resume formats and structures
- **Skill Taxonomy Management**: Maintaining comprehensive skill databases
- **Market Data Accuracy**: Ensuring current and relevant job market information
- **Personalization Balance**: Providing relevant without overwhelming recommendations
- **Privacy Concerns**: Protecting sensitive personal information

### Potential Impact
This system can accelerate career development, improve hiring processes, reduce skill mismatches in the job market, and enable data-driven career decisions for professionals across industries.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
openai==1.6.1
langchain==0.1.0
langchain-openai==0.0.5
chromadb==0.4.18
sentence-transformers==2.2.2
spacy==3.7.2
pandas==2.1.4
numpy==1.24.3
matplotlib==3.8.2
plotly==5.17.0
pdfplumber==0.9.0
python-docx==0.8.11
pytesseract==0.3.10
Pillow==10.1.0
scikit-learn==1.3.2
nltk==3.8.1
requests==2.31.0
beautifulsoup4==4.12.2
fuzzywuzzy==0.18.0
python-Levenshtein==0.23.0
datetime
logging
re
json
uuid
````

### Core Implementation

````python
import os
import json
import uuid
import logging
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

# Document processing
import pdfplumber
from docx import Document
from PIL import Image
import pytesseract

# NLP and ML
import spacy
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from fuzzywuzzy import fuzz, process

# Vector storage
import chromadb
from sentence_transformers import SentenceTransformer

# LangChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SkillCategory(Enum):
    TECHNICAL = "technical"
    SOFT = "soft"
    DOMAIN = "domain"
    LANGUAGE = "language"
    CERTIFICATION = "certification"
    TOOL = "tool"

class SkillLevel(Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"
    EXPERT = "expert"

class CareerLevel(Enum):
    ENTRY = "entry"
    MID = "mid"
    SENIOR = "senior"
    LEAD = "lead"
    EXECUTIVE = "executive"

@dataclass
class Skill:
    name: str
    category: SkillCategory
    level: SkillLevel
    confidence: float
    source: str
    related_skills: List[str] = field(default_factory=list)

@dataclass
class WorkExperience:
    title: str
    company: str
    duration: str
    description: str
    extracted_skills: List[Skill]
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None

@dataclass
class Education:
    degree: str
    institution: str
    field: str
    graduation_year: Optional[int] = None

@dataclass
class ParsedResume:
    personal_info: Dict[str, str]
    summary: str
    work_experience: List[WorkExperience]
    education: List[Education]
    skills: List[Skill]
    certifications: List[str]
    languages: List[str]
    raw_text: str
    parsing_confidence: float

@dataclass
class JobRequirement:
    title: str
    company: str
    required_skills: List[Skill]
    preferred_skills: List[Skill]
    experience_level: CareerLevel
    salary_range: Optional[Tuple[int, int]] = None

@dataclass
class SkillGap:
    missing_skills: List[Skill]
    skill_level_gaps: List[Tuple[Skill, SkillLevel]]
    matching_score: float
    improvement_priority: List[str]

@dataclass
class UpskillRecommendation:
    skill: str
    priority: int
    learning_resources: List[Dict[str, str]]
    estimated_time: str
    difficulty: str
    career_impact: str

class ResumeParser:
    """Advanced resume parsing with multiple format support."""
    
    def __init__(self):
        # Initialize NLP model
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except:
            logger.warning("Spacy model not found")
            self.nlp = None
        
        # Skill taxonomy
        self.skill_taxonomy = self._load_skill_taxonomy()
        
        # Text patterns
        self.patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'[\+]?[1-9]?[0-9]{7,15}',
            'linkedin': r'linkedin\.com/in/[\w-]+',
            'github': r'github\.com/[\w-]+',
            'years_exp': r'(\d+)[\+]?\s*(?:years?|yrs?)\s*(?:of\s*)?(?:experience|exp)',
            'dates': r'\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\.?\s+\d{4}\b'
        }
    
    def parse_resume(self, file_path: str) -> ParsedResume:
        """Parse resume from file."""
        try:
            # Extract text based on file type
            if file_path.endswith('.pdf'):
                text = self._extract_pdf_text(file_path)
            elif file_path.endswith('.docx'):
                text = self._extract_docx_text(file_path)
            else:
                text = self._extract_txt_text(file_path)
            
            # Parse structured information
            personal_info = self._extract_personal_info(text)
            summary = self._extract_summary(text)
            work_experience = self._extract_work_experience(text)
            education = self._extract_education(text)
            skills = self._extract_skills(text)
            certifications = self._extract_certifications(text)
            languages = self._extract_languages(text)
            
            # Calculate parsing confidence
            confidence = self._calculate_parsing_confidence(text, personal_info, work_experience)
            
            return ParsedResume(
                personal_info=personal_info,
                summary=summary,
                work_experience=work_experience,
                education=education,
                skills=skills,
                certifications=certifications,
                languages=languages,
                raw_text=text,
                parsing_confidence=confidence
            )
            
        except Exception as e:
            logger.error(f"Resume parsing error: {e}")
            return self._create_empty_resume()
    
    def _extract_pdf_text(self, file_path: str) -> str:
        """Extract text from PDF."""
        try:
            with pdfplumber.open(file_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
                return text
        except Exception as e:
            logger.error(f"PDF extraction error: {e}")
            return ""
    
    def _extract_docx_text(self, file_path: str) -> str:
        """Extract text from DOCX."""
        try:
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            logger.error(f"DOCX extraction error: {e}")
            return ""
    
    def _extract_txt_text(self, file_path: str) -> str:
        """Extract text from TXT."""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except Exception as e:
            logger.error(f"TXT extraction error: {e}")
            return ""
    
    def _extract_personal_info(self, text: str) -> Dict[str, str]:
        """Extract personal information."""
        info = {}
        
        # Extract email
        email_match = re.search(self.patterns['email'], text)
        if email_match:
            info['email'] = email_match.group()
        
        # Extract phone
        phone_match = re.search(self.patterns['phone'], text)
        if phone_match:
            info['phone'] = phone_match.group()
        
        # Extract LinkedIn
        linkedin_match = re.search(self.patterns['linkedin'], text)
        if linkedin_match:
            info['linkedin'] = linkedin_match.group()
        
        # Extract GitHub
        github_match = re.search(self.patterns['github'], text)
        if github_match:
            info['github'] = github_match.group()
        
        # Extract name (simple heuristic)
        lines = text.split('\n')[:5]
        for line in lines:
            line = line.strip()
            if len(line.split()) == 2 and line.replace(' ', '').isalpha():
                info['name'] = line
                break
        
        return info
    
    def _extract_summary(self, text: str) -> str:
        """Extract professional summary."""
        summary_patterns = [
            r'(?:summary|profile|objective|about)[:\s\n]+(.*?)(?:\n\s*\n|education|experience|skills)',
            r'(?:professional\s+summary)[:\s\n]+(.*?)(?:\n\s*\n|education|experience|skills)'
        ]
        
        for pattern in summary_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1).strip()[:500]
        
        # Fallback: first paragraph
        paragraphs = text.split('\n\n')
        if len(paragraphs) > 1:
            return paragraphs[1][:300]
        
        return ""
    
    def _extract_work_experience(self, text: str) -> List[WorkExperience]:
        """Extract work experience."""
        experiences = []
        
        # Split text into sections
        experience_section = self._find_section(text, ['experience', 'employment', 'work history'])
        
        if experience_section:
            # Simple pattern matching for job entries
            job_patterns = [
                r'([A-Z][^:\n]+)\s*(?:at|@)\s*([A-Z][^:\n]+)\s*\n([^:\n]+)\n(.*?)(?=\n[A-Z][^:\n]+\s*(?:at|@)|$)'
            ]
            
            for pattern in job_patterns:
                matches = re.finditer(pattern, experience_section, re.DOTALL)
                for match in matches:
                    title = match.group(1).strip()
                    company = match.group(2).strip()
                    duration = match.group(3).strip()
                    description = match.group(4).strip()
                    
                    # Extract skills from description
                    extracted_skills = self._extract_skills_from_text(description)
                    
                    experiences.append(WorkExperience(
                        title=title,
                        company=company,
                        duration=duration,
                        description=description,
                        extracted_skills=extracted_skills
                    ))
        
        return experiences
    
    def _extract_education(self, text: str) -> List[Education]:
        """Extract education information."""
        education = []
        
        education_section = self._find_section(text, ['education', 'academic', 'qualifications'])
        
        if education_section:
            # Pattern for degree, institution, year
            degree_patterns = [
                r'(Bachelor|Master|PhD|B\.S\.|M\.S\.|M\.A\.|B\.A\.).*?(?:in\s+)?([^,\n]+).*?(?:from\s+)?([^,\n]+).*?(\d{4})?'
            ]
            
            for pattern in degree_patterns:
                matches = re.finditer(pattern, education_section, re.IGNORECASE)
                for match in matches:
                    degree = match.group(1)
                    field = match.group(2).strip() if match.group(2) else ""
                    institution = match.group(3).strip() if match.group(3) else ""
                    year = int(match.group(4)) if match.group(4) else None
                    
                    education.append(Education(
                        degree=degree,
                        institution=institution,
                        field=field,
                        graduation_year=year
                    ))
        
        return education
    
    def _extract_skills(self, text: str) -> List[Skill]:
        """Extract skills from entire resume."""
        all_skills = []
        
        # Extract from skills section
        skills_section = self._find_section(text, ['skills', 'technical skills', 'competencies'])
        if skills_section:
            skills_text_skills = self._extract_skills_from_text(skills_section, source="skills_section")
            all_skills.extend(skills_text_skills)
        
        # Extract from work experience
        for exp in self._extract_work_experience(text):
            all_skills.extend(exp.extracted_skills)
        
        # Deduplicate skills
        unique_skills = {}
        for skill in all_skills:
            if skill.name.lower() not in unique_skills:
                unique_skills[skill.name.lower()] = skill
            else:
                # Update confidence if higher
                if skill.confidence > unique_skills[skill.name.lower()].confidence:
                    unique_skills[skill.name.lower()] = skill
        
        return list(unique_skills.values())
    
    def _extract_skills_from_text(self, text: str, source: str = "text") -> List[Skill]:
        """Extract skills from text using skill taxonomy."""
        found_skills = []
        text_lower = text.lower()
        
        for skill_name, skill_info in self.skill_taxonomy.items():
            # Fuzzy matching for skill names
            ratio = fuzz.partial_ratio(skill_name.lower(), text_lower)
            
            if ratio > 80:  # Threshold for skill match
                confidence = ratio / 100.0
                category = SkillCategory(skill_info.get('category', 'technical'))
                level = self._infer_skill_level(text, skill_name)
                
                found_skills.append(Skill(
                    name=skill_name,
                    category=category,
                    level=level,
                    confidence=confidence,
                    source=source,
                    related_skills=skill_info.get('related', [])
                ))
        
        return found_skills
    
    def _infer_skill_level(self, text: str, skill: str) -> SkillLevel:
        """Infer skill level from context."""
        skill_context = self._get_skill_context(text, skill)
        
        expert_indicators = ['expert', 'advanced', 'lead', 'architect', 'senior']
        advanced_indicators = ['proficient', 'experienced', 'solid', 'strong']
        intermediate_indicators = ['familiar', 'working knowledge', 'some experience']
        
        context_lower = skill_context.lower()
        
        if any(indicator in context_lower for indicator in expert_indicators):
            return SkillLevel.EXPERT
        elif any(indicator in context_lower for indicator in advanced_indicators):
            return SkillLevel.ADVANCED
        elif any(indicator in context_lower for indicator in intermediate_indicators):
            return SkillLevel.INTERMEDIATE
        else:
            return SkillLevel.BEGINNER
    
    def _get_skill_context(self, text: str, skill: str) -> str:
        """Get context around skill mention."""
        skill_pos = text.lower().find(skill.lower())
        if skill_pos == -1:
            return ""
        
        start = max(0, skill_pos - 100)
        end = min(len(text), skill_pos + len(skill) + 100)
        
        return text[start:end]
    
    def _extract_certifications(self, text: str) -> List[str]:
        """Extract certifications."""
        cert_section = self._find_section(text, ['certifications', 'certificates', 'licenses'])
        
        certifications = []
        if cert_section:
            # Common certification patterns
            cert_patterns = [
                r'([A-Z]{2,}(?:\s+[A-Z]{2,})*)',  # Acronyms
                r'(Certified\s+[^,\n]+)',
                r'([^,\n]+\s+Certification)',
            ]
            
            for pattern in cert_patterns:
                matches = re.findall(pattern, cert_section)
                certifications.extend([match.strip() for match in matches if len(match.strip()) > 3])
        
        return list(set(certifications))
    
    def _extract_languages(self, text: str) -> List[str]:
        """Extract languages."""
        lang_section = self._find_section(text, ['languages', 'language skills'])
        
        languages = []
        if lang_section:
            common_languages = [
                'English', 'Spanish', 'French', 'German', 'Italian', 'Portuguese',
                'Chinese', 'Japanese', 'Korean', 'Hindi', 'Arabic', 'Russian'
            ]
            
            for lang in common_languages:
                if lang.lower() in lang_section.lower():
                    languages.append(lang)
        
        return languages
    
    def _find_section(self, text: str, section_names: List[str]) -> str:
        """Find specific section in resume."""
        for name in section_names:
            pattern = rf'{name}[:\s]*\n(.*?)(?=\n(?:[A-Z][^:\n]*:|\Z))'
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1)
        return ""
    
    def _load_skill_taxonomy(self) -> Dict[str, Dict]:
        """Load skill taxonomy."""
        return {
            # Programming Languages
            'Python': {'category': 'technical', 'related': ['Django', 'Flask', 'FastAPI']},
            'JavaScript': {'category': 'technical', 'related': ['React', 'Node.js', 'Vue.js']},
            'Java': {'category': 'technical', 'related': ['Spring', 'Hibernate', 'Maven']},
            'C++': {'category': 'technical', 'related': ['STL', 'Boost', 'Qt']},
            'SQL': {'category': 'technical', 'related': ['MySQL', 'PostgreSQL', 'SQLite']},
            
            # Frameworks
            'React': {'category': 'technical', 'related': ['JavaScript', 'Redux', 'JSX']},
            'Django': {'category': 'technical', 'related': ['Python', 'REST', 'ORM']},
            'Spring': {'category': 'technical', 'related': ['Java', 'Hibernate', 'REST']},
            
            # Tools
            'Git': {'category': 'tool', 'related': ['GitHub', 'GitLab', 'Version Control']},
            'Docker': {'category': 'tool', 'related': ['Kubernetes', 'DevOps', 'Containers']},
            'AWS': {'category': 'tool', 'related': ['Cloud', 'EC2', 'S3']},
            
            # Soft Skills
            'Leadership': {'category': 'soft', 'related': ['Management', 'Team Building']},
            'Communication': {'category': 'soft', 'related': ['Presentation', 'Writing']},
            'Problem Solving': {'category': 'soft', 'related': ['Analytical', 'Critical Thinking']},
            
            # Domain Skills
            'Machine Learning': {'category': 'domain', 'related': ['AI', 'Deep Learning', 'Data Science']},
            'Data Analysis': {'category': 'domain', 'related': ['Statistics', 'Visualization', 'Excel']},
            'Project Management': {'category': 'domain', 'related': ['Agile', 'Scrum', 'Planning']},
        }
    
    def _calculate_parsing_confidence(self, text: str, personal_info: Dict, 
                                    work_experience: List) -> float:
        """Calculate confidence score for parsing."""
        score = 0.0
        total_checks = 5
        
        # Check if basic info extracted
        if personal_info.get('email'):
            score += 0.2
        if personal_info.get('name'):
            score += 0.2
        if len(work_experience) > 0:
            score += 0.3
        if len(text) > 100:
            score += 0.2
        if any(keyword in text.lower() for keyword in ['experience', 'skills', 'education']):
            score += 0.1
        
        return min(score, 1.0)
    
    def _create_empty_resume(self) -> ParsedResume:
        """Create empty resume for error cases."""
        return ParsedResume(
            personal_info={},
            summary="",
            work_experience=[],
            education=[],
            skills=[],
            certifications=[],
            languages=[],
            raw_text="",
            parsing_confidence=0.0
        )

class SkillGapAnalyzer:
    """Analyzes skill gaps between resume and job requirements."""
    
    def __init__(self):
        self.job_market_data = self._load_job_market_data()
        self.skill_similarity_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def analyze_gap(self, resume: ParsedResume, job_requirements: JobRequirement) -> SkillGap:
        """Analyze skill gap between resume and job."""
        try:
            # Extract current skills
            current_skills = {skill.name.lower(): skill for skill in resume.skills}
            
            # Required skills analysis
            missing_skills = []
            skill_level_gaps = []
            
            for req_skill in job_requirements.required_skills:
                skill_name_lower = req_skill.name.lower()
                
                if skill_name_lower not in current_skills:
                    missing_skills.append(req_skill)
                else:
                    current_skill = current_skills[skill_name_lower]
                    if self._skill_level_to_int(current_skill.level) < self._skill_level_to_int(req_skill.level):
                        skill_level_gaps.append((current_skill, req_skill.level))
            
            # Calculate matching score
            matching_score = self._calculate_matching_score(resume, job_requirements)
            
            # Determine improvement priorities
            improvement_priority = self._prioritize_improvements(missing_skills, skill_level_gaps)
            
            return SkillGap(
                missing_skills=missing_skills,
                skill_level_gaps=skill_level_gaps,
                matching_score=matching_score,
                improvement_priority=improvement_priority
            )
            
        except Exception as e:
            logger.error(f"Gap analysis error: {e}")
            return SkillGap([], [], 0.0, [])
    
    def _skill_level_to_int(self, level: SkillLevel) -> int:
        """Convert skill level to integer for comparison."""
        level_map = {
            SkillLevel.BEGINNER: 1,
            SkillLevel.INTERMEDIATE: 2,
            SkillLevel.ADVANCED: 3,
            SkillLevel.EXPERT: 4
        }
        return level_map.get(level, 1)
    
    def _calculate_matching_score(self, resume: ParsedResume, job_req: JobRequirement) -> float:
        """Calculate overall matching score."""
        if not job_req.required_skills:
            return 0.0
        
        current_skills = {skill.name.lower() for skill in resume.skills}
        required_skills = {skill.name.lower() for skill in job_req.required_skills}
        
        matched_skills = current_skills.intersection(required_skills)
        
        return len(matched_skills) / len(required_skills)
    
    def _prioritize_improvements(self, missing_skills: List[Skill], 
                               level_gaps: List[Tuple[Skill, SkillLevel]]) -> List[str]:
        """Prioritize skill improvements."""
        priorities = []
        
        # High priority: missing core technical skills
        for skill in missing_skills:
            if skill.category == SkillCategory.TECHNICAL:
                priorities.append(f"Learn {skill.name} (Missing core technical skill)")
        
        # Medium priority: skill level improvements
        for current_skill, target_level in level_gaps:
            priorities.append(f"Improve {current_skill.name} to {target_level.value} level")
        
        # Lower priority: missing soft skills
        for skill in missing_skills:
            if skill.category == SkillCategory.SOFT:
                priorities.append(f"Develop {skill.name} (Soft skill)")
        
        return priorities[:10]  # Top 10 priorities
    
    def _load_job_market_data(self) -> Dict:
        """Load job market data (simplified)."""
        return {
            'trending_skills': [
                'Python', 'JavaScript', 'React', 'AWS', 'Docker',
                'Machine Learning', 'Data Science', 'Kubernetes'
            ],
            'salary_impact': {
                'Python': 15000,
                'AWS': 20000,
                'Machine Learning': 25000,
                'React': 12000
            }
        }

class UpskillRecommendationEngine:
    """Generates personalized upskilling recommendations."""
    
    def __init__(self, openai_api_key: str = None):
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.7,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        else:
            self.llm = None
        
        self.learning_resources = self._load_learning_resources()
        self._initialize_prompts()
    
    def generate_recommendations(self, skill_gap: SkillGap, 
                               resume: ParsedResume) -> List[UpskillRecommendation]:
        """Generate upskilling recommendations."""
        recommendations = []
        
        try:
            # Process missing skills
            for i, skill in enumerate(skill_gap.missing_skills[:5]):
                rec = self._create_skill_recommendation(skill, i + 1, resume)
                recommendations.append(rec)
            
            # Process skill level gaps
            for i, (current_skill, target_level) in enumerate(skill_gap.skill_level_gaps[:3]):
                rec = self._create_level_improvement_recommendation(
                    current_skill, target_level, len(recommendations) + 1, resume
                )
                recommendations.append(rec)
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Recommendation generation error: {e}")
            return []
    
    def _create_skill_recommendation(self, skill: Skill, priority: int, 
                                   resume: ParsedResume) -> UpskillRecommendation:
        """Create recommendation for missing skill."""
        resources = self.learning_resources.get(skill.name, self._get_default_resources(skill.name))
        
        # Estimate learning time based on skill complexity
        time_estimates = {
            SkillCategory.TECHNICAL: "2-3 months",
            SkillCategory.TOOL: "1-2 months",
            SkillCategory.SOFT: "1-3 months",
            SkillCategory.DOMAIN: "3-6 months"
        }
        
        estimated_time = time_estimates.get(skill.category, "2-3 months")
        
        # Determine difficulty
        difficulty = "Intermediate" if skill.category == SkillCategory.TECHNICAL else "Beginner"
        
        # Assess career impact
        career_impact = self._assess_career_impact(skill, resume)
        
        return UpskillRecommendation(
            skill=skill.name,
            priority=priority,
            learning_resources=resources,
            estimated_time=estimated_time,
            difficulty=difficulty,
            career_impact=career_impact
        )
    
    def _create_level_improvement_recommendation(self, current_skill: Skill, 
                                               target_level: SkillLevel, priority: int,
                                               resume: ParsedResume) -> UpskillRecommendation:
        """Create recommendation for skill level improvement."""
        advanced_resources = self._get_advanced_resources(current_skill.name)
        
        # Shorter time for level improvement
        estimated_time = "1-2 months"
        difficulty = "Advanced"
        career_impact = f"Advancing {current_skill.name} to {target_level.value} level will enhance your expertise"
        
        return UpskillRecommendation(
            skill=f"{current_skill.name} (Level Up)",
            priority=priority,
            learning_resources=advanced_resources,
            estimated_time=estimated_time,
            difficulty=difficulty,
            career_impact=career_impact
        )
    
    def _assess_career_impact(self, skill: Skill, resume: ParsedResume) -> str:
        """Assess career impact of learning a skill."""
        impact_templates = {
            SkillCategory.TECHNICAL: f"Learning {skill.name} will open opportunities in software development and technical roles",
            SkillCategory.TOOL: f"Mastering {skill.name} will improve your development efficiency and marketability",
            SkillCategory.SOFT: f"Developing {skill.name} will enhance your leadership and collaboration abilities",
            SkillCategory.DOMAIN: f"Gaining expertise in {skill.name} will qualify you for specialized domain roles"
        }
        
        return impact_templates.get(skill.category, f"Learning {skill.name} will enhance your professional profile")
    
    def _load_learning_resources(self) -> Dict[str, List[Dict[str, str]]]:
        """Load learning resources database."""
        return {
            'Python': [
                {'name': 'Python.org Tutorial', 'type': 'Documentation', 'url': 'https://docs.python.org/3/tutorial/'},
                {'name': 'Coursera Python Specialization', 'type': 'Course', 'url': 'https://coursera.org'},
                {'name': 'Automate the Boring Stuff', 'type': 'Book', 'url': 'https://automatetheboringstuff.com/'}
            ],
            'JavaScript': [
                {'name': 'MDN JavaScript Guide', 'type': 'Documentation', 'url': 'https://developer.mozilla.org'},
                {'name': 'JavaScript: The Good Parts', 'type': 'Book', 'url': 'https://shop.oreilly.com'},
                {'name': 'freeCodeCamp', 'type': 'Interactive', 'url': 'https://freecodecamp.org'}
            ],
            'React': [
                {'name': 'Official React Tutorial', 'type': 'Documentation', 'url': 'https://react.dev'},
                {'name': 'React - The Complete Guide', 'type': 'Course', 'url': 'https://udemy.com'},
                {'name': 'React Handbook', 'type': 'Book', 'url': 'https://reacthandbook.com'}
            ],
            'AWS': [
                {'name': 'AWS Training', 'type': 'Official Training', 'url': 'https://aws.amazon.com/training/'},
                {'name': 'AWS Certified Solutions Architect', 'type': 'Certification', 'url': 'https://aws.amazon.com/certification/'},
                {'name': 'A Cloud Guru', 'type': 'Course', 'url': 'https://acloudguru.com'}
            ]
        }
    
    def _get_default_resources(self, skill_name: str) -> List[Dict[str, str]]:
        """Get default learning resources for unknown skills."""
        return [
            {'name': f'{skill_name} Documentation', 'type': 'Documentation', 'url': f'https://google.com/search?q={skill_name}+tutorial'},
            {'name': f'{skill_name} Online Course', 'type': 'Course', 'url': f'https://coursera.org/search?query={skill_name}'},
            {'name': f'{skill_name} YouTube Tutorials', 'type': 'Video', 'url': f'https://youtube.com/results?search_query={skill_name}+tutorial'}
        ]
    
    def _get_advanced_resources(self, skill_name: str) -> List[Dict[str, str]]:
        """Get advanced learning resources."""
        return [
            {'name': f'Advanced {skill_name}', 'type': 'Course', 'url': f'https://udemy.com/courses/search/?q=advanced+{skill_name}'},
            {'name': f'{skill_name} Best Practices', 'type': 'Article', 'url': f'https://medium.com/search?q={skill_name}+best+practices'},
            {'name': f'{skill_name} Certification', 'type': 'Certification', 'url': f'https://google.com/search?q={skill_name}+certification'}
        ]
    
    def _initialize_prompts(self):
        """Initialize LLM prompts."""
        self.recommendation_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are a career development expert. Generate personalized learning recommendations
            for the skill: {skill}
            
            Consider the candidate's background:
            - Current skills: {current_skills}
            - Experience level: {experience_level}
            - Career goals: {career_goals}
            
            Provide:
            1. Learning path structure
            2. Time allocation recommendations
            3. Practice project ideas
            4. Career progression insights
            """),
            ("human", "Generate learning recommendation for {skill}")
        ])

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="CV Skill Gap Analyzer",
        page_icon="üìÑ",
        layout="wide"
    )
    
    st.title("üìÑ AI-Powered CV Skill Gap Analyzer")
    st.markdown("Upload your resume and discover skill gaps with personalized upskilling recommendations")
    
    # Initialize session state
    if 'parsed_resume' not in st.session_state:
        st.session_state['parsed_resume'] = None
    if 'skill_gap' not in st.session_state:
        st.session_state['skill_gap'] = None
    
    # Initialize components
    openai_key = st.sidebar.text_input("OpenAI API Key (Optional)", type="password")
    
    with st.spinner("Initializing AI components..."):
        parser = ResumeParser()
        analyzer = SkillGapAnalyzer()
        recommender = UpskillRecommendationEngine(openai_key)
    
    # Sidebar
    with st.sidebar:
        st.header("üìã Upload Resume")
        
        uploaded_file = st.file_uploader(
            "Choose resume file",
            type=['pdf', 'docx', 'txt'],
            help="Upload your resume in PDF, DOCX, or TXT format"
        )
        
        if uploaded_file and st.button("üîç Parse Resume"):
            with st.spinner("Parsing resume..."):
                # Save uploaded file temporarily
                temp_path = f"temp_{uploaded_file.name}"
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # Parse resume
                parsed_resume = parser.parse_resume(temp_path)
                st.session_state['parsed_resume'] = parsed_resume
                
                # Clean up
                os.remove(temp_path)
                
                if parsed_resume.parsing_confidence > 0.5:
                    st.success(f"Resume parsed successfully! (Confidence: {parsed_resume.parsing_confidence:.1%})")
                else:
                    st.warning("Resume parsed with low confidence. Please check the results.")
                
                st.rerun()
    
    # Main content
    if not st.session_state['parsed_resume']:
        st.info("üëà Upload your resume to get started")
        
        # Show demo features
        st.subheader("üöÄ Features")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üìÑ Resume Parsing**
            - Multi-format support (PDF, DOCX, TXT)
            - Intelligent skill extraction
            - Experience analysis
            """)
        
        with col2:
            st.markdown("""
            **üîç Skill Gap Analysis**
            - Compare with job requirements
            - Identify missing skills
            - Level assessment
            """)
        
        with col3:
            st.markdown("""
            **üéØ Upskilling Recommendations**
            - Personalized learning paths
            - Resource suggestions
            - Career impact analysis
            """)
        
        return
    
    # Display parsed resume
    resume = st.session_state['parsed_resume']
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìÑ Resume Analysis", "üéØ Target Role", "üìä Skill Gap", "üöÄ Recommendations"])
    
    with tab1:
        st.header("üìÑ Resume Analysis")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Personal information
            if resume.personal_info:
                st.subheader("üë§ Personal Information")
                for key, value in resume.personal_info.items():
                    st.write(f"**{key.title()}:** {value}")
            
            # Summary
            if resume.summary:
                st.subheader("üìù Professional Summary")
                st.write(resume.summary)
            
            # Work experience
            if resume.work_experience:
                st.subheader("üíº Work Experience")
                for exp in resume.work_experience:
                    with st.expander(f"{exp.title} at {exp.company}"):
                        st.write(f"**Duration:** {exp.duration}")
                        st.write(f"**Description:** {exp.description}")
                        if exp.extracted_skills:
                            st.write("**Extracted Skills:**")
                            for skill in exp.extracted_skills:
                                st.write(f"‚Ä¢ {skill.name} ({skill.level.value})")
        
        with col2:
            # Skills overview
            st.subheader("üõ†Ô∏è Skills Overview")
            
            if resume.skills:
                # Group skills by category
                skill_categories = {}
                for skill in resume.skills:
                    category = skill.category.value
                    if category not in skill_categories:
                        skill_categories[category] = []
                    skill_categories[category].append(skill)
                
                for category, skills in skill_categories.items():
                    with st.expander(f"{category.title()} Skills ({len(skills)})"):
                        for skill in skills:
                            confidence_color = "üü¢" if skill.confidence > 0.8 else "üü°" if skill.confidence > 0.6 else "üî¥"
                            st.write(f"{confidence_color} {skill.name} ({skill.level.value})")
                
                # Skills distribution chart
                category_counts = {cat: len(skills) for cat, skills in skill_categories.items()}
                fig = px.pie(
                    values=list(category_counts.values()),
                    names=list(category_counts.keys()),
                    title="Skills Distribution by Category"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("No skills detected. Try uploading a different resume format.")
            
            # Education
            if resume.education:
                st.subheader("üéì Education")
                for edu in resume.education:
                    st.write(f"**{edu.degree}** in {edu.field}")
                    st.write(f"{edu.institution}")
                    if edu.graduation_year:
                        st.write(f"Year: {edu.graduation_year}")
            
            # Certifications
            if resume.certifications:
                st.subheader("üìú Certifications")
                for cert in resume.certifications:
                    st.write(f"‚Ä¢ {cert}")
    
    with tab2:
        st.header("üéØ Target Role Analysis")
        
        # Job requirements input
        col1, col2 = st.columns(2)
        
        with col1:
            job_title = st.text_input("Job Title", placeholder="e.g., Senior Software Engineer")
            company = st.text_input("Company", placeholder="e.g., Tech Corp")
            
        with col2:
            experience_level = st.selectbox(
                "Experience Level",
                [level.value for level in CareerLevel]
            )
        
        # Required skills input
        st.subheader("Required Skills")
        required_skills_text = st.text_area(
            "Enter required skills (one per line)",
            placeholder="Python\nJavaScript\nReact\nAWS\nTeam Leadership",
            height=150
        )
        
        if st.button("üîç Analyze Skill Gap") and job_title and required_skills_text:
            # Parse required skills
            required_skill_names = [skill.strip() for skill in required_skills_text.split('\n') if skill.strip()]
            
            # Create job requirements object
            required_skills = []
            for skill_name in required_skill_names:
                # Simple skill creation (could be enhanced with AI classification)
                required_skills.append(Skill(
                    name=skill_name,
                    category=SkillCategory.TECHNICAL,  # Default
                    level=SkillLevel.INTERMEDIATE,     # Default
                    confidence=1.0,
                    source="job_posting"
                ))
            
            job_requirements = JobRequirement(
                title=job_title,
                company=company,
                required_skills=required_skills,
                preferred_skills=[],
                experience_level=CareerLevel(experience_level)
            )
            
            # Analyze skill gap
            with st.spinner("Analyzing skill gap..."):
                skill_gap = analyzer.analyze_gap(resume, job_requirements)
                st.session_state['skill_gap'] = skill_gap
                st.session_state['job_requirements'] = job_requirements
            
            st.success("Skill gap analysis completed!")
            st.rerun()
    
    with tab3:
        if 'skill_gap' not in st.session_state or not st.session_state['skill_gap']:
            st.info("Complete the Target Role analysis first to see skill gaps")
        else:
            st.header("üìä Skill Gap Analysis")
            
            skill_gap = st.session_state['skill_gap']
            
            # Overall matching score
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Overall Match Score",
                    f"{skill_gap.matching_score:.1%}",
                    delta=None
                )
            
            with col2:
                st.metric(
                    "Missing Skills",
                    len(skill_gap.missing_skills),
                    delta=None
                )
            
            with col3:
                st.metric(
                    "Skills Needing Improvement",
                    len(skill_gap.skill_level_gaps),
                    delta=None
                )
            
            # Missing skills
            if skill_gap.missing_skills:
                st.subheader("‚ùå Missing Skills")
                
                missing_df = pd.DataFrame([
                    {
                        'Skill': skill.name,
                        'Category': skill.category.value.title(),
                        'Required Level': skill.level.value.title(),
                        'Priority': 'High' if skill.category == SkillCategory.TECHNICAL else 'Medium'
                    }
                    for skill in skill_gap.missing_skills
                ])
                
                st.dataframe(missing_df, use_container_width=True)
            
            # Skill level gaps
            if skill_gap.skill_level_gaps:
                st.subheader("üìà Skills Needing Level Improvement")
                
                level_gap_df = pd.DataFrame([
                    {
                        'Skill': current_skill.name,
                        'Current Level': current_skill.level.value.title(),
                        'Required Level': target_level.value.title(),
                        'Gap': f"{target_level.value.title()} ‚Üê {current_skill.level.value.title()}"
                    }
                    for current_skill, target_level in skill_gap.skill_level_gaps
                ])
                
                st.dataframe(level_gap_df, use_container_width=True)
            
            # Improvement priorities
            if skill_gap.improvement_priority:
                st.subheader("üéØ Improvement Priorities")
                
                for i, priority in enumerate(skill_gap.improvement_priority, 1):
                    st.write(f"{i}. {priority}")
    
    with tab4:
        if 'skill_gap' not in st.session_state or not st.session_state['skill_gap']:
            st.info("Complete the Skill Gap analysis first to see recommendations")
        else:
            st.header("üöÄ Upskilling Recommendations")
            
            skill_gap = st.session_state['skill_gap']
            
            with st.spinner("Generating personalized recommendations..."):
                recommendations = recommender.generate_recommendations(skill_gap, resume)
            
            if recommendations:
                for rec in recommendations:
                    with st.expander(f"Priority {rec.priority}: {rec.skill}"):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"**Estimated Time:** {rec.estimated_time}")
                            st.write(f"**Difficulty:** {rec.difficulty}")
                            st.write(f"**Career Impact:** {rec.career_impact}")
                            
                            # Learning resources
                            st.subheader("üìö Learning Resources")
                            for resource in rec.learning_resources:
                                st.write(f"‚Ä¢ [{resource['name']}]({resource['url']}) ({resource['type']})")
                        
                        with col2:
                            # Progress tracking (placeholder)
                            progress = st.slider(
                                "Learning Progress",
                                0, 100, 0,
                                key=f"progress_{rec.skill}"
                            )
                            
                            if st.button(f"Add to Learning Plan", key=f"add_{rec.skill}"):
                                st.success(f"Added {rec.skill} to your learning plan!")
            else:
                st.warning("No recommendations generated. Please check your skill gap analysis.")
            
            # Learning plan summary
            st.subheader("üìã Learning Plan Summary")
            
            if recommendations:
                total_time = len(recommendations) * 2  # Rough estimate
                st.write(f"**Total estimated time:** {total_time} months")
                st.write(f"**Number of skills to learn:** {len(recommendations)}")
                
                # Create learning timeline
                timeline_data = []
                for i, rec in enumerate(recommendations):
                    timeline_data.append({
                        'Skill': rec.skill,
                        'Start Month': i * 2,
                        'Duration': 2,  # Simplified
                        'Priority': rec.priority
                    })
                
                timeline_df = pd.DataFrame(timeline_data)
                
                fig = px.timeline(
                    timeline_df,
                    x_start='Start Month',
                    x_end=[start + duration for start, duration in zip(timeline_df['Start Month'], timeline_df['Duration'])],
                    y='Skill',
                    title="Learning Timeline",
                    color='Priority'
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Complete the skill gap analysis to see your learning plan")

if __name__ == "__main__":
    main()
````

## Project Summary

The AI-Powered CV Skill Gap Analyzer represents a comprehensive career development platform that combines intelligent resume parsing, advanced skill extraction, market-driven gap analysis, and personalized upskilling recommendations to accelerate professional growth and optimize career trajectory alignment with industry demands.

### Key Value Propositions:
- **Advanced Resume Intelligence**: Multi-format document processing with sophisticated NLP-based skill extraction, experience analysis, and structured information organization for comprehensive professional profile understanding
- **Market-Driven Skill Assessment**: Real-time comparison between current competencies and industry requirements with confidence scoring, skill-level evaluation, and gap prioritization for strategic career planning
- **Personalized Learning Pathways**: AI-powered recommendation engine providing customized upskilling strategies, resource curation, and timeline estimation based on individual career goals and market trends
- **Career Progression Mapping**: Strategic visualization of professional development routes with skill acquisition planning, transition pathway identification, and career impact assessment
- **Industry Trend Integration**: Dynamic incorporation of job market data, salary impact analysis, and emerging skill demands for future-ready career development

### Technical Highlights:
- Robust document processing pipeline using pdfplumber, python-docx, and OCR technologies for comprehensive resume content extraction across multiple formats
- Advanced NLP implementation with spaCy and custom skill taxonomy for intelligent entity recognition, skill classification, and competency level inference
- Machine learning-powered similarity analysis using sentence transformers and TF-IDF vectorization for accurate skill matching and gap identification
- LangChain integration with OpenAI GPT-4 for contextual learning recommendations and personalized career guidance generation
- Interactive Streamlit interface providing comprehensive analytics, visualization tools, and progress tracking for enhanced user experience and engagement

This system democratizes access to professional career guidance, enables data-driven skill development decisions, and bridges the gap between current capabilities and market opportunities for enhanced career success and industry alignment.