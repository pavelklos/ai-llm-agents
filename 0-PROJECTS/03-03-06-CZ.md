<small>Claude Sonnet 4 **(PersonalizovanÃ½ StudijnÃ­ Tutor s RAG)**</small>
# Personalized Learning Tutor

## KlÃ­ÄovÃ© Koncepty

### RAG (Retrieval-Augmented Generation)
RAG je technika kombinujÃ­cÃ­ vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch informacÃ­ z databÃ¡ze znalostÃ­ s generovÃ¡nÃ­m odpovÄ›dÃ­ pomocÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯. UmoÅ¾Åˆuje AI poskytovat pÅ™esnÃ© a aktuÃ¡lnÃ­ odpovÄ›di zaloÅ¾enÃ© na konkrÃ©tnÃ­ch zdrojÃ­ch.

### InstructorXL Embeddings
SpecializovanÃ© embeddingovÃ© modely optimalizovanÃ© pro vzdÄ›lÃ¡vacÃ­ obsah, kterÃ© lÃ©pe zachycujÃ­ sÃ©mantickÃ© vztahy v uÄebnÃ­ch materiÃ¡lech a umoÅ¾ÅˆujÃ­ pÅ™esnÄ›jÅ¡Ã­ vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch pasÃ¡Å¾Ã­.

### Qdrant
VysokovÃ½konnÃ¡ vektorovÃ¡ databÃ¡ze optimalizovanÃ¡ pro uklÃ¡dÃ¡nÃ­ a vyhledÃ¡vÃ¡nÃ­ embeddings. Podporuje rychlÃ© similarity search a je ideÃ¡lnÃ­ pro RAG aplikace.

### Mixtral
PokroÄilÃ½ open-source jazykovÃ½ model vyuÅ¾Ã­vajÃ­cÃ­ Mixture of Experts architekturu, kterÃ½ poskytuje vysoce kvalitnÃ­ generovÃ¡nÃ­ textu pÅ™i relativnÄ› nÃ­zkÃ½ch nÃ¡kladech.

## KomplexnÃ­ VysvÄ›tlenÃ­ Projektu

### Popis a CÃ­le
PersonalizovanÃ½ studijnÃ­ tutor pÅ™edstavuje revoluci ve vzdÄ›lÃ¡vÃ¡nÃ­ prostÅ™ednictvÃ­m AI. SystÃ©m vytvÃ¡Å™Ã­ inteligentnÃ­ho asistenta, kterÃ½ dokÃ¡Å¾e odpovÃ­dat na otÃ¡zky studentÅ¯ pomocÃ­ konkrÃ©tnÃ­ch ÃºryvkÅ¯ z uÄebnic a generovat personalizovanÃ© kvÃ­zy pro procviÄovÃ¡nÃ­.

### VÃ½zvy a Å˜eÅ¡enÃ­
- **PÅ™esnost odpovÄ›dÃ­**: RAG zajiÅ¡Å¥uje, Å¾e odpovÄ›di jsou zaloÅ¾enÃ© na ovÄ›Å™enÃ½ch zdrojÃ­ch
- **Relevance obsahu**: InstructorXL embeddings zachycujÃ­ vzdÄ›lÃ¡vacÃ­ kontext
- **Rychlost vyhledÃ¡vÃ¡nÃ­**: Qdrant poskytuje milisekundovÃ© vyhledÃ¡vÃ¡nÃ­
- **Kvalita generovÃ¡nÃ­**: Mixtral vytvÃ¡Å™Ã­ koherentnÃ­ a didakticky vhodnÃ© odpovÄ›di

### Dopad a PotenciÃ¡l
SystÃ©m umoÅ¾Åˆuje Å¡kÃ¡lovÃ¡nÃ­ kvalitnÃ­ho vzdÄ›lÃ¡vÃ¡nÃ­, poskytuje 24/7 dostupnost tutora a personalizuje uÄebnÃ­ zkuÅ¡enost podle potÅ™eb kaÅ¾dÃ©ho studenta.

## KomplexnÃ­ Implementace v Pythonu

### Instalace zÃ¡vislostÃ­

````python
# requirements.txt
langchain==0.1.0
qdrant-client==1.7.0
instructor-embeddings==1.0.1
transformers==4.36.0
torch==2.1.0
sentence-transformers==2.2.2
streamlit==1.28.0
python-dotenv==1.0.0
pandas==2.1.0
numpy==1.24.0
````

### HlavnÃ­ implementace

````python
import os
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import json
import random

import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# Konfigurace logovÃ¡nÃ­
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TextbookChunk:
    """Reprezentace Ãºryvku z uÄebnice"""
    id: str
    content: str
    subject: str
    chapter: str
    page: int
    difficulty: str
    embedding: Optional[List[float]] = None

class InstructorEmbeddings:
    """Wrapper pro InstructorXL embeddings"""
    
    def __init__(self, model_name: str = "hkunlp/instructor-xl"):
        self.model = SentenceTransformer(model_name)
        logger.info(f"NaÄten embedding model: {model_name}")
    
    def encode_texts(self, texts: List[str], instruction: str = "Represent the educational text for retrieval:") -> List[List[float]]:
        """ZakÃ³duje texty do vektorovÃ© reprezentace"""
        try:
            # PÅ™idÃ¡nÃ­ instrukce ke kaÅ¾dÃ©mu textu
            instructed_texts = [f"{instruction} {text}" for text in texts]
            embeddings = self.model.encode(instructed_texts)
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"Chyba pÅ™i kÃ³dovÃ¡nÃ­ textÅ¯: {e}")
            raise

class QdrantVectorStore:
    """SprÃ¡va vektorovÃ© databÃ¡ze Qdrant"""
    
    def __init__(self, collection_name: str = "textbook_knowledge", 
                 host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
        self.collection_name = collection_name
        self.vector_size = 768  # Velikost vektoru pro instructor-xl
        self._setup_collection()
    
    def _setup_collection(self):
        """VytvoÅ™Ã­ kolekci pokud neexistuje"""
        try:
            collections = self.client.get_collections().collections
            if not any(col.name == self.collection_name for col in collections):
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=self.vector_size,
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"VytvoÅ™ena kolekce: {self.collection_name}")
        except Exception as e:
            logger.error(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ kolekce: {e}")
            raise
    
    def add_chunks(self, chunks: List[TextbookChunk]):
        """PÅ™idÃ¡ Ãºryvky do vektorovÃ© databÃ¡ze"""
        try:
            points = []
            for chunk in chunks:
                if chunk.embedding:
                    point = PointStruct(
                        id=chunk.id,
                        vector=chunk.embedding,
                        payload={
                            "content": chunk.content,
                            "subject": chunk.subject,
                            "chapter": chunk.chapter,
                            "page": chunk.page,
                            "difficulty": chunk.difficulty
                        }
                    )
                    points.append(point)
            
            self.client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            logger.info(f"PÅ™idÃ¡no {len(points)} ÃºryvkÅ¯ do databÃ¡ze")
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i pÅ™idÃ¡vÃ¡nÃ­ ÃºryvkÅ¯: {e}")
            raise
    
    def search_similar(self, query_vector: List[float], 
                      top_k: int = 5, subject_filter: Optional[str] = None) -> List[Dict]:
        """VyhledÃ¡ podobnÃ© Ãºryvky"""
        try:
            search_filter = None
            if subject_filter:
                search_filter = {"must": [{"key": "subject", "match": {"value": subject_filter}}]}
            
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=top_k,
                query_filter=search_filter
            )
            
            return [
                {
                    "content": result.payload["content"],
                    "subject": result.payload["subject"],
                    "chapter": result.payload["chapter"],
                    "page": result.payload["page"],
                    "difficulty": result.payload["difficulty"],
                    "score": result.score
                }
                for result in results
            ]
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i vyhledÃ¡vÃ¡nÃ­: {e}")
            raise

class MixtralLLM:
    """Wrapper pro Mixtral model"""
    
    def __init__(self, model_name: str = "mistralai/Mixtral-8x7B-Instruct-v0.1"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.pipeline = None
        self._load_model()
    
    def _load_model(self):
        """NaÄte Mixtral model"""
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                device_map="auto" if device == "cuda" else None
            )
            
            self.pipeline = pipeline(
                "text-generation",
                model=self.model,
                tokenizer=self.tokenizer,
                max_length=2048,
                temperature=0.7,
                do_sample=True
            )
            
            logger.info(f"NaÄten Mixtral model na {device}")
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ modelu: {e}")
            raise
    
    def generate_answer(self, question: str, context_chunks: List[Dict]) -> str:
        """Generuje odpovÄ›Ä na zÃ¡kladÄ› otÃ¡zky a kontextu"""
        try:
            # SestavenÃ­ kontextu
            context = "\n\n".join([
                f"Zdroj (PÅ™edmÄ›t: {chunk['subject']}, Kapitola: {chunk['chapter']}, Strana: {chunk['page']}):\n{chunk['content']}"
                for chunk in context_chunks
            ])
            
            prompt = f"""Jsi odbornÃ½ tutor. Na zÃ¡kladÄ› poskytnutÃ½ch zdrojÅ¯ z uÄebnic odpovÄ›z na studentovu otÃ¡zku.

Kontext z uÄebnic:
{context}

OtÃ¡zka studenta: {question}

OdpovÄ›Ä (uveÄ konkrÃ©tnÃ­ zdroje):"""

            response = self.pipeline(prompt)[0]["generated_text"]
            # Extrakce pouze novÃ© ÄÃ¡sti odpovÄ›di
            answer = response[len(prompt):].strip()
            
            return answer
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i generovÃ¡nÃ­ odpovÄ›di: {e}")
            return "OmlouvÃ¡me se, doÅ¡lo k chybÄ› pÅ™i generovÃ¡nÃ­ odpovÄ›di."
    
    def generate_quiz(self, topic: str, content: str, num_questions: int = 3) -> List[Dict]:
        """Generuje kvÃ­z na zÃ¡kladÄ› obsahu"""
        try:
            prompt = f"""Na zÃ¡kladÄ› nÃ¡sledujÃ­cÃ­ho obsahu vytvoÅ™ {num_questions} otÃ¡zky s moÅ¾nostmi a sprÃ¡vnÃ½mi odpovÄ›Ämi pro tÃ©ma "{topic}".

Obsah:
{content}

FormÃ¡t odpovÄ›di - kaÅ¾dÃ¡ otÃ¡zka na novÃ©m Å™Ã¡dku:
Q: [otÃ¡zka]
A) [moÅ¾nost A]
B) [moÅ¾nost B] 
C) [moÅ¾nost C]
D) [moÅ¾nost D]
SprÃ¡vnÃ¡ odpovÄ›Ä: [A/B/C/D]
VysvÄ›tlenÃ­: [vysvÄ›tlenÃ­]

OtÃ¡zky:"""

            response = self.pipeline(prompt)[0]["generated_text"]
            quiz_text = response[len(prompt):].strip()
            
            # ParsovÃ¡nÃ­ kvÃ­zu (zjednoduÅ¡enÃ¡ verze)
            questions = []
            current_question = {}
            
            for line in quiz_text.split('\n'):
                line = line.strip()
                if line.startswith('Q:'):
                    if current_question:
                        questions.append(current_question)
                    current_question = {'question': line[2:].strip(), 'options': [], 'correct': '', 'explanation': ''}
                elif line.startswith(('A)', 'B)', 'C)', 'D)')):
                    current_question['options'].append(line)
                elif line.startswith('SprÃ¡vnÃ¡ odpovÄ›Ä:'):
                    current_question['correct'] = line.split(':')[1].strip()
                elif line.startswith('VysvÄ›tlenÃ­:'):
                    current_question['explanation'] = line.split(':')[1].strip()
            
            if current_question:
                questions.append(current_question)
            
            return questions[:num_questions]
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i generovÃ¡nÃ­ kvÃ­zu: {e}")
            return []

class PersonalizedTutorRAG:
    """HlavnÃ­ tÅ™Ã­da pro personalizovanÃ©ho tutora"""
    
    def __init__(self):
        self.embeddings = InstructorEmbeddings()
        self.vector_store = QdrantVectorStore()
        self.llm = MixtralLLM()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", "! ", "? "]
        )
    
    def load_textbook_data(self) -> List[TextbookChunk]:
        """NaÄte ukÃ¡zkovÃ¡ data uÄebnic"""
        # Simulace dat z uÄebnic
        sample_data = [
            {
                "content": "FotosyntÃ©za je biologickÃ½ proces, pÅ™i kterÃ©m rostliny pÅ™emÄ›ÅˆujÃ­ svÄ›telnou energii na chemickou energii. Tento proces probÃ­hÃ¡ v chloroplastech a zahrnuje dvÄ› hlavnÃ­ fÃ¡ze: svÄ›telnou a temnostnÃ­ reakci.",
                "subject": "Biologie",
                "chapter": "BunÄ›ÄnÃ© procesy",
                "page": 45,
                "difficulty": "stÅ™ednÃ­"
            },
            {
                "content": "KvadratickÃ¡ rovnice axÂ² + bx + c = 0 mÃ¡ Å™eÅ¡enÃ­ danÃ© diskriminantem Î” = bÂ² - 4ac. Pokud je Î” > 0, mÃ¡ rovnice dva rÅ¯znÃ© reÃ¡lnÃ© koÅ™eny, pokud Î” = 0, mÃ¡ jeden dvojnÃ¡sobnÃ½ koÅ™en, a pokud Î” < 0, nemÃ¡ reÃ¡lnÃ© koÅ™eny.",
                "subject": "Matematika",
                "chapter": "KvadratickÃ© rovnice",
                "page": 78,
                "difficulty": "pokroÄilÃ¡"
            },
            {
                "content": "Newtonovy pohybovÃ© zÃ¡kony tvoÅ™Ã­ zÃ¡klad klasickÃ© mechaniky. PrvnÃ­ zÃ¡kon (zÃ¡kon setrvaÄnosti) Å™Ã­kÃ¡, Å¾e tÄ›leso setrvÃ¡vÃ¡ v klidu nebo v rovnomÄ›rnÃ©m pÅ™Ã­moÄarÃ©m pohybu, dokud na nÄ›j nepÅ¯sobÃ­ vnÄ›jÅ¡Ã­ sÃ­la.",
                "subject": "Fyzika",
                "chapter": "Mechanika",
                "page": 23,
                "difficulty": "zÃ¡kladnÃ­"
            }
        ]
        
        chunks = []
        for i, data in enumerate(sample_data):
            chunk = TextbookChunk(
                id=str(i),
                content=data["content"],
                subject=data["subject"],
                chapter=data["chapter"],
                page=data["page"],
                difficulty=data["difficulty"]
            )
            chunks.append(chunk)
        
        return chunks
    
    def initialize_knowledge_base(self):
        """Inicializuje databÃ¡zi znalostÃ­"""
        try:
            chunks = self.load_textbook_data()
            
            # GenerovÃ¡nÃ­ embeddingÅ¯
            contents = [chunk.content for chunk in chunks]
            embeddings = self.embeddings.encode_texts(contents)
            
            # PÅ™iÅ™azenÃ­ embeddingÅ¯ k ÃºryvkÅ¯m
            for chunk, embedding in zip(chunks, embeddings):
                chunk.embedding = embedding
            
            # UloÅ¾enÃ­ do vektorovÃ© databÃ¡ze
            self.vector_store.add_chunks(chunks)
            
            logger.info("DatabÃ¡ze znalostÃ­ ÃºspÄ›Å¡nÄ› inicializovÃ¡na")
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i inicializaci: {e}")
            raise
    
    def answer_question(self, question: str, subject_filter: Optional[str] = None) -> Tuple[str, List[Dict]]:
        """OdpovÃ­dÃ¡ na studentovu otÃ¡zku"""
        try:
            # ZakÃ³dovÃ¡nÃ­ otÃ¡zky
            question_embedding = self.embeddings.encode_texts([question])[0]
            
            # VyhledÃ¡nÃ­ relevantnÃ­ch ÃºryvkÅ¯
            relevant_chunks = self.vector_store.search_similar(
                query_vector=question_embedding,
                top_k=3,
                subject_filter=subject_filter
            )
            
            if not relevant_chunks:
                return "BohuÅ¾el jsem nenaÅ¡el relevantnÃ­ informace k vaÅ¡Ã­ otÃ¡zce.", []
            
            # GenerovÃ¡nÃ­ odpovÄ›di
            answer = self.llm.generate_answer(question, relevant_chunks)
            
            return answer, relevant_chunks
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i odpovÃ­dÃ¡nÃ­ na otÃ¡zku: {e}")
            return "OmlouvÃ¡me se, doÅ¡lo k chybÄ› pÅ™i zpracovÃ¡nÃ­ vaÅ¡Ã­ otÃ¡zky.", []
    
    def create_practice_quiz(self, topic: str, subject: Optional[str] = None) -> List[Dict]:
        """VytvoÅ™Ã­ procviÄovacÃ­ kvÃ­z"""
        try:
            # VyhledÃ¡nÃ­ obsahu pro tÃ©ma
            topic_embedding = self.embeddings.encode_texts([topic])[0]
            relevant_chunks = self.vector_store.search_similar(
                query_vector=topic_embedding,
                top_k=2,
                subject_filter=subject
            )
            
            if not relevant_chunks:
                return []
            
            # SpojenÃ­ obsahu
            combined_content = "\n\n".join([chunk["content"] for chunk in relevant_chunks])
            
            # GenerovÃ¡nÃ­ kvÃ­zu
            quiz = self.llm.generate_quiz(topic, combined_content)
            
            return quiz
            
        except Exception as e:
            logger.error(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ kvÃ­zu: {e}")
            return []

# Streamlit aplikace
def main():
    """HlavnÃ­ Streamlit aplikace"""
    st.set_page_config(
        page_title="PersonalizovanÃ½ StudijnÃ­ Tutor",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    st.title("ğŸ“ PersonalizovanÃ½ StudijnÃ­ Tutor s RAG")
    st.markdown("---")
    
    # Inicializace session state
    if 'tutor' not in st.session_state:
        with st.spinner("NaÄÃ­tÃ¡m systÃ©m tutora..."):
            try:
                st.session_state.tutor = PersonalizedTutorRAG()
                st.session_state.tutor.initialize_knowledge_base()
                st.success("SystÃ©m ÃºspÄ›Å¡nÄ› naÄten!")
            except Exception as e:
                st.error(f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­: {e}")
                return
    
    # BoÄnÃ­ panel pro nastavenÃ­
    with st.sidebar:
        st.header("âš™ï¸ NastavenÃ­")
        
        subject_filter = st.selectbox(
            "Filtr pÅ™edmÄ›tu:",
            ["VÅ¡echny", "Matematika", "Fyzika", "Biologie", "Chemie"]
        )
        
        if subject_filter == "VÅ¡echny":
            subject_filter = None
    
    # HlavnÃ­ obsah
    tab1, tab2 = st.tabs(["ğŸ’¬ OtÃ¡zky a odpovÄ›di", "ğŸ“ ProcviÄovacÃ­ kvÃ­zy"])
    
    with tab1:
        st.header("Zeptejte se na cokoliv!")
        
        question = st.text_input(
            "VaÅ¡e otÃ¡zka:",
            placeholder="napÅ™. Jak funguje fotosyntÃ©za?"
        )
        
        if st.button("ğŸ” OdpovÄ›dÄ›t", type="primary"):
            if question:
                with st.spinner("HledÃ¡m odpovÄ›Ä..."):
                    answer, sources = st.session_state.tutor.answer_question(
                        question, subject_filter
                    )
                
                st.subheader("ğŸ“– OdpovÄ›Ä:")
                st.write(answer)
                
                if sources:
                    st.subheader("ğŸ“š Zdroje:")
                    for i, source in enumerate(sources, 1):
                        with st.expander(f"Zdroj {i}: {source['subject']} - {source['chapter']}"):
                            st.write(f"**Obsah:** {source['content']}")
                            st.write(f"**Strana:** {source['page']}")
                            st.write(f"**ObtÃ­Å¾nost:** {source['difficulty']}")
                            st.write(f"**Relevance:** {source['score']:.3f}")
            else:
                st.warning("ProsÃ­m, zadejte otÃ¡zku.")
    
    with tab2:
        st.header("ProcviÄovacÃ­ kvÃ­zy")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            topic = st.text_input(
                "TÃ©ma kvÃ­zu:",
                placeholder="napÅ™. kvadratickÃ© rovnice"
            )
        
        with col2:
            num_questions = st.number_input(
                "PoÄet otÃ¡zek:",
                min_value=1,
                max_value=5,
                value=3
            )
        
        if st.button("ğŸ¯ VytvoÅ™it kvÃ­z", type="primary"):
            if topic:
                with st.spinner("VytvÃ¡Å™Ã­m kvÃ­z..."):
                    quiz = st.session_state.tutor.create_practice_quiz(
                        topic, subject_filter
                    )
                
                if quiz:
                    st.subheader(f"ğŸ“ KvÃ­z: {topic}")
                    
                    for i, q in enumerate(quiz, 1):
                        st.markdown(f"**OtÃ¡zka {i}:** {q['question']}")
                        
                        for option in q['options']:
                            st.write(f"  {option}")
                        
                        with st.expander("Zobrazit odpovÄ›Ä"):
                            st.write(f"**SprÃ¡vnÃ¡ odpovÄ›Ä:** {q['correct']}")
                            if q['explanation']:
                                st.write(f"**VysvÄ›tlenÃ­:** {q['explanation']}")
                        
                        st.markdown("---")
                else:
                    st.warning("NepodaÅ™ilo se vytvoÅ™it kvÃ­z pro toto tÃ©ma.")
            else:
                st.warning("ProsÃ­m, zadejte tÃ©ma kvÃ­zu.")

if __name__ == "__main__":
    main()
````

### SpuÅ¡tÄ›nÃ­ aplikace

````bash
# SpuÅ¡tÄ›nÃ­ Qdrant databÃ¡ze (Docker)
docker run -p 6333:6333 qdrant/qdrant

# SpuÅ¡tÄ›nÃ­ Streamlit aplikace
streamlit run tutor_rag_system.py
````

## ShrnutÃ­ Projektu

PersonalizovanÃ½ studijnÃ­ tutor pÅ™edstavuje pokroÄilÃ© Å™eÅ¡enÃ­ kombinujÃ­cÃ­ nejmodernÄ›jÅ¡Ã­ AI technologie pro revoluci ve vzdÄ›lÃ¡vÃ¡nÃ­. SystÃ©m vyuÅ¾Ã­vÃ¡ RAG architekturu s InstructorXL embeddings pro pÅ™esnÃ© zachycenÃ­ vzdÄ›lÃ¡vacÃ­ho kontextu, Qdrant databÃ¡zi pro rychlÃ© vyhledÃ¡vÃ¡nÃ­ a Mixtral model pro kvalitnÃ­ generovÃ¡nÃ­ odpovÄ›dÃ­.

**KlÃ­ÄovÃ© vÃ½hody:**
- PÅ™esnÃ© odpovÄ›di zaloÅ¾enÃ© na ovÄ›Å™enÃ½ch zdrojÃ­ch
- PersonalizovanÃ© kvÃ­zy pro aktivnÃ­ uÄenÃ­
- Å kÃ¡lovatelnÃ¡ architektura pro tisÃ­ce studentÅ¯
- 24/7 dostupnost kvalitnÃ­ho tutora

**TechnickÃ© inovace:**
- VyuÅ¾itÃ­ specializovanÃ½ch vzdÄ›lÃ¡vacÃ­ch embeddingÅ¯
- OptimalizovanÃ¡ vektorovÃ¡ databÃ¡ze pro vzdÄ›lÃ¡vacÃ­ obsah
- ModernÃ­ LLM s efektivnÃ­ Mixture of Experts architekturou

Projekt demonstruje sÃ­lu kombinace rÅ¯znÃ½ch AI technologiÃ­ pro vytvoÅ™enÃ­ praktickÃ©ho Å™eÅ¡enÃ­, kterÃ© mÅ¯Å¾e vÃ½znamnÄ› zlepÅ¡it kvalitu a dostupnost vzdÄ›lÃ¡vÃ¡nÃ­.