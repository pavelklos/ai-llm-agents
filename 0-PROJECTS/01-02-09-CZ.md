<small>Claude Sonnet 4 **(Scientific Paper Translator & Explainer)**</small>
# Scientific Paper Translator & Explainer

## Klíčové Koncepty

### Model Context Protocol (MCP)
MCP je protokol navržený pro standardizaci komunikace mezi AI modely a externími zdroji dat. Umožňuje bezpečné a efektivní propojení AI systémů s databázemi, API a dalšími službami, čímž rozšiřuje schopnosti modelů o aktuální a specifické informace.

### Arxiv API
Arxiv API poskytuje programový přístup k rozsáhlé databázi vědeckých publikací. Umožňuje vyhledávání, stahování metadat a plných textů vědeckých článků z různých oborů včetně fyziky, matematiky, informatiky a dalších.

### LangChain
LangChain je framework pro vývoj aplikací využívajících velké jazykové modely. Poskytuje nástroje pro řetězení operací, správu promptů, integraci s externími API a vytváření komplexních AI aplikací.

### Translation Tools
Překladatelské nástroje v kontextu AI zahrnují různé služby a modely schopné převádět text mezi jazyky při zachování významu a kontextu, včetně specializovaných termínů.

### Citation Retriever
Systém pro automatické vyhledávání a extrakci citací z vědeckých textů. Umožňuje identifikaci odkazovaných prací, vytváření bibliografických záznamů a analýzu vědeckých vazeb.

### Summary Memory
Mechanismus pro udržování a správu souhrnů dlouhodobých konverzací či dokumentů. Umožňuje AI systémům pracovat s rozsáhlými texty efektivně při zachování klíčových informací.

## Komplexní Vysvětlení Projektu

### Cíle Projektu
Projekt **Scientific Paper Translator & Explainer** si klade za cíl vytvořit inteligentní systém schopný automaticky vyhledávat, překládat a vysvětlovat vědecké publikace. Systém kombinuje pokročilé AI technologie s rozsáhlými vědeckými databázemi pro poskytování přístupných vysvětlení složitých vědeckých konceptů.

### Výzvy Projektu
- **Komplexnost vědeckého jazyka**: Zachování přesnosti při překládání specializované terminologie
- **Kontextové porozumění**: Udržení vědeckého kontextu napříč různými obory
- **Správa citací**: Sledování a ověřování vědeckých odkazů
- **Škálovatelnost**: Efektivní zpracování velkých objemů dat
- **Aktuálnost**: Práce s neustále se měnící vědeckou literaturou

### Potenciální Dopad
Systém může demokratizovat přístup k vědeckým poznatkům, umožnit výzkumníkům rychleji prozkoumávat nové oblasti a pomoci studentům lépe porozumět složitým vědeckým konceptům.

## Komplexní Implementace Projektu

````python
import asyncio
import aiohttp
import feedparser
import xml.etree.ElementTree as ET
from dataclasses import dataclass
from typing import List, Dict, Optional, Any
import logging
from datetime import datetime
import re
import json
import sqlite3
from pathlib import Path

from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.memory import ConversationSummaryBufferMemory
from langchain.prompts import PromptTemplate
import openai

# Konfigurace loggingu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ScientificPaper:
    """Datová struktura pro vědecký článek"""
    id: str
    title: str
    authors: List[str]
    abstract: str
    published: datetime
    categories: List[str]
    url: str
    citations: List[str] = None
    full_text: str = None
    translated_abstract: str = None
    explanation: str = None

class ArxivAPI:
    """Třída pro komunikaci s Arxiv API"""
    
    BASE_URL = "http://export.arxiv.org/api/query"
    
    async def search_papers(
        self, 
        query: str, 
        max_results: int = 10,
        category: str = None
    ) -> List[ScientificPaper]:
        """Vyhledání vědeckých článků na Arxiv"""
        params = {
            'search_query': query,
            'start': 0,
            'max_results': max_results,
            'sortBy': 'relevance',
            'sortOrder': 'descending'
        }
        
        if category:
            params['search_query'] += f" AND cat:{category}"
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self.BASE_URL, params=params) as response:
                    content = await response.text()
                    return self._parse_arxiv_response(content)
        except Exception as e:
            logger.error(f"Chyba při vyhledávání na Arxiv: {e}")
            return []
    
    def _parse_arxiv_response(self, xml_content: str) -> List[ScientificPaper]:
        """Parsování XML odpovědi z Arxiv"""
        papers = []
        root = ET.fromstring(xml_content)
        
        # Namespace pro Arxiv
        ns = {
            'atom': 'http://www.w3.org/2005/Atom',
            'arxiv': 'http://arxiv.org/schemas/atom'
        }
        
        for entry in root.findall('atom:entry', ns):
            try:
                paper = ScientificPaper(
                    id=entry.find('atom:id', ns).text.split('/')[-1],
                    title=entry.find('atom:title', ns).text.strip(),
                    authors=[
                        author.find('atom:name', ns).text 
                        for author in entry.findall('atom:author', ns)
                    ],
                    abstract=entry.find('atom:summary', ns).text.strip(),
                    published=datetime.strptime(
                        entry.find('atom:published', ns).text[:10], 
                        '%Y-%m-%d'
                    ),
                    categories=[
                        cat.get('term') 
                        for cat in entry.findall('atom:category', ns)
                    ],
                    url=entry.find('atom:id', ns).text
                )
                papers.append(paper)
            except Exception as e:
                logger.warning(f"Chyba při parsování článku: {e}")
                continue
        
        return papers

class TranslationService:
    """Služba pro překlad vědeckých textů"""
    
    def __init__(self, openai_api_key: str):
        self.llm = OpenAI(
            openai_api_key=openai_api_key,
            temperature=0.3,
            model_name="gpt-3.5-turbo-instruct"
        )
        
        self.translation_prompt = PromptTemplate(
            input_variables=["text", "source_lang", "target_lang", "field"],
            template="""
            Přelož následující vědecký text z jazyka {source_lang} do jazyka {target_lang}.
            Oblast vědy: {field}
            
            Při překladu:
            1. Zachovej všechny odborné termíny a jejich přesný význam
            2. Udržuj vědecký styl a formálnost
            3. Pokud existují etablované české překlady termínů, použij je
            4. Neznámé termíny nech v původním jazyce a přidej vysvětlení v závorkách
            
            Text k překladu:
            {text}
            
            Překlad:
            """
        )
    
    async def translate_abstract(
        self, 
        abstract: str, 
        field: str,
        source_lang: str = "anglický",
        target_lang: str = "český"
    ) -> str:
        """Překlad abstraktu vědeckého článku"""
        try:
            prompt = self.translation_prompt.format(
                text=abstract,
                source_lang=source_lang,
                target_lang=target_lang,
                field=field
            )
            
            translation = await asyncio.get_event_loop().run_in_executor(
                None, self.llm, prompt
            )
            
            return translation.strip()
        except Exception as e:
            logger.error(f"Chyba při překladu: {e}")
            return f"Překlad nedostupný: {str(e)}"

class CitationRetriever:
    """Systém pro extrakci a správu citací"""
    
    def __init__(self, db_path: str = "citations.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Inicializace databáze citací"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS citations (
                id INTEGER PRIMARY KEY,
                paper_id TEXT,
                cited_paper_id TEXT,
                citation_text TEXT,
                confidence REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
    
    def extract_citations(self, text: str) -> List[Dict[str, Any]]:
        """Extrakce citací z textu"""
        citations = []
        
        # Regex vzory pro různé formáty citací
        patterns = [
            r'\[(\d+)\]',  # [1], [2], etc.
            r'\(([A-Za-z]+\s+et\s+al\.\s*,?\s*\d{4})\)',  # (Smith et al., 2020)
            r'\(([A-Za-z]+\s*,?\s*\d{4})\)',  # (Smith, 2020)
            r'arXiv:(\d{4}\.\d{4,5})',  # arXiv:2020.12345
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                citations.append({
                    'text': match.group(0),
                    'reference': match.group(1),
                    'position': match.span(),
                    'confidence': 0.8
                })
        
        return citations
    
    def store_citations(self, paper_id: str, citations: List[Dict[str, Any]]):
        """Uložení citací do databáze"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for citation in citations:
            cursor.execute("""
                INSERT INTO citations (paper_id, cited_paper_id, citation_text, confidence)
                VALUES (?, ?, ?, ?)
            """, (
                paper_id,
                citation.get('reference', ''),
                citation.get('text', ''),
                citation.get('confidence', 0.0)
            ))
        
        conn.commit()
        conn.close()

class SummaryMemory:
    """Systém pro správu a udržování souhrnů"""
    
    def __init__(self, openai_api_key: str, max_token_limit: int = 2000):
        self.memory = ConversationSummaryBufferMemory(
            llm=OpenAI(openai_api_key=openai_api_key, temperature=0),
            max_token_limit=max_token_limit,
            return_messages=True
        )
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.vectorstore = Chroma(embedding_function=self.embeddings)
    
    def add_paper_summary(self, paper: ScientificPaper, summary: str):
        """Přidání souhrnu článku do paměti"""
        document = Document(
            page_content=summary,
            metadata={
                'paper_id': paper.id,
                'title': paper.title,
                'authors': ', '.join(paper.authors),
                'categories': ', '.join(paper.categories),
                'published': paper.published.isoformat()
            }
        )
        
        self.vectorstore.add_documents([document])
    
    def retrieve_relevant_context(self, query: str, k: int = 3) -> List[Document]:
        """Získání relevantního kontextu z paměti"""
        return self.vectorstore.similarity_search(query, k=k)

class ScientificExplainer:
    """Hlavní třída pro vysvětlování vědeckých článků"""
    
    def __init__(self, openai_api_key: str):
        self.llm = OpenAI(
            openai_api_key=openai_api_key,
            temperature=0.4,
            model_name="gpt-3.5-turbo-instruct"
        )
        
        self.explanation_prompt = PromptTemplate(
            input_variables=["title", "abstract", "field", "context"],
            template="""
            Vysvětli následující vědecký článek v češtině pro širší veřejnost:
            
            Název: {title}
            Oblast: {field}
            Abstrakt: {abstract}
            
            Souvislosti z dalších článků:
            {context}
            
            Vytvoř vysvětlení, které:
            1. Shrne hlavní myšlenku článku v jednoduchých termínech
            2. Vysvětlí proč je tento výzkum důležitý
            3. Popíše možné praktické aplikace
            4. Propojí s kontextem dalších výzkumů
            5. Zdůrazní nové poznatky nebo objevy
            
            Vysvětlení by mělo být srozumitelné pro vzdělanou veřejnost bez specializovaných znalostí.
            
            Vysvětlení:
            """
        )
    
    async def explain_paper(
        self, 
        paper: ScientificPaper, 
        context: List[Document] = None
    ) -> str:
        """Vytvoření vysvětlení vědeckého článku"""
        try:
            context_text = ""
            if context:
                context_text = "\n".join([
                    f"- {doc.metadata.get('title', 'Neznámý název')}: {doc.page_content[:200]}..."
                    for doc in context
                ])
            
            prompt = self.explanation_prompt.format(
                title=paper.title,
                abstract=paper.translated_abstract or paper.abstract,
                field=", ".join(paper.categories),
                context=context_text
            )
            
            explanation = await asyncio.get_event_loop().run_in_executor(
                None, self.llm, prompt
            )
            
            return explanation.strip()
        except Exception as e:
            logger.error(f"Chyba při vytváření vysvětlení: {e}")
            return f"Vysvětlení nedostupné: {str(e)}"

class ScientificPaperProcessor:
    """Hlavní třída orchestrující celý proces"""
    
    def __init__(self, openai_api_key: str):
        self.arxiv_api = ArxivAPI()
        self.translator = TranslationService(openai_api_key)
        self.citation_retriever = CitationRetriever()
        self.summary_memory = SummaryMemory(openai_api_key)
        self.explainer = ScientificExplainer(openai_api_key)
    
    async def process_query(
        self, 
        query: str, 
        max_papers: int = 5,
        category: str = None
    ) -> List[ScientificPaper]:
        """Kompletní zpracování dotazu na vědecké články"""
        logger.info(f"Zpracovávám dotaz: {query}")
        
        # 1. Vyhledání článků
        papers = await self.arxiv_api.search_papers(
            query=query, 
            max_results=max_papers,
            category=category
        )
        
        if not papers:
            logger.warning("Žádné články nenalezeny")
            return []
        
        # 2. Zpracování každého článku
        for paper in papers:
            try:
                # Překlad abstraktu
                field = paper.categories[0] if paper.categories else "obecná věda"
                paper.translated_abstract = await self.translator.translate_abstract(
                    paper.abstract, 
                    field
                )
                
                # Extrakce citací
                citations = self.citation_retriever.extract_citations(paper.abstract)
                paper.citations = citations
                self.citation_retriever.store_citations(paper.id, citations)
                
                # Získání relevantního kontextu
                context = self.summary_memory.retrieve_relevant_context(
                    f"{paper.title} {paper.abstract}"
                )
                
                # Vytvoření vysvětlení
                paper.explanation = await self.explainer.explain_paper(paper, context)
                
                # Uložení souhrnu do paměti
                summary = f"Název: {paper.title}\nVysvětlení: {paper.explanation[:500]}..."
                self.summary_memory.add_paper_summary(paper, summary)
                
                logger.info(f"Zpracován článek: {paper.title}")
                
            except Exception as e:
                logger.error(f"Chyba při zpracování článku {paper.id}: {e}")
                paper.explanation = f"Zpracování se nezdařilo: {str(e)}"
        
        return papers
    
    def generate_report(self, papers: List[ScientificPaper]) -> str:
        """Generování závěrečné zprávy"""
        if not papers:
            return "Žádné články nebyly nalezeny nebo zpracovány."
        
        report = f"# Zpráva o Vědeckých Článcích\n\n"
        report += f"**Celkem zpracováno:** {len(papers)} článků\n"
        report += f"**Datum zpracování:** {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n"
        
        for i, paper in enumerate(papers, 1):
            report += f"## {i}. {paper.title}\n\n"
            report += f"**Autoři:** {', '.join(paper.authors)}\n"
            report += f"**Kategorie:** {', '.join(paper.categories)}\n"
            report += f"**Publikováno:** {paper.published.strftime('%d.%m.%Y')}\n"
            report += f"**URL:** {paper.url}\n\n"
            
            if paper.translated_abstract:
                report += f"### Přeložený abstrakt\n{paper.translated_abstract}\n\n"
            
            if paper.explanation:
                report += f"### Vysvětlení\n{paper.explanation}\n\n"
            
            if paper.citations:
                report += f"### Citace ({len(paper.citations)})\n"
                for citation in paper.citations[:3]:  # Max 3 citace
                    report += f"- {citation['text']}\n"
                report += "\n"
            
            report += "---\n\n"
        
        return report

# Hlavní funkce pro demonstraci
async def main():
    """Hlavní demonstrační funkce"""
    # Konfigurace (v produkci použijte environment variables)
    OPENAI_API_KEY = "your-openai-api-key-here"
    
    if OPENAI_API_KEY == "your-openai-api-key-here":
        print("⚠️  Prosím nastavte svůj OpenAI API klíč")
        return
    
    # Inicializace procesoru
    processor = ScientificPaperProcessor(OPENAI_API_KEY)
    
    # Příklad dotazu
    query = "machine learning neural networks"
    category = "cs.AI"  # Computer Science - Artificial Intelligence
    
    print(f"🔍 Vyhledávám články pro: '{query}'")
    print(f"📂 Kategorie: {category}")
    print("=" * 50)
    
    # Zpracování dotazu
    papers = await processor.process_query(
        query=query,
        max_papers=3,
        category=category
    )
    
    # Generování zprávy
    report = processor.generate_report(papers)
    
    # Uložení zprávy
    report_path = Path("scientific_report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"📊 Zpráva uložena do: {report_path}")
    print(f"🎉 Zpracováno {len(papers)} článků")
    
    # Ukázka prvního článku
    if papers:
        paper = papers[0]
        print(f"\n📄 Ukázka prvního článku:")
        print(f"Název: {paper.title}")
        print(f"Vysvětlení: {paper.explanation[:300]}...")

if __name__ == "__main__":
    asyncio.run(main())
````

````python
aiohttp==3.9.1
feedparser==6.0.10
langchain==0.1.0
openai==1.7.2
chromadb==0.4.20
sqlite3
python-dotenv==1.0.0
asyncio
logging
datetime
re
json
pathlib
xml
````

````python
import os
from pathlib import Path
from dotenv import load_dotenv

# Načtení environment variables
load_dotenv()

class Config:
    """Konfigurace aplikace"""
    
    # API klíče
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # Databáze
    DATABASE_PATH = Path("data/scientific_papers.db")
    VECTOR_DB_PATH = Path("data/vectorstore")
    
    # Arxiv API
    ARXIV_BASE_URL = "http://export.arxiv.org/api/query"
    MAX_PAPERS_PER_QUERY = 10
    
    # Překlad
    DEFAULT_SOURCE_LANGUAGE = "anglický"
    DEFAULT_TARGET_LANGUAGE = "český"
    
    # Memory
    MAX_MEMORY_TOKENS = 2000
    SIMILARITY_SEARCH_K = 3
    
    # Logging
    LOG_LEVEL = "INFO"
    LOG_FILE = Path("logs/scientific_processor.log")
    
    @classmethod
    def validate(cls):
        """Validace konfigurace"""
        errors = []
        
        if not cls.OPENAI_API_KEY:
            errors.append("OPENAI_API_KEY není nastaven")
        
        # Vytvoření adresářů
        cls.DATABASE_PATH.parent.mkdir(exist_ok=True)
        cls.VECTOR_DB_PATH.mkdir(exist_ok=True)
        cls.LOG_FILE.parent.mkdir(exist_ok=True)
        
        if errors:
            raise ValueError(f"Chyby v konfiguraci: {', '.join(errors)}")
        
        return True
````

## Shrnutí Projektu

**Scientific Paper Translator & Explainer** představuje pokročilý AI systém, který revolucionizuje způsob, jakým přistupujeme k vědecké literatuře. Kombinací Model Context Protocol, Arxiv API, LangChain a dalších moderních technologií vytváří inteligentní most mezi složitými vědeckými texty a jejich srozumitelným vysvětlením.

### Klíčové Přínosy
- **Automatizovaný překlad** vědeckých abstrakt s zachováním odborné přesnosti
- **Inteligentní vysvětlování** složitých konceptů pro širší veřejnost
- **Správa citací** a vědeckých referencí
- **Kontextové učení** prostřednictvím vector embeddings
- **Škálovatelná architektura** pro zpracování velkých objemů dat

### Technologická Hodnota
Projekt demonstruje praktické využití moderních AI frameworků v reálných aplikacích, včetně asynchronního programování, vector databází a pokročilých NLP technik. Architektura je navržena s důrazem na modularity, rozšiřitelnost a maintainability.

Tento systém má potenciál výrazně zpřístupnit vědecké poznatky širší veřejnosti a urychlit vědeckou komunikaci napříč jazykovými bariérami.