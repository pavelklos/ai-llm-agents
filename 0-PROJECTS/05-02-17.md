<small>Claude Sonnet 4 **(Resume & Job Matching Agent)**</small>
# Resume & Job Matching Agent

## Key Concepts Explanation

### Resume Parsing and Information Extraction
Advanced document processing system that extracts structured data from various resume formats (PDF, DOC, TXT) using OCR, NLP, and pattern recognition to identify contact information, work experience, education, skills, and achievements with high accuracy.

### Job Scraping and Aggregation
Automated web scraping framework that collects job postings from multiple platforms (LinkedIn, Indeed, Glassdoor, company websites) using ethical scraping techniques, handling rate limiting, and maintaining real-time job market data feeds.

### Semantic Matching and Similarity Analysis
AI-powered matching engine that uses vector embeddings, transformer models, and semantic understanding to calculate compatibility scores between resumes and job descriptions based on skills alignment, experience relevance, and cultural fit indicators.

### Skills Gap Analysis
Intelligent assessment system that identifies missing skills and qualifications by comparing candidate profiles against job requirements, providing personalized recommendations for skill development and career advancement.

### Career Recommendation Engine
ML-driven recommendation system that suggests optimal career paths, relevant job opportunities, and professional development strategies based on individual experience, market trends, and success patterns of similar profiles.

## Comprehensive Project Explanation

### Objectives
The Resume & Job Matching Agent automates the job search process by intelligently parsing resumes, scraping relevant job postings, and providing semantic matching with personalized recommendations to optimize career opportunities and hiring efficiency.

### Key Features
- **Multi-format Resume Parsing**: Extract data from PDF, Word, and text resumes
- **Real-time Job Aggregation**: Scrape and aggregate jobs from multiple sources
- **Intelligent Matching**: Semantic similarity analysis with scoring algorithms
- **Skills Analysis**: Gap identification and development recommendations
- **Market Insights**: Salary trends and demand analysis

### Challenges
- **Data Quality**: Handling inconsistent resume formats and job posting structures
- **Scalability**: Processing large volumes of resumes and job postings efficiently
- **Semantic Understanding**: Accurately matching similar concepts across different terminology
- **Legal Compliance**: Ensuring ethical scraping practices and data privacy protection

### Potential Impact
This system can revolutionize job searching by reducing time-to-hire, improving candidate-job fit quality, democratizing access to career opportunities, and providing data-driven insights for career development and workforce planning.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
langchain==0.1.0
langchain-openai==0.0.5
chromadb==0.4.18
sentence-transformers==2.2.2
pandas==2.1.4
numpy==1.24.3
plotly==5.17.0
requests==2.31.0
beautifulsoup4==4.12.2
selenium==4.15.2
PyPDF2==3.0.1
python-docx==0.8.11
spacy==3.7.2
scikit-learn==1.3.2
nltk==3.8.1
fuzzywuzzy==0.18.0
python-levenshtein==0.23.0
pydantic==2.5.0
sqlite3
datetime
json
re
uuid
logging
typing
dataclasses
enum
````

### Core Implementation

````python
import sqlite3
import json
import logging
import re
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import io

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np

# NLP and ML
import spacy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from fuzzywuzzy import fuzz, process

# Document processing
import PyPDF2
from docx import Document
import requests
from bs4 import BeautifulSoup

# Vector database
import chromadb
from chromadb.config import Settings

# LangChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import BaseMessage

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ExperienceLevel(Enum):
    ENTRY = "entry"
    JUNIOR = "junior"
    MID = "mid"
    SENIOR = "senior"
    LEAD = "lead"
    EXECUTIVE = "executive"

class JobType(Enum):
    FULL_TIME = "full_time"
    PART_TIME = "part_time"
    CONTRACT = "contract"
    FREELANCE = "freelance"
    INTERNSHIP = "internship"

class SkillCategory(Enum):
    TECHNICAL = "technical"
    SOFT = "soft"
    LANGUAGE = "language"
    CERTIFICATION = "certification"

@dataclass
class Contact:
    email: Optional[str] = None
    phone: Optional[str] = None
    linkedin: Optional[str] = None
    github: Optional[str] = None
    location: Optional[str] = None

@dataclass
class Education:
    degree: str
    field: str
    institution: str
    graduation_year: Optional[int] = None
    gpa: Optional[float] = None

@dataclass
class Experience:
    job_title: str
    company: str
    start_date: str
    end_date: Optional[str] = None
    description: str
    skills_used: List[str] = field(default_factory=list)
    achievements: List[str] = field(default_factory=list)

@dataclass
class Skill:
    name: str
    category: SkillCategory
    proficiency: Optional[str] = None
    years_experience: Optional[int] = None

@dataclass
class Resume:
    resume_id: str
    candidate_name: str
    contact: Contact
    summary: str
    education: List[Education]
    experience: List[Experience]
    skills: List[Skill]
    certifications: List[str] = field(default_factory=list)
    languages: List[str] = field(default_factory=list)
    raw_text: str = ""
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class JobPosting:
    job_id: str
    title: str
    company: str
    location: str
    job_type: JobType
    experience_level: ExperienceLevel
    description: str
    requirements: List[str]
    nice_to_have: List[str] = field(default_factory=list)
    salary_min: Optional[float] = None
    salary_max: Optional[float] = None
    posted_date: datetime = field(default_factory=datetime.now)
    source: str = "manual"
    url: Optional[str] = None

@dataclass
class MatchResult:
    job_id: str
    resume_id: str
    overall_score: float
    skills_match_score: float
    experience_match_score: float
    education_match_score: float
    missing_skills: List[str]
    matching_skills: List[str]
    recommendations: List[str]
    created_at: datetime = field(default_factory=datetime.now)

class ResumeParser:
    """Extract structured information from resume files."""
    
    def __init__(self):
        # Download required NLTK data
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('stopwords', quiet=True)
            nltk.download('averaged_perceptron_tagger', quiet=True)
        except:
            pass
        
        # Load spaCy model
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            logger.warning("spaCy model not found. Install with: python -m spacy download en_core_web_sm")
            self.nlp = None
        
        # Initialize patterns
        self._initialize_patterns()
    
    def _initialize_patterns(self):
        """Initialize regex patterns for information extraction."""
        self.patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'(\+?\d{1,3}[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}',
            'linkedin': r'linkedin\.com/in/[A-Za-z0-9-]+',
            'github': r'github\.com/[A-Za-z0-9-]+',
            'education_keywords': r'(bachelor|master|phd|doctorate|degree|university|college|education)',
            'experience_keywords': r'(experience|work|employment|career|position|role)',
            'skills_keywords': r'(skills|technologies|tools|programming|languages)'
        }
        
        # Common skills database
        self.skill_database = [
            # Programming languages
            'python', 'java', 'javascript', 'c++', 'c#', 'go', 'rust', 'swift', 'kotlin',
            'typescript', 'php', 'ruby', 'scala', 'r', 'matlab', 'sql',
            
            # Frameworks and libraries
            'react', 'angular', 'vue', 'node.js', 'express', 'django', 'flask', 'spring',
            'tensorflow', 'pytorch', 'scikit-learn', 'pandas', 'numpy',
            
            # Databases
            'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'cassandra',
            
            # Cloud and DevOps
            'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'terraform',
            'ansible', 'git', 'linux', 'bash',
            
            # Soft skills
            'leadership', 'communication', 'teamwork', 'problem-solving', 'analytical',
            'project management', 'agile', 'scrum'
        ]
    
    def parse_pdf(self, file_content: bytes) -> str:
        """Extract text from PDF file."""
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            logger.error(f"PDF parsing error: {e}")
            return ""
    
    def parse_docx(self, file_content: bytes) -> str:
        """Extract text from DOCX file."""
        try:
            doc = Document(io.BytesIO(file_content))
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            logger.error(f"DOCX parsing error: {e}")
            return ""
    
    def extract_contact_info(self, text: str) -> Contact:
        """Extract contact information from resume text."""
        contact = Contact()
        
        # Email
        email_match = re.search(self.patterns['email'], text, re.IGNORECASE)
        if email_match:
            contact.email = email_match.group(0)
        
        # Phone
        phone_match = re.search(self.patterns['phone'], text)
        if phone_match:
            contact.phone = phone_match.group(0)
        
        # LinkedIn
        linkedin_match = re.search(self.patterns['linkedin'], text, re.IGNORECASE)
        if linkedin_match:
            contact.linkedin = f"https://{linkedin_match.group(0)}"
        
        # GitHub
        github_match = re.search(self.patterns['github'], text, re.IGNORECASE)
        if github_match:
            contact.github = f"https://{github_match.group(0)}"
        
        return contact
    
    def extract_skills(self, text: str) -> List[Skill]:
        """Extract skills from resume text."""
        skills = []
        text_lower = text.lower()
        
        # Find skills section
        skills_section = ""
        lines = text.split('\n')
        in_skills_section = False
        
        for line in lines:
            if re.search(self.patterns['skills_keywords'], line.lower()):
                in_skills_section = True
                continue
            
            if in_skills_section:
                if any(keyword in line.lower() for keyword in ['experience', 'education', 'work']):
                    break
                skills_section += line + " "
        
        # Extract known skills
        found_skills = set()
        for skill_name in self.skill_database:
            if skill_name.lower() in text_lower:
                # Determine category
                if skill_name.lower() in ['leadership', 'communication', 'teamwork', 'problem-solving']:
                    category = SkillCategory.SOFT
                else:
                    category = SkillCategory.TECHNICAL
                
                skills.append(Skill(name=skill_name, category=category))
                found_skills.add(skill_name.lower())
        
        return skills
    
    def extract_experience(self, text: str) -> List[Experience]:
        """Extract work experience from resume text."""
        experiences = []
        
        # This is a simplified extraction - in practice, you'd use more sophisticated NLP
        lines = text.split('\n')
        current_exp = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Look for job titles and companies (simplified pattern)
            if re.search(r'(engineer|developer|manager|analyst|consultant|coordinator)', line.lower()):
                if current_exp:
                    experiences.append(current_exp)
                
                current_exp = Experience(
                    job_title=line,
                    company="Company Name",  # Would extract this properly
                    start_date="2020",  # Would extract dates properly
                    description=line
                )
        
        if current_exp:
            experiences.append(current_exp)
        
        return experiences
    
    def extract_education(self, text: str) -> List[Education]:
        """Extract education information from resume text."""
        education = []
        
        # Look for degree patterns
        degree_patterns = [
            r'(bachelor|master|phd|doctorate|b\.?s\.?|m\.?s\.?|b\.?a\.?|m\.?a\.?)',
            r'(computer science|engineering|business|mathematics|physics)'
        ]
        
        lines = text.split('\n')
        for line in lines:
            line_lower = line.lower()
            if any(re.search(pattern, line_lower) for pattern in degree_patterns):
                education.append(Education(
                    degree="Bachelor's Degree",  # Would extract properly
                    field="Computer Science",  # Would extract properly
                    institution="University"  # Would extract properly
                ))
                break
        
        return education
    
    def parse_resume(self, file_content: bytes, filename: str) -> Resume:
        """Parse resume file and extract structured information."""
        try:
            # Extract text based on file type
            if filename.lower().endswith('.pdf'):
                text = self.parse_pdf(file_content)
            elif filename.lower().endswith('.docx'):
                text = self.parse_docx(file_content)
            else:
                text = file_content.decode('utf-8', errors='ignore')
            
            if not text.strip():
                raise ValueError("No text could be extracted from the file")
            
            # Extract information
            contact = self.extract_contact_info(text)
            skills = self.extract_skills(text)
            experience = self.extract_experience(text)
            education = self.extract_education(text)
            
            # Extract candidate name (simplified)
            lines = text.split('\n')
            candidate_name = "Unknown"
            for line in lines[:5]:  # Check first 5 lines
                line = line.strip()
                if line and len(line.split()) <= 4 and not '@' in line:
                    candidate_name = line
                    break
            
            # Create summary (first few sentences)
            sentences = text.split('.')[:3]
            summary = '. '.join(sentences[:2]) + '.' if sentences else "No summary available"
            
            resume = Resume(
                resume_id=str(uuid.uuid4()),
                candidate_name=candidate_name,
                contact=contact,
                summary=summary,
                education=education,
                experience=experience,
                skills=skills,
                raw_text=text
            )
            
            logger.info(f"Successfully parsed resume for {candidate_name}")
            return resume
        
        except Exception as e:
            logger.error(f"Resume parsing error: {e}")
            raise

class JobScraper:
    """Scrape job postings from various sources."""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def scrape_sample_jobs(self) -> List[JobPosting]:
        """Generate sample job postings for demonstration."""
        sample_jobs = [
            JobPosting(
                job_id=str(uuid.uuid4()),
                title="Senior Software Engineer",
                company="TechCorp Inc.",
                location="San Francisco, CA",
                job_type=JobType.FULL_TIME,
                experience_level=ExperienceLevel.SENIOR,
                description="We are seeking a senior software engineer to join our growing team. You will work on cutting-edge projects using modern technologies.",
                requirements=[
                    "5+ years of software development experience",
                    "Strong proficiency in Python, Java, or Go",
                    "Experience with cloud platforms (AWS, Azure, GCP)",
                    "Knowledge of microservices architecture",
                    "Strong problem-solving skills"
                ],
                nice_to_have=[
                    "Experience with Docker and Kubernetes",
                    "Machine learning knowledge",
                    "Open source contributions"
                ],
                salary_min=120000,
                salary_max=180000,
                source="company_website"
            ),
            
            JobPosting(
                job_id=str(uuid.uuid4()),
                title="Data Scientist",
                company="DataTech Solutions",
                location="New York, NY",
                job_type=JobType.FULL_TIME,
                experience_level=ExperienceLevel.MID,
                description="Join our data science team to build predictive models and extract insights from large datasets.",
                requirements=[
                    "3+ years of data science experience",
                    "Strong Python and R skills",
                    "Experience with machine learning frameworks",
                    "SQL and database knowledge",
                    "Statistical analysis expertise"
                ],
                nice_to_have=[
                    "PhD in related field",
                    "Deep learning experience",
                    "Experience with big data tools"
                ],
                salary_min=90000,
                salary_max=140000,
                source="job_board"
            ),
            
            JobPosting(
                job_id=str(uuid.uuid4()),
                title="Frontend Developer",
                company="WebDev Studio",
                location="Remote",
                job_type=JobType.FULL_TIME,
                experience_level=ExperienceLevel.JUNIOR,
                description="Looking for a passionate frontend developer to create amazing user experiences.",
                requirements=[
                    "2+ years of frontend development",
                    "Proficiency in React or Vue.js",
                    "Strong HTML, CSS, JavaScript skills",
                    "Experience with responsive design",
                    "Git version control"
                ],
                nice_to_have=[
                    "TypeScript experience",
                    "Testing framework knowledge",
                    "UI/UX design skills"
                ],
                salary_min=60000,
                salary_max=90000,
                source="linkedin"
            ),
            
            JobPosting(
                job_id=str(uuid.uuid4()),
                title="DevOps Engineer",
                company="CloudFirst Inc.",
                location="Austin, TX",
                job_type=JobType.FULL_TIME,
                experience_level=ExperienceLevel.MID,
                description="We need a DevOps engineer to help scale our infrastructure and improve deployment processes.",
                requirements=[
                    "3+ years of DevOps experience",
                    "Strong knowledge of AWS or Azure",
                    "Experience with Docker and Kubernetes",
                    "CI/CD pipeline experience",
                    "Infrastructure as Code (Terraform, CloudFormation)"
                ],
                nice_to_have=[
                    "Monitoring and logging tools",
                    "Security best practices",
                    "Scripting languages (Bash, Python)"
                ],
                salary_min=95000,
                salary_max=130000,
                source="indeed"
            )
        ]
        
        return sample_jobs

class SemanticMatcher:
    """Perform semantic matching between resumes and job postings."""
    
    def __init__(self):
        try:
            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            logger.warning(f"Could not load sentence transformer: {e}")
            self.sentence_transformer = None
        
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        
        # Initialize vector database
        self.chroma_client = chromadb.Client(
            Settings(allow_reset=True, anonymized_telemetry=False)
        )
        
        try:
            self.collection = self.chroma_client.create_collection(
                name="job_resume_embeddings",
                metadata={"description": "Job and resume embeddings for matching"}
            )
        except:
            self.collection = self.chroma_client.get_collection("job_resume_embeddings")
    
    def calculate_skills_match(self, resume_skills: List[str], job_requirements: List[str]) -> Tuple[float, List[str], List[str]]:
        """Calculate skills matching score and identify gaps."""
        if not resume_skills or not job_requirements:
            return 0.0, [], job_requirements
        
        # Normalize skills for comparison
        resume_skills_lower = [skill.lower() for skill in resume_skills]
        job_requirements_lower = [req.lower() for req in job_requirements]
        
        matching_skills = []
        missing_skills = []
        
        for requirement in job_requirements:
            req_lower = requirement.lower()
            
            # Exact match
            if req_lower in resume_skills_lower:
                matching_skills.append(requirement)
            else:
                # Fuzzy match
                best_match = process.extractOne(req_lower, resume_skills_lower)
                if best_match and best_match[1] > 80:  # 80% similarity threshold
                    matching_skills.append(requirement)
                else:
                    missing_skills.append(requirement)
        
        # Calculate match score
        if job_requirements:
            match_score = len(matching_skills) / len(job_requirements)
        else:
            match_score = 0.0
        
        return match_score, matching_skills, missing_skills
    
    def calculate_experience_match(self, resume: Resume, job: JobPosting) -> float:
        """Calculate experience level matching score."""
        # Map experience levels to numeric values
        experience_values = {
            ExperienceLevel.ENTRY: 0,
            ExperienceLevel.JUNIOR: 1,
            ExperienceLevel.MID: 2,
            ExperienceLevel.SENIOR: 3,
            ExperienceLevel.LEAD: 4,
            ExperienceLevel.EXECUTIVE: 5
        }
        
        # Estimate candidate's experience level based on work history
        total_experience = len(resume.experience)
        
        if total_experience == 0:
            candidate_level = ExperienceLevel.ENTRY
        elif total_experience <= 2:
            candidate_level = ExperienceLevel.JUNIOR
        elif total_experience <= 4:
            candidate_level = ExperienceLevel.MID
        else:
            candidate_level = ExperienceLevel.SENIOR
        
        candidate_value = experience_values[candidate_level]
        job_value = experience_values[job.experience_level]
        
        # Calculate match score (closer levels = higher score)
        diff = abs(candidate_value - job_value)
        max_diff = max(experience_values.values())
        
        match_score = 1.0 - (diff / max_diff)
        return max(0.0, match_score)
    
    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """Calculate semantic similarity between two texts."""
        if not self.sentence_transformer:
            # Fallback to TF-IDF similarity
            try:
                tfidf_matrix = self.tfidf_vectorizer.fit_transform([text1, text2])
                similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                return float(similarity)
            except:
                return 0.0
        
        try:
            embeddings = self.sentence_transformer.encode([text1, text2])
            similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
            return float(similarity)
        except Exception as e:
            logger.error(f"Semantic similarity calculation error: {e}")
            return 0.0
    
    def match_resume_to_job(self, resume: Resume, job: JobPosting) -> MatchResult:
        """Perform comprehensive matching between resume and job posting."""
        try:
            # Extract skills from resume
            resume_skills = [skill.name for skill in resume.skills]
            
            # Combine job requirements
            all_requirements = job.requirements + job.nice_to_have
            
            # Calculate skills match
            skills_score, matching_skills, missing_skills = self.calculate_skills_match(
                resume_skills, all_requirements
            )
            
            # Calculate experience match
            experience_score = self.calculate_experience_match(resume, job)
            
            # Calculate semantic similarity between resume and job description
            resume_text = f"{resume.summary} {' '.join([exp.description for exp in resume.experience])}"
            semantic_score = self.calculate_semantic_similarity(resume_text, job.description)
            
            # Education match (simplified)
            education_score = 0.7 if resume.education else 0.3
            
            # Calculate overall score (weighted average)
            overall_score = (
                skills_score * 0.4 +
                experience_score * 0.3 +
                semantic_score * 0.2 +
                education_score * 0.1
            )
            
            # Generate recommendations
            recommendations = []
            if skills_score < 0.6:
                recommendations.append("Consider developing missing technical skills")
            if experience_score < 0.5:
                recommendations.append("Gain more relevant work experience")
            if semantic_score < 0.3:
                recommendations.append("Tailor resume content to better match job description")
            
            match_result = MatchResult(
                job_id=job.job_id,
                resume_id=resume.resume_id,
                overall_score=overall_score,
                skills_match_score=skills_score,
                experience_match_score=experience_score,
                education_match_score=education_score,
                missing_skills=missing_skills,
                matching_skills=matching_skills,
                recommendations=recommendations
            )
            
            logger.info(f"Matched resume {resume.resume_id} to job {job.job_id} with score {overall_score:.2f}")
            return match_result
        
        except Exception as e:
            logger.error(f"Matching error: {e}")
            return MatchResult(
                job_id=job.job_id,
                resume_id=resume.resume_id,
                overall_score=0.0,
                skills_match_score=0.0,
                experience_match_score=0.0,
                education_match_score=0.0,
                missing_skills=[],
                matching_skills=[],
                recommendations=["Error occurred during matching"]
            )

class JobMatchingDatabase:
    """Database management for job matching system."""
    
    def __init__(self, db_path: str = "job_matching.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize database tables."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # Resumes table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS resumes (
                    resume_id TEXT PRIMARY KEY,
                    candidate_name TEXT,
                    email TEXT,
                    summary TEXT,
                    skills TEXT,
                    experience TEXT,
                    education TEXT,
                    raw_text TEXT,
                    created_at TEXT
                )
            """)
            
            # Jobs table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS jobs (
                    job_id TEXT PRIMARY KEY,
                    title TEXT,
                    company TEXT,
                    location TEXT,
                    job_type TEXT,
                    experience_level TEXT,
                    description TEXT,
                    requirements TEXT,
                    salary_min REAL,
                    salary_max REAL,
                    source TEXT,
                    posted_date TEXT
                )
            """)
            
            # Matches table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS matches (
                    match_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    job_id TEXT,
                    resume_id TEXT,
                    overall_score REAL,
                    skills_score REAL,
                    experience_score REAL,
                    education_score REAL,
                    missing_skills TEXT,
                    matching_skills TEXT,
                    recommendations TEXT,
                    created_at TEXT,
                    FOREIGN KEY (job_id) REFERENCES jobs (job_id),
                    FOREIGN KEY (resume_id) REFERENCES resumes (resume_id)
                )
            """)
            
            conn.commit()
    
    def save_resume(self, resume: Resume):
        """Save resume to database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO resumes 
                    (resume_id, candidate_name, email, summary, skills, experience, education, raw_text, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    resume.resume_id,
                    resume.candidate_name,
                    resume.contact.email,
                    resume.summary,
                    json.dumps([skill.name for skill in resume.skills]),
                    json.dumps([exp.__dict__ for exp in resume.experience]),
                    json.dumps([edu.__dict__ for edu in resume.education]),
                    resume.raw_text,
                    resume.created_at.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving resume: {e}")
    
    def save_job(self, job: JobPosting):
        """Save job posting to database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO jobs 
                    (job_id, title, company, location, job_type, experience_level, description, 
                     requirements, salary_min, salary_max, source, posted_date)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    job.job_id,
                    job.title,
                    job.company,
                    job.location,
                    job.job_type.value,
                    job.experience_level.value,
                    job.description,
                    json.dumps(job.requirements),
                    job.salary_min,
                    job.salary_max,
                    job.source,
                    job.posted_date.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving job: {e}")
    
    def save_match(self, match: MatchResult):
        """Save match result to database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO matches 
                    (job_id, resume_id, overall_score, skills_score, experience_score, education_score,
                     missing_skills, matching_skills, recommendations, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    match.job_id,
                    match.resume_id,
                    match.overall_score,
                    match.skills_match_score,
                    match.experience_match_score,
                    match.education_match_score,
                    json.dumps(match.missing_skills),
                    json.dumps(match.matching_skills),
                    json.dumps(match.recommendations),
                    match.created_at.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving match: {e}")
    
    def get_all_resumes(self) -> List[Dict]:
        """Retrieve all resumes from database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM resumes")
                columns = [description[0] for description in cursor.description]
                results = []
                for row in cursor.fetchall():
                    results.append(dict(zip(columns, row)))
                return results
        except Exception as e:
            logger.error(f"Error retrieving resumes: {e}")
            return []
    
    def get_all_jobs(self) -> List[Dict]:
        """Retrieve all jobs from database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM jobs")
                columns = [description[0] for description in cursor.description]
                results = []
                for row in cursor.fetchall():
                    results.append(dict(zip(columns, row)))
                return results
        except Exception as e:
            logger.error(f"Error retrieving jobs: {e}")
            return []

class ResumeJobMatchingAgent:
    """Main agent orchestrating resume-job matching process."""
    
    def __init__(self, openai_api_key: Optional[str] = None):
        self.parser = ResumeParser()
        self.scraper = JobScraper()
        self.matcher = SemanticMatcher()
        self.database = JobMatchingDatabase()
        
        self.llm = None
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.3,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
    
    def process_resume(self, file_content: bytes, filename: str) -> Resume:
        """Process uploaded resume file."""
        try:
            resume = self.parser.parse_resume(file_content, filename)
            self.database.save_resume(resume)
            logger.info(f"Successfully processed resume: {resume.resume_id}")
            return resume
        except Exception as e:
            logger.error(f"Resume processing error: {e}")
            raise
    
    def load_sample_jobs(self) -> List[JobPosting]:
        """Load sample job postings."""
        try:
            jobs = self.scraper.scrape_sample_jobs()
            for job in jobs:
                self.database.save_job(job)
            logger.info(f"Loaded {len(jobs)} sample jobs")
            return jobs
        except Exception as e:
            logger.error(f"Job loading error: {e}")
            return []
    
    def find_matching_jobs(self, resume_id: str, max_results: int = 10) -> List[MatchResult]:
        """Find matching jobs for a given resume."""
        try:
            # Load resume data
            resumes_data = self.database.get_all_resumes()
            resume_data = next((r for r in resumes_data if r['resume_id'] == resume_id), None)
            
            if not resume_data:
                logger.error(f"Resume {resume_id} not found")
                return []
            
            # Reconstruct resume object (simplified)
            resume = Resume(
                resume_id=resume_data['resume_id'],
                candidate_name=resume_data['candidate_name'],
                contact=Contact(email=resume_data['email']),
                summary=resume_data['summary'],
                education=[],
                experience=[],
                skills=[Skill(name=skill, category=SkillCategory.TECHNICAL) 
                       for skill in json.loads(resume_data['skills'])] if resume_data['skills'] else [],
                raw_text=resume_data['raw_text']
            )
            
            # Load all jobs
            jobs_data = self.database.get_all_jobs()
            matches = []
            
            for job_data in jobs_data:
                # Reconstruct job object
                job = JobPosting(
                    job_id=job_data['job_id'],
                    title=job_data['title'],
                    company=job_data['company'],
                    location=job_data['location'],
                    job_type=JobType(job_data['job_type']),
                    experience_level=ExperienceLevel(job_data['experience_level']),
                    description=job_data['description'],
                    requirements=json.loads(job_data['requirements']),
                    salary_min=job_data['salary_min'],
                    salary_max=job_data['salary_max'],
                    source=job_data['source']
                )
                
                # Perform matching
                match = self.matcher.match_resume_to_job(resume, job)
                matches.append(match)
                
                # Save match result
                self.database.save_match(match)
            
            # Sort by overall score and return top matches
            matches.sort(key=lambda x: x.overall_score, reverse=True)
            return matches[:max_results]
        
        except Exception as e:
            logger.error(f"Job matching error: {e}")
            return []
    
    def get_analytics(self) -> Dict[str, Any]:
        """Generate analytics and insights."""
        try:
            resumes_data = self.database.get_all_resumes()
            jobs_data = self.database.get_all_jobs()
            
            analytics = {
                "total_resumes": len(resumes_data),
                "total_jobs": len(jobs_data),
                "job_sources": {},
                "skill_demand": {},
                "salary_ranges": {}
            }
            
            # Analyze job sources
            for job in jobs_data:
                source = job['source']
                analytics["job_sources"][source] = analytics["job_sources"].get(source, 0) + 1
            
            # Analyze skill demand (from job requirements)
            skill_count = {}
            for job in jobs_data:
                requirements = json.loads(job['requirements'])
                for req in requirements:
                    req_lower = req.lower()
                    skill_count[req_lower] = skill_count.get(req_lower, 0) + 1
            
            # Top 10 in-demand skills
            analytics["skill_demand"] = dict(sorted(skill_count.items(), key=lambda x: x[1], reverse=True)[:10])
            
            # Salary analysis
            salaries = []
            for job in jobs_data:
                if job['salary_min'] and job['salary_max']:
                    avg_salary = (job['salary_min'] + job['salary_max']) / 2
                    salaries.append(avg_salary)
            
            if salaries:
                analytics["salary_ranges"] = {
                    "min": min(salaries),
                    "max": max(salaries),
                    "average": sum(salaries) / len(salaries),
                    "median": sorted(salaries)[len(salaries) // 2]
                }
            
            return analytics
        
        except Exception as e:
            logger.error(f"Analytics error: {e}")
            return {}

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="Resume & Job Matching Agent",
        page_icon="üíº",
        layout="wide"
    )
    
    st.title("üíº Resume & Job Matching Agent")
    st.markdown("**AI-powered resume parsing and intelligent job matching system**")
    
    # Initialize session state
    if 'agent' not in st.session_state:
        st.session_state['agent'] = None
    if 'processed_resumes' not in st.session_state:
        st.session_state['processed_resumes'] = []
    if 'job_matches' not in st.session_state:
        st.session_state['job_matches'] = []
    
    # Sidebar
    with st.sidebar:
        st.header("üîß Configuration")
        
        openai_key = st.text_input("OpenAI API Key (Optional)", type="password")
        
        if st.button("Initialize Agent") or st.session_state['agent'] is None:
            with st.spinner("Initializing Resume & Job Matching Agent..."):
                st.session_state['agent'] = ResumeJobMatchingAgent(openai_key)
                st.success("Agent initialized!")
        
        st.header("üìÇ Data Management")
        
        if st.session_state['agent']:
            if st.button("Load Sample Jobs"):
                with st.spinner("Loading sample job postings..."):
                    jobs = st.session_state['agent'].load_sample_jobs()
                    st.success(f"Loaded {len(jobs)} sample jobs!")
    
    if not st.session_state['agent']:
        st.info("üëà Please initialize the Resume & Job Matching Agent")
        return
    
    agent = st.session_state['agent']
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìÑ Resume Upload", "üíº Job Matching", "üìä Analytics", "üíæ Database", "‚öôÔ∏è Settings"])
    
    with tab1:
        st.header("üìÑ Resume Processing")
        
        uploaded_file = st.file_uploader(
            "Upload Resume",
            type=['pdf', 'docx', 'txt'],
            help="Upload your resume in PDF, DOCX, or TXT format"
        )
        
        if uploaded_file is not None:
            if st.button("Process Resume"):
                try:
                    with st.spinner("Processing resume..."):
                        file_content = uploaded_file.read()
                        resume = agent.process_resume(file_content, uploaded_file.name)
                        st.session_state['processed_resumes'].append(resume)
                        st.success(f"Successfully processed resume for {resume.candidate_name}")
                    
                    # Display extracted information
                    st.subheader("üìã Extracted Information")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**Contact Information:**")
                        if resume.contact.email:
                            st.write(f"üìß {resume.contact.email}")
                        if resume.contact.phone:
                            st.write(f"üìû {resume.contact.phone}")
                        if resume.contact.linkedin:
                            st.write(f"üîó {resume.contact.linkedin}")
                    
                    with col2:
                        st.write("**Skills Extracted:**")
                        if resume.skills:
                            for skill in resume.skills[:10]:  # Show first 10 skills
                                st.write(f"‚Ä¢ {skill.name}")
                        else:
                            st.write("No skills detected")
                    
                    # Summary
                    st.subheader("üìù Summary")
                    st.write(resume.summary)
                    
                    # Experience
                    if resume.experience:
                        st.subheader("üíº Experience")
                        for exp in resume.experience:
                            st.write(f"**{exp.job_title}** at {exp.company}")
                            st.write(exp.description)
                    
                    # Education
                    if resume.education:
                        st.subheader("üéì Education")
                        for edu in resume.education:
                            st.write(f"**{edu.degree}** in {edu.field} from {edu.institution}")
                
                except Exception as e:
                    st.error(f"Error processing resume: {e}")
        
        # Display processed resumes
        if st.session_state['processed_resumes']:
            st.subheader("üìã Processed Resumes")
            
            for i, resume in enumerate(st.session_state['processed_resumes']):
                with st.expander(f"{resume.candidate_name} - {resume.resume_id[:8]}"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write(f"**Name:** {resume.candidate_name}")
                    with col2:
                        st.write(f"**Email:** {resume.contact.email or 'Not found'}")
                    with col3:
                        st.write(f"**Skills:** {len(resume.skills)}")
                    
                    if st.button(f"Find Jobs for {resume.candidate_name}", key=f"find_jobs_{i}"):
                        with st.spinner("Finding matching jobs..."):
                            matches = agent.find_matching_jobs(resume.resume_id)
                            st.session_state['job_matches'] = matches
                            st.success(f"Found {len(matches)} potential matches!")
                            st.rerun()
    
    with tab2:
        st.header("üíº Job Matching Results")
        
        if st.session_state['job_matches']:
            st.subheader("üéØ Top Job Matches")
            
            for i, match in enumerate(st.session_state['job_matches'][:5]):  # Show top 5
                # Get job details
                jobs_data = agent.database.get_all_jobs()
                job_data = next((j for j in jobs_data if j['job_id'] == match.job_id), None)
                
                if job_data:
                    with st.expander(f"#{i+1} {job_data['title']} at {job_data['company']} - {match.overall_score:.1%} match"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"**Company:** {job_data['company']}")
                            st.write(f"**Location:** {job_data['location']}")
                            st.write(f"**Type:** {job_data['job_type'].replace('_', ' ').title()}")
                            st.write(f"**Experience Level:** {job_data['experience_level'].replace('_', ' ').title()}")
                            
                            if job_data['salary_min'] and job_data['salary_max']:
                                st.write(f"**Salary:** ${job_data['salary_min']:,.0f} - ${job_data['salary_max']:,.0f}")
                        
                        with col2:
                            # Match scores
                            st.write("**Match Breakdown:**")
                            st.progress(match.overall_score, f"Overall: {match.overall_score:.1%}")
                            st.progress(match.skills_match_score, f"Skills: {match.skills_match_score:.1%}")
                            st.progress(match.experience_match_score, f"Experience: {match.experience_match_score:.1%}")
                            st.progress(match.education_match_score, f"Education: {match.education_match_score:.1%}")
                        
                        # Job description
                        st.write("**Job Description:**")
                        st.write(job_data['description'])
                        
                        # Requirements
                        requirements = json.loads(job_data['requirements'])
                        if requirements:
                            st.write("**Requirements:**")
                            for req in requirements:
                                if req in match.matching_skills:
                                    st.write(f"‚úÖ {req}")
                                elif req in match.missing_skills:
                                    st.write(f"‚ùå {req}")
                                else:
                                    st.write(f"‚Ä¢ {req}")
                        
                        # Recommendations
                        if match.recommendations:
                            st.write("**Recommendations:**")
                            for rec in match.recommendations:
                                st.write(f"üí° {rec}")
            
            # Matching statistics
            st.subheader("üìä Matching Statistics")
            
            if st.session_state['job_matches']:
                scores = [match.overall_score for match in st.session_state['job_matches']]
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Best Match", f"{max(scores):.1%}")
                with col2:
                    st.metric("Average Match", f"{np.mean(scores):.1%}")
                with col3:
                    st.metric("Total Matches", len(st.session_state['job_matches']))
                with col4:
                    strong_matches = len([s for s in scores if s > 0.7])
                    st.metric("Strong Matches", strong_matches)
                
                # Score distribution
                fig = px.histogram(
                    x=scores,
                    nbins=20,
                    title="Match Score Distribution",
                    labels={'x': 'Match Score', 'y': 'Number of Jobs'}
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No job matches found. Please upload and process a resume first, then click 'Find Jobs'.")
    
    with tab3:
        st.header("üìä Analytics & Insights")
        
        if st.button("Generate Analytics"):
            with st.spinner("Analyzing data..."):
                analytics = agent.get_analytics()
                
                if analytics:
                    # Key metrics
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Total Resumes", analytics.get('total_resumes', 0))
                    with col2:
                        st.metric("Total Jobs", analytics.get('total_jobs', 0))
                    with col3:
                        avg_salary = analytics.get('salary_ranges', {}).get('average', 0)
                        st.metric("Avg Salary", f"${avg_salary:,.0f}" if avg_salary else "N/A")
                    
                    # Job sources
                    if analytics.get('job_sources'):
                        st.subheader("üìà Job Sources")
                        
                        sources_df = pd.DataFrame(
                            list(analytics['job_sources'].items()),
                            columns=['Source', 'Count']
                        )
                        
                        fig = px.pie(sources_df, values='Count', names='Source', title='Job Postings by Source')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Skill demand
                    if analytics.get('skill_demand'):
                        st.subheader("üî• Top In-Demand Skills")
                        
                        skills_df = pd.DataFrame(
                            list(analytics['skill_demand'].items()),
                            columns=['Skill', 'Demand']
                        )
                        
                        fig = px.bar(skills_df, x='Demand', y='Skill', orientation='h',
                                   title='Most Requested Skills in Job Postings')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Salary analysis
                    if analytics.get('salary_ranges'):
                        st.subheader("üí∞ Salary Analysis")
                        
                        salary_data = analytics['salary_ranges']
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Minimum", f"${salary_data['min']:,.0f}")
                        with col2:
                            st.metric("Average", f"${salary_data['average']:,.0f}")
                        with col3:
                            st.metric("Median", f"${salary_data['median']:,.0f}")
                        with col4:
                            st.metric("Maximum", f"${salary_data['max']:,.0f}")
                else:
                    st.warning("No data available for analytics")
    
    with tab4:
        st.header("üíæ Database Management")
        
        # Display resumes in database
        st.subheader("üìÑ Stored Resumes")
        
        resumes_data = agent.database.get_all_resumes()
        if resumes_data:
            resumes_df = pd.DataFrame(resumes_data)
            
            # Select relevant columns for display
            display_columns = ['candidate_name', 'email', 'created_at']
            display_df = resumes_df[display_columns].copy()
            display_df['created_at'] = pd.to_datetime(display_df['created_at']).dt.strftime('%Y-%m-%d %H:%M')
            
            st.dataframe(display_df, use_container_width=True)
        else:
            st.info("No resumes in database")
        
        # Display jobs in database
        st.subheader("üíº Stored Jobs")
        
        jobs_data = agent.database.get_all_jobs()
        if jobs_data:
            jobs_df = pd.DataFrame(jobs_data)
            
            # Select relevant columns for display
            display_columns = ['title', 'company', 'location', 'job_type', 'experience_level', 'source']
            display_df = jobs_df[display_columns].copy()
            
            st.dataframe(display_df, use_container_width=True)
        else:
            st.info("No jobs in database")
    
    with tab5:
        st.header("‚öôÔ∏è Settings & Configuration")
        
        st.subheader("üîß Parsing Settings")
        
        # Resume parsing settings
        extract_skills = st.checkbox("Extract skills automatically", True)
        extract_education = st.checkbox("Extract education information", True)
        extract_experience = st.checkbox("Extract work experience", True)
        
        st.subheader("üéØ Matching Settings")
        
        # Matching algorithm settings
        skills_weight = st.slider("Skills matching weight", 0.0, 1.0, 0.4, 0.1)
        experience_weight = st.slider("Experience matching weight", 0.0, 1.0, 0.3, 0.1)
        semantic_weight = st.slider("Semantic similarity weight", 0.0, 1.0, 0.2, 0.1)
        education_weight = st.slider("Education matching weight", 0.0, 1.0, 0.1, 0.1)
        
        # Ensure weights sum to 1.0
        total_weight = skills_weight + experience_weight + semantic_weight + education_weight
        if total_weight != 1.0:
            st.warning(f"Weights should sum to 1.0 (current: {total_weight:.1f})")
        
        st.subheader("üìä Display Settings")
        
        max_matches = st.number_input("Maximum matches to display", 1, 50, 10)
        min_score_threshold = st.slider("Minimum match score threshold", 0.0, 1.0, 0.0, 0.05)
        
        st.subheader("üîí Privacy Settings")
        
        anonymize_data = st.checkbox("Anonymize personal information", False)
        data_retention_days = st.number_input("Data retention period (days)", 1, 365, 90)
        
        if st.button("Apply Settings"):
            st.success("Settings applied successfully!")

if __name__ == "__main__":
    main()
````

## Project Summary

The Resume & Job Matching Agent revolutionizes recruitment through intelligent document parsing, automated job aggregation, and semantic matching algorithms that deliver precise candidate-job compatibility scores with actionable insights for both job seekers and recruiters.

### Key Value Propositions:
- **Intelligent Parsing**: Multi-format resume processing with advanced information extraction
- **Comprehensive Job Discovery**: Automated scraping and aggregation from multiple job platforms
- **Semantic Matching**: AI-powered similarity analysis with detailed compatibility scoring
- **Skills Gap Analysis**: Personalized recommendations for career development and skill improvement

### Technical Architecture:
The system integrates document processing engines for resume parsing, web scraping frameworks for job aggregation, transformer models for semantic similarity, and vector databases for efficient matching, creating a scalable recruitment platform that transforms hiring processes through data-driven insights while maintaining focus on accuracy, privacy, and user experience optimization.