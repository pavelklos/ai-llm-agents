<small>Claude Sonnet 4 **(Decentralizovaná síť pro ověřování zpráv)**</small>
# Decentralized News Verification Network

## Klíčové koncepty

### Multi-Agent Systems (Multi-agentní systémy)
Systém složený z více autonomních softwarových agentů, kteří spolupracují při řešení komplexních úloh. Každý agent má specifickou roli a schopnosti, komunikuje s ostatními agenty a přispívá k celkovému cíli systému.

### Fact-checking (Ověřování faktů)
Proces systematického ověřování pravdivosti informací a tvrzení prostřednictvím kontroly primárních zdrojů, odborných databází a věrohodných referenčních materiálů.

### Source Verification (Ověřování zdrojů)
Analýza a hodnocení věrohodnosti informačních zdrojů na základě jejich historie, transparentnosti, odbornosti a nezávislosti.

### Bias Detection (Detekce zaujatosti)
Identifikace a analýza politických, ideologických nebo komerčních předsudků v mediálním obsahu pomocí textové analýzy a machine learning algoritmů.

### Information Credibility Scoring (Hodnocení věrohodnosti informací)
Kvantitativní systém pro ohodnocení důvěryhodnosti informací na základě múltiple faktorů jako je zdroj, konzistence, ověřitelnost a historická přesnost.

### Misinformation Flagging (Označování dezinformací)
Automatické nebo semi-automatické označování potenciálně nepravdivých nebo zavádějících informací pro varování uživatelů.

## Komplexní vysvětlení projektu

Decentralizovaná síť pro ověřování zpráv představuje inovativní přístup k boji proti dezinformacím v digitálním věku. Projekt využívá multi-agentní architekturu, kde každý agent má specializovanou roli v procesu ověřování informací.

### Cíle projektu
- **Automatizace fact-checkingu**: Rychlé ověřování faktických tvrzení v reálném čase
- **Decentralizované ověřování**: Eliminace single point of failure a zvýšení odolnosti systému
- **Transparentní hodnocení**: Poskytování jasných důvodů pro hodnocení věrohodnosti
- **Škálovatelnost**: Schopnost zpracovat velké množství informací současně

### Hlavní výzvy
- **Komplexnost jazyka**: Pochopení kontextu, sarkasmu a nuancí v textu
- **Rychlost vs. přesnost**: Vyváženost mezi rychlým zpracováním a důkladnou analýzou
- **Evoluce dezinformací**: Adaptace na nové formy a techniky šíření nepravdivých informací
- **Kulturní kontext**: Respektování různých kulturních a jazykových specifik

### Potenciální dopad
Systém může významně snížit šíření dezinformací, zvýšit mediální gramotnost a posílit důvěru veřejnosti v kvalitní žurnalistiku.

## Komplexní příklad s implementací v Pythonu

````python
import asyncio
import json
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import hashlib

from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.schema import Document
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
from textblob import TextBlob
import re

# Konfigurace logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class NewsArticle:
    """Reprezentace zpravodajského článku"""
    id: str
    title: str
    content: str
    source: str
    url: str
    timestamp: datetime
    credibility_score: Optional[float] = None
    bias_score: Optional[float] = None
    fact_check_results: Optional[Dict] = None

@dataclass
class VerificationResult:
    """Výsledek ověření článku"""
    article_id: str
    overall_score: float
    credibility_score: float
    bias_score: float
    fact_accuracy: float
    source_reliability: float
    flags: List[str]
    evidence: List[str]
    reasoning: str

class BaseAgent:
    """Základní třída pro všechny agenty"""
    
    def __init__(self, name: str, llm_model: str = "gpt-3.5-turbo"):
        self.name = name
        self.llm = OpenAI(model_name=llm_model, temperature=0.1)
        self.embeddings = OpenAIEmbeddings()
        
    async def process(self, article: NewsArticle) -> Dict:
        """Zpracování článku agentem"""
        raise NotImplementedError

class SourceVerificationAgent(BaseAgent):
    """Agent pro ověřování zdrojů"""
    
    def __init__(self):
        super().__init__("SourceVerifier")
        # Databáze známých zdrojů s jejich hodnocením
        self.source_database = {
            "cnn.com": {"reliability": 0.8, "bias": 0.3},
            "bbc.com": {"reliability": 0.9, "bias": 0.1},
            "rt.com": {"reliability": 0.4, "bias": 0.8},
            "wikipedia.org": {"reliability": 0.7, "bias": 0.2},
            # Přidejte více zdrojů podle potřeby
        }
    
    async def process(self, article: NewsArticle) -> Dict:
        """Ověření věrohodnosti zdroje"""
        try:
            domain = self._extract_domain(article.url)
            
            # Kontrola v databázi známých zdrojů
            if domain in self.source_database:
                reliability = self.source_database[domain]["reliability"]
                bias = self.source_database[domain]["bias"]
            else:
                # Analýza neznámého zdroje
                reliability, bias = await self._analyze_unknown_source(domain)
            
            # Kontrola SSL certifikátu a technických aspektů
            technical_score = await self._check_technical_aspects(article.url)
            
            final_score = (reliability + technical_score) / 2
            
            return {
                "source_reliability": final_score,
                "bias_level": bias,
                "domain": domain,
                "flags": self._generate_flags(final_score, bias),
                "evidence": [f"Doména {domain} má historickou spolehlivost {reliability:.2f}"]
            }
            
        except Exception as e:
            logger.error(f"Chyba při ověřování zdroje: {e}")
            return {"source_reliability": 0.5, "bias_level": 0.5, "flags": ["CHYBA_ANALÝZY"]}
    
    def _extract_domain(self, url: str) -> str:
        """Extrakce domény z URL"""
        from urllib.parse import urlparse
        return urlparse(url).netloc.lower()
    
    async def _analyze_unknown_source(self, domain: str) -> Tuple[float, float]:
        """Analýza neznámého zdroje"""
        # Simulace analýzy neznámého zdroje
        # V produkční verzi by zde byla komplexní analýza
        return 0.5, 0.5
    
    async def _check_technical_aspects(self, url: str) -> float:
        """Kontrola technických aspektů webu"""
        try:
            response = requests.head(url, timeout=5)
            score = 0.5
            
            # HTTPS bonus
            if url.startswith("https://"):
                score += 0.2
                
            # Status kód kontrola
            if response.status_code == 200:
                score += 0.2
                
            return min(score, 1.0)
            
        except:
            return 0.3
    
    def _generate_flags(self, reliability: float, bias: float) -> List[str]:
        """Generování varovných značek"""
        flags = []
        
        if reliability < 0.3:
            flags.append("NÍZKÁ_SPOLEHLIVOST")
        if bias > 0.7:
            flags.append("VYSOKÁ_ZAUJATOST")
        if reliability < 0.5 and bias > 0.5:
            flags.append("PROBLEMATICKÝ_ZDROJ")
            
        return flags

class FactCheckingAgent(BaseAgent):
    """Agent pro ověřování faktů"""
    
    def __init__(self):
        super().__init__("FactChecker")
        self.knowledge_base = self._load_knowledge_base()
    
    def _load_knowledge_base(self):
        """Načtení znalostní databáze"""
        # Vytvoření ukázkových faktů pro demonstraci
        facts = [
            "Česká republika má rozlohu 78 867 km²",
            "Praha je hlavní město České republiky",
            "COVID-19 byl poprvé identifikován v roce 2019",
            "Voda vře při 100°C za normálního tlaku",
            "Albert Einstein formuloval teorii relativity"
        ]
        
        documents = [Document(page_content=fact) for fact in facts]
        
        # Vytvoření vektorové databáze
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory="./knowledge_base"
        )
        
        return RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever()
        )
    
    async def process(self, article: NewsArticle) -> Dict:
        """Ověření faktických tvrzení v článku"""
        try:
            # Extrakce faktických tvrzení
            claims = self._extract_claims(article.content)
            
            verified_claims = []
            accuracy_scores = []
            
            for claim in claims:
                # Ověření každého tvrzení
                verification = await self._verify_claim(claim)
                verified_claims.append(verification)
                accuracy_scores.append(verification["accuracy"])
            
            overall_accuracy = np.mean(accuracy_scores) if accuracy_scores else 0.5
            
            return {
                "fact_accuracy": overall_accuracy,
                "verified_claims": verified_claims,
                "flags": self._generate_fact_flags(overall_accuracy),
                "evidence": [f"Ověřeno {len(claims)} faktických tvrzení"]
            }
            
        except Exception as e:
            logger.error(f"Chyba při fact-checkingu: {e}")
            return {"fact_accuracy": 0.5, "flags": ["CHYBA_FAKTŮ"]}
    
    def _extract_claims(self, content: str) -> List[str]:
        """Extrakce faktických tvrzení z textu"""
        # Jednoduché rozdělení na věty
        sentences = re.split(r'[.!?]+', content)
        
        # Filtrování vět obsahujících potenciální fakta
        claims = []
        fact_indicators = ["podle", "údaje", "statistiky", "výzkum", "studie", "čísla"]
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:  # Minimální délka
                for indicator in fact_indicators:
                    if indicator in sentence.lower():
                        claims.append(sentence)
                        break
        
        return claims[:5]  # Max 5 tvrzení pro demo
    
    async def _verify_claim(self, claim: str) -> Dict:
        """Ověření jednotlivého tvrzení"""
        try:
            # Dotaz do znalostní databáze
            result = self.knowledge_base.run(claim)
            
            # Jednoduché hodnocení na základě podobnosti
            similarity = self._calculate_similarity(claim, result)
            
            return {
                "claim": claim,
                "accuracy": similarity,
                "evidence": result,
                "status": "OVĚŘENO" if similarity > 0.7 else "SPORNÉ"
            }
            
        except Exception as e:
            return {
                "claim": claim,
                "accuracy": 0.3,
                "evidence": "Chyba při ověřování",
                "status": "CHYBA"
            }
    
    def _calculate_similarity(self, claim: str, evidence: str) -> float:
        """Výpočet podobnosti mezi tvrzením a důkazem"""
        # Zjednodušená podobnost založená na překryvu slov
        claim_words = set(claim.lower().split())
        evidence_words = set(evidence.lower().split())
        
        if not claim_words or not evidence_words:
            return 0.3
        
        intersection = len(claim_words.intersection(evidence_words))
        union = len(claim_words.union(evidence_words))
        
        return intersection / union if union > 0 else 0.3
    
    def _generate_fact_flags(self, accuracy: float) -> List[str]:
        """Generování značek pro faktickou přesnost"""
        flags = []
        
        if accuracy < 0.3:
            flags.append("FAKTICKÉ_CHYBY")
        elif accuracy < 0.5:
            flags.append("SPORNÉ_FAKTY")
        elif accuracy > 0.8:
            flags.append("OVĚŘENÉ_FAKTY")
            
        return flags

class BiasDetectionAgent(BaseAgent):
    """Agent pro detekci zaujatosti"""
    
    def __init__(self):
        super().__init__("BiasDetector")
        self.bias_keywords = {
            "political_left": ["pokrokový", "sociální spravedlnost", "rovnost"],
            "political_right": ["tradice", "svoboda", "konzervativní"],
            "emotional": ["šokující", "neuvěřitelné", "skandální", "katastrofa"],
            "sensational": ["exkluzivní", "tajné", "odhalení", "bombastické"]
        }
    
    async def process(self, article: NewsArticle) -> Dict:
        """Detekce zaujatosti v článku"""
        try:
            # Analýza sentimentu
            sentiment_score = self._analyze_sentiment(article.content)
            
            # Detekce zaujatých slov
            bias_indicators = self._detect_bias_keywords(article.content)
            
            # Analýza stylu psaní
            writing_style_score = self._analyze_writing_style(article.content)
            
            # Kombinace výsledků
            overall_bias = (abs(sentiment_score) + bias_indicators + writing_style_score) / 3
            
            return {
                "bias_score": overall_bias,
                "sentiment": sentiment_score,
                "bias_indicators": bias_indicators,
                "writing_style": writing_style_score,
                "flags": self._generate_bias_flags(overall_bias),
                "evidence": [f"Sentiment: {sentiment_score:.2f}", f"Zaujatá slova: {bias_indicators:.2f}"]
            }
            
        except Exception as e:
            logger.error(f"Chyba při detekci zaujatosti: {e}")
            return {"bias_score": 0.5, "flags": ["CHYBA_BIAS"]}
    
    def _analyze_sentiment(self, content: str) -> float:
        """Analýza sentimentu textu"""
        try:
            blob = TextBlob(content)
            # Sentiment polarity je mezi -1 a 1
            return blob.sentiment.polarity
        except:
            return 0.0
    
    def _detect_bias_keywords(self, content: str) -> float:
        """Detekce zaujatých klíčových slov"""
        content_lower = content.lower()
        total_bias_words = 0
        total_words = len(content.split())
        
        for category, keywords in self.bias_keywords.items():
            for keyword in keywords:
                total_bias_words += content_lower.count(keyword)
        
        return min(total_bias_words / max(total_words, 1), 1.0)
    
    def _analyze_writing_style(self, content: str) -> float:
        """Analýza stylu psaní"""
        # Počet vykřičníků a otazníků
        exclamations = content.count('!')
        questions = content.count('?')
        
        # Délka vět
        sentences = re.split(r'[.!?]+', content)
        avg_sentence_length = np.mean([len(s.split()) for s in sentences if s.strip()])
        
        # Hodnocení stylu (více vykřičníků = více zaujatosti)
        style_score = min((exclamations + questions) / max(len(sentences), 1), 1.0)
        
        return style_score
    
    def _generate_bias_flags(self, bias_score: float) -> List[str]:
        """Generování značek pro zaujatost"""
        flags = []
        
        if bias_score > 0.7:
            flags.append("VYSOKÁ_ZAUJATOST")
        elif bias_score > 0.5:
            flags.append("MÍRNÁ_ZAUJATOST")
        elif bias_score < 0.2:
            flags.append("NEUTRÁLNÍ_OBSAH")
            
        return flags

class CoordinatorAgent(BaseAgent):
    """Koordinátor pro řízení celého procesu ověřování"""
    
    def __init__(self):
        super().__init__("Coordinator")
        self.source_agent = SourceVerificationAgent()
        self.fact_agent = FactCheckingAgent()
        self.bias_agent = BiasDetectionAgent()
    
    async def verify_article(self, article: NewsArticle) -> VerificationResult:
        """Kompletní ověření článku všemi agenty"""
        try:
            logger.info(f"Zahájeno ověřování článku: {article.title}")
            
            # Paralelní zpracování všemi agenty
            source_result, fact_result, bias_result = await asyncio.gather(
                self.source_agent.process(article),
                self.fact_agent.process(article),
                self.bias_agent.process(article)
            )
            
            # Kombinace výsledků
            overall_score = self._calculate_overall_score(
                source_result, fact_result, bias_result
            )
            
            # Generování závěrečných značek
            final_flags = self._combine_flags(
                source_result.get("flags", []),
                fact_result.get("flags", []),
                bias_result.get("flags", [])
            )
            
            # Generování zdůvodnění
            reasoning = self._generate_reasoning(
                source_result, fact_result, bias_result, overall_score
            )
            
            result = VerificationResult(
                article_id=article.id,
                overall_score=overall_score,
                credibility_score=source_result.get("source_reliability", 0.5),
                bias_score=bias_result.get("bias_score", 0.5),
                fact_accuracy=fact_result.get("fact_accuracy", 0.5),
                source_reliability=source_result.get("source_reliability", 0.5),
                flags=final_flags,
                evidence=self._combine_evidence(source_result, fact_result, bias_result),
                reasoning=reasoning
            )
            
            logger.info(f"Ověřování dokončeno. Celkové skóre: {overall_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"Chyba při ověřování článku: {e}")
            return VerificationResult(
                article_id=article.id,
                overall_score=0.3,
                credibility_score=0.3,
                bias_score=0.5,
                fact_accuracy=0.3,
                source_reliability=0.3,
                flags=["SYSTÉMOVÁ_CHYBA"],
                evidence=["Nastala chyba při zpracování"],
                reasoning="Zpracování článku selhalo kvůli systémové chybě."
            )
    
    def _calculate_overall_score(self, source_result: Dict, fact_result: Dict, bias_result: Dict) -> float:
        """Výpočet celkového skóre"""
        weights = {
            "source": 0.3,
            "facts": 0.4,
            "bias": 0.3
        }
        
        source_score = source_result.get("source_reliability", 0.5)
        fact_score = fact_result.get("fact_accuracy", 0.5)
        bias_score = 1.0 - bias_result.get("bias_score", 0.5)  # Inverze bias skóre
        
        overall = (
            source_score * weights["source"] +
            fact_score * weights["facts"] +
            bias_score * weights["bias"]
        )
        
        return min(max(overall, 0.0), 1.0)
    
    def _combine_flags(self, *flag_lists) -> List[str]:
        """Kombinace značek ze všech agentů"""
        all_flags = []
        for flags in flag_lists:
            all_flags.extend(flags)
        return list(set(all_flags))  # Odstranění duplikátů
    
    def _combine_evidence(self, *results) -> List[str]:
        """Kombinace důkazů ze všech agentů"""
        all_evidence = []
        for result in results:
            all_evidence.extend(result.get("evidence", []))
        return all_evidence
    
    def _generate_reasoning(self, source_result: Dict, fact_result: Dict, 
                          bias_result: Dict, overall_score: float) -> str:
        """Generování lidsky čitelného zdůvodnění"""
        source_score = source_result.get("source_reliability", 0.5)
        fact_score = fact_result.get("fact_accuracy", 0.5)
        bias_score = bias_result.get("bias_score", 0.5)
        
        reasoning_parts = []
        
        # Hodnocení zdroje
        if source_score > 0.7:
            reasoning_parts.append("Zdroj je považován za spolehlivý.")
        elif source_score < 0.4:
            reasoning_parts.append("Zdroj má nízkou spolehlivost.")
        else:
            reasoning_parts.append("Zdroj má střední spolehlivost.")
        
        # Hodnocení faktů
        if fact_score > 0.7:
            reasoning_parts.append("Faktická tvrzení jsou převážně ověřená.")
        elif fact_score < 0.4:
            reasoning_parts.append("Nalezeny byly faktické nepřesnosti.")
        else:
            reasoning_parts.append("Faktická přesnost je střední.")
        
        # Hodnocení zaujatosti
        if bias_score > 0.6:
            reasoning_parts.append("Obsah vykazuje značnou zaujatost.")
        elif bias_score < 0.3:
            reasoning_parts.append("Obsah je relativně neutrální.")
        else:
            reasoning_parts.append("Obsah má mírnou zaujatost.")
        
        # Celkové hodnocení
        if overall_score > 0.7:
            reasoning_parts.append("Celkově je článek hodnocen jako věrohodný.")
        elif overall_score < 0.4:
            reasoning_parts.append("Článek vykazuje významné problémy s věrohodností.")
        else:
            reasoning_parts.append("Článek má střední věrohodnost - doporučuje se opatrnost.")
        
        return " ".join(reasoning_parts)

class NewsVerificationSystem:
    """Hlavní třída systému pro ověřování zpráv"""
    
    def __init__(self):
        self.coordinator = CoordinatorAgent()
        self.verified_articles = {}
        
    async def verify_article_from_url(self, url: str) -> VerificationResult:
        """Ověření článku z URL"""
        try:
            # Stažení obsahu článku
            article = await self._scrape_article(url)
            
            # Ověření článku
            result = await self.coordinator.verify_article(article)
            
            # Uložení výsledku
            self.verified_articles[article.id] = result
            
            return result
            
        except Exception as e:
            logger.error(f"Chyba při ověřování článku z URL {url}: {e}")
            raise
    
    async def verify_article_text(self, title: str, content: str, source: str = "unknown") -> VerificationResult:
        """Ověření článku z textu"""
        try:
            # Vytvoření článku
            article = NewsArticle(
                id=hashlib.md5(content.encode()).hexdigest()[:8],
                title=title,
                content=content,
                source=source,
                url="",
                timestamp=datetime.now()
            )
            
            # Ověření článku
            result = await self.coordinator.verify_article(article)
            
            # Uložení výsledku
            self.verified_articles[article.id] = result
            
            return result
            
        except Exception as e:
            logger.error(f"Chyba při ověřování textu článku: {e}")
            raise
    
    async def _scrape_article(self, url: str) -> NewsArticle:
        """Stažení a parsování článku z URL"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extrakce titulku
            title_tag = soup.find('title') or soup.find('h1')
            title = title_tag.get_text().strip() if title_tag else "Bez titulku"
            
            # Extrakce obsahu (zjednodušené)
            content_tags = soup.find_all(['p', 'div'], class_=lambda x: x and any(
                keyword in x.lower() for keyword in ['content', 'article', 'text', 'body']
            ))
            
            if not content_tags:
                content_tags = soup.find_all('p')
            
            content = ' '.join([tag.get_text().strip() for tag in content_tags[:10]])
            
            if not content:
                raise ValueError("Nepodařilo se extrahovat obsah článku")
            
            return NewsArticle(
                id=hashlib.md5(url.encode()).hexdigest()[:8],
                title=title,
                content=content,
                source=url,
                url=url,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Chyba při stahování článku: {e}")
            raise
    
    def get_verification_history(self) -> List[VerificationResult]:
        """Získání historie ověřování"""
        return list(self.verified_articles.values())
    
    def get_statistics(self) -> Dict:
        """Získání statistik systému"""
        if not self.verified_articles:
            return {"total_articles": 0}
        
        scores = [result.overall_score for result in self.verified_articles.values()]
        flags = []
        for result in self.verified_articles.values():
            flags.extend(result.flags)
        
        from collections import Counter
        flag_counts = Counter(flags)
        
        return {
            "total_articles": len(self.verified_articles),
            "average_score": np.mean(scores),
            "high_quality_articles": len([s for s in scores if s > 0.7]),
            "low_quality_articles": len([s for s in scores if s < 0.4]),
            "most_common_flags": flag_counts.most_common(5)
        }

# Demonstrační funkce
async def demo():
    """Demonstrace systému"""
    system = NewsVerificationSystem()
    
    # Testovací článek
    test_article = {
        "title": "Průlomový objev: Vědci vyvinuli novou technologii",
        "content": """
        Podle nejnovějších výzkumů vědci z Univerzity Karlovy vyvinuli 
        revoluční technologii, která může změnit svět! Tato neuvěřitelná 
        technologie dokáže zpracovat obrovské množství dat rychlostí blesku.
        Odborníci tvrdí, že se jedná o největší průlom za posledních 50 let.
        Statistiky ukazují 300% nárůst efektivity. Praha je hlavní město 
        České republiky, která má rozlohu 78 867 km².
        """,
        "source": "example.com"
    }
    
    print("🔍 Spuštění demonstrace systému ověřování zpráv")
    print("=" * 60)
    
    # Ověření článku
    result = await system.verify_article_text(
        test_article["title"],
        test_article["content"],
        test_article["source"]
    )
    
    # Zobrazení výsledků
    print(f"📰 Článek: {test_article['title']}")
    print(f"🏆 Celkové skóre: {result.overall_score:.2f}")
    print(f"📊 Věrohodnost zdroje: {result.source_reliability:.2f}")
    print(f"✅ Faktická přesnost: {result.fact_accuracy:.2f}")
    print(f"⚖️  Zaujatost: {result.bias_score:.2f}")
    print(f"🚩 Značky: {', '.join(result.flags) if result.flags else 'Žádné'}")
    print(f"💭 Zdůvodnění: {result.reasoning}")
    
    print("\n📈 Statistiky systému:")
    stats = system.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")

if __name__ == "__main__":
    # Instalace závislostí
    print("📦 Instalace závislostí...")
    import subprocess
    import sys
    
    dependencies = [
        "langchain",
        "openai",
        "chromadb", 
        "beautifulsoup4",
        "textblob",
        "pandas",
        "numpy",
        "requests"
    ]
    
    for dep in dependencies:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", dep])
        except:
            print(f"⚠️  Nepodařilo se nainstalovat {dep}")
    
    # Spuštění demo
    asyncio.run(demo())
````

## Souhrn projektu

Decentralizovaná síť pro ověřování zpráv představuje pokročilý multi-agentní systém, který automatizuje proces fact-checkingu a hodnocení věrohodnosti mediálního obsahu. Projekt kombinuje moderní technologie umělé inteligence s robustní architekturou pro vytvoření škálovatelného řešení problému dezinformací.

### Klíčové hodnoty projektu:
- **Automatizace**: Snížení manuální práce při ověřování faktů
- **Transparentnost**: Jasné zdůvodnění hodnocení pro uživatele  
- **Škálovatelnost**: Schopnost zpracovat tisíce článků denně
- **Přesnost**: Kombinace více specializovaných agentů pro vyšší spolehlivost
- **Flexibilita**: Možnost přizpůsobení různým typům obsahu a zdrojů

### Technologické výhody:
- Využití pokročilých LLM modelů pro porozumění kontextu
- Vektorové databáze pro efektivní vyhledávání faktů
- Asynchronní zpracování pro vysoký výkon
- Modulární architektura umožňující snadné rozšíření

Systém může být nasazen jako služba pro mediální organizace, sociální sítě nebo jako samostatná aplikace pro širokou veřejnost, přispívající tak k boji proti dezinformacím a zvyšování mediální gramotnosti.