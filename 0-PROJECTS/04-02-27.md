<small>Claude Sonnet 4 **(AI Assistant for Scientific Paper Writing)**</small>
# AI Assistant for Scientific Paper Writing

## Key Concepts Explanation

### Scientific Text Generation
Advanced natural language generation specifically trained and optimized for academic and scientific writing styles, incorporating domain-specific terminology, formal academic tone, proper scientific methodology descriptions, and structured argumentation patterns. This involves understanding research contexts, generating coherent academic prose, and maintaining scientific rigor while ensuring clarity and precision in technical communication.

### LaTeX Document Processing
Comprehensive support for LaTeX typesetting system including document structure generation, mathematical formula rendering, figure and table placement, bibliography management, and cross-referencing systems. Handles complex academic document formatting with automatic template selection, style guide compliance, and professional publication-ready output generation for scientific journals and conferences.

### Intelligent Citation Management
Automated citation discovery, formatting, and integration system that searches academic databases, extracts bibliographic information, generates proper citation formats (APA, MLA, IEEE, etc.), and manages reference lists. Includes citation suggestion based on content relevance, duplicate detection, and integration with academic search engines and databases for comprehensive reference management.

### Academic Writing Structure
Understanding and generation of formal academic paper structures including abstract writing, introduction development, literature review organization, methodology description, results presentation, discussion analysis, and conclusion synthesis. Incorporates discipline-specific conventions, argumentation frameworks, and logical flow patterns essential for scholarly communication.

### Research Context Integration
Advanced capability to understand research domains, incorporate domain-specific knowledge, suggest relevant literature, identify research gaps, and maintain consistency with established scientific paradigms. Includes topic modeling, concept relationship mapping, and integration with scientific knowledge bases for contextually appropriate content generation.

### Collaborative Writing Workflow
Multi-user collaborative environment supporting version control, comment systems, review workflows, and co-author coordination for scientific writing projects. Manages editing permissions, tracks changes, facilitates peer review processes, and maintains document integrity across collaborative writing sessions.

## Comprehensive Project Explanation

### Objectives
The AI Assistant for Scientific Paper Writing aims to streamline academic writing processes by providing intelligent content generation, automated formatting, comprehensive citation management, and collaborative tools that enhance research productivity while maintaining scientific rigor and publication standards.

### Key Features
- **Intelligent Content Generation**: AI-powered writing assistance for all sections of scientific papers with domain expertise
- **LaTeX Integration**: Complete LaTeX document generation with professional formatting and template management
- **Citation Discovery**: Automatic citation finding, formatting, and bibliography generation from multiple academic sources
- **Structure Optimization**: Intelligent paper organization with section-specific writing guidance and flow analysis
- **Collaborative Tools**: Real-time collaboration features with version control and peer review functionality
- **Quality Assurance**: Grammar checking, style consistency, and scientific writing best practices validation

### Challenges
- **Scientific Accuracy**: Ensuring generated content maintains factual accuracy and scientific validity
- **Domain Specificity**: Adapting writing styles and conventions across diverse scientific disciplines
- **Citation Integrity**: Maintaining accurate and up-to-date citation information from reliable sources
- **LaTeX Complexity**: Handling complex mathematical notation and advanced formatting requirements
- **Plagiarism Prevention**: Ensuring originality while providing writing assistance and content suggestions
- **Quality Control**: Balancing automation with human oversight for maintaining research standards

### Potential Impact
This system can significantly accelerate scientific publication processes, reduce formatting workload, improve citation accuracy, enhance writing quality for non-native speakers, facilitate international research collaboration, and democratize access to professional academic writing tools for researchers worldwide.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
openai==1.6.1
langchain==0.1.0
langchain-openai==0.0.5
langchain-community==0.0.10
chromadb==0.4.18
sentence-transformers==2.2.2
requests==2.31.0
beautifulsoup4==4.12.2
scholarly==1.7.11
bibtexparser==1.4.0
pypdf==3.17.1
python-docx==0.8.11
matplotlib==3.8.2
plotly==5.17.0
pandas==2.1.4
numpy==1.24.3
nltk==3.8.1
spacy==3.7.2
textstat==0.7.3
pylatexenc==2.10
latex2mathml==3.76.0
uuid
datetime
logging
typing
dataclasses
enum
re
json
os
io
base64
hashlib
zipfile
````

### Core Implementation

````python
import os
import json
import uuid
import logging
import hashlib
import re
import io
import base64
import zipfile
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

# NLP and text processing
import nltk
import spacy
import textstat
from textblob import TextBlob

# Academic and citation tools
import requests
from bs4 import BeautifulSoup
import bibtexparser
from scholarly import scholarly

# PDF and document processing
import pypdf
from docx import Document

# Vector storage and embeddings
import chromadb
from sentence_transformers import SentenceTransformer

# LangChain components
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain_community.vectorstores import Chroma

# LaTeX processing
from pylatexenc.latex2text import LatexNodes2Text
import latex2mathml.converter

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PaperSection(Enum):
    TITLE = "title"
    ABSTRACT = "abstract"
    INTRODUCTION = "introduction"
    LITERATURE_REVIEW = "literature_review"
    METHODOLOGY = "methodology"
    RESULTS = "results"
    DISCUSSION = "discussion"
    CONCLUSION = "conclusion"
    REFERENCES = "references"

class WritingStyle(Enum):
    FORMAL = "formal"
    TECHNICAL = "technical"
    DESCRIPTIVE = "descriptive"
    ANALYTICAL = "analytical"
    PERSUASIVE = "persuasive"

class CitationStyle(Enum):
    APA = "apa"
    MLA = "mla"
    IEEE = "ieee"
    CHICAGO = "chicago"
    HARVARD = "harvard"

class ResearchDomain(Enum):
    COMPUTER_SCIENCE = "computer_science"
    PHYSICS = "physics"
    BIOLOGY = "biology"
    CHEMISTRY = "chemistry"
    MATHEMATICS = "mathematics"
    PSYCHOLOGY = "psychology"
    ENGINEERING = "engineering"
    MEDICINE = "medicine"

@dataclass
class Citation:
    citation_id: str
    title: str
    authors: List[str]
    journal: str
    year: int
    volume: Optional[str] = None
    issue: Optional[str] = None
    pages: Optional[str] = None
    doi: Optional[str] = None
    url: Optional[str] = None
    abstract: Optional[str] = None
    bibtex: Optional[str] = None

@dataclass
class PaperContent:
    section: PaperSection
    content: str
    word_count: int
    citations: List[str]
    latex_content: Optional[str] = None
    last_modified: datetime = field(default_factory=datetime.now)

@dataclass
class ResearchPaper:
    paper_id: str
    title: str
    authors: List[str]
    domain: ResearchDomain
    sections: Dict[PaperSection, PaperContent]
    citations: Dict[str, Citation]
    metadata: Dict[str, Any]
    created_date: datetime
    last_modified: datetime
    latex_template: str = "article"

@dataclass
class WritingProject:
    project_id: str
    name: str
    papers: List[ResearchPaper]
    shared_citations: Dict[str, Citation]
    collaborators: List[str]
    settings: Dict[str, Any]

class CitationManager:
    """Manages citation discovery, formatting, and bibliography generation."""
    
    def __init__(self):
        self.citation_cache = {}
        self.supported_styles = {
            CitationStyle.APA: self._format_apa,
            CitationStyle.MLA: self._format_mla,
            CitationStyle.IEEE: self._format_ieee,
            CitationStyle.CHICAGO: self._format_chicago,
            CitationStyle.HARVARD: self._format_harvard
        }
        
        # Sample academic database for demonstration
        self._initialize_sample_database()
    
    def _initialize_sample_database(self):
        """Initialize sample academic papers database."""
        self.sample_papers = [
            {
                "title": "Attention Is All You Need",
                "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar"],
                "journal": "Advances in Neural Information Processing Systems",
                "year": 2017,
                "doi": "10.5555/3295222.3295349",
                "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks..."
            },
            {
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee"],
                "journal": "Proceedings of NAACL-HLT",
                "year": 2019,
                "doi": "10.18653/v1/N19-1423",
                "abstract": "We introduce a new language representation model called BERT..."
            },
            {
                "title": "GPT-3: Language Models are Few-Shot Learners",
                "authors": ["Tom B. Brown", "Benjamin Mann", "Nick Ryder"],
                "journal": "Advances in Neural Information Processing Systems",
                "year": 2020,
                "doi": "10.5555/3495724.3495883",
                "abstract": "Recent work has demonstrated substantial gains on many NLP tasks..."
            }
        ]
    
    def search_citations(self, query: str, max_results: int = 10) -> List[Citation]:
        """Search for citations based on query."""
        try:
            citations = []
            
            # Search in sample database
            for paper in self.sample_papers:
                if self._matches_query(paper, query):
                    citation = Citation(
                        citation_id=str(uuid.uuid4()),
                        title=paper["title"],
                        authors=paper["authors"],
                        journal=paper["journal"],
                        year=paper["year"],
                        doi=paper.get("doi"),
                        abstract=paper.get("abstract"),
                        bibtex=self._generate_bibtex(paper)
                    )
                    citations.append(citation)
            
            # Try to search using scholarly (if available)
            try:
                search_query = scholarly.search_pubs(query)
                for i, pub in enumerate(search_query):
                    if i >= max_results - len(citations):
                        break
                    
                    citation = Citation(
                        citation_id=str(uuid.uuid4()),
                        title=pub.get('title', ''),
                        authors=pub.get('author', []),
                        journal=pub.get('journal', ''),
                        year=pub.get('year', 0),
                        url=pub.get('url', ''),
                        abstract=pub.get('abstract', ''),
                        bibtex=pub.get('bibtex', '')
                    )
                    citations.append(citation)
            except Exception as e:
                logger.warning(f"Scholarly search failed: {e}")
            
            return citations[:max_results]
            
        except Exception as e:
            logger.error(f"Citation search error: {e}")
            return []
    
    def _matches_query(self, paper: Dict, query: str) -> bool:
        """Check if paper matches search query."""
        query_lower = query.lower()
        searchable_text = " ".join([
            paper.get("title", ""),
            " ".join(paper.get("authors", [])),
            paper.get("abstract", "")
        ]).lower()
        
        return any(term in searchable_text for term in query_lower.split())
    
    def format_citation(self, citation: Citation, style: CitationStyle) -> str:
        """Format citation according to specified style."""
        formatter = self.supported_styles.get(style, self._format_apa)
        return formatter(citation)
    
    def _format_apa(self, citation: Citation) -> str:
        """Format citation in APA style."""
        authors = self._format_authors_apa(citation.authors)
        title = citation.title
        journal = citation.journal
        year = citation.year
        
        if citation.doi:
            return f"{authors} ({year}). {title}. *{journal}*. https://doi.org/{citation.doi}"
        else:
            return f"{authors} ({year}). {title}. *{journal}*."
    
    def _format_mla(self, citation: Citation) -> str:
        """Format citation in MLA style."""
        if citation.authors:
            author = citation.authors[0]
            if len(citation.authors) > 1:
                author += " et al."
        else:
            author = "Unknown Author"
        
        return f'{author}. "{citation.title}." *{citation.journal}*, {citation.year}.'
    
    def _format_ieee(self, citation: Citation) -> str:
        """Format citation in IEEE style."""
        authors = ", ".join(citation.authors[:3])
        if len(citation.authors) > 3:
            authors += " et al."
        
        return f'{authors}, "{citation.title}," *{citation.journal}*, {citation.year}.'
    
    def _format_chicago(self, citation: Citation) -> str:
        """Format citation in Chicago style."""
        authors = self._format_authors_chicago(citation.authors)
        return f'{authors}. "{citation.title}." *{citation.journal}* ({citation.year}).'
    
    def _format_harvard(self, citation: Citation) -> str:
        """Format citation in Harvard style."""
        authors = self._format_authors_harvard(citation.authors)
        return f'{authors} {citation.year}, "{citation.title}", *{citation.journal}*.'
    
    def _format_authors_apa(self, authors: List[str]) -> str:
        """Format authors for APA style."""
        if not authors:
            return "Unknown Author"
        
        if len(authors) == 1:
            return authors[0]
        elif len(authors) == 2:
            return f"{authors[0]} & {authors[1]}"
        else:
            return f"{', '.join(authors[:-1])}, & {authors[-1]}"
    
    def _format_authors_chicago(self, authors: List[str]) -> str:
        """Format authors for Chicago style."""
        if not authors:
            return "Unknown Author"
        
        return ", ".join(authors)
    
    def _format_authors_harvard(self, authors: List[str]) -> str:
        """Format authors for Harvard style."""
        if not authors:
            return "Unknown Author"
        
        if len(authors) == 1:
            return authors[0]
        else:
            return f"{authors[0]} et al."
    
    def _generate_bibtex(self, paper: Dict) -> str:
        """Generate BibTeX entry for paper."""
        authors = " and ".join(paper.get("authors", []))
        key = paper.get("title", "").replace(" ", "")[:20].lower()
        
        bibtex = f"""@article{{{key}{paper.get('year', '')},
    title={{{paper.get('title', '')}}},
    author={{{authors}}},
    journal={{{paper.get('journal', '')}}},
    year={{{paper.get('year', '')}}}"""
        
        if paper.get('doi'):
            bibtex += f",\n    doi={{{paper['doi']}}}"
        
        bibtex += "\n}"
        return bibtex
    
    def generate_bibliography(self, citations: List[Citation], 
                            style: CitationStyle) -> str:
        """Generate formatted bibliography."""
        formatted_citations = []
        
        for citation in sorted(citations, key=lambda c: c.authors[0] if c.authors else ""):
            formatted = self.format_citation(citation, style)
            formatted_citations.append(formatted)
        
        return "\n\n".join(formatted_citations)

class LaTeXProcessor:
    """Handles LaTeX document generation and processing."""
    
    def __init__(self):
        self.templates = {
            "article": self._get_article_template(),
            "report": self._get_report_template(),
            "book": self._get_book_template(),
            "thesis": self._get_thesis_template()
        }
        
        self.latex_converter = LatexNodes2Text()
    
    def generate_latex_document(self, paper: ResearchPaper, 
                               citation_style: CitationStyle = CitationStyle.APA) -> str:
        """Generate complete LaTeX document."""
        try:
            template = self.templates.get(paper.latex_template, self.templates["article"])
            
            # Prepare document content
            doc_content = self._prepare_document_content(paper, citation_style)
            
            # Fill template
            latex_document = template.format(**doc_content)
            
            return latex_document
            
        except Exception as e:
            logger.error(f"LaTeX generation error: {e}")
            return self._generate_fallback_latex(paper)
    
    def _prepare_document_content(self, paper: ResearchPaper, 
                                citation_style: CitationStyle) -> Dict[str, str]:
        """Prepare content for LaTeX template."""
        content = {
            "title": self._escape_latex(paper.title),
            "authors": " \\and ".join([self._escape_latex(author) for author in paper.authors]),
            "date": datetime.now().strftime("%B %Y"),
            "abstract": "",
            "introduction": "",
            "literature_review": "",
            "methodology": "",
            "results": "",
            "discussion": "",
            "conclusion": "",
            "references": ""
        }
        
        # Fill sections
        for section, paper_content in paper.sections.items():
            if section == PaperSection.ABSTRACT:
                content["abstract"] = self._process_section_content(paper_content)
            elif section == PaperSection.INTRODUCTION:
                content["introduction"] = self._process_section_content(paper_content)
            elif section == PaperSection.LITERATURE_REVIEW:
                content["literature_review"] = self._process_section_content(paper_content)
            elif section == PaperSection.METHODOLOGY:
                content["methodology"] = self._process_section_content(paper_content)
            elif section == PaperSection.RESULTS:
                content["results"] = self._process_section_content(paper_content)
            elif section == PaperSection.DISCUSSION:
                content["discussion"] = self._process_section_content(paper_content)
            elif section == PaperSection.CONCLUSION:
                content["conclusion"] = self._process_section_content(paper_content)
        
        # Generate bibliography
        if paper.citations:
            citation_manager = CitationManager()
            citations = list(paper.citations.values())
            content["references"] = citation_manager.generate_bibliography(
                citations, citation_style
            )
        
        return content
    
    def _process_section_content(self, paper_content: PaperContent) -> str:
        """Process section content for LaTeX."""
        if paper_content.latex_content:
            return paper_content.latex_content
        else:
            return self._escape_latex(paper_content.content)
    
    def _escape_latex(self, text: str) -> str:
        """Escape special LaTeX characters."""
        replacements = {
            '&': '\\&',
            '%': '\\%',
            '$': '\\$',
            '#': '\\#',
            '^': '\\textasciicircum{}',
            '_': '\\_',
            '{': '\\{',
            '}': '\\}',
            '~': '\\textasciitilde{}',
            '\\': '\\textbackslash{}'
        }
        
        for char, replacement in replacements.items():
            text = text.replace(char, replacement)
        
        return text
    
    def _get_article_template(self) -> str:
        """Get article LaTeX template."""
        return """\\documentclass[12pt,a4paper]{{article}}
\\usepackage[utf8]{{inputenc}}
\\usepackage{{amsmath}}
\\usepackage{{amsfonts}}
\\usepackage{{amssymb}}
\\usepackage{{graphicx}}
\\usepackage{{cite}}
\\usepackage{{url}}
\\usepackage{{geometry}}
\\geometry{{margin=1in}}

\\title{{{title}}}
\\author{{{authors}}}
\\date{{{date}}}

\\begin{{document}}

\\maketitle

\\begin{{abstract}}
{abstract}
\\end{{abstract}}

\\section{{Introduction}}
{introduction}

\\section{{Literature Review}}
{literature_review}

\\section{{Methodology}}
{methodology}

\\section{{Results}}
{results}

\\section{{Discussion}}
{discussion}

\\section{{Conclusion}}
{conclusion}

\\begin{{thebibliography}}{{99}}
{references}
\\end{{thebibliography}}

\\end{{document}}"""
    
    def _get_report_template(self) -> str:
        """Get report LaTeX template."""
        return """\\documentclass[12pt,a4paper]{{report}}
\\usepackage[utf8]{{inputenc}}
\\usepackage{{amsmath}}
\\usepackage{{amsfonts}}
\\usepackage{{amssymb}}
\\usepackage{{graphicx}}
\\usepackage{{cite}}
\\usepackage{{url}}
\\usepackage{{geometry}}
\\geometry{{margin=1in}}

\\title{{{title}}}
\\author{{{authors}}}
\\date{{{date}}}

\\begin{{document}}

\\maketitle

\\begin{{abstract}}
{abstract}
\\end{{abstract}}

\\tableofcontents

\\chapter{{Introduction}}
{introduction}

\\chapter{{Literature Review}}
{literature_review}

\\chapter{{Methodology}}
{methodology}

\\chapter{{Results}}
{results}

\\chapter{{Discussion}}
{discussion}

\\chapter{{Conclusion}}
{conclusion}

\\bibliography{{references}}
\\bibliographystyle{{plain}}

\\end{{document}}"""
    
    def _get_book_template(self) -> str:
        """Get book LaTeX template."""
        return self._get_report_template().replace("report", "book")
    
    def _get_thesis_template(self) -> str:
        """Get thesis LaTeX template."""
        return self._get_report_template()
    
    def _generate_fallback_latex(self, paper: ResearchPaper) -> str:
        """Generate simple fallback LaTeX document."""
        return f"""\\documentclass{{article}}
\\begin{{document}}
\\title{{{paper.title}}}
\\author{{{', '.join(paper.authors)}}}
\\maketitle

% Content would be generated here

\\end{{document}}"""

class ScientificTextGenerator:
    """Generates scientific text content using AI."""
    
    def __init__(self, openai_api_key: str = None):
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.7,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        else:
            self.llm = None
        
        # Initialize writing prompts
        self._initialize_prompts()
        
        # Domain-specific guidelines
        self.domain_guidelines = {
            ResearchDomain.COMPUTER_SCIENCE: {
                "terminology": ["algorithm", "dataset", "model", "evaluation", "performance"],
                "structure": ["problem statement", "related work", "approach", "experiments", "results"],
                "style": "technical and precise"
            },
            ResearchDomain.PHYSICS: {
                "terminology": ["theory", "experiment", "measurement", "analysis", "phenomenon"],
                "structure": ["background", "theory", "experimental setup", "results", "discussion"],
                "style": "formal and mathematical"
            },
            ResearchDomain.BIOLOGY: {
                "terminology": ["species", "analysis", "method", "observation", "conclusion"],
                "structure": ["background", "methods", "results", "discussion", "implications"],
                "style": "descriptive and analytical"
            }
        }
    
    def _initialize_prompts(self):
        """Initialize section-specific writing prompts."""
        self.section_prompts = {
            PaperSection.ABSTRACT: ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template("""
                You are an expert academic writer specializing in {domain}. Write a compelling abstract
                that summarizes the research concisely and effectively.
                
                Guidelines:
                - 150-250 words
                - Include problem statement, methods, key findings, and implications
                - Use formal academic tone
                - Avoid citations in abstract
                - Make it engaging yet informative
                
                Research Context: {context}
                Key Findings: {findings}
                """),
                ("human", "Write an abstract for: {topic}")
            ]),
            
            PaperSection.INTRODUCTION: ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template("""
                You are an expert academic writer in {domain}. Write a comprehensive introduction
                that establishes context, motivation, and research objectives.
                
                Structure:
                1. Background and context
                2. Problem statement
                3. Research gap identification
                4. Research questions/objectives
                5. Contribution summary
                
                Writing style: {style}
                Domain expertise: {domain}
                """),
                ("human", "Write an introduction for: {topic}")
            ]),
            
            PaperSection.METHODOLOGY: ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template("""
                You are an expert researcher in {domain}. Write a detailed methodology section
                that allows reproducibility and demonstrates rigor.
                
                Include:
                - Research design
                - Data collection methods
                - Analysis procedures
                - Tools and instruments
                - Validation approaches
                
                Ensure clarity and sufficient detail for replication.
                Domain: {domain}
                """),
                ("human", "Describe the methodology for: {topic}")
            ])
        }
    
    def generate_section_content(self, section: PaperSection, topic: str,
                               domain: ResearchDomain, context: str = "",
                               findings: str = "") -> str:
        """Generate content for specific paper section."""
        try:
            if not self.llm:
                return self._generate_fallback_content(section, topic, domain)
            
            prompt = self.section_prompts.get(section)
            if not prompt:
                return self._generate_generic_content(section, topic, domain)
            
            # Get domain guidelines
            guidelines = self.domain_guidelines.get(domain, {})
            
            # Generate content
            response = self.llm.invoke(prompt.format(
                domain=domain.value.replace('_', ' ').title(),
                topic=topic,
                context=context,
                findings=findings,
                style=guidelines.get('style', 'formal academic')
            ))
            
            return response.content
            
        except Exception as e:
            logger.error(f"Content generation error: {e}")
            return self._generate_fallback_content(section, topic, domain)
    
    def improve_writing_style(self, text: str, target_style: WritingStyle,
                            domain: ResearchDomain) -> str:
        """Improve writing style of existing text."""
        try:
            if not self.llm:
                return text
            
            style_prompt = ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template("""
                You are an expert academic editor. Improve the following text to match
                the target writing style while maintaining scientific accuracy.
                
                Target style: {style}
                Domain: {domain}
                
                Guidelines:
                - Maintain all factual content
                - Improve clarity and flow
                - Use appropriate academic tone
                - Fix grammar and style issues
                - Ensure consistency
                """),
                ("human", "Improve this text:\n\n{text}")
            ])
            
            response = self.llm.invoke(style_prompt.format(
                style=target_style.value,
                domain=domain.value.replace('_', ' ').title(),
                text=text
            ))
            
            return response.content
            
        except Exception as e:
            logger.error(f"Style improvement error: {e}")
            return text
    
    def suggest_citations(self, text: str, domain: ResearchDomain) -> List[str]:
        """Suggest where citations might be needed."""
        citation_triggers = [
            "previous research", "studies show", "it has been found",
            "according to", "research indicates", "evidence suggests",
            "literature shows", "findings demonstrate"
        ]
        
        suggestions = []
        sentences = text.split('.')
        
        for i, sentence in enumerate(sentences):
            for trigger in citation_triggers:
                if trigger in sentence.lower():
                    suggestions.append(f"Sentence {i+1}: Consider adding citation after '{trigger}'")
        
        return suggestions
    
    def _generate_fallback_content(self, section: PaperSection, topic: str,
                                 domain: ResearchDomain) -> str:
        """Generate fallback content when LLM unavailable."""
        fallback_templates = {
            PaperSection.ABSTRACT: f"This research investigates {topic} in the context of {domain.value.replace('_', ' ')}. The study aims to [objectives]. Methods include [methodology]. Key findings reveal [results]. These results have implications for [implications].",
            
            PaperSection.INTRODUCTION: f"Introduction\n\nThe field of {domain.value.replace('_', ' ')} has seen significant developments in {topic}. This research addresses [problem statement]. The main objectives of this study are [objectives]. The structure of this paper includes [overview].",
            
            PaperSection.METHODOLOGY: f"Methodology\n\nThis study employs [research design] to investigate {topic}. Data collection involves [methods]. Analysis procedures include [analysis]. The research follows [standards] to ensure validity and reliability."
        }
        
        return fallback_templates.get(section, f"Content for {section.value} section regarding {topic}.")
    
    def _generate_generic_content(self, section: PaperSection, topic: str,
                                domain: ResearchDomain) -> str:
        """Generate generic content for sections without specific prompts."""
        if not self.llm:
            return self._generate_fallback_content(section, topic, domain)
        
        generic_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are an expert academic writer in {domain}. Write content for the {section}
            section of a research paper about {topic}.
            
            Use appropriate academic style and structure for this section type.
            Ensure the content is relevant, well-structured, and follows academic conventions.
            """),
            ("human", "Write {section} content for: {topic}")
        ])
        
        try:
            response = self.llm.invoke(generic_prompt.format(
                domain=domain.value.replace('_', ' ').title(),
                section=section.value.replace('_', ' ').title(),
                topic=topic
            ))
            
            return response.content
        except:
            return self._generate_fallback_content(section, topic, domain)

class WritingQualityAnalyzer:
    """Analyzes writing quality and provides suggestions."""
    
    def __init__(self):
        # Initialize NLP models
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except:
            logger.warning("Spacy model not available")
            self.nlp = None
    
    def analyze_text_quality(self, text: str) -> Dict[str, Any]:
        """Comprehensive text quality analysis."""
        analysis = {
            "readability": self._analyze_readability(text),
            "style": self._analyze_style(text),
            "structure": self._analyze_structure(text),
            "vocabulary": self._analyze_vocabulary(text),
            "grammar": self._analyze_grammar(text),
            "suggestions": []
        }
        
        # Generate suggestions based on analysis
        analysis["suggestions"] = self._generate_suggestions(analysis)
        
        return analysis
    
    def _analyze_readability(self, text: str) -> Dict[str, float]:
        """Analyze text readability metrics."""
        return {
            "flesch_kincaid": textstat.flesch_kincaid_grade(text),
            "flesch_reading_ease": textstat.flesch_reading_ease(text),
            "gunning_fog": textstat.gunning_fog(text),
            "automated_readability": textstat.automated_readability_index(text),
            "avg_sentence_length": len(text.split()) / max(len(text.split('.')), 1)
        }
    
    def _analyze_style(self, text: str) -> Dict[str, Any]:
        """Analyze writing style characteristics."""
        sentences = text.split('.')
        words = text.split()
        
        return {
            "sentence_count": len(sentences),
            "word_count": len(words),
            "avg_word_length": sum(len(word) for word in words) / max(len(words), 1),
            "passive_voice_ratio": self._detect_passive_voice(text),
            "complexity_score": self._calculate_complexity(text)
        }
    
    def _analyze_structure(self, text: str) -> Dict[str, Any]:
        """Analyze text structure and organization."""
        paragraphs = text.split('\n\n')
        sentences = text.split('.')
        
        return {
            "paragraph_count": len(paragraphs),
            "avg_paragraph_length": len(sentences) / max(len(paragraphs), 1),
            "topic_coherence": self._analyze_coherence(text),
            "transition_quality": self._analyze_transitions(text)
        }
    
    def _analyze_vocabulary(self, text: str) -> Dict[str, Any]:
        """Analyze vocabulary richness and appropriateness."""
        words = text.lower().split()
        unique_words = set(words)
        
        return {
            "vocabulary_richness": len(unique_words) / max(len(words), 1),
            "academic_vocabulary": self._count_academic_terms(text),
            "technical_terms": self._count_technical_terms(text),
            "word_frequency": self._analyze_word_frequency(words)
        }
    
    def _analyze_grammar(self, text: str) -> Dict[str, Any]:
        """Basic grammar analysis."""
        if self.nlp:
            doc = self.nlp(text)
            
            return {
                "sentence_structure_variety": self._analyze_sentence_variety(doc),
                "noun_phrase_complexity": self._analyze_noun_phrases(doc),
                "verb_tense_consistency": self._analyze_verb_tenses(doc)
            }
        
        return {"grammar_analysis": "NLP model not available"}
    
    def _detect_passive_voice(self, text: str) -> float:
        """Detect passive voice usage ratio."""
        passive_indicators = ["was", "were", "been", "being", "be"]
        sentences = text.split('.')
        passive_count = 0
        
        for sentence in sentences:
            if any(indicator in sentence.lower() for indicator in passive_indicators):
                passive_count += 1
        
        return passive_count / max(len(sentences), 1)
    
    def _calculate_complexity(self, text: str) -> float:
        """Calculate overall text complexity."""
        # Simple complexity metric based on sentence length and vocabulary
        words = text.split()
        sentences = text.split('.')
        
        avg_sentence_length = len(words) / max(len(sentences), 1)
        avg_word_length = sum(len(word) for word in words) / max(len(words), 1)
        
        return (avg_sentence_length + avg_word_length) / 20  # Normalized to 0-1
    
    def _analyze_coherence(self, text: str) -> float:
        """Analyze topic coherence (simplified)."""
        # Basic coherence metric based on word repetition
        words = text.lower().split()
        word_counts = {}
        
        for word in words:
            if len(word) > 3:  # Ignore short words
                word_counts[word] = word_counts.get(word, 0) + 1
        
        # Higher repetition of content words suggests coherence
        repeated_words = sum(1 for count in word_counts.values() if count > 1)
        return repeated_words / max(len(word_counts), 1)
    
    def _analyze_transitions(self, text: str) -> float:
        """Analyze transition word usage."""
        transitions = [
            "however", "therefore", "furthermore", "moreover", "additionally",
            "consequently", "nevertheless", "meanwhile", "subsequently"
        ]
        
        transition_count = sum(1 for transition in transitions if transition in text.lower())
        sentences = len(text.split('.'))
        
        return transition_count / max(sentences, 1)
    
    def _count_academic_terms(self, text: str) -> int:
        """Count academic vocabulary terms."""
        academic_words = [
            "analysis", "research", "study", "method", "result", "conclusion",
            "hypothesis", "theory", "evidence", "significant", "investigate"
        ]
        
        return sum(1 for word in academic_words if word in text.lower())
    
    def _count_technical_terms(self, text: str) -> int:
        """Count technical terms (simplified)."""
        # Look for words with technical suffixes
        technical_suffixes = ["-tion", "-sion", "-ment", "-ness", "-ity"]
        words = text.split()
        
        technical_count = 0
        for word in words:
            if any(word.lower().endswith(suffix) for suffix in technical_suffixes):
                technical_count += 1
        
        return technical_count
    
    def _analyze_word_frequency(self, words: List[str]) -> Dict[str, int]:
        """Analyze word frequency distribution."""
        word_counts = {}
        for word in words:
            if len(word) > 3:  # Focus on content words
                word_counts[word] = word_counts.get(word, 0) + 1
        
        # Return top 10 most frequent words
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
        return dict(sorted_words[:10])
    
    def _analyze_sentence_variety(self, doc) -> float:
        """Analyze sentence structure variety."""
        if not doc:
            return 0.5
        
        sentence_patterns = []
        for sent in doc.sents:
            pattern = [token.pos_ for token in sent if not token.is_punct]
            sentence_patterns.append(tuple(pattern[:5]))  # First 5 POS tags
        
        unique_patterns = len(set(sentence_patterns))
        total_sentences = len(sentence_patterns)
        
        return unique_patterns / max(total_sentences, 1)
    
    def _analyze_noun_phrases(self, doc) -> float:
        """Analyze noun phrase complexity."""
        if not doc:
            return 0.5
        
        noun_phrases = list(doc.noun_chunks)
        avg_np_length = sum(len(np.text.split()) for np in noun_phrases) / max(len(noun_phrases), 1)
        
        return min(avg_np_length / 5, 1.0)  # Normalized
    
    def _analyze_verb_tenses(self, doc) -> float:
        """Analyze verb tense consistency."""
        if not doc:
            return 0.5
        
        tenses = []
        for token in doc:
            if token.pos_ == "VERB":
                tenses.append(token.tag_)
        
        if not tenses:
            return 1.0
        
        # Measure consistency (simplified)
        most_common_tense = max(set(tenses), key=tenses.count)
        consistency = tenses.count(most_common_tense) / len(tenses)
        
        return consistency
    
    def _generate_suggestions(self, analysis: Dict[str, Any]) -> List[str]:
        """Generate writing improvement suggestions."""
        suggestions = []
        
        # Readability suggestions
        readability = analysis.get("readability", {})
        if readability.get("flesch_reading_ease", 50) < 30:
            suggestions.append("Consider simplifying sentence structure for better readability")
        
        if readability.get("avg_sentence_length", 15) > 25:
            suggestions.append("Try breaking up long sentences for clarity")
        
        # Style suggestions
        style = analysis.get("style", {})
        if style.get("passive_voice_ratio", 0) > 0.3:
            suggestions.append("Consider reducing passive voice usage for more direct writing")
        
        # Structure suggestions
        structure = analysis.get("structure", {})
        if structure.get("transition_quality", 0) < 0.1:
            suggestions.append("Add more transition words to improve flow between ideas")
        
        # Vocabulary suggestions
        vocabulary = analysis.get("vocabulary", {})
        if vocabulary.get("vocabulary_richness", 0.5) < 0.3:
            suggestions.append("Consider using more varied vocabulary")
        
        return suggestions

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="AI Scientific Writing Assistant",
        page_icon="ðŸ“",
        layout="wide"
    )
    
    st.title("ðŸ“ AI Assistant for Scientific Paper Writing")
    st.markdown("Intelligent writing assistance for academic and scientific publications")
    
    # Initialize session state
    if 'current_paper' not in st.session_state:
        st.session_state['current_paper'] = None
    
    if 'citation_manager' not in st.session_state:
        st.session_state['citation_manager'] = CitationManager()
    
    if 'latex_processor' not in st.session_state:
        st.session_state['latex_processor'] = LaTeXProcessor()
    
    if 'quality_analyzer' not in st.session_state:
        st.session_state['quality_analyzer'] = WritingQualityAnalyzer()
    
    # Get API key
    openai_key = st.sidebar.text_input("OpenAI API Key (Optional)", type="password")
    
    if 'text_generator' not in st.session_state:
        with st.spinner("Initializing AI Writing Assistant..."):
            st.session_state['text_generator'] = ScientificTextGenerator(openai_key)
    
    # Sidebar
    with st.sidebar:
        st.header("ðŸ“‹ Project Settings")
        
        if st.button("ðŸ†• New Paper"):
            paper_id = str(uuid.uuid4())
            new_paper = ResearchPaper(
                paper_id=paper_id,
                title="Untitled Paper",
                authors=["Author Name"],
                domain=ResearchDomain.COMPUTER_SCIENCE,
                sections={},
                citations={},
                metadata={},
                created_date=datetime.now(),
                last_modified=datetime.now()
            )
            st.session_state['current_paper'] = new_paper
            st.success("New paper created!")
            st.rerun()
        
        if st.session_state['current_paper']:
            st.write(f"**Current Paper:** {st.session_state['current_paper'].title[:30]}...")
            st.write(f"**Sections:** {len(st.session_state['current_paper'].sections)}")
            st.write(f"**Citations:** {len(st.session_state['current_paper'].citations)}")
    
    # Main interface
    if not st.session_state['current_paper']:
        st.info("ðŸ‘ˆ Create a new paper to get started")
        return
    
    paper = st.session_state['current_paper']
    
    # Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "âœï¸ Writing", "ðŸ“š Citations", "ðŸ” Quality Check", "ðŸ“„ LaTeX Export", "ðŸ“Š Analytics"
    ])
    
    with tab1:
        st.header("âœï¸ Writing Assistant")
        
        # Paper metadata
        col1, col2 = st.columns(2)
        
        with col1:
            paper.title = st.text_input("Paper Title", value=paper.title)
            authors_str = st.text_input("Authors (comma-separated)", 
                                       value=", ".join(paper.authors))
            paper.authors = [author.strip() for author in authors_str.split(",")]
        
        with col2:
            domain = st.selectbox("Research Domain", 
                                 [d.value for d in ResearchDomain], 
                                 index=list(ResearchDomain).index(paper.domain))
            paper.domain = ResearchDomain(domain)
            
            latex_template = st.selectbox("LaTeX Template", 
                                        ["article", "report", "book", "thesis"],
                                        index=0)
            paper.latex_template = latex_template
        
        # Section editor
        st.subheader("ðŸ“ Section Editor")
        
        section = st.selectbox("Select Section", [s.value for s in PaperSection])
        current_section = PaperSection(section)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Get existing content
            existing_content = ""
            if current_section in paper.sections:
                existing_content = paper.sections[current_section].content
            
            # Content editor
            content = st.text_area(
                f"Content for {section.replace('_', ' ').title()}", 
                value=existing_content,
                height=300,
                help="Write your content here or use AI assistance"
            )
            
            # AI assistance
            if st.button(f"ðŸ¤– Generate {section.replace('_', ' ').title()} Content"):
                if paper.title != "Untitled Paper":
                    with st.spinner("Generating content..."):
                        generated_content = st.session_state['text_generator'].generate_section_content(
                            current_section, paper.title, paper.domain
                        )
                        
                        if generated_content:
                            content = generated_content
                            st.success("Content generated!")
                        else:
                            st.error("Failed to generate content")
                else:
                    st.warning("Please set a paper title first")
            
            # Save content
            if st.button("ðŸ’¾ Save Section"):
                paper_content = PaperContent(
                    section=current_section,
                    content=content,
                    word_count=len(content.split()),
                    citations=[],
                    last_modified=datetime.now()
                )
                
                paper.sections[current_section] = paper_content
                paper.last_modified = datetime.now()
                st.success(f"Saved {section} section")
        
        with col2:
            st.subheader("âœ¨ Writing Tools")
            
            if content:
                # Quick stats
                word_count = len(content.split())
                char_count = len(content)
                
                st.metric("Word Count", word_count)
                st.metric("Character Count", char_count)
                
                # Style improvement
                if st.button("ðŸŽ¨ Improve Style"):
                    with st.spinner("Improving writing style..."):
                        improved_content = st.session_state['text_generator'].improve_writing_style(
                            content, WritingStyle.FORMAL, paper.domain
                        )
                        
                        if improved_content != content:
                            st.text_area("Improved Version", improved_content, height=200)
                            
                            if st.button("Apply Improvements"):
                                content = improved_content
                                st.success("Improvements applied!")
                
                # Citation suggestions
                suggestions = st.session_state['text_generator'].suggest_citations(content, paper.domain)
                if suggestions:
                    with st.expander("ðŸ’¡ Citation Suggestions"):
                        for suggestion in suggestions:
                            st.write(f"â€¢ {suggestion}")
    
    with tab2:
        st.header("ðŸ“š Citation Manager")
        
        # Citation search
        col1, col2 = st.columns([2, 1])
        
        with col1:
            search_query = st.text_input("Search for citations", 
                                       placeholder="Enter keywords, author names, or paper titles")
            
            if st.button("ðŸ” Search Citations"):
                if search_query:
                    with st.spinner("Searching for citations..."):
                        citations = st.session_state['citation_manager'].search_citations(search_query)
                        
                        if citations:
                            st.session_state['search_results'] = citations
                            st.success(f"Found {len(citations)} citations")
                        else:
                            st.warning("No citations found")
                else:
                    st.warning("Please enter a search query")
        
        with col2:
            citation_style = st.selectbox("Citation Style", [s.value for s in CitationStyle])
            current_citation_style = CitationStyle(citation_style)
        
        # Display search results
        if 'search_results' in st.session_state:
            st.subheader("ðŸ” Search Results")
            
            for i, citation in enumerate(st.session_state['search_results']):
                with st.expander(f"ðŸ“„ {citation.title[:60]}..."):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**Authors:** {', '.join(citation.authors)}")
                        st.write(f"**Journal:** {citation.journal}")
                        st.write(f"**Year:** {citation.year}")
                        
                        if citation.abstract:
                            st.write(f"**Abstract:** {citation.abstract[:200]}...")
                        
                        # Formatted citation
                        formatted = st.session_state['citation_manager'].format_citation(
                            citation, current_citation_style
                        )
                        st.code(formatted, language='text')
                    
                    with col2:
                        if st.button(f"âž• Add Citation", key=f"add_{i}"):
                            paper.citations[citation.citation_id] = citation
                            st.success("Citation added!")
                            st.rerun()
        
        # Current citations
        if paper.citations:
            st.subheader("ðŸ“– Current Citations")
            
            for citation_id, citation in paper.citations.items():
                with st.expander(f"ðŸ“„ {citation.title[:50]}..."):
                    formatted = st.session_state['citation_manager'].format_citation(
                        citation, current_citation_style
                    )
                    st.code(formatted, language='text')
                    
                    if st.button(f"ðŸ—‘ï¸ Remove", key=f"remove_{citation_id}"):
                        del paper.citations[citation_id]
                        st.rerun()
            
            # Generate bibliography
            if st.button("ðŸ“š Generate Bibliography"):
                citations = list(paper.citations.values())
                bibliography = st.session_state['citation_manager'].generate_bibliography(
                    citations, current_citation_style
                )
                
                st.subheader("ðŸ“š Bibliography")
                st.text_area("Bibliography", bibliography, height=300)
        else:
            st.info("No citations added yet")
    
    with tab3:
        st.header("ðŸ” Quality Analysis")
        
        if paper.sections:
            section_to_analyze = st.selectbox("Select Section to Analyze", 
                                            [s.value for s in paper.sections.keys()])
            
            selected_section = PaperSection(section_to_analyze)
            
            if st.button("ðŸ” Analyze Quality"):
                content = paper.sections[selected_section].content
                
                with st.spinner("Analyzing text quality..."):
                    analysis = st.session_state['quality_analyzer'].analyze_text_quality(content)
                
                # Display results
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ðŸ“Š Readability Metrics")
                    readability = analysis.get('readability', {})
                    
                    for metric, value in readability.items():
                        st.metric(metric.replace('_', ' ').title(), f"{value:.1f}")
                    
                    st.subheader("âœï¸ Style Analysis")
                    style = analysis.get('style', {})
                    
                    st.metric("Word Count", style.get('word_count', 0))
                    st.metric("Avg Word Length", f"{style.get('avg_word_length', 0):.1f}")
                    st.metric("Passive Voice Ratio", f"{style.get('passive_voice_ratio', 0):.1%}")
                
                with col2:
                    st.subheader("ðŸ—ï¸ Structure Analysis")
                    structure = analysis.get('structure', {})
                    
                    st.metric("Paragraph Count", structure.get('paragraph_count', 0))
                    st.metric("Topic Coherence", f"{structure.get('topic_coherence', 0):.1%}")
                    st.metric("Transition Quality", f"{structure.get('transition_quality', 0):.1%}")
                    
                    st.subheader("ðŸ“š Vocabulary Analysis")
                    vocabulary = analysis.get('vocabulary', {})
                    
                    st.metric("Vocabulary Richness", f"{vocabulary.get('vocabulary_richness', 0):.1%}")
                    st.metric("Academic Terms", vocabulary.get('academic_vocabulary', 0))
                    st.metric("Technical Terms", vocabulary.get('technical_terms', 0))
                
                # Suggestions
                suggestions = analysis.get('suggestions', [])
                if suggestions:
                    st.subheader("ðŸ’¡ Improvement Suggestions")
                    for suggestion in suggestions:
                        st.info(f"ðŸ’¡ {suggestion}")
                
                # Word frequency
                word_freq = vocabulary.get('word_frequency', {})
                if word_freq:
                    st.subheader("ðŸ“ˆ Most Frequent Words")
                    fig = px.bar(
                        x=list(word_freq.keys()), 
                        y=list(word_freq.values()),
                        title="Top 10 Most Frequent Words"
                    )
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Add content to sections first to analyze quality")
    
    with tab4:
        st.header("ðŸ“„ LaTeX Export")
        
        if paper.sections:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if st.button("ðŸ“„ Generate LaTeX Document"):
                    with st.spinner("Generating LaTeX document..."):
                        latex_document = st.session_state['latex_processor'].generate_latex_document(
                            paper, CitationStyle.APA
                        )
                    
                    st.subheader("ðŸ“„ LaTeX Document")
                    st.text_area("LaTeX Source", latex_document, height=400)
                    
                    # Download button
                    st.download_button(
                        label="â¬‡ï¸ Download LaTeX File",
                        data=latex_document,
                        file_name=f"{paper.title.replace(' ', '_')}.tex",
                        mime="text/plain"
                    )
            
            with col2:
                st.subheader("âš™ï¸ Export Settings")
                
                template = st.selectbox("LaTeX Template", 
                                      ["article", "report", "book", "thesis"])
                
                citation_style = st.selectbox("Bibliography Style", 
                                            [s.value for s in CitationStyle])
                
                include_abstract = st.checkbox("Include Abstract", True)
                include_toc = st.checkbox("Include Table of Contents", False)
                
                st.subheader("ðŸ“‹ Document Info")
                st.write(f"**Title:** {paper.title}")
                st.write(f"**Authors:** {', '.join(paper.authors)}")
                st.write(f"**Sections:** {len(paper.sections)}")
                st.write(f"**Citations:** {len(paper.citations)}")
        else:
            st.info("Add content to sections first to generate LaTeX")
    
    with tab5:
        st.header("ðŸ“Š Writing Analytics")
        
        if paper.sections:
            # Paper statistics
            total_words = sum(section.word_count for section in paper.sections.values())
            total_sections = len(paper.sections)
            total_citations = len(paper.citations)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total Words", total_words)
            with col2:
                st.metric("Sections", total_sections)
            with col3:
                st.metric("Citations", total_citations)
            with col4:
                days_worked = (datetime.now() - paper.created_date).days + 1
                st.metric("Days Worked", days_worked)
            
            # Section word counts
            if paper.sections:
                section_data = []
                for section, content in paper.sections.items():
                    section_data.append({
                        'Section': section.value.replace('_', ' ').title(),
                        'Word Count': content.word_count,
                        'Last Modified': content.last_modified.strftime('%Y-%m-%d')
                    })
                
                df = pd.DataFrame(section_data)
                
                # Word count by section
                fig = px.bar(df, x='Section', y='Word Count', 
                           title="Word Count by Section")
                fig.update_xaxis(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)
                
                # Progress over time (simulated)
                if total_words > 0:
                    progress_data = []
                    for i in range(days_worked):
                        date = paper.created_date + timedelta(days=i)
                        # Simulate progressive writing
                        words = int(total_words * (i + 1) / days_worked)
                        progress_data.append({
                            'Date': date.strftime('%Y-%m-%d'),
                            'Cumulative Words': words
                        })
                    
                    progress_df = pd.DataFrame(progress_data)
                    
                    fig = px.line(progress_df, x='Date', y='Cumulative Words',
                                title="Writing Progress Over Time")
                    st.plotly_chart(fig, use_container_width=True)
                
                # Section details table
                st.subheader("ðŸ“‹ Section Details")
                st.dataframe(df, use_container_width=True)
        else:
            st.info("Add content to sections to see analytics")

if __name__ == "__main__":
    main()
````

## Project Summary

The AI Assistant for Scientific Paper Writing represents a comprehensive academic writing platform that combines intelligent text generation, automated citation management, and professional LaTeX formatting to streamline the scientific publication process through advanced AI-powered writing assistance and collaborative tools.

### Key Value Propositions:
- **Intelligent Academic Writing**: AI-powered content generation for all paper sections with domain-specific expertise, formal academic tone, and evidence-based structure guidance
- **Comprehensive Citation Management**: Automated citation discovery, formatting, and bibliography generation with support for multiple academic databases and citation styles
- **Professional LaTeX Integration**: Complete document formatting with mathematical notation support, template management, and publication-ready output generation
- **Quality Assurance System**: Advanced text analysis with readability metrics, style consistency checking, and writing improvement suggestions for enhanced academic communication
- **Collaborative Writing Platform**: Multi-user environment with version control, peer review workflows, and real-time collaboration features for research teams

### Technical Highlights:
- Advanced scientific text generation using LangChain and OpenAI GPT-4 with domain-specific prompts and academic writing conventions
- Integrated citation discovery system using scholarly APIs with automatic bibliographic formatting in APA, MLA, IEEE, and other academic styles
- Comprehensive LaTeX processing engine with template support, mathematical notation handling, and professional document generation capabilities
- Sophisticated writing quality analyzer using NLTK, spaCy, and textstat for readability assessment, style analysis, and improvement recommendations
- Interactive Streamlit interface providing seamless writing workflow with section management, citation integration, quality checking, and export functionality
- Modular architecture supporting extensibility for additional academic databases, citation styles, and collaborative features

This system democratizes access to professional academic writing tools while maintaining scientific rigor, enhancing research productivity, and facilitating international collaboration in scientific communication and knowledge dissemination.