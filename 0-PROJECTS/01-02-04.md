<small>Claude Sonnet 4 **(Codebase Companion for Developers - AI-Enhanced MCP Integration)**</small>
# Codebase Companion for Developers

## Key Concepts Explanation

### Model Context Protocol (MCP)
Advanced context management framework that maintains comprehensive developer workspace awareness across multiple programming sessions, tracking code changes, project evolution, debugging sessions, and development patterns to provide contextually intelligent assistance throughout the software development lifecycle.

### VS Code Plugin Integration
Seamless integration with Visual Studio Code through custom extensions that capture real-time developer activity, monitor code editing patterns, track file interactions, and provide in-IDE AI assistance while maintaining workspace context and developer workflow continuity.

### RAG (Retrieval-Augmented Generation)
Sophisticated information retrieval system that combines vector similarity search with generative AI to provide accurate, contextually relevant code assistance by accessing local codebase knowledge, external documentation, and programming best practices.

### Embedding Index Architecture
Advanced vector database system that creates semantic representations of code files, functions, documentation, and development artifacts, enabling intelligent code search, similarity detection, and contextual code understanding across large codebases.

### Git Integration and Version Control
Deep integration with Git workflows that tracks code evolution, commit patterns, branch strategies, and collaborative development activities to maintain historical context and support intelligent code review and development assistance.

### Developer Context Tracking
Comprehensive system that monitors developer behavior patterns, coding preferences, project focus areas, and workflow habits to provide personalized assistance and maintain continuity across development sessions and projects.

## Comprehensive Project Explanation

The Codebase Companion for Developers revolutionizes software development by providing AI-enhanced coding assistance that understands project context, tracks development patterns, and offers intelligent support throughout the software development lifecycle. This system combines advanced code analysis with contextual awareness to deliver personalized, project-specific assistance that evolves with developer needs and project complexity.

### Objectives
- **Intelligent Code Understanding**: Provide deep semantic analysis of codebases using advanced embedding techniques to understand code structure, dependencies, and architectural patterns
- **Contextual Development Assistance**: Deliver personalized coding assistance based on current project context, developer history, and real-time workspace activity
- **Seamless IDE Integration**: Integrate directly into developer workflows through VS Code extensions that provide unobtrusive, contextually aware assistance
- **Version Control Intelligence**: Leverage Git history and collaborative development patterns to provide insights on code evolution and team development practices
- **Scalable Knowledge Management**: Maintain comprehensive knowledge bases of code patterns, documentation, and development best practices across multiple projects and repositories

### Challenges
- **Codebase Scale and Complexity**: Managing semantic analysis and context tracking across large, complex codebases with millions of lines of code and diverse architectural patterns
- **Real-Time Performance**: Providing instant responses to developer queries while maintaining comprehensive context analysis and embedding updates
- **Privacy and Security**: Ensuring sensitive code and proprietary information remain secure while providing cloud-enhanced AI assistance and collaboration features
- **Multi-Language Support**: Supporting diverse programming languages, frameworks, and development environments with consistent quality and accuracy
- **Context Continuity**: Maintaining relevant context across development sessions, project switches, and collaborative team environments

### Potential Impact
This platform could significantly enhance developer productivity by reducing time spent on code exploration, accelerating onboarding for new team members, improving code quality through intelligent suggestions, and democratizing access to advanced software development knowledge and best practices across development teams.

## Comprehensive Project Example with Python Implementation

````python
import asyncio
import json
import logging
import os
import subprocess
import threading
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
import ast
import hashlib
import uuid

# Core dependencies
import pandas as pd
import numpy as np

# AI and ML
import openai
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma, FAISS
from langchain.schema import Document
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# Database
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy import Column, String, DateTime, Text, JSON, Integer, Boolean

# Web and API
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn

# Code analysis
import tree_sitter
from tree_sitter import Language, Parser
import git
from git import Repo
import pygments
from pygments.lexers import get_lexer_by_name
from pygments.util import ClassNotFound

# File watching
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# Utilities
import aiofiles
import asyncio
from concurrent.futures import ThreadPoolExecutor
import warnings
warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database Models
Base = declarative_base()

class CodeFile(Base):
    __tablename__ = "code_files"
    
    id = Column(String, primary_key=True)
    file_path = Column(String, nullable=False, unique=True)
    file_hash = Column(String, nullable=False)
    language = Column(String)
    content = Column(Text)
    functions = Column(JSON)
    classes = Column(JSON)
    imports = Column(JSON)
    last_analyzed = Column(DateTime, default=datetime.utcnow)
    embedding_updated = Column(DateTime)

class ProjectContext(Base):
    __tablename__ = "project_context"
    
    id = Column(String, primary_key=True)
    project_path = Column(String, nullable=False)
    project_name = Column(String)
    technologies = Column(JSON)
    dependencies = Column(JSON)
    structure_summary = Column(Text)
    last_updated = Column(DateTime, default=datetime.utcnow)

class DeveloperSession(Base):
    __tablename__ = "developer_sessions"
    
    id = Column(String, primary_key=True)
    session_start = Column(DateTime, default=datetime.utcnow)
    session_end = Column(DateTime)
    active_files = Column(JSON)
    queries = Column(JSON)
    context_data = Column(JSON)
    productivity_metrics = Column(JSON)

class CodeInteraction(Base):
    __tablename__ = "code_interactions"
    
    id = Column(String, primary_key=True)
    session_id = Column(String, nullable=False)
    interaction_type = Column(String)  # query, edit, debug, search
    file_path = Column(String)
    query_text = Column(Text)
    response_text = Column(Text)
    timestamp = Column(DateTime, default=datetime.utcnow)
    context_used = Column(JSON)

@dataclass
class CodeAnalysis:
    file_path: str
    language: str
    functions: List[Dict[str, Any]]
    classes: List[Dict[str, Any]]
    imports: List[str]
    complexity_score: int
    documentation_coverage: float

@dataclass
class DeveloperQuery:
    query_id: str
    query_text: str
    context_files: List[str]
    query_type: str
    timestamp: datetime

class CodeAnalyzer:
    """Advanced code analysis and parsing engine"""
    
    def __init__(self):
        self.supported_languages = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.cs': 'csharp',
            '.go': 'go',
            '.rs': 'rust',
            '.php': 'php'
        }
        
        # Initialize parsers for different languages
        self.parsers = {}
        self._initialize_parsers()
    
    def _initialize_parsers(self):
        """Initialize Tree-sitter parsers for supported languages"""
        try:
            # Note: In a real implementation, you would need to build Tree-sitter language libraries
            # For demo purposes, we'll use AST parsing for Python
            pass
        except Exception as e:
            logger.warning(f"Parser initialization failed: {e}")
    
    async def analyze_file(self, file_path: str) -> Optional[CodeAnalysis]:
        """Analyze a code file and extract structural information"""
        try:
            if not os.path.exists(file_path):
                return None
            
            # Determine language
            file_ext = Path(file_path).suffix
            language = self.supported_languages.get(file_ext, 'unknown')
            
            if language == 'unknown':
                return None
            
            # Read file content
            async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                content = await file.read()
            
            # Analyze based on language
            if language == 'python':
                return await self._analyze_python_file(file_path, content)
            else:
                return await self._analyze_generic_file(file_path, content, language)
                
        except Exception as e:
            logger.error(f"File analysis failed for {file_path}: {e}")
            return None
    
    async def _analyze_python_file(self, file_path: str, content: str) -> CodeAnalysis:
        """Analyze Python file using AST"""
        try:
            tree = ast.parse(content)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'args': [arg.arg for arg in node.args.args],
                        'docstring': ast.get_docstring(node),
                        'is_async': isinstance(node, ast.AsyncFunctionDef)
                    }
                    functions.append(func_info)
                
                elif isinstance(node, ast.ClassDef):
                    class_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'methods': [n.name for n in node.body if isinstance(n, ast.FunctionDef)],
                        'docstring': ast.get_docstring(node)
                    }
                    classes.append(class_info)
                
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.append(alias.name)
                    else:
                        module = node.module or ''
                        for alias in node.names:
                            imports.append(f"{module}.{alias.name}")
            
            # Calculate complexity score (simplified)
            complexity_score = len(functions) + len(classes) * 2
            
            # Calculate documentation coverage
            documented_functions = sum(1 for f in functions if f['docstring'])
            documented_classes = sum(1 for c in classes if c['docstring'])
            total_items = len(functions) + len(classes)
            documentation_coverage = (documented_functions + documented_classes) / max(total_items, 1)
            
            return CodeAnalysis(
                file_path=file_path,
                language='python',
                functions=functions,
                classes=classes,
                imports=imports,
                complexity_score=complexity_score,
                documentation_coverage=documentation_coverage
            )
            
        except SyntaxError as e:
            logger.warning(f"Syntax error in {file_path}: {e}")
            return self._create_basic_analysis(file_path, content, 'python')
        except Exception as e:
            logger.error(f"Python analysis failed for {file_path}: {e}")
            return self._create_basic_analysis(file_path, content, 'python')
    
    async def _analyze_generic_file(self, file_path: str, content: str, language: str) -> CodeAnalysis:
        """Basic analysis for non-Python files"""
        try:
            # Simple pattern-based analysis
            import re
            
            # Find function-like patterns
            function_patterns = {
                'javascript': r'function\s+(\w+)',
                'java': r'(?:public|private|protected)?\s*(?:static)?\s*\w+\s+(\w+)\s*\(',
                'cpp': r'\w+\s+(\w+)\s*\([^)]*\)\s*{',
                'go': r'func\s+(\w+)\s*\(',
            }
            
            functions = []
            if language in function_patterns:
                pattern = function_patterns[language]
                matches = re.finditer(pattern, content, re.MULTILINE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    functions.append({
                        'name': match.group(1),
                        'line': line_num,
                        'language': language
                    })
            
            # Find import-like patterns
            imports = []
            import_patterns = {
                'javascript': r'import\s+.*?\s+from\s+[\'"]([^\'"]+)[\'"]',
                'java': r'import\s+([^;]+);',
                'cpp': r'#include\s*[<"]([^>"]+)[>"]',
                'go': r'import\s+[\'"]([^\'"]+)[\'"]',
            }
            
            if language in import_patterns:
                pattern = import_patterns[language]
                imports = re.findall(pattern, content)
            
            return CodeAnalysis(
                file_path=file_path,
                language=language,
                functions=functions,
                classes=[],
                imports=imports,
                complexity_score=len(functions),
                documentation_coverage=0.0
            )
            
        except Exception as e:
            logger.error(f"Generic analysis failed for {file_path}: {e}")
            return self._create_basic_analysis(file_path, content, language)
    
    def _create_basic_analysis(self, file_path: str, content: str, language: str) -> CodeAnalysis:
        """Create basic analysis when detailed analysis fails"""
        return CodeAnalysis(
            file_path=file_path,
            language=language,
            functions=[],
            classes=[],
            imports=[],
            complexity_score=0,
            documentation_coverage=0.0
        )

class EmbeddingManager:
    """Manages code embeddings and vector storage"""
    
    def __init__(self, project_path: str):
        self.project_path = project_path
        self.embeddings = OpenAIEmbeddings()
        
        # Initialize vector stores
        self.code_vector_store = Chroma(
            embedding_function=self.embeddings,
            persist_directory=os.path.join(project_path, ".codebase_companion", "code_embeddings")
        )
        
        self.doc_vector_store = Chroma(
            embedding_function=self.embeddings,
            persist_directory=os.path.join(project_path, ".codebase_companion", "doc_embeddings")
        )
        
        # Text splitter for code
        self.code_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\nclass ", "\n\ndef ", "\n\n", "\n", " "]
        )
    
    async def create_code_embeddings(self, code_analysis: CodeAnalysis, content: str):
        """Create and store embeddings for a code file"""
        try:
            # Create document chunks
            chunks = self.code_splitter.split_text(content)
            
            documents = []
            for i, chunk in enumerate(chunks):
                metadata = {
                    "file_path": code_analysis.file_path,
                    "language": code_analysis.language,
                    "chunk_index": i,
                    "functions": [f["name"] for f in code_analysis.functions],
                    "classes": [c["name"] for c in code_analysis.classes],
                    "complexity": code_analysis.complexity_score
                }
                
                doc = Document(
                    page_content=chunk,
                    metadata=metadata
                )
                documents.append(doc)
            
            # Add to vector store
            if documents:
                self.code_vector_store.add_documents(documents)
                logger.info(f"Created embeddings for {code_analysis.file_path}")
            
        except Exception as e:
            logger.error(f"Embedding creation failed for {code_analysis.file_path}: {e}")
    
    async def search_similar_code(self, query: str, k: int = 5, 
                                file_filters: Optional[List[str]] = None) -> List[Document]:
        """Search for similar code snippets"""
        try:
            filter_dict = {}
            if file_filters:
                filter_dict = {"file_path": {"$in": file_filters}}
            
            results = self.code_vector_store.similarity_search(
                query, k=k, filter=filter_dict if filter_dict else None
            )
            
            return results
            
        except Exception as e:
            logger.error(f"Code search failed: {e}")
            return []
    
    async def get_file_context(self, file_path: str) -> List[Document]:
        """Get all embeddings for a specific file"""
        try:
            results = self.code_vector_store.similarity_search(
                "", k=100, filter={"file_path": file_path}
            )
            return results
        except Exception as e:
            logger.error(f"File context retrieval failed: {e}")
            return []

class GitIntegration:
    """Git repository integration and analysis"""
    
    def __init__(self, repo_path: str):
        self.repo_path = repo_path
        try:
            self.repo = Repo(repo_path)
        except git.exc.InvalidGitRepositoryError:
            self.repo = None
            logger.warning(f"No Git repository found at {repo_path}")
    
    def get_recent_changes(self, days: int = 7) -> List[Dict[str, Any]]:
        """Get recent Git changes"""
        try:
            if not self.repo:
                return []
            
            since_date = datetime.now() - timedelta(days=days)
            commits = list(self.repo.iter_commits(since=since_date))
            
            changes = []
            for commit in commits[:20]:  # Limit to 20 commits
                change_info = {
                    "hash": commit.hexsha,
                    "message": commit.message.strip(),
                    "author": commit.author.name,
                    "date": commit.committed_datetime,
                    "files_changed": len(commit.stats.files),
                    "insertions": commit.stats.total['insertions'],
                    "deletions": commit.stats.total['deletions']
                }
                changes.append(change_info)
            
            return changes
            
        except Exception as e:
            logger.error(f"Git analysis failed: {e}")
            return []
    
    def get_file_history(self, file_path: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Get commit history for a specific file"""
        try:
            if not self.repo:
                return []
            
            commits = list(self.repo.iter_commits(paths=file_path, max_count=limit))
            
            history = []
            for commit in commits:
                history.append({
                    "hash": commit.hexsha,
                    "message": commit.message.strip(),
                    "author": commit.author.name,
                    "date": commit.committed_datetime
                })
            
            return history
            
        except Exception as e:
            logger.error(f"File history retrieval failed: {e}")
            return []
    
    def get_current_branch(self) -> str:
        """Get current Git branch"""
        try:
            if not self.repo:
                return "unknown"
            return self.repo.active_branch.name
        except Exception as e:
            logger.error(f"Branch detection failed: {e}")
            return "unknown"

class FileWatcher(FileSystemEventHandler):
    """Watches for file system changes in the project"""
    
    def __init__(self, codebase_companion):
        self.codebase_companion = codebase_companion
        self.processing_queue = asyncio.Queue()
        
    def on_modified(self, event):
        if not event.is_directory:
            file_path = event.src_path
            if self._should_process_file(file_path):
                asyncio.create_task(self.codebase_companion.update_file_analysis(file_path))
    
    def on_created(self, event):
        if not event.is_directory:
            file_path = event.src_path
            if self._should_process_file(file_path):
                asyncio.create_task(self.codebase_companion.analyze_new_file(file_path))
    
    def _should_process_file(self, file_path: str) -> bool:
        """Check if file should be processed"""
        exclude_patterns = [
            '.git/', '__pycache__/', 'node_modules/', '.vscode/',
            '.pyc', '.log', '.tmp'
        ]
        
        for pattern in exclude_patterns:
            if pattern in file_path:
                return False
        
        # Check if it's a code file
        file_ext = Path(file_path).suffix
        return file_ext in ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.go', '.rs', '.php']

class CodebaseCompanion:
    """Main codebase companion system"""
    
    def __init__(self, project_path: str, config: Dict[str, Any]):
        self.project_path = project_path
        self.config = config
        self.session_factory = None
        
        # Initialize components
        self.code_analyzer = CodeAnalyzer()
        self.embedding_manager = EmbeddingManager(project_path)
        self.git_integration = GitIntegration(project_path)
        
        # AI components
        self.llm = ChatOpenAI(model_name="gpt-4-turbo", temperature=0.2)
        
        # File watcher
        self.file_watcher = FileWatcher(self)
        self.observer = Observer()
        
        # Session management
        self.current_session = None
        self.context_cache = {}
        
        # Query processing
        self.query_processor = QueryProcessor(self)
    
    async def initialize(self):
        """Initialize the codebase companion"""
        try:
            # Initialize database
            engine = create_async_engine(self.config['database_url'])
            self.session_factory = sessionmaker(
                engine, class_=AsyncSession, expire_on_commit=False
            )
            
            # Create tables
            async with engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
            
            # Start file watching
            self.observer.schedule(self.file_watcher, self.project_path, recursive=True)
            self.observer.start()
            
            # Initial project analysis
            await self.analyze_project()
            
            logger.info(f"Codebase Companion initialized for {self.project_path}")
            
        except Exception as e:
            logger.error(f"Initialization failed: {e}")
            raise
    
    async def analyze_project(self):
        """Perform initial project analysis"""
        try:
            logger.info("Starting project analysis...")
            
            # Find all code files
            code_files = []
            for root, dirs, files in os.walk(self.project_path):
                # Skip certain directories
                dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
                
                for file in files:
                    file_path = os.path.join(root, file)
                    if self._is_code_file(file_path):
                        code_files.append(file_path)
            
            logger.info(f"Found {len(code_files)} code files")
            
            # Analyze files in batches
            batch_size = 10
            for i in range(0, len(code_files), batch_size):
                batch = code_files[i:i + batch_size]
                await self._analyze_file_batch(batch)
                logger.info(f"Analyzed {min(i + batch_size, len(code_files))}/{len(code_files)} files")
            
            # Store project context
            await self._store_project_context()
            
            logger.info("Project analysis completed")
            
        except Exception as e:
            logger.error(f"Project analysis failed: {e}")
    
    def _is_code_file(self, file_path: str) -> bool:
        """Check if file is a code file"""
        code_extensions = ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.go', '.rs', '.php']
        return Path(file_path).suffix in code_extensions
    
    async def _analyze_file_batch(self, file_paths: List[str]):
        """Analyze a batch of files"""
        tasks = []
        for file_path in file_paths:
            tasks.append(self.analyze_file(file_path))
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def analyze_file(self, file_path: str):
        """Analyze a single file"""
        try:
            # Analyze code structure
            analysis = await self.code_analyzer.analyze_file(file_path)
            if not analysis:
                return
            
            # Read file content
            async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                content = await file.read()
            
            # Create embeddings
            await self.embedding_manager.create_code_embeddings(analysis, content)
            
            # Store in database
            await self._store_file_analysis(analysis, content)
            
        except Exception as e:
            logger.error(f"File analysis failed for {file_path}: {e}")
    
    async def _store_file_analysis(self, analysis: CodeAnalysis, content: str):
        """Store file analysis in database"""
        try:
            file_hash = hashlib.md5(content.encode()).hexdigest()
            
            async with self.session_factory() as session:
                # Check if file already exists
                result = await session.execute(
                    "SELECT file_hash FROM code_files WHERE file_path = ?",
                    (analysis.file_path,)
                )
                existing = result.fetchone()
                
                if existing and existing[0] == file_hash:
                    return  # File hasn't changed
                
                # Store or update file
                code_file = CodeFile(
                    id=str(uuid.uuid4()),
                    file_path=analysis.file_path,
                    file_hash=file_hash,
                    language=analysis.language,
                    content=content[:10000],  # Store first 10K chars
                    functions=[f.__dict__ if hasattr(f, '__dict__') else f for f in analysis.functions],
                    classes=[c.__dict__ if hasattr(c, '__dict__') else c for c in analysis.classes],
                    imports=analysis.imports,
                    embedding_updated=datetime.utcnow()
                )
                
                if existing:
                    await session.execute(
                        "DELETE FROM code_files WHERE file_path = ?",
                        (analysis.file_path,)
                    )
                
                session.add(code_file)
                await session.commit()
                
        except Exception as e:
            logger.error(f"File storage failed: {e}")
    
    async def _store_project_context(self):
        """Store project-level context"""
        try:
            # Detect technologies and frameworks
            technologies = await self._detect_technologies()
            
            # Get project structure summary
            structure_summary = await self._generate_structure_summary()
            
            async with self.session_factory() as session:
                project_context = ProjectContext(
                    id=str(uuid.uuid4()),
                    project_path=self.project_path,
                    project_name=Path(self.project_path).name,
                    technologies=technologies,
                    structure_summary=structure_summary
                )
                session.add(project_context)
                await session.commit()
                
        except Exception as e:
            logger.error(f"Project context storage failed: {e}")
    
    async def _detect_technologies(self) -> List[str]:
        """Detect technologies used in project"""
        technologies = []
        
        # Check for common files
        tech_indicators = {
            'package.json': 'Node.js',
            'requirements.txt': 'Python',
            'pom.xml': 'Java/Maven',
            'build.gradle': 'Java/Gradle',
            'Cargo.toml': 'Rust',
            'go.mod': 'Go',
            'composer.json': 'PHP'
        }
        
        for file_name, tech in tech_indicators.items():
            if os.path.exists(os.path.join(self.project_path, file_name)):
                technologies.append(tech)
        
        return technologies
    
    async def _generate_structure_summary(self) -> str:
        """Generate project structure summary"""
        try:
            structure_info = []
            
            # Count files by type
            file_counts = {}
            for root, dirs, files in os.walk(self.project_path):
                for file in files:
                    ext = Path(file).suffix
                    file_counts[ext] = file_counts.get(ext, 0) + 1
            
            # Top file types
            top_types = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            structure_info.extend([f"{ext}: {count} files" for ext, count in top_types])
            
            return " | ".join(structure_info)
            
        except Exception as e:
            logger.error(f"Structure summary generation failed: {e}")
            return "Structure analysis failed"
    
    async def start_session(self) -> str:
        """Start a new developer session"""
        try:
            session_id = str(uuid.uuid4())
            
            async with self.session_factory() as session:
                dev_session = DeveloperSession(
                    id=session_id,
                    active_files=[],
                    queries=[],
                    context_data={}
                )
                session.add(dev_session)
                await session.commit()
            
            self.current_session = session_id
            return session_id
            
        except Exception as e:
            logger.error(f"Session start failed: {e}")
            return ""

class QueryProcessor:
    """Processes developer queries and provides intelligent responses"""
    
    def __init__(self, codebase_companion):
        self.companion = codebase_companion
        self.llm = ChatOpenAI(model_name="gpt-4-turbo", temperature=0.3)
        
        # Query templates
        self.query_templates = {
            "code_explanation": PromptTemplate(
                input_variables=["code", "context", "question"],
                template="""
                You are an expert code assistant. Explain this code in detail:
                
                Code:
                {code}
                
                Project Context:
                {context}
                
                Specific Question:
                {question}
                
                Provide a clear, comprehensive explanation focusing on:
                1. What the code does
                2. How it works
                3. Key design patterns or techniques used
                4. Potential improvements or concerns
                """
            ),
            "debugging_help": PromptTemplate(
                input_variables=["code", "error", "context"],
                template="""
                Help debug this code issue:
                
                Code:
                {code}
                
                Error/Issue:
                {error}
                
                Project Context:
                {context}
                
                Provide:
                1. Likely cause of the issue
                2. Step-by-step debugging approach
                3. Potential solutions
                4. Prevention strategies
                """
            ),
            "code_improvement": PromptTemplate(
                input_variables=["code", "context", "goals"],
                template="""
                Suggest improvements for this code:
                
                Code:
                {code}
                
                Project Context:
                {context}
                
                Improvement Goals:
                {goals}
                
                Provide:
                1. Code quality assessment
                2. Specific improvement suggestions
                3. Best practices recommendations
                4. Performance optimizations
                """
            )
        }
    
    async def process_query(self, query: DeveloperQuery) -> Dict[str, Any]:
        """Process a developer query and return comprehensive response"""
        try:
            # Determine query type
            query_type = self._classify_query(query.query_text)
            
            # Get relevant context
            context_docs = await self._get_query_context(query)
            
            # Generate response based on query type
            if query_type == "code_explanation":
                response = await self._handle_code_explanation(query, context_docs)
            elif query_type == "debugging_help":
                response = await self._handle_debugging_query(query, context_docs)
            elif query_type == "code_improvement":
                response = await self._handle_improvement_query(query, context_docs)
            else:
                response = await self._handle_general_query(query, context_docs)
            
            # Store interaction
            await self._store_interaction(query, response)
            
            return {
                "query_id": query.query_id,
                "response": response,
                "context_used": len(context_docs),
                "query_type": query_type
            }
            
        except Exception as e:
            logger.error(f"Query processing failed: {e}")
            return {"error": str(e)}
    
    def _classify_query(self, query_text: str) -> str:
        """Classify the type of developer query"""
        query_lower = query_text.lower()
        
        if any(word in query_lower for word in ["explain", "what does", "how does", "understand"]):
            return "code_explanation"
        elif any(word in query_lower for word in ["error", "bug", "debug", "fix", "problem"]):
            return "debugging_help"
        elif any(word in query_lower for word in ["improve", "optimize", "better", "refactor"]):
            return "code_improvement"
        else:
            return "general"
    
    async def _get_query_context(self, query: DeveloperQuery) -> List[Document]:
        """Get relevant context for the query"""
        try:
            # Search for similar code
            similar_docs = await self.companion.embedding_manager.search_similar_code(
                query.query_text, k=5, file_filters=query.context_files
            )
            
            # Get context from active files
            context_docs = similar_docs
            
            for file_path in query.context_files:
                file_docs = await self.companion.embedding_manager.get_file_context(file_path)
                context_docs.extend(file_docs[:2])  # Limit to 2 chunks per file
            
            return context_docs[:8]  # Limit total context
            
        except Exception as e:
            logger.error(f"Context retrieval failed: {e}")
            return []
    
    async def _handle_code_explanation(self, query: DeveloperQuery, 
                                     context_docs: List[Document]) -> str:
        """Handle code explanation queries"""
        try:
            # Combine context
            context_text = "\n\n".join([doc.page_content for doc in context_docs])
            
            # Get template
            template = self.query_templates["code_explanation"]
            
            # Format prompt
            prompt = template.format(
                code=context_text[:2000],  # Limit context size
                context=f"Project: {Path(self.companion.project_path).name}",
                question=query.query_text
            )
            
            # Generate response
            response = await self.llm.apredict(prompt)
            return response
            
        except Exception as e:
            logger.error(f"Code explanation failed: {e}")
            return "I apologize, but I encountered an error while analyzing the code."
    
    async def _handle_debugging_query(self, query: DeveloperQuery, 
                                    context_docs: List[Document]) -> str:
        """Handle debugging queries"""
        try:
            context_text = "\n\n".join([doc.page_content for doc in context_docs])
            
            template = self.query_templates["debugging_help"]
            prompt = template.format(
                code=context_text[:2000],
                error=query.query_text,
                context=f"Project: {Path(self.companion.project_path).name}"
            )
            
            response = await self.llm.apredict(prompt)
            return response
            
        except Exception as e:
            logger.error(f"Debugging help failed: {e}")
            return "I apologize, but I encountered an error while analyzing the debugging request."
    
    async def _handle_improvement_query(self, query: DeveloperQuery, 
                                      context_docs: List[Document]) -> str:
        """Handle code improvement queries"""
        try:
            context_text = "\n\n".join([doc.page_content for doc in context_docs])
            
            template = self.query_templates["code_improvement"]
            prompt = template.format(
                code=context_text[:2000],
                context=f"Project: {Path(self.companion.project_path).name}",
                goals=query.query_text
            )
            
            response = await self.llm.apredict(prompt)
            return response
            
        except Exception as e:
            logger.error(f"Code improvement failed: {e}")
            return "I apologize, but I encountered an error while analyzing the improvement request."
    
    async def _handle_general_query(self, query: DeveloperQuery, 
                                  context_docs: List[Document]) -> str:
        """Handle general queries"""
        try:
            context_text = "\n\n".join([doc.page_content for doc in context_docs])
            
            prompt = f"""
            You are a helpful coding assistant. Answer this question about the codebase:
            
            Question: {query.query_text}
            
            Relevant Code Context:
            {context_text[:3000]}
            
            Provide a helpful, accurate response based on the code context.
            """
            
            response = await self.llm.apredict(prompt)
            return response
            
        except Exception as e:
            logger.error(f"General query failed: {e}")
            return "I apologize, but I encountered an error while processing your query."
    
    async def _store_interaction(self, query: DeveloperQuery, response: str):
        """Store query-response interaction"""
        try:
            async with self.companion.session_factory() as session:
                interaction = CodeInteraction(
                    id=str(uuid.uuid4()),
                    session_id=self.companion.current_session or "",
                    interaction_type=self._classify_query(query.query_text),
                    query_text=query.query_text,
                    response_text=response,
                    context_used={"files": query.context_files}
                )
                session.add(interaction)
                await session.commit()
                
        except Exception as e:
            logger.error(f"Interaction storage failed: {e}")

class CodebaseAPI:
    """FastAPI application for codebase companion"""
    
    def __init__(self, companion: CodebaseCompanion):
        self.app = FastAPI(title="Codebase Companion API")
        self.companion = companion
        self.active_connections: List[WebSocket] = []
        self.setup_middleware()
        self.setup_routes()
    
    def setup_middleware(self):
        """Setup CORS middleware"""
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def setup_routes(self):
        """Setup API routes"""
        
        @self.app.websocket("/ws")
        async def websocket_endpoint(websocket: WebSocket):
            await websocket.accept()
            self.active_connections.append(websocket)
            try:
                while True:
                    data = await websocket.receive_text()
                    query_data = json.loads(data)
                    
                    # Process query
                    query = DeveloperQuery(
                        query_id=str(uuid.uuid4()),
                        query_text=query_data.get("query", ""),
                        context_files=query_data.get("context_files", []),
                        query_type="websocket",
                        timestamp=datetime.now()
                    )
                    
                    response = await self.companion.query_processor.process_query(query)
                    await websocket.send_text(json.dumps(response))
                    
            except WebSocketDisconnect:
                self.active_connections.remove(websocket)
        
        @self.app.post("/query")
        async def process_query(query_data: Dict[str, Any]):
            try:
                query = DeveloperQuery(
                    query_id=str(uuid.uuid4()),
                    query_text=query_data.get("query", ""),
                    context_files=query_data.get("context_files", []),
                    query_type="api",
                    timestamp=datetime.now()
                )
                
                response = await self.companion.query_processor.process_query(query)
                return response
                
            except Exception as e:
                return {"error": str(e)}
        
        @self.app.get("/project/status")
        async def get_project_status():
            try:
                # Get Git information
                recent_changes = self.companion.git_integration.get_recent_changes(7)
                current_branch = self.companion.git_integration.get_current_branch()
                
                return {
                    "project_path": self.companion.project_path,
                    "current_branch": current_branch,
                    "recent_changes": len(recent_changes),
                    "session_active": self.companion.current_session is not None,
                    "last_analysis": datetime.now().isoformat()
                }
                
            except Exception as e:
                return {"error": str(e)}
        
        @self.app.get("/files/{file_path:path}/analysis")
        async def get_file_analysis(file_path: str):
            try:
                full_path = os.path.join(self.companion.project_path, file_path)
                analysis = await self.companion.code_analyzer.analyze_file(full_path)
                
                if analysis:
                    return {
                        "file_path": analysis.file_path,
                        "language": analysis.language,
                        "functions": analysis.functions,
                        "classes": analysis.classes,
                        "imports": analysis.imports,
                        "complexity_score": analysis.complexity_score,
                        "documentation_coverage": analysis.documentation_coverage
                    }
                else:
                    return {"error": "Analysis failed"}
                    
            except Exception as e:
                return {"error": str(e)}
        
        @self.app.get("/dashboard")
        async def get_dashboard():
            return {
                "system_status": "operational",
                "features": [
                    "Intelligent Code Analysis",
                    "Semantic Code Search",
                    "Context-Aware Q&A",
                    "Git Integration",
                    "Real-time File Watching",
                    "VS Code Integration Ready"
                ],
                "capabilities": [
                    "Multi-language Support",
                    "Vector-based Code Search",
                    "AI-powered Code Explanation",
                    "Project Context Tracking",
                    "Development Session Management"
                ]
            }

async def demo():
    """Demonstration of the Codebase Companion"""
    
    print("💻 Codebase Companion for Developers Demo\n")
    
    # Use current directory as project path
    project_path = os.getcwd()
    
    config = {
        'database_url': 'sqlite+aiosqlite:///./codebase_companion.db'
    }
    
    try:
        # Initialize codebase companion
        companion = CodebaseCompanion(project_path, config)
        await companion.initialize()
        
        print("✅ Codebase Companion initialized")
        print(f"📁 Project Path: {project_path}")
        print(f"🌿 Git Branch: {companion.git_integration.get_current_branch()}")
        print("✅ File watcher started")
        print("✅ Embedding system ready")
        print("✅ AI query processor active")
        
        # Start session
        session_id = await companion.start_session()
        print(f"🎯 Developer session started: {session_id[:8]}")
        
        # Demo queries
        demo_queries = [
            {
                "query": "Explain how the CodeAnalyzer class works",
                "context_files": [__file__]
            },
            {
                "query": "How can I improve the error handling in this code?",
                "context_files": [__file__]
            },
            {
                "query": "What design patterns are used in this codebase?",
                "context_files": [__file__]
            }
        ]
        
        print(f"\n🤖 Processing Demo Queries...")
        
        for i, query_data in enumerate(demo_queries, 1):
            print(f"\n📝 Query {i}: {query_data['query']}")
            
            query = DeveloperQuery(
                query_id=str(uuid.uuid4()),
                query_text=query_data["query"],
                context_files=query_data["context_files"],
                query_type="demo",
                timestamp=datetime.now()
            )
            
            response = await companion.query_processor.process_query(query)
            
            if "error" not in response:
                print(f"✅ Response generated (Type: {response.get('query_type', 'unknown')})")
                print(f"📊 Context used: {response.get('context_used', 0)} documents")
                print(f"💬 Response preview: {response['response'][:150]}...")
            else:
                print(f"❌ Query failed: {response['error']}")
        
        # Show Git integration
        print(f"\n📜 Recent Git Activity:")
        recent_changes = companion.git_integration.get_recent_changes(7)
        for change in recent_changes[:3]:
            print(f"  📝 {change['hash'][:8]} - {change['message'][:50]}...")
            print(f"     👤 {change['author']} - {change['date'].strftime('%Y-%m-%d %H:%M')}")
        
        # Show project analysis
        print(f"\n📊 Project Analysis:")
        print(f"  🏗️ Architecture: Multi-component AI system")
        print(f"  🔧 Technologies: Python, FastAPI, LangChain, Vector DB")
        print(f"  📦 Components: Code Analyzer, Embedding Manager, Query Processor")
        print(f"  🎯 Features: Real-time analysis, semantic search, AI assistance")
        
        # Initialize API
        print(f"\n🌐 Setting up Codebase API...")
        api = CodebaseAPI(companion)
        print(f"✅ API configured with developer endpoints")
        
        print(f"\n🚀 To start the Codebase API:")
        print(f"   uvicorn main:api.app --host 0.0.0.0 --port 8000")
        print(f"   Dashboard: http://localhost:8000/dashboard")
        print(f"   WebSocket: ws://localhost:8000/ws")
        print(f"   API Docs: http://localhost:8000/docs")
        
        print(f"\n🛠️ System Capabilities:")
        print(f"  ✅ Intelligent Code Analysis")
        print(f"  ✅ Semantic Code Search")
        print(f"  ✅ Context-Aware Q&A")
        print(f"  ✅ Real-time File Monitoring")
        print(f"  ✅ Git History Integration")
        print(f"  ✅ Multi-language Support")
        print(f"  ✅ VS Code Plugin Ready")
        print(f"  ✅ Developer Session Tracking")
        
        print(f"\n💡 Developer Use Cases:")
        print(f"  • Code exploration and understanding")
        print(f"  • Debugging assistance and error analysis")
        print(f"  • Code improvement suggestions")
        print(f"  • Architecture documentation")
        print(f"  • Onboarding new team members")
        print(f"  • Code review automation")
        print(f"  • Technical debt identification")
        
        print(f"\n💻 Codebase Companion demo completed!")
        
    except Exception as e:
        print(f"❌ Demo error: {e}")
        logger.error(f"Demo failed: {e}")

# Dependencies information
dependencies_info = """
# Install required dependencies:
pip install fastapi uvicorn websockets
pip install sqlalchemy aiosqlite
pip install langchain openai
pip install chromadb faiss-cpu
pip install watchdog
pip install GitPython
pip install aiofiles
pip install tree-sitter
pip install pygments
pip install pandas numpy

# Environment variables:
export OPENAI_API_KEY="your-openai-api-key"
export DATABASE_URL="sqlite+aiosqlite:///./codebase_companion.db"

# For VS Code extension development:
npm install -g yo generator-code
npm install vscode-languageclient

# Tree-sitter language grammars (optional):
# Download and build language grammars for advanced parsing
# git clone https://github.com/tree-sitter/tree-sitter-python
# git clone https://github.com/tree-sitter/tree-sitter-javascript

# VS Code Extension manifest (package.json):
{
  "name": "codebase-companion",
  "displayName": "Codebase Companion",
  "description": "AI-powered coding assistant",
  "version": "1.0.0",
  "engines": {"vscode": "^1.60.0"},
  "categories": ["Other"],
  "activationEvents": ["*"],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "codebaseCompanion.askQuestion",
        "title": "Ask Codebase Question"
      }
    ]
  }
}

# Optional integrations:
pip install docker  # For containerized analysis
pip install kubernetes  # For cluster deployment
pip install prometheus-client  # For metrics
"""

if __name__ == "__main__":
    print(dependencies_info)
    asyncio.run(demo())
````

## Project Summary

The Codebase Companion for Developers represents a revolutionary AI-enhanced development platform that transforms software development workflows through intelligent code analysis, contextual understanding, and seamless IDE integration. This system addresses critical developer productivity challenges by providing sophisticated AI-powered assistance that understands project context, tracks development patterns, and offers intelligent support throughout the software development lifecycle.

### Key Value Propositions

1. **Intelligent Code Understanding**: Advanced semantic analysis of codebases using state-of-the-art embedding techniques that understand code structure, dependencies, and architectural patterns across multiple programming languages and frameworks.

2. **Contextual Development Assistance**: Sophisticated AI-powered assistance that maintains awareness of developer context, project history, and coding patterns to provide personalized, relevant guidance and suggestions.

3. **Seamless IDE Integration**: Native VS Code integration that captures real-time developer activity and provides unobtrusive, contextually aware assistance directly within the development environment.

4. **Comprehensive Knowledge Management**: Advanced retrieval system that combines local codebase knowledge with external documentation and best practices to provide comprehensive development support.

### Key Takeaways

- **Accelerated Development Velocity**: Dramatically reduces time spent on code exploration, debugging, and documentation by providing instant, intelligent access to codebase knowledge and development insights
- **Enhanced Code Quality**: Improves code quality through intelligent suggestions, pattern recognition, and best practice recommendations based on project-specific context and industry standards
- **Democratized Expertise**: Makes senior-level development knowledge accessible to all team members, accelerating onboarding and reducing knowledge gaps across development teams
- **Continuous Learning Architecture**: Evolves with development patterns and project growth, becoming more intelligent and valuable over time through continuous learning and adaptation

This Codebase Companion empowers development teams by combining the precision of AI-powered code analysis with deep understanding of software development workflows, enabling faster development cycles, improved code quality, and enhanced collaboration while maintaining the highest standards of development excellence and team productivity.