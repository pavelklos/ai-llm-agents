<small>Claude Sonnet 4 **(Enterprise Knowledge Base Chatbot s RAG)**</small>
# Enterprise Knowledge Base Chatbot

## 1. Kl√≠ƒçov√© Koncepty

### RAG (Retrieval-Augmented Generation)
**RAG** je technika kombinuj√≠c√≠ vyhled√°v√°n√≠ relevantn√≠ch informac√≠ s generov√°n√≠m odpovƒõd√≠ pomoc√≠ jazykov√Ωch model≈Ø. M√≠sto spol√©h√°n√≠ pouze na p≈ôedtr√©novan√° data model p≈ôistupuje k extern√≠ datab√°zi znalost√≠.

### Confluence Integration
**Confluence** je podnikov√Ω syst√©m pro spr√°vu dokumentace. Integrace umo≈æ≈àuje automatick√© naƒç√≠t√°n√≠ a indexov√°n√≠ firemn√≠ch dokument≈Ø, wiki str√°nek a znalost√≠.

### Vector Database (Pinecone)
**Pinecone** je cloudov√° vektorov√° datab√°ze optimalizovan√° pro s√©mantick√© vyhled√°v√°n√≠. Ukl√°d√° embeddings dokument≈Ø a umo≈æ≈àuje rychl√© vyhled√°v√°n√≠ podobn√Ωch text≈Ø.

### Azure OpenAI
**Azure OpenAI** poskytuje p≈ô√≠stup k pokroƒçil√Ωm jazykov√Ωm model≈Øm (GPT-4, GPT-3.5) prost≈ôednictv√≠m Microsoft Azure cloudu s enterprise zabezpeƒçen√≠m.

### Slack Bot API
**Slack Bot API** umo≈æ≈àuje vytvo≈ôen√≠ chatbot≈Ø integrovan√Ωch p≈ô√≠mo do Slack workspace, kde mohou zamƒõstnanci pokl√°dat ot√°zky a dost√°vat odpovƒõdi.

## 2. Komplexn√≠ Vysvƒõtlen√≠ Projektu

### C√≠le Projektu
Projekt vytv√°≈ô√≠ inteligentn√≠ho chatbota, kter√Ω slou≈æ√≠ jako centr√°ln√≠ bod pro p≈ô√≠stup k firemn√≠m znalostem. Zamƒõstnanci mohou pokl√°dat ot√°zky v p≈ôirozen√©m jazyce a dost√°vat p≈ôesn√© odpovƒõdi zalo≈æen√© na intern√≠ dokumentaci.

### V√Ωzvy
- **Integrace heterogenn√≠ch zdroj≈Ø dat** - Confluence, SharePoint, PDF dokumenty
- **Udr≈æov√°n√≠ aktu√°lnosti** - Automatick√° synchronizace p≈ôi zmƒõn√°ch dokument≈Ø
- **Relevance odpovƒõd√≠** - Zaji≈°tƒõn√≠, ≈æe bot najde spr√°vn√© informace
- **Bezpeƒçnost** - Respektov√°n√≠ p≈ô√≠stupov√Ωch pr√°v a citliv√Ωch informac√≠
- **≈†k√°lovatelnost** - Podpora tis√≠c≈Ø u≈æivatel≈Ø souƒçasnƒõ

### Potenci√°ln√≠ Dopad
- **Zv√Ω≈°en√≠ produktivity** - Rychl√Ω p≈ô√≠stup k informac√≠m bez proch√°zen√≠ dokument≈Ø
- **Sn√≠≈æen√≠ z√°tƒõ≈æe IT podpory** - Automatizace ƒçast√Ωch dotaz≈Ø
- **Lep≈°√≠ onboarding** - Nov√© zamƒõstnance mohou snadno naj√≠t pot≈ôebn√© informace
- **Konzistence odpovƒõd√≠** - Jednotn√© informace nap≈ô√≠ƒç organizac√≠

## 3. Komplexn√≠ Implementace s Pythonem

### Po≈æadovan√© Z√°vislosti

````python
fastapi==0.104.1
uvicorn==0.24.0
langchain==0.1.0
langchain-openai==0.0.5
pinecone-client==3.0.0
slack-bolt==1.18.1
python-multipart==0.0.6
pydantic==2.5.0
python-dotenv==1.0.0
requests==2.31.0
beautifulsoup4==4.12.2
pypdf2==3.0.1
schedule==1.2.0
redis==5.0.1
loguru==0.7.2
````

### Konfigurace a Prost≈ôed√≠

````python
import os
from pydantic import BaseSettings
from typing import List

class Settings(BaseSettings):
    # Azure OpenAI konfigurace
    azure_openai_api_key: str
    azure_openai_endpoint: str
    azure_openai_deployment: str = "gpt-4"
    azure_openai_api_version: str = "2024-02-01"
    
    # Pinecone konfigurace
    pinecone_api_key: str
    pinecone_environment: str
    pinecone_index_name: str = "enterprise-kb"
    
    # Slack konfigurace
    slack_bot_token: str
    slack_signing_secret: str
    slack_app_token: str
    
    # Confluence konfigurace
    confluence_url: str
    confluence_username: str
    confluence_api_token: str
    confluence_spaces: List[str] = ["IT", "HR", "DEV"]
    
    # Redis konfigurace
    redis_url: str = "redis://localhost:6379"
    
    # Obecn√© nastaven√≠
    embedding_dimension: int = 1536
    max_chunk_size: int = 1000
    chunk_overlap: int = 100
    
    class Config:
        env_file = ".env"

settings = Settings()
````

### Spr√°vce Dokument≈Ø a Embeddings

````python
import asyncio
import hashlib
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import PyPDF2
from io import BytesIO

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings
from langchain.schema import Document
import pinecone
import redis
from loguru import logger

from config import settings

@dataclass
class DocumentMetadata:
    source: str
    title: str
    url: str
    last_updated: datetime
    content_hash: str
    space: Optional[str] = None
    author: Optional[str] = None

class DocumentManager:
    def __init__(self):
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment="text-embedding-ada-002",
            azure_endpoint=settings.azure_openai_endpoint,
            api_key=settings.azure_openai_api_key,
            api_version=settings.azure_openai_api_version
        )
        
        # Inicializace Pinecone
        pinecone.init(
            api_key=settings.pinecone_api_key,
            environment=settings.pinecone_environment
        )
        
        self.index = pinecone.Index(settings.pinecone_index_name)
        self.redis_client = redis.from_url(settings.redis_url)
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=settings.max_chunk_size,
            chunk_overlap=settings.chunk_overlap,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def _calculate_content_hash(self, content: str) -> str:
        """Vypoƒç√≠t√° hash obsahu pro detekci zmƒõn."""
        return hashlib.md5(content.encode()).hexdigest()
    
    async def fetch_confluence_pages(self, space_key: str) -> List[Dict[str, Any]]:
        """Naƒçte str√°nky z Confluence prostoru."""
        try:
            auth = (settings.confluence_username, settings.confluence_api_token)
            base_url = f"{settings.confluence_url}/rest/api/content"
            
            params = {
                'spaceKey': space_key,
                'expand': 'body.storage,version,space,history.lastUpdated',
                'limit': 100
            }
            
            response = requests.get(base_url, auth=auth, params=params)
            response.raise_for_status()
            
            data = response.json()
            pages = []
            
            for page in data['results']:
                content = BeautifulSoup(
                    page['body']['storage']['value'], 
                    'html.parser'
                ).get_text()
                
                pages.append({
                    'id': page['id'],
                    'title': page['title'],
                    'content': content,
                    'url': f"{settings.confluence_url}/pages/viewpage.action?pageId={page['id']}",
                    'space': page['space']['name'],
                    'last_updated': datetime.fromisoformat(
                        page['history']['lastUpdated']['when'].replace('Z', '+00:00')
                    ),
                    'author': page['history']['lastUpdated']['by']['displayName']
                })
            
            return pages
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ Confluence: {e}")
            return []
    
    async def process_document(self, content: str, metadata: DocumentMetadata) -> List[str]:
        """Zpracuje dokument na chunky a vytvo≈ô√≠ embeddings."""
        try:
            # Kontrola, zda se dokument zmƒõnil
            cached_hash = self.redis_client.get(f"doc_hash:{metadata.url}")
            if cached_hash and cached_hash.decode() == metadata.content_hash:
                logger.info(f"Dokument {metadata.title} nebyl zmƒõnƒõn, p≈ôeskakuji.")
                return []
            
            # Rozdƒõlen√≠ na chunky
            documents = [Document(
                page_content=content,
                metadata={
                    "source": metadata.source,
                    "title": metadata.title,
                    "url": metadata.url,
                    "space": metadata.space,
                    "author": metadata.author,
                    "last_updated": metadata.last_updated.isoformat()
                }
            )]
            
            chunks = self.text_splitter.split_documents(documents)
            
            # Generov√°n√≠ embeddings
            chunk_ids = []
            for i, chunk in enumerate(chunks):
                chunk_id = f"{metadata.url}#{i}"
                
                embedding = await self.embeddings.aembed_query(chunk.page_content)
                
                # Ulo≈æen√≠ do Pinecone
                self.index.upsert([{
                    'id': chunk_id,
                    'values': embedding,
                    'metadata': {
                        **chunk.metadata,
                        'text': chunk.page_content,
                        'chunk_index': i
                    }
                }])
                
                chunk_ids.append(chunk_id)
            
            # Ulo≈æen√≠ hash do cache
            self.redis_client.set(
                f"doc_hash:{metadata.url}", 
                metadata.content_hash,
                ex=86400  # 24 hodin
            )
            
            logger.info(f"Zpracov√°n dokument {metadata.title}: {len(chunks)} chunk≈Ø")
            return chunk_ids
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ dokumentu {metadata.title}: {e}")
            return []
    
    async def sync_confluence_space(self, space_key: str):
        """Synchronizuje jeden Confluence prostor."""
        pages = await self.fetch_confluence_pages(space_key)
        
        for page in pages:
            metadata = DocumentMetadata(
                source="confluence",
                title=page['title'],
                url=page['url'],
                last_updated=page['last_updated'],
                content_hash=self._calculate_content_hash(page['content']),
                space=page['space'],
                author=page['author']
            )
            
            await self.process_document(page['content'], metadata)
    
    async def sync_all_spaces(self):
        """Synchronizuje v≈°echny nakonfigurovan√© Confluence prostory."""
        logger.info("Zah√°jen√≠ synchronizace Confluence prostor≈Ø")
        
        tasks = []
        for space in settings.confluence_spaces:
            tasks.append(self.sync_confluence_space(space))
        
        await asyncio.gather(*tasks)
        logger.info("Synchronizace dokonƒçena")
    
    async def search_similar_documents(
        self, 
        query: str, 
        top_k: int = 5,
        filter_dict: Optional[Dict] = None
    ) -> List[Dict[str, Any]]:
        """Vyhled√° podobn√© dokumenty pro dan√Ω dotaz."""
        try:
            # Generov√°n√≠ embedding pro dotaz
            query_embedding = await self.embeddings.aembed_query(query)
            
            # Vyhled√°n√≠ v Pinecone
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter=filter_dict
            )
            
            documents = []
            for match in results['matches']:
                documents.append({
                    'content': match['metadata']['text'],
                    'title': match['metadata']['title'],
                    'url': match['metadata']['url'],
                    'source': match['metadata']['source'],
                    'space': match['metadata'].get('space'),
                    'score': match['score'],
                    'last_updated': match['metadata']['last_updated']
                })
            
            return documents
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            return []
````

### RAG Syst√©m s LangChain

````python
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import PromptTemplate
from loguru import logger

from document_manager import DocumentManager
from config import settings

class RAGSystem:
    def __init__(self):
        self.document_manager = DocumentManager()
        
        self.llm = AzureChatOpenAI(
            azure_deployment=settings.azure_openai_deployment,
            azure_endpoint=settings.azure_openai_endpoint,
            api_key=settings.azure_openai_api_key,
            api_version=settings.azure_openai_api_version,
            temperature=0.1,
            max_tokens=1000
        )
        
        self.system_prompt = """Jsi u≈æiteƒçn√Ω asistent pro firemn√≠ znalostn√≠ b√°zi. Tv√Ωm √∫kolem je odpov√≠dat na ot√°zky zamƒõstnanc≈Ø na z√°kladƒõ poskytnut√Ωch dokument≈Ø.

INSTRUKCE:
1. Odpov√≠dej pouze na z√°kladƒõ poskytnut√Ωch dokument≈Ø
2. Pokud informace nen√≠ v dokumentech, ≈ôekni to otev≈ôenƒõ
3. Uveƒè zdroje informac√≠ (title a URL)
4. Odpov√≠dej v ƒçe≈°tinƒõ
5. Buƒè p≈ôesn√Ω a konkr√©tn√≠
6. Pokud je ot√°zka nejasn√°, po≈æ√°dej o up≈ôesnƒõn√≠

FORM√ÅT ODPOVƒöDI:
- Hlavn√≠ odpovƒõƒè
- Zdroje: [Title](URL)
"""

    async def generate_answer(
        self, 
        question: str, 
        context_documents: List[Dict[str, Any]],
        user_info: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Generuje odpovƒõƒè na z√°kladƒõ kontextov√Ωch dokument≈Ø."""
        try:
            # P≈ô√≠prava kontextu
            context = self._prepare_context(context_documents)
            
            # Vytvo≈ôen√≠ promptu
            prompt = f"""KONTEXT:
{context}

OT√ÅZKA: {question}

Odpovƒõz na ot√°zku na z√°kladƒõ poskytnut√©ho kontextu."""

            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=prompt)
            ]
            
            # Generov√°n√≠ odpovƒõdi
            response = await self.llm.agenerate([messages])
            answer = response.generations[0][0].text
            
            # P≈ô√≠prava zdroj≈Ø
            sources = self._extract_sources(context_documents)
            
            return {
                "answer": answer,
                "sources": sources,
                "context_used": len(context_documents),
                "timestamp": datetime.now().isoformat(),
                "user_info": user_info
            }
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi generov√°n√≠ odpovƒõdi: {e}")
            return {
                "answer": "Omlouv√°m se, ale do≈°lo k chybƒõ p≈ôi zpracov√°n√≠ va≈°√≠ ot√°zky. Zkuste to pros√≠m pozdƒõji.",
                "sources": [],
                "context_used": 0,
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
    
    def _prepare_context(self, documents: List[Dict[str, Any]]) -> str:
        """P≈ôiprav√≠ kontext z dokument≈Ø."""
        context_parts = []
        
        for i, doc in enumerate(documents, 1):
            context_parts.append(f"""
DOKUMENT {i}:
N√°zev: {doc['title']}
Zdroj: {doc['source']} ({doc.get('space', 'N/A')})
Obsah: {doc['content']}
---""")
        
        return "\n".join(context_parts)
    
    def _extract_sources(self, documents: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """Extrahuje zdroje z dokument≈Ø."""
        sources = []
        seen_urls = set()
        
        for doc in documents:
            if doc['url'] not in seen_urls:
                sources.append({
                    "title": doc['title'],
                    "url": doc['url'],
                    "source": doc['source'],
                    "space": doc.get('space'),
                    "score": round(doc['score'], 3)
                })
                seen_urls.add(doc['url'])
        
        return sources
    
    async def answer_question(
        self, 
        question: str,
        filters: Optional[Dict] = None,
        user_info: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Hlavn√≠ metoda pro odpov√≠d√°n√≠ na ot√°zky."""
        logger.info(f"Zpracov√°v√°m ot√°zku: {question}")
        
        # Vyhled√°n√≠ relevantn√≠ch dokument≈Ø
        documents = await self.document_manager.search_similar_documents(
            query=question,
            top_k=5,
            filter_dict=filters
        )
        
        if not documents:
            return {
                "answer": "Omlouv√°m se, ale nena≈°el jsem ≈æ√°dn√© relevantn√≠ informace k va≈°√≠ ot√°zce. Zkuste p≈ôeformulovat dotaz nebo kontaktujte IT podporu.",
                "sources": [],
                "context_used": 0,
                "timestamp": datetime.now().isoformat()
            }
        
        # Generov√°n√≠ odpovƒõdi
        result = await self.generate_answer(question, documents, user_info)
        
        logger.info(f"Odpovƒõƒè vygenerov√°na s {len(documents)} zdroji")
        return result
    
    async def get_trending_questions(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Z√≠sk√° nejƒçastƒõj≈°√≠ ot√°zky (implementace s Redis)."""
        try:
            # Z√≠sk√°n√≠ nejƒçastƒõj≈°√≠ch ot√°zek z Redis
            trending = self.document_manager.redis_client.zrevrange(
                "trending_questions", 0, limit-1, withscores=True
            )
            
            return [
                {
                    "question": question.decode(),
                    "count": int(score)
                }
                for question, score in trending
            ]
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi z√≠sk√°v√°n√≠ trending ot√°zek: {e}")
            return []
    
    async def log_question(self, question: str, user_id: str = None):
        """Loguje ot√°zku pro anal√Ωzu trend≈Ø."""
        try:
            # Ulo≈æen√≠ do trending questions
            self.document_manager.redis_client.zincrby(
                "trending_questions", 1, question
            )
            
            # Logov√°n√≠ pro anal√Ωzu
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "user_id": user_id
            }
            
            self.document_manager.redis_client.lpush(
                "question_log", 
                json.dumps(log_entry)
            )
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi logov√°n√≠ ot√°zky: {e}")
````

### Slack Bot Integrace

````python
import asyncio
import json
from typing import Dict, Any
from datetime import datetime

from slack_bolt.async_app import AsyncApp
from slack_bolt.adapter.socket_mode.async_handler import AsyncSocketModeHandler
from loguru import logger

from rag_system import RAGSystem
from config import settings

class SlackBot:
    def __init__(self):
        self.app = AsyncApp(
            token=settings.slack_bot_token,
            signing_secret=settings.slack_signing_secret
        )
        
        self.rag_system = RAGSystem()
        
        # Registrace event handler≈Ø
        self._register_handlers()
    
    def _register_handlers(self):
        """Registruje v≈°echny event handlery."""
        
        @self.app.message(".*")
        async def handle_message(message, say, client):
            """Zpracov√°v√° v≈°echny zpr√°vy v DM nebo mentions."""
            await self._handle_question(message, say, client)
        
        @self.app.command("/ask-kb")
        async def handle_ask_command(ack, respond, command, client):
            """Slash command pro dotazy do znalostn√≠ b√°ze."""
            await ack()
            
            question = command['text'].strip()
            if not question:
                await respond("Pros√≠m zadejte ot√°zku. Nap≈ô: `/ask-kb Jak se p≈ôihl√°s√≠m do VPN?`")
                return
            
            user_info = await self._get_user_info(command['user_id'], client)
            await self._process_question(question, respond, user_info, command['channel_id'])
        
        @self.app.command("/kb-trending")
        async def handle_trending_command(ack, respond):
            """Zobraz√≠ nejƒçastƒõj≈°√≠ ot√°zky."""
            await ack()
            
            trending = await self.rag_system.get_trending_questions(10)
            
            if not trending:
                await respond("Zat√≠m nejsou k dispozici ≈æ√°dn√© trending ot√°zky.")
                return
            
            blocks = self._create_trending_blocks(trending)
            await respond(blocks=blocks)
        
        @self.app.event("app_mention")
        async def handle_mention(event, say, client):
            """Zpracov√°v√° mentions bota."""
            # Odstranƒõn√≠ mention z textu
            text = event['text']
            bot_user_id = await self._get_bot_user_id(client)
            question = text.replace(f'<@{bot_user_id}>', '').strip()
            
            if not question:
                await say("Ahoj! Zeptejte se mƒõ na cokoliv o firemn√≠ dokumentaci. üìö")
                return
            
            user_info = await self._get_user_info(event['user'], client)
            await self._process_question_mention(question, say, user_info, event)
    
    async def _handle_question(self, message, say, client):
        """Zpracov√°v√° obecn√© zpr√°vy."""
        # Pouze v DM nebo pokud je bot zm√≠nƒõn
        channel_type = message.get('channel_type')
        if channel_type != 'im':
            return
        
        question = message['text'].strip()
        user_info = await self._get_user_info(message['user'], client)
        
        await self._process_question_dm(question, say, user_info, message)
    
    async def _process_question(
        self, 
        question: str, 
        respond_func, 
        user_info: Dict,
        channel_id: str = None
    ):
        """Zpracuje ot√°zku a po≈°le odpovƒõƒè."""
        try:
            # Logov√°n√≠ ot√°zky
            await self.rag_system.log_question(question, user_info.get('id'))
            
            # Thinking zpr√°va
            thinking_message = await respond_func(
                text="ü§î Hled√°m odpovƒõƒè v dokumentaci...",
                response_type="in_channel"
            )
            
            # Z√≠sk√°n√≠ odpovƒõdi
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            # Vytvo≈ôen√≠ blok≈Ø pro odpovƒõƒè
            blocks = self._create_answer_blocks(result, question)
            
            # Aktualizace zpr√°vy
            await respond_func(
                blocks=blocks,
                response_type="in_channel",
                replace_original=True
            )
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ ot√°zky: {e}")
            await respond_func(
                text="üòî Omlouv√°m se, do≈°lo k chybƒõ. Zkuste to pros√≠m pozdƒõji.",
                response_type="ephemeral"
            )
    
    async def _process_question_mention(self, question: str, say, user_info: Dict, event):
        """Zpracuje ot√°zku z mention."""
        try:
            await self.rag_system.log_question(question, user_info.get('id'))
            
            # Thinking reakce
            thinking_msg = await say("ü§î Hled√°m odpovƒõƒè v dokumentaci...")
            
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            blocks = self._create_answer_blocks(result, question)
            
            # Aktualizace zpr√°vy
            await say(blocks=blocks, thread_ts=event.get('ts'))
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ mention: {e}")
            await say("üòî Omlouv√°m se, do≈°lo k chybƒõ. Zkuste to pros√≠m pozdƒõji.")
    
    async def _process_question_dm(self, question: str, say, user_info: Dict, message):
        """Zpracuje ot√°zku z DM."""
        try:
            await self.rag_system.log_question(question, user_info.get('id'))
            
            await say("ü§î Hled√°m odpovƒõƒè v dokumentaci...")
            
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            blocks = self._create_answer_blocks(result, question)
            await say(blocks=blocks)
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ DM: {e}")
            await say("üòî Omlouv√°m se, do≈°lo k chybƒõ. Zkuste to pros√≠m pozdƒõji.")
    
    def _create_answer_blocks(self, result: Dict[str, Any], question: str) -> list:
        """Vytvo≈ô√≠ Slack blocks pro odpovƒõƒè."""
        blocks = [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*Ot√°zka:* {question}"
                }
            },
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*Odpovƒõƒè:*\n{result['answer']}"
                }
            }
        ]
        
        # P≈ôid√°n√≠ zdroj≈Ø
        if result['sources']:
            sources_text = "*Zdroje:*\n"
            for source in result['sources']:
                sources_text += f"‚Ä¢ <{source['url']}|{source['title']}> "
                sources_text += f"({source['source']}"
                if source.get('space'):
                    sources_text += f" - {source['space']}"
                sources_text += f", relevance: {source['score']})\n"
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": sources_text
                }
            })
        
        # Footer s metadaty
        blocks.append({
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"Pou≈æito {result['context_used']} dokument≈Ø | {result['timestamp']}"
                }
            ]
        })
        
        return blocks
    
    def _create_trending_blocks(self, trending: list) -> list:
        """Vytvo≈ô√≠ bloky pro trending ot√°zky."""
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "üìà Nejƒçastƒõj≈°√≠ ot√°zky"
                }
            }
        ]
        
        for i, item in enumerate(trending, 1):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"{i}. {item['question']} _(dot√°z√°no {item['count']}x)_"
                }
            })
        
        return blocks
    
    async def _get_user_info(self, user_id: str, client) -> Dict:
        """Z√≠sk√° informace o u≈æivateli."""
        try:
            response = await client.users_info(user=user_id)
            user = response['user']
            
            return {
                'id': user_id,
                'name': user.get('real_name', user.get('name')),
                'email': user.get('profile', {}).get('email'),
                'team': user.get('profile', {}).get('team'),
                'title': user.get('profile', {}).get('title')
            }
        except Exception as e:
            logger.error(f"Chyba p≈ôi z√≠sk√°v√°n√≠ user info: {e}")
            return {'id': user_id}
    
    async def _get_bot_user_id(self, client) -> str:
        """Z√≠sk√° ID bota."""
        try:
            response = await client.auth_test()
            return response['user_id']
        except Exception as e:
            logger.error(f"Chyba p≈ôi z√≠sk√°v√°n√≠ bot ID: {e}")
            return ""
    
    async def start(self):
        """Spust√≠ Slack bota."""
        handler = AsyncSocketModeHandler(self.app, settings.slack_app_token)
        await handler.start_async()
````

### Hlavn√≠ Aplikace a Scheduler

````python
import asyncio
import schedule
import time
from threading import Thread
from datetime import datetime

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from loguru import logger

from slack_bot import SlackBot
from rag_system import RAGSystem
from document_manager import DocumentManager
from config import settings

# FastAPI aplikace
app = FastAPI(title="Enterprise Knowledge Base RAG", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Glob√°ln√≠ instance
rag_system = RAGSystem()
document_manager = DocumentManager()

class QuestionRequest(BaseModel):
    question: str
    filters: dict = None
    user_info: dict = None

class SyncRequest(BaseModel):
    spaces: list = None

@app.get("/")
async def root():
    return {"message": "Enterprise Knowledge Base RAG API", "version": "1.0.0"}

@app.post("/ask")
async def ask_question(request: QuestionRequest):
    """API endpoint pro dotazy."""
    try:
        result = await rag_system.answer_question(
            question=request.question,
            filters=request.filters,
            user_info=request.user_info
        )
        return result
    except Exception as e:
        logger.error(f"Chyba v /ask: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/trending")
async def get_trending():
    """API endpoint pro trending ot√°zky."""
    try:
        trending = await rag_system.get_trending_questions()
        return {"trending": trending}
    except Exception as e:
        logger.error(f"Chyba v /trending: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/sync")
async def sync_documents(request: SyncRequest):
    """API endpoint pro manu√°ln√≠ synchronizaci."""
    try:
        if request.spaces:
            for space in request.spaces:
                await document_manager.sync_confluence_space(space)
        else:
            await document_manager.sync_all_spaces()
        
        return {"message": "Synchronizace dokonƒçena", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Chyba v /sync: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "pinecone": "connected",
            "azure_openai": "connected",
            "redis": "connected"
        }
    }

def schedule_sync():
    """Pl√°nov√°n√≠ pravideln√© synchronizace."""
    schedule.every(6).hours.do(lambda: asyncio.run(document_manager.sync_all_spaces()))
    
    while True:
        schedule.run_pending()
        time.sleep(60)

async def start_slack_bot():
    """Spust√≠ Slack bota."""
    slack_bot = SlackBot()
    await slack_bot.start()

if __name__ == "__main__":
    import uvicorn
    
    # Spu≈°tƒõn√≠ scheduleru v samostatn√©m vl√°knƒõ
    scheduler_thread = Thread(target=schedule_sync, daemon=True)
    scheduler_thread.start()
    
    # Spu≈°tƒõn√≠ Slack bota v samostatn√©m vl√°knƒõ
    def run_slack_bot():
        asyncio.run(start_slack_bot())
    
    slack_thread = Thread(target=run_slack_bot, daemon=True)
    slack_thread.start()
    
    # Spu≈°tƒõn√≠ FastAPI
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        log_level="info"
    )
````

### Docker a Deployment

````dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instalace syst√©mov√Ωch z√°vislost√≠
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Kop√≠rov√°n√≠ po≈æadavk≈Ø a instalace
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Kop√≠rov√°n√≠ k√≥du
COPY . .

# Exposov√°n√≠ portu
EXPOSE 8000

# Spu≈°tƒõn√≠ aplikace
CMD ["python", "main.py"]
````

````yaml
version: '3.8'

services:
  kb-rag:
    build: .
    ports:
      - "8000:8000"
    environment:
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - SLACK_APP_TOKEN=${SLACK_APP_TOKEN}
      - CONFLUENCE_URL=${CONFLUENCE_URL}
      - CONFLUENCE_USERNAME=${CONFLUENCE_USERNAME}
      - CONFLUENCE_API_TOKEN=${CONFLUENCE_API_TOKEN}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    volumes:
      - ./logs:/app/logs

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
````

## 4. Shrnut√≠ Projektu

### Hodnota Projektu
Enterprise Knowledge Base Chatbot s RAG p≈ôedstavuje revoluƒçn√≠ ≈ôe≈°en√≠ pro p≈ô√≠stup k firemn√≠m znalostem. Integrace s Confluence, Slack a pokroƒçil√Ωmi AI modely vytv√°≈ô√≠ efektivn√≠ most mezi zamƒõstnanci a informacemi.

### Kl√≠ƒçov√© V√Ωhody
- **Okam≈æit√Ω p≈ô√≠stup** - Zamƒõstnanci z√≠skaj√≠ odpovƒõdi bƒõhem sekund
- **Centralizace znalost√≠** - V≈°echny informace na jednom m√≠stƒõ
- **Automatick√° aktualizace** - Synchronizace s existuj√≠c√≠mi syst√©my
- **≈†k√°lovatelnost** - Podpora tis√≠c≈Ø souƒçasn√Ωch u≈æivatel≈Ø
- **Analytika** - Sledov√°n√≠ trend≈Ø a ƒçasto kladen√Ωch ot√°zek

### Technologick√© P≈ôednosti
- **Modern√≠ architektura** - LangChain, Pinecone, Azure OpenAI
- **Vysok√° dostupnost** - Redis cache, fault tolerance
- **Bezpeƒçnost** - Enterprise-grade Azure zabezpeƒçen√≠
- **Flexibilita** - Snadn√© roz≈°√≠≈ôen√≠ o dal≈°√≠ zdroje dat

Tento projekt demonstruje s√≠lu kombinace retrieval-augmented generation s enterprise integrac√≠ pro vytvo≈ôen√≠ skuteƒçnƒõ u≈æiteƒçn√©ho AI asistenta.