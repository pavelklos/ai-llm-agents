<small>Claude Sonnet 4 **(Enterprise Knowledge Base Chatbot s RAG)**</small>
# Enterprise Knowledge Base Chatbot

## 1. Klíčové Koncepty

### RAG (Retrieval-Augmented Generation)
**RAG** je technika kombinující vyhledávání relevantních informací s generováním odpovědí pomocí jazykových modelů. Místo spoléhání pouze na předtrénovaná data model přistupuje k externí databázi znalostí.

### Confluence Integration
**Confluence** je podnikový systém pro správu dokumentace. Integrace umožňuje automatické načítání a indexování firemních dokumentů, wiki stránek a znalostí.

### Vector Database (Pinecone)
**Pinecone** je cloudová vektorová databáze optimalizovaná pro sémantické vyhledávání. Ukládá embeddings dokumentů a umožňuje rychlé vyhledávání podobných textů.

### Azure OpenAI
**Azure OpenAI** poskytuje přístup k pokročilým jazykovým modelům (GPT-4, GPT-3.5) prostřednictvím Microsoft Azure cloudu s enterprise zabezpečením.

### Slack Bot API
**Slack Bot API** umožňuje vytvoření chatbotů integrovaných přímo do Slack workspace, kde mohou zaměstnanci pokládat otázky a dostávat odpovědi.

## 2. Komplexní Vysvětlení Projektu

### Cíle Projektu
Projekt vytváří inteligentního chatbota, který slouží jako centrální bod pro přístup k firemním znalostem. Zaměstnanci mohou pokládat otázky v přirozeném jazyce a dostávat přesné odpovědi založené na interní dokumentaci.

### Výzvy
- **Integrace heterogenních zdrojů dat** - Confluence, SharePoint, PDF dokumenty
- **Udržování aktuálnosti** - Automatická synchronizace při změnách dokumentů
- **Relevance odpovědí** - Zajištění, že bot najde správné informace
- **Bezpečnost** - Respektování přístupových práv a citlivých informací
- **Škálovatelnost** - Podpora tisíců uživatelů současně

### Potenciální Dopad
- **Zvýšení produktivity** - Rychlý přístup k informacím bez procházení dokumentů
- **Snížení zátěže IT podpory** - Automatizace častých dotazů
- **Lepší onboarding** - Nové zaměstnance mohou snadno najít potřebné informace
- **Konzistence odpovědí** - Jednotné informace napříč organizací

## 3. Komplexní Implementace s Pythonem

### Požadované Závislosti

````python
fastapi==0.104.1
uvicorn==0.24.0
langchain==0.1.0
langchain-openai==0.0.5
pinecone-client==3.0.0
slack-bolt==1.18.1
python-multipart==0.0.6
pydantic==2.5.0
python-dotenv==1.0.0
requests==2.31.0
beautifulsoup4==4.12.2
pypdf2==3.0.1
schedule==1.2.0
redis==5.0.1
loguru==0.7.2
````

### Konfigurace a Prostředí

````python
import os
from pydantic import BaseSettings
from typing import List

class Settings(BaseSettings):
    # Azure OpenAI konfigurace
    azure_openai_api_key: str
    azure_openai_endpoint: str
    azure_openai_deployment: str = "gpt-4"
    azure_openai_api_version: str = "2024-02-01"
    
    # Pinecone konfigurace
    pinecone_api_key: str
    pinecone_environment: str
    pinecone_index_name: str = "enterprise-kb"
    
    # Slack konfigurace
    slack_bot_token: str
    slack_signing_secret: str
    slack_app_token: str
    
    # Confluence konfigurace
    confluence_url: str
    confluence_username: str
    confluence_api_token: str
    confluence_spaces: List[str] = ["IT", "HR", "DEV"]
    
    # Redis konfigurace
    redis_url: str = "redis://localhost:6379"
    
    # Obecné nastavení
    embedding_dimension: int = 1536
    max_chunk_size: int = 1000
    chunk_overlap: int = 100
    
    class Config:
        env_file = ".env"

settings = Settings()
````

### Správce Dokumentů a Embeddings

````python
import asyncio
import hashlib
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import PyPDF2
from io import BytesIO

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings
from langchain.schema import Document
import pinecone
import redis
from loguru import logger

from config import settings

@dataclass
class DocumentMetadata:
    source: str
    title: str
    url: str
    last_updated: datetime
    content_hash: str
    space: Optional[str] = None
    author: Optional[str] = None

class DocumentManager:
    def __init__(self):
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment="text-embedding-ada-002",
            azure_endpoint=settings.azure_openai_endpoint,
            api_key=settings.azure_openai_api_key,
            api_version=settings.azure_openai_api_version
        )
        
        # Inicializace Pinecone
        pinecone.init(
            api_key=settings.pinecone_api_key,
            environment=settings.pinecone_environment
        )
        
        self.index = pinecone.Index(settings.pinecone_index_name)
        self.redis_client = redis.from_url(settings.redis_url)
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=settings.max_chunk_size,
            chunk_overlap=settings.chunk_overlap,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def _calculate_content_hash(self, content: str) -> str:
        """Vypočítá hash obsahu pro detekci změn."""
        return hashlib.md5(content.encode()).hexdigest()
    
    async def fetch_confluence_pages(self, space_key: str) -> List[Dict[str, Any]]:
        """Načte stránky z Confluence prostoru."""
        try:
            auth = (settings.confluence_username, settings.confluence_api_token)
            base_url = f"{settings.confluence_url}/rest/api/content"
            
            params = {
                'spaceKey': space_key,
                'expand': 'body.storage,version,space,history.lastUpdated',
                'limit': 100
            }
            
            response = requests.get(base_url, auth=auth, params=params)
            response.raise_for_status()
            
            data = response.json()
            pages = []
            
            for page in data['results']:
                content = BeautifulSoup(
                    page['body']['storage']['value'], 
                    'html.parser'
                ).get_text()
                
                pages.append({
                    'id': page['id'],
                    'title': page['title'],
                    'content': content,
                    'url': f"{settings.confluence_url}/pages/viewpage.action?pageId={page['id']}",
                    'space': page['space']['name'],
                    'last_updated': datetime.fromisoformat(
                        page['history']['lastUpdated']['when'].replace('Z', '+00:00')
                    ),
                    'author': page['history']['lastUpdated']['by']['displayName']
                })
            
            return pages
            
        except Exception as e:
            logger.error(f"Chyba při načítání Confluence: {e}")
            return []
    
    async def process_document(self, content: str, metadata: DocumentMetadata) -> List[str]:
        """Zpracuje dokument na chunky a vytvoří embeddings."""
        try:
            # Kontrola, zda se dokument změnil
            cached_hash = self.redis_client.get(f"doc_hash:{metadata.url}")
            if cached_hash and cached_hash.decode() == metadata.content_hash:
                logger.info(f"Dokument {metadata.title} nebyl změněn, přeskakuji.")
                return []
            
            # Rozdělení na chunky
            documents = [Document(
                page_content=content,
                metadata={
                    "source": metadata.source,
                    "title": metadata.title,
                    "url": metadata.url,
                    "space": metadata.space,
                    "author": metadata.author,
                    "last_updated": metadata.last_updated.isoformat()
                }
            )]
            
            chunks = self.text_splitter.split_documents(documents)
            
            # Generování embeddings
            chunk_ids = []
            for i, chunk in enumerate(chunks):
                chunk_id = f"{metadata.url}#{i}"
                
                embedding = await self.embeddings.aembed_query(chunk.page_content)
                
                # Uložení do Pinecone
                self.index.upsert([{
                    'id': chunk_id,
                    'values': embedding,
                    'metadata': {
                        **chunk.metadata,
                        'text': chunk.page_content,
                        'chunk_index': i
                    }
                }])
                
                chunk_ids.append(chunk_id)
            
            # Uložení hash do cache
            self.redis_client.set(
                f"doc_hash:{metadata.url}", 
                metadata.content_hash,
                ex=86400  # 24 hodin
            )
            
            logger.info(f"Zpracován dokument {metadata.title}: {len(chunks)} chunků")
            return chunk_ids
            
        except Exception as e:
            logger.error(f"Chyba při zpracování dokumentu {metadata.title}: {e}")
            return []
    
    async def sync_confluence_space(self, space_key: str):
        """Synchronizuje jeden Confluence prostor."""
        pages = await self.fetch_confluence_pages(space_key)
        
        for page in pages:
            metadata = DocumentMetadata(
                source="confluence",
                title=page['title'],
                url=page['url'],
                last_updated=page['last_updated'],
                content_hash=self._calculate_content_hash(page['content']),
                space=page['space'],
                author=page['author']
            )
            
            await self.process_document(page['content'], metadata)
    
    async def sync_all_spaces(self):
        """Synchronizuje všechny nakonfigurované Confluence prostory."""
        logger.info("Zahájení synchronizace Confluence prostorů")
        
        tasks = []
        for space in settings.confluence_spaces:
            tasks.append(self.sync_confluence_space(space))
        
        await asyncio.gather(*tasks)
        logger.info("Synchronizace dokončena")
    
    async def search_similar_documents(
        self, 
        query: str, 
        top_k: int = 5,
        filter_dict: Optional[Dict] = None
    ) -> List[Dict[str, Any]]:
        """Vyhledá podobné dokumenty pro daný dotaz."""
        try:
            # Generování embedding pro dotaz
            query_embedding = await self.embeddings.aembed_query(query)
            
            # Vyhledání v Pinecone
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter=filter_dict
            )
            
            documents = []
            for match in results['matches']:
                documents.append({
                    'content': match['metadata']['text'],
                    'title': match['metadata']['title'],
                    'url': match['metadata']['url'],
                    'source': match['metadata']['source'],
                    'space': match['metadata'].get('space'),
                    'score': match['score'],
                    'last_updated': match['metadata']['last_updated']
                })
            
            return documents
            
        except Exception as e:
            logger.error(f"Chyba při vyhledávání: {e}")
            return []
````

### RAG Systém s LangChain

````python
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import PromptTemplate
from loguru import logger

from document_manager import DocumentManager
from config import settings

class RAGSystem:
    def __init__(self):
        self.document_manager = DocumentManager()
        
        self.llm = AzureChatOpenAI(
            azure_deployment=settings.azure_openai_deployment,
            azure_endpoint=settings.azure_openai_endpoint,
            api_key=settings.azure_openai_api_key,
            api_version=settings.azure_openai_api_version,
            temperature=0.1,
            max_tokens=1000
        )
        
        self.system_prompt = """Jsi užitečný asistent pro firemní znalostní bázi. Tvým úkolem je odpovídat na otázky zaměstnanců na základě poskytnutých dokumentů.

INSTRUKCE:
1. Odpovídej pouze na základě poskytnutých dokumentů
2. Pokud informace není v dokumentech, řekni to otevřeně
3. Uveď zdroje informací (title a URL)
4. Odpovídej v češtině
5. Buď přesný a konkrétní
6. Pokud je otázka nejasná, požádej o upřesnění

FORMÁT ODPOVĚDI:
- Hlavní odpověď
- Zdroje: [Title](URL)
"""

    async def generate_answer(
        self, 
        question: str, 
        context_documents: List[Dict[str, Any]],
        user_info: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Generuje odpověď na základě kontextových dokumentů."""
        try:
            # Příprava kontextu
            context = self._prepare_context(context_documents)
            
            # Vytvoření promptu
            prompt = f"""KONTEXT:
{context}

OTÁZKA: {question}

Odpověz na otázku na základě poskytnutého kontextu."""

            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=prompt)
            ]
            
            # Generování odpovědi
            response = await self.llm.agenerate([messages])
            answer = response.generations[0][0].text
            
            # Příprava zdrojů
            sources = self._extract_sources(context_documents)
            
            return {
                "answer": answer,
                "sources": sources,
                "context_used": len(context_documents),
                "timestamp": datetime.now().isoformat(),
                "user_info": user_info
            }
            
        except Exception as e:
            logger.error(f"Chyba při generování odpovědi: {e}")
            return {
                "answer": "Omlouvám se, ale došlo k chybě při zpracování vaší otázky. Zkuste to prosím později.",
                "sources": [],
                "context_used": 0,
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
    
    def _prepare_context(self, documents: List[Dict[str, Any]]) -> str:
        """Připraví kontext z dokumentů."""
        context_parts = []
        
        for i, doc in enumerate(documents, 1):
            context_parts.append(f"""
DOKUMENT {i}:
Název: {doc['title']}
Zdroj: {doc['source']} ({doc.get('space', 'N/A')})
Obsah: {doc['content']}
---""")
        
        return "\n".join(context_parts)
    
    def _extract_sources(self, documents: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """Extrahuje zdroje z dokumentů."""
        sources = []
        seen_urls = set()
        
        for doc in documents:
            if doc['url'] not in seen_urls:
                sources.append({
                    "title": doc['title'],
                    "url": doc['url'],
                    "source": doc['source'],
                    "space": doc.get('space'),
                    "score": round(doc['score'], 3)
                })
                seen_urls.add(doc['url'])
        
        return sources
    
    async def answer_question(
        self, 
        question: str,
        filters: Optional[Dict] = None,
        user_info: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Hlavní metoda pro odpovídání na otázky."""
        logger.info(f"Zpracovávám otázku: {question}")
        
        # Vyhledání relevantních dokumentů
        documents = await self.document_manager.search_similar_documents(
            query=question,
            top_k=5,
            filter_dict=filters
        )
        
        if not documents:
            return {
                "answer": "Omlouvám se, ale nenašel jsem žádné relevantní informace k vaší otázce. Zkuste přeformulovat dotaz nebo kontaktujte IT podporu.",
                "sources": [],
                "context_used": 0,
                "timestamp": datetime.now().isoformat()
            }
        
        # Generování odpovědi
        result = await self.generate_answer(question, documents, user_info)
        
        logger.info(f"Odpověď vygenerována s {len(documents)} zdroji")
        return result
    
    async def get_trending_questions(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Získá nejčastější otázky (implementace s Redis)."""
        try:
            # Získání nejčastějších otázek z Redis
            trending = self.document_manager.redis_client.zrevrange(
                "trending_questions", 0, limit-1, withscores=True
            )
            
            return [
                {
                    "question": question.decode(),
                    "count": int(score)
                }
                for question, score in trending
            ]
            
        except Exception as e:
            logger.error(f"Chyba při získávání trending otázek: {e}")
            return []
    
    async def log_question(self, question: str, user_id: str = None):
        """Loguje otázku pro analýzu trendů."""
        try:
            # Uložení do trending questions
            self.document_manager.redis_client.zincrby(
                "trending_questions", 1, question
            )
            
            # Logování pro analýzu
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "user_id": user_id
            }
            
            self.document_manager.redis_client.lpush(
                "question_log", 
                json.dumps(log_entry)
            )
            
        except Exception as e:
            logger.error(f"Chyba při logování otázky: {e}")
````

### Slack Bot Integrace

````python
import asyncio
import json
from typing import Dict, Any
from datetime import datetime

from slack_bolt.async_app import AsyncApp
from slack_bolt.adapter.socket_mode.async_handler import AsyncSocketModeHandler
from loguru import logger

from rag_system import RAGSystem
from config import settings

class SlackBot:
    def __init__(self):
        self.app = AsyncApp(
            token=settings.slack_bot_token,
            signing_secret=settings.slack_signing_secret
        )
        
        self.rag_system = RAGSystem()
        
        # Registrace event handlerů
        self._register_handlers()
    
    def _register_handlers(self):
        """Registruje všechny event handlery."""
        
        @self.app.message(".*")
        async def handle_message(message, say, client):
            """Zpracovává všechny zprávy v DM nebo mentions."""
            await self._handle_question(message, say, client)
        
        @self.app.command("/ask-kb")
        async def handle_ask_command(ack, respond, command, client):
            """Slash command pro dotazy do znalostní báze."""
            await ack()
            
            question = command['text'].strip()
            if not question:
                await respond("Prosím zadejte otázku. Např: `/ask-kb Jak se přihlásím do VPN?`")
                return
            
            user_info = await self._get_user_info(command['user_id'], client)
            await self._process_question(question, respond, user_info, command['channel_id'])
        
        @self.app.command("/kb-trending")
        async def handle_trending_command(ack, respond):
            """Zobrazí nejčastější otázky."""
            await ack()
            
            trending = await self.rag_system.get_trending_questions(10)
            
            if not trending:
                await respond("Zatím nejsou k dispozici žádné trending otázky.")
                return
            
            blocks = self._create_trending_blocks(trending)
            await respond(blocks=blocks)
        
        @self.app.event("app_mention")
        async def handle_mention(event, say, client):
            """Zpracovává mentions bota."""
            # Odstranění mention z textu
            text = event['text']
            bot_user_id = await self._get_bot_user_id(client)
            question = text.replace(f'<@{bot_user_id}>', '').strip()
            
            if not question:
                await say("Ahoj! Zeptejte se mě na cokoliv o firemní dokumentaci. 📚")
                return
            
            user_info = await self._get_user_info(event['user'], client)
            await self._process_question_mention(question, say, user_info, event)
    
    async def _handle_question(self, message, say, client):
        """Zpracovává obecné zprávy."""
        # Pouze v DM nebo pokud je bot zmíněn
        channel_type = message.get('channel_type')
        if channel_type != 'im':
            return
        
        question = message['text'].strip()
        user_info = await self._get_user_info(message['user'], client)
        
        await self._process_question_dm(question, say, user_info, message)
    
    async def _process_question(
        self, 
        question: str, 
        respond_func, 
        user_info: Dict,
        channel_id: str = None
    ):
        """Zpracuje otázku a pošle odpověď."""
        try:
            # Logování otázky
            await self.rag_system.log_question(question, user_info.get('id'))
            
            # Thinking zpráva
            thinking_message = await respond_func(
                text="🤔 Hledám odpověď v dokumentaci...",
                response_type="in_channel"
            )
            
            # Získání odpovědi
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            # Vytvoření bloků pro odpověď
            blocks = self._create_answer_blocks(result, question)
            
            # Aktualizace zprávy
            await respond_func(
                blocks=blocks,
                response_type="in_channel",
                replace_original=True
            )
            
        except Exception as e:
            logger.error(f"Chyba při zpracování otázky: {e}")
            await respond_func(
                text="😔 Omlouvám se, došlo k chybě. Zkuste to prosím později.",
                response_type="ephemeral"
            )
    
    async def _process_question_mention(self, question: str, say, user_info: Dict, event):
        """Zpracuje otázku z mention."""
        try:
            await self.rag_system.log_question(question, user_info.get('id'))
            
            # Thinking reakce
            thinking_msg = await say("🤔 Hledám odpověď v dokumentaci...")
            
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            blocks = self._create_answer_blocks(result, question)
            
            # Aktualizace zprávy
            await say(blocks=blocks, thread_ts=event.get('ts'))
            
        except Exception as e:
            logger.error(f"Chyba při zpracování mention: {e}")
            await say("😔 Omlouvám se, došlo k chybě. Zkuste to prosím později.")
    
    async def _process_question_dm(self, question: str, say, user_info: Dict, message):
        """Zpracuje otázku z DM."""
        try:
            await self.rag_system.log_question(question, user_info.get('id'))
            
            await say("🤔 Hledám odpověď v dokumentaci...")
            
            result = await self.rag_system.answer_question(
                question=question,
                user_info=user_info
            )
            
            blocks = self._create_answer_blocks(result, question)
            await say(blocks=blocks)
            
        except Exception as e:
            logger.error(f"Chyba při zpracování DM: {e}")
            await say("😔 Omlouvám se, došlo k chybě. Zkuste to prosím později.")
    
    def _create_answer_blocks(self, result: Dict[str, Any], question: str) -> list:
        """Vytvoří Slack blocks pro odpověď."""
        blocks = [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*Otázka:* {question}"
                }
            },
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*Odpověď:*\n{result['answer']}"
                }
            }
        ]
        
        # Přidání zdrojů
        if result['sources']:
            sources_text = "*Zdroje:*\n"
            for source in result['sources']:
                sources_text += f"• <{source['url']}|{source['title']}> "
                sources_text += f"({source['source']}"
                if source.get('space'):
                    sources_text += f" - {source['space']}"
                sources_text += f", relevance: {source['score']})\n"
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": sources_text
                }
            })
        
        # Footer s metadaty
        blocks.append({
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"Použito {result['context_used']} dokumentů | {result['timestamp']}"
                }
            ]
        })
        
        return blocks
    
    def _create_trending_blocks(self, trending: list) -> list:
        """Vytvoří bloky pro trending otázky."""
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "📈 Nejčastější otázky"
                }
            }
        ]
        
        for i, item in enumerate(trending, 1):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"{i}. {item['question']} _(dotázáno {item['count']}x)_"
                }
            })
        
        return blocks
    
    async def _get_user_info(self, user_id: str, client) -> Dict:
        """Získá informace o uživateli."""
        try:
            response = await client.users_info(user=user_id)
            user = response['user']
            
            return {
                'id': user_id,
                'name': user.get('real_name', user.get('name')),
                'email': user.get('profile', {}).get('email'),
                'team': user.get('profile', {}).get('team'),
                'title': user.get('profile', {}).get('title')
            }
        except Exception as e:
            logger.error(f"Chyba při získávání user info: {e}")
            return {'id': user_id}
    
    async def _get_bot_user_id(self, client) -> str:
        """Získá ID bota."""
        try:
            response = await client.auth_test()
            return response['user_id']
        except Exception as e:
            logger.error(f"Chyba při získávání bot ID: {e}")
            return ""
    
    async def start(self):
        """Spustí Slack bota."""
        handler = AsyncSocketModeHandler(self.app, settings.slack_app_token)
        await handler.start_async()
````

### Hlavní Aplikace a Scheduler

````python
import asyncio
import schedule
import time
from threading import Thread
from datetime import datetime

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from loguru import logger

from slack_bot import SlackBot
from rag_system import RAGSystem
from document_manager import DocumentManager
from config import settings

# FastAPI aplikace
app = FastAPI(title="Enterprise Knowledge Base RAG", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Globální instance
rag_system = RAGSystem()
document_manager = DocumentManager()

class QuestionRequest(BaseModel):
    question: str
    filters: dict = None
    user_info: dict = None

class SyncRequest(BaseModel):
    spaces: list = None

@app.get("/")
async def root():
    return {"message": "Enterprise Knowledge Base RAG API", "version": "1.0.0"}

@app.post("/ask")
async def ask_question(request: QuestionRequest):
    """API endpoint pro dotazy."""
    try:
        result = await rag_system.answer_question(
            question=request.question,
            filters=request.filters,
            user_info=request.user_info
        )
        return result
    except Exception as e:
        logger.error(f"Chyba v /ask: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/trending")
async def get_trending():
    """API endpoint pro trending otázky."""
    try:
        trending = await rag_system.get_trending_questions()
        return {"trending": trending}
    except Exception as e:
        logger.error(f"Chyba v /trending: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/sync")
async def sync_documents(request: SyncRequest):
    """API endpoint pro manuální synchronizaci."""
    try:
        if request.spaces:
            for space in request.spaces:
                await document_manager.sync_confluence_space(space)
        else:
            await document_manager.sync_all_spaces()
        
        return {"message": "Synchronizace dokončena", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Chyba v /sync: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "pinecone": "connected",
            "azure_openai": "connected",
            "redis": "connected"
        }
    }

def schedule_sync():
    """Plánování pravidelné synchronizace."""
    schedule.every(6).hours.do(lambda: asyncio.run(document_manager.sync_all_spaces()))
    
    while True:
        schedule.run_pending()
        time.sleep(60)

async def start_slack_bot():
    """Spustí Slack bota."""
    slack_bot = SlackBot()
    await slack_bot.start()

if __name__ == "__main__":
    import uvicorn
    
    # Spuštění scheduleru v samostatném vlákně
    scheduler_thread = Thread(target=schedule_sync, daemon=True)
    scheduler_thread.start()
    
    # Spuštění Slack bota v samostatném vlákně
    def run_slack_bot():
        asyncio.run(start_slack_bot())
    
    slack_thread = Thread(target=run_slack_bot, daemon=True)
    slack_thread.start()
    
    # Spuštění FastAPI
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        log_level="info"
    )
````

### Docker a Deployment

````dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instalace systémových závislostí
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Kopírování požadavků a instalace
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Kopírování kódu
COPY . .

# Exposování portu
EXPOSE 8000

# Spuštění aplikace
CMD ["python", "main.py"]
````

````yaml
version: '3.8'

services:
  kb-rag:
    build: .
    ports:
      - "8000:8000"
    environment:
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - SLACK_APP_TOKEN=${SLACK_APP_TOKEN}
      - CONFLUENCE_URL=${CONFLUENCE_URL}
      - CONFLUENCE_USERNAME=${CONFLUENCE_USERNAME}
      - CONFLUENCE_API_TOKEN=${CONFLUENCE_API_TOKEN}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    volumes:
      - ./logs:/app/logs

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
````

## 4. Shrnutí Projektu

### Hodnota Projektu
Enterprise Knowledge Base Chatbot s RAG představuje revoluční řešení pro přístup k firemním znalostem. Integrace s Confluence, Slack a pokročilými AI modely vytváří efektivní most mezi zaměstnanci a informacemi.

### Klíčové Výhody
- **Okamžitý přístup** - Zaměstnanci získají odpovědi během sekund
- **Centralizace znalostí** - Všechny informace na jednom místě
- **Automatická aktualizace** - Synchronizace s existujícími systémy
- **Škálovatelnost** - Podpora tisíců současných uživatelů
- **Analytika** - Sledování trendů a často kladených otázek

### Technologické Přednosti
- **Moderní architektura** - LangChain, Pinecone, Azure OpenAI
- **Vysoká dostupnost** - Redis cache, fault tolerance
- **Bezpečnost** - Enterprise-grade Azure zabezpečení
- **Flexibilita** - Snadné rozšíření o další zdroje dat

Tento projekt demonstruje sílu kombinace retrieval-augmented generation s enterprise integrací pro vytvoření skutečně užitečného AI asistenta.