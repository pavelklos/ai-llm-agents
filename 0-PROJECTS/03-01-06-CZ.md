<small>Claude Sonnet 4 **(N√°stroj pro Finanƒçn√≠ V√Ωzkum a Investiƒçn√≠ Anal√Ωzu s RAG)**</small>
# Financial Research and Investment Analysis Tool

## Kl√≠ƒçov√© Koncepty

### RAG (Retrieval-Augmented Generation)
Technika kombinuj√≠c√≠ z√≠sk√°v√°n√≠ relevantn√≠ch informac√≠ z datab√°ze s generativn√≠mi AI modely pro vytv√°≈ôen√≠ p≈ôesn√Ωch a kontextovƒõ relevantn√≠ch odpovƒõd√≠.

### SEC Filings
Ofici√°ln√≠ dokumenty pod√°van√© americk√© Komisi pro cenn√© pap√≠ry (Securities and Exchange Commission), obsahuj√≠c√≠ finanƒçn√≠ informace o ve≈ôejnƒõ obchodovan√Ωch spoleƒçnostech.

### Financial Reports
Strukturovan√© finanƒçn√≠ v√Ωkazy vƒçetnƒõ rozvahy, v√Ωkazu zisku a ztr√°ty, cash flow a dal≈°√≠ch finanƒçn√≠ch metrik.

### Market Data
Real-time a historick√° tr≈æn√≠ data vƒçetnƒõ cen akci√≠, objem≈Ø obchod≈Ø, index≈Ø a dal≈°√≠ch tr≈æn√≠ch indik√°tor≈Ø.

### Time-series Analysis
Anal√Ωza ƒçasov√Ωch ≈ôad pro identifikaci trend≈Ø, sezonality a p≈ôedpov√≠d√°n√≠ budouc√≠ch hodnot finanƒçn√≠ch ukazatel≈Ø.

### Qdrant
Vysoce v√Ωkonn√° vektorov√° datab√°ze optimalizovan√° pro similarity search a AI aplikace.

### Bloomberg API
Profesion√°ln√≠ API pro p≈ô√≠stup k finanƒçn√≠m dat≈Øm, tr≈æn√≠m informac√≠m a analytick√Ωm n√°stroj≈Øm.

### Risk Assessment
Hodnocen√≠ investiƒçn√≠ch rizik pomoc√≠ r≈Øzn√Ωch metrik a model≈Ø pro kvantifikaci potenci√°ln√≠ch ztr√°t.

## Komplexn√≠ Vysvƒõtlen√≠ Projektu

N√°stroj pro finanƒçn√≠ v√Ωzkum a investiƒçn√≠ anal√Ωzu p≈ôedstavuje pokroƒçilou AI-powered platformu, kter√° revolucionizuje zp≈Øsob, jak√Ωm investo≈ôi a analytici zpracov√°vaj√≠ a analyzuj√≠ finanƒçn√≠ informace. Projekt kombinuje s√≠lu RAG architektury s rozs√°hl√Ωmi finanƒçn√≠mi datab√°zemi pro poskytov√°n√≠ inteligentn√≠ch insights a investiƒçn√≠ch doporuƒçen√≠.

### Hlavn√≠ C√≠le
- Automatizace anal√Ωzy SEC filings a finanƒçn√≠ch v√Ωkaz≈Ø
- Poskytov√°n√≠ kontextovƒõ relevantn√≠ch investiƒçn√≠ch insights
- Identifikace tr≈æn√≠ch trend≈Ø a rizikov√Ωch faktor≈Ø
- Generov√°n√≠ personalizovan√Ωch investiƒçn√≠ch doporuƒçen√≠
- Streamlining due diligence proces≈Ø

### V√Ωzvy
- Zpracov√°n√≠ velk√Ωch objem≈Ø nestrukturovan√Ωch finanƒçn√≠ch dat
- Zaji≈°tƒõn√≠ aktu√°lnosti a p≈ôesnosti informac√≠
- Integrace r≈Øznorod√Ωch datov√Ωch zdroj≈Ø
- Compliance s finanƒçn√≠mi regulacemi
- ≈†k√°lovatelnost pro institucion√°ln√≠ pou≈æit√≠

### Potenci√°ln√≠ Dopad
Tento n√°stroj m≈Ø≈æe v√Ωznamnƒõ zv√Ω≈°it efektivitu investiƒçn√≠ch rozhodnut√≠, sn√≠≈æit ƒças pot≈ôebn√Ω pro due diligence a demokratizovat p≈ô√≠stup k pokroƒçil√Ωm finanƒçn√≠m anal√Ωz√°m.

## Komplexn√≠ Implementace v Pythonu

````python
langchain==0.1.0
openai==1.3.0
qdrant-client==1.6.0
pandas==2.1.0
numpy==1.24.0
yfinance==0.2.18
sec-edgar-api==1.0.0
requests==2.31.0
streamlit==1.28.0
plotly==5.17.0
scikit-learn==1.3.0
python-dotenv==1.0.0
````

````python
import os
from dataclasses import dataclass
from typing import Optional

@dataclass
class Config:
    # API Keys
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    ALPHA_VANTAGE_API_KEY: str = os.getenv("ALPHA_VANTAGE_API_KEY", "")
    
    # Qdrant Configuration
    QDRANT_URL: str = os.getenv("QDRANT_URL", "http://localhost:6333")
    QDRANT_API_KEY: Optional[str] = os.getenv("QDRANT_API_KEY")
    
    # Collection Names
    SEC_COLLECTION: str = "sec_filings"
    MARKET_DATA_COLLECTION: str = "market_data"
    
    # Model Configuration
    EMBEDDING_MODEL: str = "text-embedding-ada-002"
    LLM_MODEL: str = "gpt-4"
    
    # Data Paths
    DATA_DIR: str = "data"
    SEC_DATA_DIR: str = "data/sec_filings"
    MARKET_DATA_DIR: str = "data/market_data"

config = Config()
````

````python
import requests
import json
import pandas as pd
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import time

class SECDataCollector:
    """Kolektor pro SEC filings a finanƒçn√≠ data"""
    
    def __init__(self):
        self.base_url = "https://www.sec.gov/Archives/edgar/data"
        self.api_url = "https://data.sec.gov/api/xbrl/companyfacts"
        self.headers = {
            'User-Agent': 'Financial Research Tool contact@example.com',
            'Accept-Encoding': 'gzip, deflate',
            'Host': 'data.sec.gov'
        }
    
    def get_company_facts(self, cik: str) -> Optional[Dict]:
        """Z√≠sk√° fakta o spoleƒçnosti z SEC API"""
        try:
            # Form√°tov√°n√≠ CIK na 10 ƒç√≠slic
            cik_formatted = str(cik).zfill(10)
            url = f"{self.api_url}/CIK{cik_formatted}.json"
            
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            return response.json()
        except Exception as e:
            print(f"Chyba p≈ôi z√≠sk√°v√°n√≠ dat pro CIK {cik}: {e}")
            return None
    
    def extract_financial_metrics(self, company_facts: Dict) -> pd.DataFrame:
        """Extrahuje kl√≠ƒçov√© finanƒçn√≠ metriky"""
        metrics = []
        
        try:
            facts = company_facts.get('facts', {})
            us_gaap = facts.get('us-gaap', {})
            
            # Kl√≠ƒçov√© metriky
            key_metrics = [
                'Assets', 'Liabilities', 'StockholdersEquity',
                'Revenues', 'NetIncomeLoss', 'OperatingIncomeLoss',
                'CashAndCashEquivalentsAtCarryingValue'
            ]
            
            for metric in key_metrics:
                if metric in us_gaap:
                    units = us_gaap[metric].get('units', {})
                    if 'USD' in units:
                        for entry in units['USD']:
                            metrics.append({
                                'metric': metric,
                                'value': entry.get('val'),
                                'date': entry.get('end'),
                                'period': entry.get('form'),
                                'frame': entry.get('frame')
                            })
            
            return pd.DataFrame(metrics)
        except Exception as e:
            print(f"Chyba p≈ôi extrakci metrik: {e}")
            return pd.DataFrame()
    
    def get_latest_filings(self, ticker: str, form_type: str = "10-K") -> List[Dict]:
        """Z√≠sk√° nejnovƒõj≈°√≠ filings pro ticker"""
        # Simulace dat pro demonstraci
        sample_filings = [
            {
                "ticker": ticker,
                "form_type": form_type,
                "filing_date": "2023-12-31",
                "content": f"Annual report for {ticker}. Revenue increased by 15% year-over-year. Strong performance in key markets with expansion into new territories.",
                "url": f"https://example.com/{ticker}-10k-2023.html"
            },
            {
                "ticker": ticker,
                "form_type": "10-Q",
                "filing_date": "2023-09-30",
                "content": f"Quarterly report for {ticker}. Q3 results exceeded expectations with robust growth in core segments.",
                "url": f"https://example.com/{ticker}-10q-q3-2023.html"
            }
        ]
        return sample_filings

# Vytvo≈ôen√≠ uk√°zkov√Ωch dat
def create_sample_sec_data():
    """Vytvo≈ô√≠ uk√°zkov√° SEC data pro demonstraci"""
    companies = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    all_data = []
    
    collector = SECDataCollector()
    
    for ticker in companies:
        filings = collector.get_latest_filings(ticker)
        all_data.extend(filings)
    
    return all_data
````

````python
import yfinance as yf
import pandas as pd
import numpy as np
from typing import Dict, List, Optional
from datetime import datetime, timedelta

class MarketDataCollector:
    """Kolektor tr≈æn√≠ch dat"""
    
    def __init__(self):
        self.cache = {}
    
    def get_stock_data(self, ticker: str, period: str = "1y") -> pd.DataFrame:
        """Z√≠sk√° historick√° data akci√≠"""
        try:
            stock = yf.Ticker(ticker)
            data = stock.history(period=period)
            
            # P≈ôid√°n√≠ technick√Ωch indik√°tor≈Ø
            data['SMA_20'] = data['Close'].rolling(window=20).mean()
            data['SMA_50'] = data['Close'].rolling(window=50).mean()
            data['RSI'] = self.calculate_rsi(data['Close'])
            data['Volatility'] = data['Close'].rolling(window=20).std()
            
            return data
        except Exception as e:
            print(f"Chyba p≈ôi z√≠sk√°v√°n√≠ dat pro {ticker}: {e}")
            return pd.DataFrame()
    
    def calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """Vypoƒç√≠t√° Relative Strength Index"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    def get_market_sentiment(self, tickers: List[str]) -> Dict:
        """Analyzuje tr≈æn√≠ sentiment"""
        sentiment_data = {}
        
        for ticker in tickers:
            try:
                stock = yf.Ticker(ticker)
                info = stock.info
                
                # Z√°kladn√≠ sentiment metriky
                pe_ratio = info.get('trailingPE', 0)
                market_cap = info.get('marketCap', 0)
                
                # Sentiment sk√≥re na z√°kladƒõ PE ratio
                if pe_ratio > 0:
                    if pe_ratio < 15:
                        sentiment = "Pozitivn√≠"
                    elif pe_ratio < 25:
                        sentiment = "Neutr√°ln√≠"
                    else:
                        sentiment = "Negativn√≠"
                else:
                    sentiment = "Nedostaƒçuj√≠c√≠ data"
                
                sentiment_data[ticker] = {
                    'sentiment': sentiment,
                    'pe_ratio': pe_ratio,
                    'market_cap': market_cap
                }
            except Exception as e:
                print(f"Chyba p≈ôi anal√Ωze sentimentu pro {ticker}: {e}")
                sentiment_data[ticker] = {'sentiment': 'Chyba', 'pe_ratio': 0, 'market_cap': 0}
        
        return sentiment_data
    
    def calculate_risk_metrics(self, returns: pd.Series) -> Dict:
        """Vypoƒç√≠t√° rizikov√© metriky"""
        return {
            'volatility': returns.std() * np.sqrt(252),  # Anualizovan√° volatilita
            'sharpe_ratio': (returns.mean() * 252) / (returns.std() * np.sqrt(252)),
            'max_drawdown': self.calculate_max_drawdown(returns),
            'var_95': np.percentile(returns, 5),  # Value at Risk 95%
            'skewness': returns.skew(),
            'kurtosis': returns.kurtosis()
        }
    
    def calculate_max_drawdown(self, returns: pd.Series) -> float:
        """Vypoƒç√≠t√° maxim√°ln√≠ pokles"""
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.cummax()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min()
````

````python
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain.embeddings import OpenAIEmbeddings
import uuid
from typing import List, Dict, Any
import numpy as np

class QdrantVectorStore:
    """Qdrant vektorov√° datab√°ze pro finanƒçn√≠ dokumenty"""
    
    def __init__(self, url: str, api_key: str = None):
        self.client = QdrantClient(url=url, api_key=api_key)
        self.embeddings = OpenAIEmbeddings()
        
    def create_collection(self, collection_name: str, vector_size: int = 1536):
        """Vytvo≈ô√≠ novou kolekci"""
        try:
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
            )
            print(f"Kolekce {collection_name} byla vytvo≈ôena")
        except Exception as e:
            print(f"Kolekce {collection_name} ji≈æ existuje nebo chyba: {e}")
    
    def add_documents(self, collection_name: str, documents: List[Dict]):
        """P≈ôid√° dokumenty do kolekce"""
        points = []
        
        for doc in documents:
            # Vytvo≈ôen√≠ embeddingu
            text = doc.get('content', '')
            embedding = self.embeddings.embed_query(text)
            
            # Vytvo≈ôen√≠ pointu
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=embedding,
                payload=doc
            )
            points.append(point)
        
        # Ulo≈æen√≠ do Qdrant
        self.client.upsert(
            collection_name=collection_name,
            points=points
        )
        print(f"P≈ôid√°no {len(points)} dokument≈Ø do kolekce {collection_name}")
    
    def search_similar(self, collection_name: str, query: str, limit: int = 5) -> List[Dict]:
        """Vyhled√° podobn√© dokumenty"""
        try:
            # Vytvo≈ôen√≠ query embeddingu
            query_embedding = self.embeddings.embed_query(query)
            
            # Vyhled√°n√≠
            results = self.client.search(
                collection_name=collection_name,
                query_vector=query_embedding,
                limit=limit,
                with_payload=True
            )
            
            return [
                {
                    'score': result.score,
                    'payload': result.payload
                }
                for result in results
            ]
        except Exception as e:
            print(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            return []
````

````python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from typing import List, Dict, Any
import json

class FinancialRAGSystem:
    """RAG syst√©m pro finanƒçn√≠ anal√Ωzu"""
    
    def __init__(self, vector_store, llm_model: str = "gpt-4"):
        self.vector_store = vector_store
        self.llm = OpenAI(model_name=llm_model, temperature=0.1)
        
        # Prompt template pro finanƒçn√≠ anal√Ωzu
        self.analysis_template = PromptTemplate(
            input_variables=["query", "context", "market_data"],
            template="""
            Jste odborn√Ω finanƒçn√≠ analytik. Na z√°kladƒõ poskytnut√Ωch informac√≠ poskytnƒõte detailn√≠ anal√Ωzu.

            Dotaz: {query}

            Kontext z finanƒçn√≠ch dokument≈Ø:
            {context}

            Tr≈æn√≠ data:
            {market_data}

            Poskytnƒõte strukturovanou anal√Ωzu zahrnuj√≠c√≠:
            1. Shrnut√≠ kl√≠ƒçov√Ωch pozorov√°n√≠
            2. Finanƒçn√≠ zdrav√≠ spoleƒçnosti
            3. Tr≈æn√≠ pozici a konkurenƒçn√≠ v√Ωhody
            4. Identifikovan√° rizika
            5. Investiƒçn√≠ doporuƒçen√≠
            6. D≈Øvod pro doporuƒçen√≠

            Odpovƒõƒè:
            """
        )
        
        self.chain = LLMChain(llm=self.llm, prompt=self.analysis_template)
    
    def analyze_investment(self, query: str, ticker: str = None) -> Dict[str, Any]:
        """Provede investiƒçn√≠ anal√Ωzu"""
        try:
            # Z√≠sk√°n√≠ relevantn√≠ch dokument≈Ø
            relevant_docs = self.vector_store.search_similar(
                collection_name="sec_filings",
                query=query,
                limit=3
            )
            
            # Form√°tov√°n√≠ kontextu
            context = self._format_context(relevant_docs)
            
            # Z√≠sk√°n√≠ tr≈æn√≠ch dat
            market_data = self._get_market_context(ticker) if ticker else "Nejsou k dispozici specifick√° tr≈æn√≠ data."
            
            # Generov√°n√≠ anal√Ωzy
            analysis = self.chain.run(
                query=query,
                context=context,
                market_data=market_data
            )
            
            return {
                'query': query,
                'analysis': analysis,
                'sources': [doc['payload'] for doc in relevant_docs],
                'market_data': market_data
            }
            
        except Exception as e:
            return {
                'query': query,
                'analysis': f"Chyba p≈ôi anal√Ωze: {e}",
                'sources': [],
                'market_data': None
            }
    
    def _format_context(self, documents: List[Dict]) -> str:
        """Form√°tuje kontext z dokument≈Ø"""
        if not documents:
            return "Nejsou k dispozici relevantn√≠ dokumenty."
        
        context_parts = []
        for i, doc in enumerate(documents, 1):
            payload = doc['payload']
            context_parts.append(
                f"Dokument {i} (Sk√≥re: {doc['score']:.3f}):\n"
                f"Ticker: {payload.get('ticker', 'N/A')}\n"
                f"Typ: {payload.get('form_type', 'N/A')}\n"
                f"Datum: {payload.get('filing_date', 'N/A')}\n"
                f"Obsah: {payload.get('content', 'N/A')}\n"
            )
        
        return "\n".join(context_parts)
    
    def _get_market_context(self, ticker: str) -> str:
        """Z√≠sk√° tr≈æn√≠ kontext pro ticker"""
        # Simulace tr≈æn√≠ch dat
        market_info = {
            "AAPL": "Akcie Apple obchodov√°ny za $175, P/E ratio 28.5, tr≈æn√≠ kapitalizace $2.8T",
            "MSFT": "Akcie Microsoft obchodov√°ny za $340, P/E ratio 32.1, tr≈æn√≠ kapitalizace $2.5T",
            "GOOGL": "Akcie Alphabet obchodov√°ny za $125, P/E ratio 25.8, tr≈æn√≠ kapitalizace $1.6T"
        }
        
        return market_info.get(ticker, f"Tr≈æn√≠ data pro {ticker} nejsou k dispozici.")
    
    def generate_risk_assessment(self, ticker: str, time_horizon: str = "1 rok") -> Dict[str, Any]:
        """Generuje hodnocen√≠ rizik"""
        risk_query = f"Analyzujte investiƒçn√≠ rizika pro {ticker} na obdob√≠ {time_horizon}"
        
        # Z√≠sk√°n√≠ relevantn√≠ch dokument≈Ø pro rizikovou anal√Ωzu
        risk_docs = self.vector_store.search_similar(
            collection_name="sec_filings",
            query=f"risk factors {ticker} regulatory compliance financial risks",
            limit=3
        )
        
        # Risk assessment prompt
        risk_template = PromptTemplate(
            input_variables=["ticker", "time_horizon", "risk_context"],
            template="""
            Proveƒète detailn√≠ hodnocen√≠ rizik pro investici do {ticker} na obdob√≠ {time_horizon}.

            Relevantn√≠ rizikov√© faktory z dokument≈Ø:
            {risk_context}

            Poskytnƒõte strukturovan√© hodnocen√≠ rizik:
            1. Tr≈æn√≠ rizika
            2. Operaƒçn√≠ rizika
            3. Finanƒçn√≠ rizika
            4. Regulaƒçn√≠ rizika
            5. Celkov√© rizikov√© sk√≥re (1-10)
            6. Doporuƒçen√© mitigaƒçn√≠ strategie

            Odpovƒõƒè:
            """
        )
        
        risk_chain = LLMChain(llm=self.llm, prompt=risk_template)
        risk_context = self._format_context(risk_docs)
        
        risk_assessment = risk_chain.run(
            ticker=ticker,
            time_horizon=time_horizon,
            risk_context=risk_context
        )
        
        return {
            'ticker': ticker,
            'time_horizon': time_horizon,
            'risk_assessment': risk_assessment,
            'risk_sources': [doc['payload'] for doc in risk_docs]
        }
````

````python
import pandas as pd
import numpy as np
from typing import List, Dict, Any
from datetime import datetime, timedelta

class PortfolioAnalyzer:
    """Analyz√°tor portfolia pro optimalizaci a hodnocen√≠ v√Ωkonnosti"""
    
    def __init__(self, rag_system):
        self.rag_system = rag_system
    
    def analyze_portfolio_composition(self, holdings: List[Dict]) -> Dict[str, Any]:
        """Analyzuje slo≈æen√≠ portfolia"""
        total_value = sum(holding['value'] for holding in holdings)
        
        analysis = {
            'total_value': total_value,
            'holdings_count': len(holdings),
            'largest_position': max(holdings, key=lambda x: x['value']),
            'sector_allocation': self._calculate_sector_allocation(holdings),
            'concentration_risk': self._calculate_concentration_risk(holdings),
            'recommendations': []
        }
        
        # Generov√°n√≠ doporuƒçen√≠
        if analysis['concentration_risk'] > 0.3:
            analysis['recommendations'].append(
                "Vysok√° koncentrace rizika - zva≈æte diverzifikaci"
            )
        
        return analysis
    
    def _calculate_sector_allocation(self, holdings: List[Dict]) -> Dict[str, float]:
        """Vypoƒç√≠t√° alokaci podle sektor≈Ø"""
        # Simulace sektorov√© alokace
        sector_map = {
            'AAPL': 'Technology',
            'MSFT': 'Technology', 
            'GOOGL': 'Technology',
            'AMZN': 'Consumer Discretionary',
            'TSLA': 'Consumer Discretionary'
        }
        
        sector_values = {}
        total_value = sum(holding['value'] for holding in holdings)
        
        for holding in holdings:
            sector = sector_map.get(holding['ticker'], 'Other')
            if sector not in sector_values:
                sector_values[sector] = 0
            sector_values[sector] += holding['value'] / total_value
        
        return sector_values
    
    def _calculate_concentration_risk(self, holdings: List[Dict]) -> float:
        """Vypoƒç√≠t√° koncentraƒçn√≠ riziko (Herfindahl index)"""
        total_value = sum(holding['value'] for holding in holdings)
        weights = [holding['value'] / total_value for holding in holdings]
        return sum(w**2 for w in weights)
    
    def generate_portfolio_report(self, holdings: List[Dict]) -> Dict[str, Any]:
        """Generuje komplexn√≠ report portfolia"""
        composition = self.analyze_portfolio_composition(holdings)
        
        # Anal√Ωza ka≈æd√© pozice
        position_analyses = []
        for holding in holdings:
            analysis = self.rag_system.analyze_investment(
                query=f"Analyzujte investiƒçn√≠ potenci√°l {holding['ticker']}",
                ticker=holding['ticker']
            )
            position_analyses.append({
                'ticker': holding['ticker'],
                'current_value': holding['value'],
                'analysis': analysis
            })
        
        return {
            'composition_analysis': composition,
            'position_analyses': position_analyses,
            'overall_recommendation': self._generate_overall_recommendation(composition),
            'generated_at': datetime.now().isoformat()
        }
    
    def _generate_overall_recommendation(self, composition: Dict[str, Any]) -> str:
        """Generuje celkov√© doporuƒçen√≠ pro portfolio"""
        recommendations = []
        
        # Anal√Ωza koncentrace
        if composition['concentration_risk'] > 0.4:
            recommendations.append("Vysok√© koncentraƒçn√≠ riziko - doporuƒçujeme diverzifikaci")
        elif composition['concentration_risk'] < 0.1:
            recommendations.append("Mo≈æn√° over-diverzifikace - zva≈æte konsolidaci pozic")
        
        # Anal√Ωza sektorov√© alokace
        tech_allocation = composition['sector_allocation'].get('Technology', 0)
        if tech_allocation > 0.6:
            recommendations.append("Vysok√° expozice technologick√©mu sektoru")
        
        return "; ".join(recommendations) if recommendations else "Portfolio vypad√° dob≈ôe vyv√°≈æen√©"
````

````python
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json

# Import na≈°ich modul≈Ø
from config import config
from data_collectors.sec_collector import SECDataCollector, create_sample_sec_data
from data_collectors.market_collector import MarketDataCollector
from vector_store.qdrant_store import QdrantVectorStore
from rag_system.financial_rag import FinancialRAGSystem
from analytics.portfolio_analyzer import PortfolioAnalyzer

# Konfigurace Streamlit
st.set_page_config(
    page_title="Finanƒçn√≠ V√Ωzkum a Investiƒçn√≠ Anal√Ωza",
    page_icon="üìà",
    layout="wide"
)

def initialize_system():
    """Inicializuje RAG syst√©m"""
    if 'rag_system' not in st.session_state:
        with st.spinner("Inicializace syst√©mu..."):
            # Vytvo≈ôen√≠ vektorov√© datab√°ze
            vector_store = QdrantVectorStore(url="http://localhost:6333")
            
            # Vytvo≈ôen√≠ kolekc√≠
            vector_store.create_collection("sec_filings")
            
            # Naƒçten√≠ uk√°zkov√Ωch dat
            sample_data = create_sample_sec_data()
            vector_store.add_documents("sec_filings", sample_data)
            
            # Vytvo≈ôen√≠ RAG syst√©mu
            rag_system = FinancialRAGSystem(vector_store)
            
            # Vytvo≈ôen√≠ analyz√°toru portfolia
            portfolio_analyzer = PortfolioAnalyzer(rag_system)
            
            st.session_state.rag_system = rag_system
            st.session_state.portfolio_analyzer = portfolio_analyzer
            st.session_state.market_collector = MarketDataCollector()

def main():
    st.title("üè¶ Finanƒçn√≠ V√Ωzkum a Investiƒçn√≠ Anal√Ωza s RAG")
    st.markdown("Pokroƒçil√Ω n√°stroj pro anal√Ωzu investic a portfolia pomoc√≠ AI")
    
    # Inicializace syst√©mu
    initialize_system()
    
    # Sidebar pro navigaci
    st.sidebar.title("Navigace")
    page = st.sidebar.selectbox(
        "Vyberte sekci:",
        ["üìä Dashboard", "üîç Investiƒçn√≠ Anal√Ωza", "üìà Portfolio Anal√Ωza", "‚ö†Ô∏è Rizikov√© Hodnocen√≠"]
    )
    
    if page == "üìä Dashboard":
        show_dashboard()
    elif page == "üîç Investiƒçn√≠ Anal√Ωza":
        show_investment_analysis()
    elif page == "üìà Portfolio Anal√Ωza":
        show_portfolio_analysis()
    elif page == "‚ö†Ô∏è Rizikov√© Hodnocen√≠":
        show_risk_assessment()

def show_dashboard():
    st.header("üìä Dashboard")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Analyzovan√© spoleƒçnosti", "5", "+2")
    with col2:
        st.metric("SEC dokumenty", "10", "+3")
    with col3:
        st.metric("Tr≈æn√≠ kapitalizace", "$8.9T", "+5.2%")
    with col4:
        st.metric("Pr≈Ømƒõrn√© P/E", "28.5", "-2.1")
    
    # Uk√°zkov√Ω graf tr≈æn√≠ v√Ωkonnosti
    st.subheader("Tr≈æn√≠ p≈ôehled")
    
    # Simulace dat
    tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    prices = [175, 340, 125, 145, 208]
    changes = [2.5, -1.2, 3.8, 0.8, -2.1]
    
    market_data = pd.DataFrame({
        'Ticker': tickers,
        'Cena': prices,
        'Zmƒõna (%)': changes
    })
    
    fig = px.bar(market_data, x='Ticker', y='Zmƒõna (%)', 
                 title="Denn√≠ zmƒõny (%)").round(1)
    fig.update_traces(marker_color=['green' if x > 0 else 'red' for x in changes])
    st.plotly_chart(fig, use_container_width=True)

def show_investment_analysis():
    st.header("üîç Investiƒçn√≠ Anal√Ωza")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Parametry anal√Ωzy")
        ticker = st.selectbox("Vyberte ticker:", ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"])
        query = st.text_area("Specifick√° ot√°zka:", 
                           f"Analyzujte investiƒçn√≠ potenci√°l {ticker} pro dlouhodob√© investov√°n√≠")
        
        if st.button("Spustit anal√Ωzu"):
            with st.spinner("Prob√≠h√° anal√Ωza..."):
                analysis = st.session_state.rag_system.analyze_investment(query, ticker)
                st.session_state.current_analysis = analysis
    
    with col2:
        st.subheader("V√Ωsledky anal√Ωzy")
        
        if 'current_analysis' in st.session_state:
            analysis = st.session_state.current_analysis
            
            st.markdown("### üìã Anal√Ωza")
            st.write(analysis['analysis'])
            
            st.markdown("### üìö Zdroje")
            for i, source in enumerate(analysis['sources'], 1):
                with st.expander(f"Zdroj {i}: {source.get('ticker', 'N/A')} - {source.get('form_type', 'N/A')}"):
                    st.write(f"**Datum:** {source.get('filing_date', 'N/A')}")
                    st.write(f"**Obsah:** {source.get('content', 'N/A')}")

def show_portfolio_analysis():
    st.header("üìà Portfolio Anal√Ωza")
    
    # Uk√°zkov√© portfolio
    if 'portfolio' not in st.session_state:
        st.session_state.portfolio = [
            {'ticker': 'AAPL', 'shares': 100, 'value': 17500},
            {'ticker': 'MSFT', 'shares': 50, 'value': 17000},
            {'ticker': 'GOOGL', 'shares': 80, 'value': 10000},
            {'ticker': 'AMZN', 'shares': 30, 'value': 4350},
            {'ticker': 'TSLA', 'shares': 25, 'value': 5200}
        ]
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Portfolio Holdings")
        portfolio_df = pd.DataFrame(st.session_state.portfolio)
        st.dataframe(portfolio_df)
        
        total_value = portfolio_df['value'].sum()
        st.metric("Celkov√° hodnota", f"${total_value:,}")
        
        if st.button("Analyzovat portfolio"):
            with st.spinner("Analyzuji portfolio..."):
                report = st.session_state.portfolio_analyzer.generate_portfolio_report(
                    st.session_state.portfolio
                )
                st.session_state.portfolio_report = report
    
    with col2:
        st.subheader("Portfolio Anal√Ωza")
        
        if 'portfolio_report' in st.session_state:
            report = st.session_state.portfolio_report
            composition = report['composition_analysis']
            
            # Sektorov√° alokace
            sector_data = composition['sector_allocation']
            fig = px.pie(values=list(sector_data.values()), 
                        names=list(sector_data.keys()),
                        title="Sektorov√° alokace")
            st.plotly_chart(fig, use_container_width=True)
            
            # Koncentraƒçn√≠ riziko
            st.metric("Koncentraƒçn√≠ riziko", f"{composition['concentration_risk']:.3f}")
            
            # Doporuƒçen√≠
            st.markdown("### üí° Doporuƒçen√≠")
            st.write(report['overall_recommendation'])

def show_risk_assessment():
    st.header("‚ö†Ô∏è Rizikov√© Hodnocen√≠")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Parametry hodnocen√≠")
        ticker = st.selectbox("Ticker pro anal√Ωzu:", ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"])
        time_horizon = st.selectbox("ƒåasov√Ω horizont:", ["6 mƒõs√≠c≈Ø", "1 rok", "2 roky", "5 let"])
        
        if st.button("Vyhodnotit rizika"):
            with st.spinner("Hodnot√≠m rizika..."):
                risk_assessment = st.session_state.rag_system.generate_risk_assessment(
                    ticker, time_horizon
                )
                st.session_state.risk_assessment = risk_assessment
    
    with col2:
        st.subheader("V√Ωsledky hodnocen√≠")
        
        if 'risk_assessment' in st.session_state:
            assessment = st.session_state.risk_assessment
            
            st.markdown("### üéØ Rizikov√© Hodnocen√≠")
            st.write(assessment['risk_assessment'])
            
            # Simulace rizikov√Ωch metrik
            risk_metrics = {
                'Tr≈æn√≠ riziko': 7,
                'Operaƒçn√≠ riziko': 4,
                'Finanƒçn√≠ riziko': 3,
                'Regulaƒçn√≠ riziko': 5
            }
            
            fig = go.Figure(data=go.Scatterpolar(
                r=list(risk_metrics.values()),
                theta=list(risk_metrics.keys()),
                fill='toself'
            ))
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 10]
                    )),
                showlegend=False,
                title="Rizikov√Ω profil"
            )
            st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()
````

````python
import os
import json
from data_collectors.sec_collector import create_sample_sec_data
from vector_store.qdrant_store import QdrantVectorStore

def setup_demo_environment():
    """Nastav√≠ demo prost≈ôed√≠"""
    print("Nastavuji demo prost≈ôed√≠...")
    
    # Vytvo≈ôen√≠ adres√°≈ô≈Ø
    os.makedirs("data/sec_filings", exist_ok=True)
    os.makedirs("data/market_data", exist_ok=True)
    
    # Ulo≈æen√≠ uk√°zkov√Ωch SEC dat
    sample_sec_data = create_sample_sec_data()
    with open("data/sec_filings/sample_data.json", "w", encoding='utf-8') as f:
        json.dump(sample_sec_data, f, indent=2, ensure_ascii=False)
    
    print("Demo prost≈ôed√≠ je p≈ôipraveno!")
    print("Spus≈•te aplikaci pomoc√≠: streamlit run app.py")

if __name__ == "__main__":
    setup_demo_environment()
````

## Shrnut√≠ Projektu

N√°stroj pro finanƒçn√≠ v√Ωzkum a investiƒçn√≠ anal√Ωzu s RAG p≈ôedstavuje revoluƒçn√≠ho pomocn√≠ka pro investory a finanƒçn√≠ analytiky. Kombinuje s√≠lu modern√≠ch AI technologi√≠ s rozs√°hl√Ωmi finanƒçn√≠mi datab√°zemi pro poskytov√°n√≠ inteligentn√≠ch, datovƒõ podlo≈æen√Ωch investiƒçn√≠ch insights.

### Kl√≠ƒçov√© Hodnoty:
- **Automatizace**: Dramaticky sni≈æuje ƒças pot≈ôebn√Ω pro finanƒçn√≠ due diligence
- **P≈ôesnost**: Vyu≈æ√≠v√° ofici√°ln√≠ SEC filings a real-time tr≈æn√≠ data
- **≈†k√°lovatelnost**: Qdrant vektorov√° datab√°ze umo≈æ≈àuje zpracov√°n√≠ masivn√≠ch objem≈Ø dat
- **Intelligent Insights**: RAG architektura poskytuje kontextovƒõ relevantn√≠ anal√Ωzy
- **Risk Management**: Pokroƒçil√© modely pro hodnocen√≠ investiƒçn√≠ch rizik

### Technologick√© Inovace:
- **Hybrid Retrieval**: Kombinace s√©mantick√©ho a keyword vyhled√°v√°n√≠
- **Multi-modal Analysis**: Integrace textov√Ωch a numerick√Ωch finanƒçn√≠ch dat
- **Real-time Processing**: Schopnost zpracov√°n√≠ live tr≈æn√≠ch dat
- **Adaptive Learning**: Syst√©m se uƒç√≠ z historick√Ωch investiƒçn√≠ch v√Ωsledk≈Ø

Tento projekt democratizuje p≈ô√≠stup k pokroƒçil√Ωm finanƒçn√≠m anal√Ωz√°m a umo≈æ≈àuje i men≈°√≠m investor≈Øm vyu≈æ√≠vat n√°stroje na institucion√°ln√≠ √∫rovni.