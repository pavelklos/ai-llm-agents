<small>Claude Sonnet 4 **(Voice-controlled Home Automation Chatbot)**</small>
# Voice-controlled Home Automation Chatbot

## Key Concepts Explanation

### Natural Language Command Processing
Advanced system that converts human speech into structured device commands by parsing natural language, understanding context, and mapping intentions to specific IoT actions. Handles variations in phrasing, implicit commands, temporal references, and multi-device scenarios while maintaining conversational context for follow-up commands.

### Action-to-Intent Mapping
Intelligent framework that translates user intentions into executable IoT device actions through semantic understanding, device capability matching, and command optimization. Maps abstract requests like "make it cozy" to specific device configurations while considering user preferences, current conditions, and device states.

### IoT Device Integration Layer
Comprehensive interface system that communicates with diverse smart home devices through standardized protocols (MQTT, HTTP, WebSocket), manages device discovery, maintains real-time status monitoring, and handles command execution with error recovery and feedback mechanisms.

### Conversational Context Management
Sophisticated memory system that maintains conversation history, user preferences, device states, and temporal context to enable natural multi-turn interactions. Handles pronouns, relative references, and complex commands spanning multiple devices while learning from user behavior patterns.

### Voice Recognition and Synthesis
Integrated speech processing pipeline that converts audio input to text using automatic speech recognition, processes commands through NLP models, and generates natural speech responses using text-to-speech synthesis with emotion and personality customization.

### Smart Scene Orchestration
Advanced automation engine that coordinates multiple devices to create ambient scenes, executes complex routines, and adapts to user habits through machine learning while optimizing energy consumption and device coordination timing.

## Comprehensive Project Explanation

### Objectives
The Voice-controlled Home Automation Chatbot aims to democratize smart home interaction by providing intuitive, conversational control over IoT devices, eliminating the need for complex interfaces while creating personalized, adaptive home environments that respond naturally to human needs and preferences.

### Key Features
- **Natural Voice Commands**: Intuitive speech-based device control with conversational responses
- **Multi-Device Orchestration**: Coordinated control of lights, thermostats, security, entertainment systems
- **Context-Aware Interactions**: Understanding of implicit commands and conversational context
- **Personalized Automation**: Learning user preferences and creating adaptive routines
- **Real-time Device Monitoring**: Continuous status tracking and proactive notifications
- **Secure Communication**: Encrypted device communication with privacy protection

### Challenges
- **Speech Recognition Accuracy**: Handling accents, background noise, and natural speech variations
- **Intent Disambiguation**: Resolving ambiguous commands and understanding context-dependent meanings
- **Device Compatibility**: Supporting diverse IoT protocols and manufacturers with varying capabilities
- **Latency Optimization**: Ensuring responsive command execution while processing complex natural language
- **Privacy and Security**: Protecting voice data and securing IoT device communications
- **Reliability Assurance**: Maintaining system availability and graceful degradation when devices fail

### Potential Impact
This system can transform home living experiences by making smart homes accessible to all users regardless of technical expertise, improving accessibility for elderly and disabled users, reducing energy consumption through intelligent automation, and enhancing security through voice-activated monitoring and control.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
openai==1.6.1
langchain==0.1.0
langchain-openai==0.0.5
streamlit==1.29.0
speech_recognition==3.10.0
pyttsx3==2.90
pygame==2.5.2
paho-mqtt==1.6.1
requests==2.31.0
websockets==12.0
asyncio-mqtt==0.13.0
python-dotenv==1.0.0
pydantic==2.5.0
numpy==1.24.3
pandas==2.1.4
plotly==5.17.0
spacy==3.7.2
nltk==3.8.1
dateparser==1.2.0
schedule==1.2.0
threading
json
uuid
logging
datetime
typing
dataclasses
enum
re
time
asyncio
````

### Core Implementation

````python
import os
import json
import uuid
import logging
import asyncio
import threading
import time
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Callable
from dataclasses import dataclass, field
from enum import Enum

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

# Speech processing
import speech_recognition as sr
import pyttsx3
import pygame

# IoT communication
import paho.mqtt.client as mqtt
import requests
import websockets

# NLP processing
import spacy
import nltk
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from langchain.schema import BaseOutputParser

# Utilities
import dateparser
import schedule
from pydantic import BaseModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DeviceType(Enum):
    LIGHT = "light"
    THERMOSTAT = "thermostat"
    LOCK = "lock"
    CAMERA = "camera"
    SPEAKER = "speaker"
    TV = "tv"
    FAN = "fan"
    BLINDS = "blinds"
    SENSOR = "sensor"
    SWITCH = "switch"

class DeviceState(Enum):
    ON = "on"
    OFF = "off"
    UNKNOWN = "unknown"
    ERROR = "error"

class CommandType(Enum):
    CONTROL = "control"
    QUERY = "query"
    SCENE = "scene"
    SCHEDULE = "schedule"
    AUTOMATION = "automation"

class Priority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class DeviceCapability:
    capability_id: str
    name: str
    data_type: str  # boolean, integer, float, string, enum
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    enum_values: List[str] = field(default_factory=list)
    unit: str = ""
    read_only: bool = False

@dataclass
class IoTDevice:
    device_id: str
    name: str
    device_type: DeviceType
    location: str
    protocol: str  # mqtt, http, websocket
    connection_info: Dict[str, Any]
    capabilities: List[DeviceCapability]
    current_state: Dict[str, Any] = field(default_factory=dict)
    last_seen: Optional[datetime] = None
    is_online: bool = False
    battery_level: Optional[float] = None

@dataclass
class VoiceCommand:
    command_id: str
    raw_text: str
    processed_text: str
    intent: str
    entities: Dict[str, Any]
    confidence: float
    timestamp: datetime
    user_id: str = "default"
    context: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DeviceAction:
    action_id: str
    device_id: str
    command_type: CommandType
    parameters: Dict[str, Any]
    priority: Priority = Priority.MEDIUM
    scheduled_time: Optional[datetime] = None
    retry_count: int = 0
    max_retries: int = 3

@dataclass
class AutomationRule:
    rule_id: str
    name: str
    trigger_conditions: Dict[str, Any]
    actions: List[DeviceAction]
    enabled: bool = True
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class Scene:
    scene_id: str
    name: str
    description: str
    device_states: Dict[str, Dict[str, Any]]
    created_by: str = "user"
    activation_count: int = 0

class SpeechProcessor:
    """Handles speech recognition and text-to-speech."""
    
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        
        # Initialize TTS engine
        self.tts_engine = pyttsx3.init()
        self.tts_engine.setProperty('rate', 150)
        self.tts_engine.setProperty('volume', 0.8)
        
        # Adjust for ambient noise
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source)
        
        logger.info("Speech processor initialized")
    
    def listen_for_command(self, timeout: int = 5) -> Optional[str]:
        """Listen for voice command."""
        try:
            with self.microphone as source:
                logger.info("Listening for command...")
                audio = self.recognizer.listen(source, timeout=timeout, phrase_time_limit=10)
            
            # Recognize speech
            text = self.recognizer.recognize_google(audio)
            logger.info(f"Recognized: {text}")
            return text.lower().strip()
            
        except sr.WaitTimeoutError:
            logger.info("Listening timeout")
            return None
        except sr.UnknownValueError:
            logger.warning("Could not understand audio")
            return None
        except sr.RequestError as e:
            logger.error(f"Speech recognition error: {e}")
            return None
    
    def speak_response(self, text: str):
        """Convert text to speech."""
        try:
            logger.info(f"Speaking: {text}")
            self.tts_engine.say(text)
            self.tts_engine.runAndWait()
        except Exception as e:
            logger.error(f"TTS error: {e}")
    
    def set_voice_properties(self, rate: int = 150, volume: float = 0.8, voice_id: int = 0):
        """Configure voice properties."""
        try:
            voices = self.tts_engine.getProperty('voices')
            if voices and len(voices) > voice_id:
                self.tts_engine.setProperty('voice', voices[voice_id].id)
            
            self.tts_engine.setProperty('rate', rate)
            self.tts_engine.setProperty('volume', volume)
        except Exception as e:
            logger.error(f"Voice configuration error: {e}")

class IntentClassifier:
    """Classifies user intents from natural language commands."""
    
    def __init__(self, openai_api_key: str = None):
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0.1,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        else:
            self.llm = None
        
        # Intent patterns
        self.intent_patterns = {
            'turn_on': [
                r'turn on (?:the )?(.+)',
                r'switch on (?:the )?(.+)',
                r'activate (?:the )?(.+)',
                r'start (?:the )?(.+)'
            ],
            'turn_off': [
                r'turn off (?:the )?(.+)',
                r'switch off (?:the )?(.+)',
                r'deactivate (?:the )?(.+)',
                r'stop (?:the )?(.+)'
            ],
            'set_level': [
                r'set (?:the )?(.+) to (\d+)%?',
                r'dim (?:the )?(.+) to (\d+)%?',
                r'brighten (?:the )?(.+) to (\d+)%?'
            ],
            'change_temperature': [
                r'set (?:the )?temperature to (\d+)',
                r'make it (\d+) degrees',
                r'heat to (\d+)',
                r'cool to (\d+)'
            ],
            'query_status': [
                r'what is (?:the )?(.+) status',
                r'how is (?:the )?(.+)',
                r'check (?:the )?(.+)',
                r'status of (?:the )?(.+)'
            ],
            'activate_scene': [
                r'activate (.+) scene',
                r'set (.+) mode',
                r'start (.+) scene'
            ]
        }
        
        self.intent_classification_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are an expert at understanding smart home voice commands. Analyze the user's command
            and extract the intent, target devices, and parameters.
            
            Return a JSON response with:
            {
                "intent": "action_type",
                "devices": ["device_names"],
                "parameters": {"key": "value"},
                "confidence": 0.0-1.0
            }
            
            Common intents: turn_on, turn_off, set_level, change_temperature, query_status, activate_scene
            """),
            ("human", "Command: {command}")
        ])
    
    def classify_intent(self, command: str) -> Dict[str, Any]:
        """Classify intent from natural language command."""
        command = command.lower().strip()
        
        # Try pattern matching first
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, command)
                if match:
                    entities = self._extract_entities_from_match(intent, match)
                    return {
                        'intent': intent,
                        'entities': entities,
                        'confidence': 0.8,
                        'method': 'pattern_matching'
                    }
        
        # Use LLM if available
        if self.llm:
            return self._classify_with_llm(command)
        
        # Fallback to basic keyword matching
        return self._classify_with_keywords(command)
    
    def _extract_entities_from_match(self, intent: str, match) -> Dict[str, Any]:
        """Extract entities from regex match."""
        entities = {}
        
        if intent in ['turn_on', 'turn_off', 'query_status']:
            entities['device'] = match.group(1).strip()
        
        elif intent == 'set_level':
            entities['device'] = match.group(1).strip()
            entities['level'] = int(match.group(2))
        
        elif intent == 'change_temperature':
            entities['temperature'] = int(match.group(1))
        
        elif intent == 'activate_scene':
            entities['scene'] = match.group(1).strip()
        
        return entities
    
    def _classify_with_llm(self, command: str) -> Dict[str, Any]:
        """Classify intent using LLM."""
        try:
            response = self.llm.invoke(self.intent_classification_prompt.format(command=command))
            
            # Parse JSON response
            import json
            result = json.loads(response.content)
            
            return {
                'intent': result.get('intent', 'unknown'),
                'entities': result.get('parameters', {}),
                'confidence': result.get('confidence', 0.5),
                'method': 'llm'
            }
            
        except Exception as e:
            logger.error(f"LLM classification error: {e}")
            return self._classify_with_keywords(command)
    
    def _classify_with_keywords(self, command: str) -> Dict[str, Any]:
        """Fallback keyword-based classification."""
        keywords = {
            'turn_on': ['on', 'start', 'activate', 'open'],
            'turn_off': ['off', 'stop', 'deactivate', 'close'],
            'query_status': ['status', 'check', 'how', 'what'],
            'activate_scene': ['scene', 'mode', 'atmosphere']
        }
        
        for intent, words in keywords.items():
            if any(word in command for word in words):
                return {
                    'intent': intent,
                    'entities': {'raw_command': command},
                    'confidence': 0.4,
                    'method': 'keyword'
                }
        
        return {
            'intent': 'unknown',
            'entities': {'raw_command': command},
            'confidence': 0.1,
            'method': 'fallback'
        }

class DeviceManager:
    """Manages IoT device communication and state."""
    
    def __init__(self):
        self.devices = {}
        self.device_protocols = {}
        
        # MQTT client
        self.mqtt_client = mqtt.Client()
        self.mqtt_client.on_connect = self._on_mqtt_connect
        self.mqtt_client.on_message = self._on_mqtt_message
        
        # Initialize sample devices
        self._initialize_sample_devices()
        
        logger.info("Device manager initialized")
    
    def _initialize_sample_devices(self):
        """Initialize sample smart home devices."""
        
        # Living room light
        living_light = IoTDevice(
            device_id="living_light_001",
            name="living room light",
            device_type=DeviceType.LIGHT,
            location="living room",
            protocol="mqtt",
            connection_info={"topic": "home/living_room/light"},
            capabilities=[
                DeviceCapability("power", "Power", "boolean"),
                DeviceCapability("brightness", "Brightness", "integer", 0, 100, unit="%"),
                DeviceCapability("color", "Color", "string")
            ],
            current_state={"power": False, "brightness": 0, "color": "white"},
            is_online=True
        )
        
        # Thermostat
        thermostat = IoTDevice(
            device_id="thermostat_001",
            name="thermostat",
            device_type=DeviceType.THERMOSTAT,
            location="living room",
            protocol="http",
            connection_info={"url": "http://localhost:8080/api/thermostat"},
            capabilities=[
                DeviceCapability("temperature", "Temperature", "float", 10, 35, unit="¬∞C"),
                DeviceCapability("mode", "Mode", "enum", enum_values=["heat", "cool", "auto", "off"]),
                DeviceCapability("current_temp", "Current Temperature", "float", unit="¬∞C", read_only=True)
            ],
            current_state={"temperature": 21, "mode": "auto", "current_temp": 20.5},
            is_online=True
        )
        
        # Bedroom light
        bedroom_light = IoTDevice(
            device_id="bedroom_light_001",
            name="bedroom light",
            device_type=DeviceType.LIGHT,
            location="bedroom",
            protocol="mqtt",
            connection_info={"topic": "home/bedroom/light"},
            capabilities=[
                DeviceCapability("power", "Power", "boolean"),
                DeviceCapability("brightness", "Brightness", "integer", 0, 100, unit="%")
            ],
            current_state={"power": False, "brightness": 0},
            is_online=True
        )
        
        # Smart lock
        smart_lock = IoTDevice(
            device_id="front_door_lock_001",
            name="front door lock",
            device_type=DeviceType.LOCK,
            location="front door",
            protocol="websocket",
            connection_info={"url": "ws://localhost:8081/lock"},
            capabilities=[
                DeviceCapability("locked", "Locked", "boolean"),
                DeviceCapability("battery", "Battery Level", "integer", 0, 100, unit="%", read_only=True)
            ],
            current_state={"locked": True, "battery": 85},
            is_online=True
        )
        
        devices = [living_light, thermostat, bedroom_light, smart_lock]
        
        for device in devices:
            self.devices[device.device_id] = device
            self.devices[device.name] = device  # Allow lookup by name
    
    def _on_mqtt_connect(self, client, userdata, flags, rc):
        """MQTT connection callback."""
        if rc == 0:
            logger.info("Connected to MQTT broker")
            # Subscribe to device topics
            for device in self.devices.values():
                if isinstance(device, IoTDevice) and device.protocol == "mqtt":
                    topic = device.connection_info.get("topic", "") + "/status"
                    client.subscribe(topic)
        else:
            logger.error(f"MQTT connection failed: {rc}")
    
    def _on_mqtt_message(self, client, userdata, msg):
        """MQTT message callback."""
        try:
            topic_parts = msg.topic.split('/')
            if len(topic_parts) >= 3:
                location = topic_parts[1]
                device_type = topic_parts[2]
                
                # Find matching device
                for device in self.devices.values():
                    if (isinstance(device, IoTDevice) and 
                        device.location.replace(' ', '_') == location and
                        device.device_type.value == device_type):
                        
                        # Update device state
                        payload = json.loads(msg.payload.decode())
                        device.current_state.update(payload)
                        device.last_seen = datetime.now()
                        break
                        
        except Exception as e:
            logger.error(f"MQTT message processing error: {e}")
    
    def find_device(self, device_name: str) -> Optional[IoTDevice]:
        """Find device by name or ID."""
        device_name = device_name.lower().strip()
        
        # Direct lookup
        if device_name in self.devices:
            device = self.devices[device_name]
            if isinstance(device, IoTDevice):
                return device
        
        # Fuzzy matching
        for device in self.devices.values():
            if isinstance(device, IoTDevice):
                if device_name in device.name.lower():
                    return device
                
                # Check location + type combinations
                location_type = f"{device.location} {device.device_type.value}"
                if device_name in location_type.lower():
                    return device
        
        return None
    
    def execute_device_action(self, action: DeviceAction) -> bool:
        """Execute action on device."""
        device = None
        
        # Find device by ID or name
        if action.device_id in self.devices:
            device = self.devices[action.device_id]
        else:
            device = self.find_device(action.device_id)
        
        if not device:
            logger.error(f"Device not found: {action.device_id}")
            return False
        
        if not device.is_online:
            logger.error(f"Device offline: {device.name}")
            return False
        
        try:
            if device.protocol == "mqtt":
                return self._execute_mqtt_action(device, action)
            elif device.protocol == "http":
                return self._execute_http_action(device, action)
            elif device.protocol == "websocket":
                return self._execute_websocket_action(device, action)
            else:
                logger.error(f"Unsupported protocol: {device.protocol}")
                return False
                
        except Exception as e:
            logger.error(f"Action execution error: {e}")
            return False
    
    def _execute_mqtt_action(self, device: IoTDevice, action: DeviceAction) -> bool:
        """Execute MQTT device action."""
        try:
            topic = device.connection_info["topic"] + "/command"
            payload = json.dumps(action.parameters)
            
            # Simulate MQTT publish (in real implementation, use actual MQTT)
            logger.info(f"MQTT: {topic} -> {payload}")
            
            # Update device state immediately for simulation
            device.current_state.update(action.parameters)
            device.last_seen = datetime.now()
            
            return True
            
        except Exception as e:
            logger.error(f"MQTT action error: {e}")
            return False
    
    def _execute_http_action(self, device: IoTDevice, action: DeviceAction) -> bool:
        """Execute HTTP device action."""
        try:
            url = device.connection_info["url"]
            
            # Simulate HTTP request
            logger.info(f"HTTP POST: {url} -> {action.parameters}")
            
            # Update device state for simulation
            device.current_state.update(action.parameters)
            device.last_seen = datetime.now()
            
            return True
            
        except Exception as e:
            logger.error(f"HTTP action error: {e}")
            return False
    
    def _execute_websocket_action(self, device: IoTDevice, action: DeviceAction) -> bool:
        """Execute WebSocket device action."""
        try:
            # Simulate WebSocket communication
            logger.info(f"WebSocket: {device.connection_info['url']} -> {action.parameters}")
            
            # Update device state for simulation
            device.current_state.update(action.parameters)
            device.last_seen = datetime.now()
            
            return True
            
        except Exception as e:
            logger.error(f"WebSocket action error: {e}")
            return False
    
    def get_device_status(self, device_name: str) -> Optional[Dict[str, Any]]:
        """Get current device status."""
        device = self.find_device(device_name)
        if device:
            return {
                'name': device.name,
                'type': device.device_type.value,
                'location': device.location,
                'state': device.current_state,
                'online': device.is_online,
                'last_seen': device.last_seen.isoformat() if device.last_seen else None
            }
        return None

class SceneManager:
    """Manages smart home scenes and routines."""
    
    def __init__(self, device_manager: DeviceManager):
        self.device_manager = device_manager
        self.scenes = {}
        self._initialize_default_scenes()
    
    def _initialize_default_scenes(self):
        """Initialize default scenes."""
        
        # Movie night scene
        movie_scene = Scene(
            scene_id="movie_night",
            name="movie night",
            description="Dim lights and prepare for movie watching",
            device_states={
                "living room light": {"power": True, "brightness": 20},
                "bedroom light": {"power": False}
            }
        )
        
        # Good morning scene
        morning_scene = Scene(
            scene_id="good_morning",
            name="good morning",
            description="Bright lights and comfortable temperature",
            device_states={
                "living room light": {"power": True, "brightness": 80},
                "bedroom light": {"power": True, "brightness": 60},
                "thermostat": {"temperature": 22}
            }
        )
        
        # Good night scene
        night_scene = Scene(
            scene_id="good_night",
            name="good night",
            description="Turn off lights and lock doors",
            device_states={
                "living room light": {"power": False},
                "bedroom light": {"power": False},
                "front door lock": {"locked": True}
            }
        )
        
        for scene in [movie_scene, morning_scene, night_scene]:
            self.scenes[scene.name] = scene
    
    def activate_scene(self, scene_name: str) -> bool:
        """Activate a scene."""
        scene_name = scene_name.lower().strip()
        
        if scene_name not in self.scenes:
            logger.error(f"Scene not found: {scene_name}")
            return False
        
        scene = self.scenes[scene_name]
        success_count = 0
        total_actions = len(scene.device_states)
        
        for device_name, target_state in scene.device_states.items():
            action = DeviceAction(
                action_id=str(uuid.uuid4()),
                device_id=device_name,
                command_type=CommandType.CONTROL,
                parameters=target_state,
                priority=Priority.MEDIUM
            )
            
            if self.device_manager.execute_device_action(action):
                success_count += 1
            else:
                logger.warning(f"Failed to control {device_name} in scene {scene_name}")
        
        scene.activation_count += 1
        
        if success_count == total_actions:
            logger.info(f"Scene '{scene_name}' activated successfully")
            return True
        else:
            logger.warning(f"Scene '{scene_name}' partially activated ({success_count}/{total_actions})")
            return success_count > 0

class VoiceHomeAutomation:
    """Main voice-controlled home automation system."""
    
    def __init__(self, openai_api_key: str = None):
        self.speech_processor = SpeechProcessor()
        self.intent_classifier = IntentClassifier(openai_api_key)
        self.device_manager = DeviceManager()
        self.scene_manager = SceneManager(self.device_manager)
        
        # Command history
        self.command_history = []
        self.conversation_context = {}
        
        # System state
        self.is_listening = False
        self.wake_word = "hey assistant"
        
        logger.info("Voice home automation system initialized")
    
    def start_listening(self):
        """Start continuous listening mode."""
        self.is_listening = True
        logger.info("Started listening mode")
        
        while self.is_listening:
            try:
                # Listen for wake word or direct command
                command_text = self.speech_processor.listen_for_command(timeout=2)
                
                if command_text:
                    if self.wake_word in command_text:
                        # Remove wake word and process command
                        command_text = command_text.replace(self.wake_word, "").strip()
                        if command_text:
                            self.process_voice_command(command_text)
                        else:
                            self.speech_processor.speak_response("Yes, how can I help?")
                    else:
                        # Process direct command
                        self.process_voice_command(command_text)
            
            except KeyboardInterrupt:
                self.stop_listening()
                break
            except Exception as e:
                logger.error(f"Listening error: {e}")
                time.sleep(1)
    
    def stop_listening(self):
        """Stop listening mode."""
        self.is_listening = False
        logger.info("Stopped listening mode")
    
    def process_voice_command(self, command_text: str, user_id: str = "default") -> Dict[str, Any]:
        """Process a voice command and return result."""
        logger.info(f"Processing command: {command_text}")
        
        # Create command record
        command = VoiceCommand(
            command_id=str(uuid.uuid4()),
            raw_text=command_text,
            processed_text=command_text.lower().strip(),
            intent="",
            entities={},
            confidence=0.0,
            timestamp=datetime.now(),
            user_id=user_id
        )
        
        try:
            # Classify intent
            intent_result = self.intent_classifier.classify_intent(command_text)
            command.intent = intent_result['intent']
            command.entities = intent_result['entities']
            command.confidence = intent_result['confidence']
            
            # Execute command
            result = self._execute_command(command)
            
            # Add to history
            self.command_history.append(command)
            
            # Speak response
            response_text = result.get('response', 'Command processed')
            self.speech_processor.speak_response(response_text)
            
            return result
            
        except Exception as e:
            logger.error(f"Command processing error: {e}")
            error_response = "Sorry, I couldn't process that command."
            self.speech_processor.speak_response(error_response)
            
            return {
                'success': False,
                'error': str(e),
                'response': error_response
            }
    
    def _execute_command(self, command: VoiceCommand) -> Dict[str, Any]:
        """Execute the classified command."""
        intent = command.intent
        entities = command.entities
        
        if intent == 'turn_on':
            return self._handle_turn_on(entities)
        
        elif intent == 'turn_off':
            return self._handle_turn_off(entities)
        
        elif intent == 'set_level':
            return self._handle_set_level(entities)
        
        elif intent == 'change_temperature':
            return self._handle_change_temperature(entities)
        
        elif intent == 'query_status':
            return self._handle_query_status(entities)
        
        elif intent == 'activate_scene':
            return self._handle_activate_scene(entities)
        
        else:
            return {
                'success': False,
                'response': f"I don't understand the command: {command.raw_text}",
                'intent': intent
            }
    
    def _handle_turn_on(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle turn on command."""
        device_name = entities.get('device', '')
        
        if not device_name:
            return {'success': False, 'response': 'Which device would you like to turn on?'}
        
        device = self.device_manager.find_device(device_name)
        if not device:
            return {'success': False, 'response': f'Device "{device_name}" not found'}
        
        action = DeviceAction(
            action_id=str(uuid.uuid4()),
            device_id=device.device_id,
            command_type=CommandType.CONTROL,
            parameters={'power': True}
        )
        
        success = self.device_manager.execute_device_action(action)
        
        if success:
            return {
                'success': True,
                'response': f'Turned on the {device.name}',
                'device': device.name
            }
        else:
            return {
                'success': False,
                'response': f'Failed to turn on the {device.name}'
            }
    
    def _handle_turn_off(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle turn off command."""
        device_name = entities.get('device', '')
        
        if not device_name:
            return {'success': False, 'response': 'Which device would you like to turn off?'}
        
        device = self.device_manager.find_device(device_name)
        if not device:
            return {'success': False, 'response': f'Device "{device_name}" not found'}
        
        action = DeviceAction(
            action_id=str(uuid.uuid4()),
            device_id=device.device_id,
            command_type=CommandType.CONTROL,
            parameters={'power': False}
        )
        
        success = self.device_manager.execute_device_action(action)
        
        if success:
            return {
                'success': True,
                'response': f'Turned off the {device.name}',
                'device': device.name
            }
        else:
            return {
                'success': False,
                'response': f'Failed to turn off the {device.name}'
            }
    
    def _handle_set_level(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle set level command."""
        device_name = entities.get('device', '')
        level = entities.get('level', 0)
        
        if not device_name:
            return {'success': False, 'response': 'Which device would you like to adjust?'}
        
        device = self.device_manager.find_device(device_name)
        if not device:
            return {'success': False, 'response': f'Device "{device_name}" not found'}
        
        action = DeviceAction(
            action_id=str(uuid.uuid4()),
            device_id=device.device_id,
            command_type=CommandType.CONTROL,
            parameters={'brightness': level, 'power': True}
        )
        
        success = self.device_manager.execute_device_action(action)
        
        if success:
            return {
                'success': True,
                'response': f'Set the {device.name} to {level}%',
                'device': device.name,
                'level': level
            }
        else:
            return {
                'success': False,
                'response': f'Failed to adjust the {device.name}'
            }
    
    def _handle_change_temperature(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle temperature change command."""
        temperature = entities.get('temperature')
        
        if temperature is None:
            return {'success': False, 'response': 'What temperature would you like?'}
        
        # Find thermostat
        thermostat = None
        for device in self.device_manager.devices.values():
            if isinstance(device, IoTDevice) and device.device_type == DeviceType.THERMOSTAT:
                thermostat = device
                break
        
        if not thermostat:
            return {'success': False, 'response': 'No thermostat found'}
        
        action = DeviceAction(
            action_id=str(uuid.uuid4()),
            device_id=thermostat.device_id,
            command_type=CommandType.CONTROL,
            parameters={'temperature': temperature}
        )
        
        success = self.device_manager.execute_device_action(action)
        
        if success:
            return {
                'success': True,
                'response': f'Set the temperature to {temperature} degrees',
                'temperature': temperature
            }
        else:
            return {
                'success': False,
                'response': 'Failed to change the temperature'
            }
    
    def _handle_query_status(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle status query command."""
        device_name = entities.get('device', '')
        
        if not device_name:
            return {'success': False, 'response': 'Which device status would you like to check?'}
        
        status = self.device_manager.get_device_status(device_name)
        
        if status:
            state_text = []
            for key, value in status['state'].items():
                if key == 'power':
                    state_text.append('on' if value else 'off')
                elif key == 'brightness':
                    state_text.append(f'{value}% brightness')
                elif key == 'temperature':
                    state_text.append(f'{value} degrees')
                else:
                    state_text.append(f'{key}: {value}')
            
            response = f"The {status['name']} is {', '.join(state_text)}"
            
            return {
                'success': True,
                'response': response,
                'status': status
            }
        else:
            return {
                'success': False,
                'response': f'Device "{device_name}" not found'
            }
    
    def _handle_activate_scene(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Handle scene activation command."""
        scene_name = entities.get('scene', '')
        
        if not scene_name:
            return {'success': False, 'response': 'Which scene would you like to activate?'}
        
        success = self.scene_manager.activate_scene(scene_name)
        
        if success:
            return {
                'success': True,
                'response': f'Activated the {scene_name} scene',
                'scene': scene_name
            }
        else:
            return {
                'success': False,
                'response': f'Failed to activate the {scene_name} scene'
            }

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="Voice Home Automation",
        page_icon="üè†",
        layout="wide"
    )
    
    st.title("üè† Voice-controlled Home Automation Chatbot")
    st.markdown("Control your smart home with natural voice commands")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        openai_api_key = st.text_input("OpenAI API Key (Optional)", type="password")
        
        st.header("üéôÔ∏è Voice Settings")
        speech_rate = st.slider("Speech Rate", 100, 300, 150)
        speech_volume = st.slider("Speech Volume", 0.0, 1.0, 0.8)
        
        st.header("üè† System Status")
        if 'automation' in st.session_state:
            automation = st.session_state['automation']
            online_devices = sum(1 for d in automation.device_manager.devices.values() 
                               if isinstance(d, IoTDevice) and d.is_online)
            st.metric("Online Devices", online_devices)
            st.metric("Available Scenes", len(automation.scene_manager.scenes))
    
    # Initialize automation system
    if 'automation' not in st.session_state:
        with st.spinner("Initializing voice automation system..."):
            st.session_state['automation'] = VoiceHomeAutomation(openai_api_key)
            st.success("Voice automation system ready!")
    
    automation = st.session_state['automation']
    
    # Update speech settings
    automation.speech_processor.set_voice_properties(rate=speech_rate, volume=speech_volume)
    
    # Main tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "üéôÔ∏è Voice Control",
        "üè† Device Management",
        "üé¨ Scenes & Automation",
        "üìä System Analytics"
    ])
    
    with tab1:
        st.header("üéôÔ∏è Voice Command Interface")
        
        # Manual text input for testing
        st.subheader("üí¨ Text Command Input")
        
        command_text = st.text_input(
            "Enter command:",
            placeholder="e.g., turn on the living room light, set thermostat to 22 degrees"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üöÄ Execute Command", type="primary"):
                if command_text:
                    with st.spinner("Processing command..."):
                        result = automation.process_voice_command(command_text)
                        
                        if result['success']:
                            st.success(f"‚úÖ {result['response']}")
                        else:
                            st.error(f"‚ùå {result['response']}")
        
        with col2:
            if st.button("üé§ Start Voice Listening"):
                st.info("Voice listening would start here (requires microphone access)")
        
        # Quick command buttons
        st.subheader("‚ö° Quick Commands")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üí° All Lights On"):
                automation.process_voice_command("turn on all lights")
        
        with col2:
            if st.button("üåô Good Night"):
                automation.process_voice_command("activate good night scene")
        
        with col3:
            if st.button("üå°Ô∏è Set to 22¬∞C"):
                automation.process_voice_command("set temperature to 22")
        
        with col4:
            if st.button("üîí Lock Doors"):
                automation.process_voice_command("lock the front door")
        
        # Command history
        st.subheader("üìú Recent Commands")
        
        if automation.command_history:
            history_df = pd.DataFrame([
                {
                    'Time': cmd.timestamp.strftime('%H:%M:%S'),
                    'Command': cmd.raw_text,
                    'Intent': cmd.intent,
                    'Confidence': f"{cmd.confidence:.1%}"
                }
                for cmd in automation.command_history[-10:]
            ])
            
            st.dataframe(history_df, use_container_width=True)
        else:
            st.info("No commands executed yet.")
    
    with tab2:
        st.header("üè† Smart Home Device Management")
        
        # Device overview
        devices = [d for d in automation.device_manager.devices.values() 
                  if isinstance(d, IoTDevice)]
        
        if devices:
            # Device status cards
            for device in devices:
                with st.expander(f"üîß {device.name.title()} ({device.location})"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**Type:** {device.device_type.value.title()}")
                        st.write(f"**Status:** {'üü¢ Online' if device.is_online else 'üî¥ Offline'}")
                        st.write(f"**Protocol:** {device.protocol.upper()}")
                        
                        if device.last_seen:
                            st.write(f"**Last Seen:** {device.last_seen.strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    with col2:
                        st.write("**Current State:**")
                        for key, value in device.current_state.items():
                            if isinstance(value, bool):
                                status = "‚úÖ On" if value else "‚ùå Off"
                                st.write(f"‚Ä¢ {key.title()}: {status}")
                            else:
                                st.write(f"‚Ä¢ {key.title()}: {value}")
                    
                    # Device controls
                    st.write("**Quick Controls:**")
                    control_col1, control_col2, control_col3 = st.columns(3)
                    
                    with control_col1:
                        if st.button(f"Turn On", key=f"on_{device.device_id}"):
                            automation.process_voice_command(f"turn on the {device.name}")
                            st.rerun()
                    
                    with control_col2:
                        if st.button(f"Turn Off", key=f"off_{device.device_id}"):
                            automation.process_voice_command(f"turn off the {device.name}")
                            st.rerun()
                    
                    with control_col3:
                        if st.button(f"Check Status", key=f"status_{device.device_id}"):
                            automation.process_voice_command(f"check the {device.name} status")
        
        # Device statistics
        st.subheader("üìä Device Statistics")
        
        device_types = {}
        online_count = 0
        
        for device in devices:
            device_type = device.device_type.value
            device_types[device_type] = device_types.get(device_type, 0) + 1
            if device.is_online:
                online_count += 1
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Devices", len(devices))
        with col2:
            st.metric("Online Devices", online_count)
        with col3:
            st.metric("Device Types", len(device_types))
        
        # Device type distribution
        if device_types:
            fig = px.pie(
                values=list(device_types.values()),
                names=list(device_types.keys()),
                title="Device Type Distribution"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.header("üé¨ Scenes & Automation")
        
        # Available scenes
        st.subheader("üé≠ Available Scenes")
        
        scenes = automation.scene_manager.scenes
        
        for scene_name, scene in scenes.items():
            with st.expander(f"üé¨ {scene.name.title()}"):
                st.write(f"**Description:** {scene.description}")
                st.write(f"**Activation Count:** {scene.activation_count}")
                
                st.write("**Device Actions:**")
                for device_name, state in scene.device_states.items():
                    state_text = ", ".join([f"{k}: {v}" for k, v in state.items()])
                    st.write(f"‚Ä¢ {device_name.title()}: {state_text}")
                
                if st.button(f"Activate Scene", key=f"scene_{scene.scene_id}"):
                    automation.process_voice_command(f"activate {scene.name} scene")
                    st.rerun()
        
        # Create new scene
        st.subheader("‚ûï Create New Scene")
        
        with st.form("new_scene"):
            scene_name = st.text_input("Scene Name")
            scene_description = st.text_area("Description")
            
            st.write("**Device States:**")
            
            # Simple device state configuration
            devices = [d for d in automation.device_manager.devices.values() 
                      if isinstance(d, IoTDevice)]
            
            device_states = {}
            
            for device in devices[:3]:  # Limit for demo
                st.write(f"**{device.name.title()}:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    power = st.selectbox(f"Power", ["No Change", "On", "Off"], 
                                       key=f"power_{device.device_id}")
                
                with col2:
                    if device.device_type == DeviceType.LIGHT:
                        brightness = st.slider("Brightness", 0, 100, 50, 
                                             key=f"brightness_{device.device_id}")
                        if power != "No Change":
                            device_states[device.name] = {
                                "power": power == "On",
                                "brightness": brightness
                            }
            
            if st.form_submit_button("Create Scene"):
                if scene_name and device_states:
                    new_scene = Scene(
                        scene_id=scene_name.lower().replace(' ', '_'),
                        name=scene_name.lower(),
                        description=scene_description,
                        device_states=device_states
                    )
                    
                    automation.scene_manager.scenes[new_scene.name] = new_scene
                    st.success(f"Created scene: {scene_name}")
                    st.rerun()
                else:
                    st.error("Please provide scene name and at least one device state")
    
    with tab4:
        st.header("üìä System Analytics")
        
        # Command statistics
        if automation.command_history:
            st.subheader("üìà Command Usage")
            
            # Intent distribution
            intent_counts = {}
            for cmd in automation.command_history:
                intent = cmd.intent
                intent_counts[intent] = intent_counts.get(intent, 0) + 1
            
            if intent_counts:
                fig = px.bar(
                    x=list(intent_counts.keys()),
                    y=list(intent_counts.values()),
                    title="Command Intent Distribution",
                    labels={'x': 'Intent Type', 'y': 'Count'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Confidence levels
            confidence_scores = [cmd.confidence for cmd in automation.command_history]
            
            if confidence_scores:
                fig = px.histogram(
                    x=confidence_scores,
                    title="Intent Classification Confidence",
                    labels={'x': 'Confidence Score', 'y': 'Count'},
                    nbins=20
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Recent activity timeline
            st.subheader("üïí Recent Activity")
            
            if len(automation.command_history) > 0:
                activity_df = pd.DataFrame([
                    {
                        'Time': cmd.timestamp,
                        'Command': cmd.raw_text,
                        'Intent': cmd.intent,
                        'Confidence': cmd.confidence
                    }
                    for cmd in automation.command_history[-20:]
                ])
                
                fig = px.scatter(
                    activity_df,
                    x='Time',
                    y='Confidence',
                    color='Intent',
                    hover_data=['Command'],
                    title="Command Confidence Over Time"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # System performance
        st.subheader("‚ö° System Performance")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_commands = len(automation.command_history)
            st.metric("Total Commands", total_commands)
        
        with col2:
            if automation.command_history:
                avg_confidence = np.mean([cmd.confidence for cmd in automation.command_history])
                st.metric("Avg Confidence", f"{avg_confidence:.1%}")
            else:
                st.metric("Avg Confidence", "N/A")
        
        with col3:
            successful_intents = len([cmd for cmd in automation.command_history 
                                    if cmd.intent != 'unknown'])
            success_rate = successful_intents / max(total_commands, 1)
            st.metric("Success Rate", f"{success_rate:.1%}")
        
        with col4:
            scene_activations = sum(scene.activation_count 
                                  for scene in automation.scene_manager.scenes.values())
            st.metric("Scene Activations", scene_activations)

if __name__ == "__main__":
    main()
````

## Project Summary

The Voice-controlled Home Automation Chatbot represents a sophisticated IoT integration system that transforms natural speech into intelligent home automation through advanced natural language processing, multi-protocol device communication, and context-aware scene orchestration.

### Key Value Propositions:
- **Natural Language Interface**: Intuitive voice commands with conversational context understanding for effortless smart home control
- **Multi-Protocol IoT Integration**: Comprehensive device support across MQTT, HTTP, and WebSocket protocols with real-time status monitoring
- **Intelligent Intent Mapping**: Advanced NLP processing that converts abstract commands into specific device actions with confidence scoring
- **Scene-Based Automation**: Coordinated multi-device control with customizable scenes and adaptive routine learning
- **Conversational Context Management**: Maintains dialogue history and user preferences for natural multi-turn interactions

### Technical Highlights:
- Advanced speech processing pipeline with automatic speech recognition and text-to-speech synthesis
- LangChain-powered intent classification with OpenAI integration for complex command understanding
- Asynchronous IoT device management supporting multiple communication protocols with error recovery
- Real-time device state monitoring with automatic discovery and status synchronization
- Interactive Streamlit interface providing voice control simulation, device management, and system analytics
- Modular architecture enabling easy integration of new device types and automation protocols

This system demonstrates how AI can make smart home technology accessible through natural voice interaction, eliminating technical barriers while providing powerful automation capabilities that adapt to user behavior and preferences for enhanced living experiences.