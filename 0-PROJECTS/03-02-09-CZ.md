<small>Claude Sonnet 4 **(Scientific Paper Explorer pro Inženýry)**</small>
# Scientific Paper Explorer for Engineers

## Klíčové Koncepty

### RAG (Retrieval-Augmented Generation)
RAG je architektura, která kombinuje vyhledávání relevantních dokumentů s generováním odpovědí pomocí LLM. Umožňuje AI systémům pracovat s aktuálními a specifickými daty bez nutnosti přetrénování modelu.

### LlamaIndex
Framework pro budování RAG aplikací, který poskytuje nástroje pro indexování, dotazování a integraci různých datových zdrojů s LLM modely.

### ArXiv API
Veřejné API pro přístup k vědeckým publikacím z arXiv.org databáze, umožňující programové vyhledávání a stahování vědeckých článků.

### Embedding Comparison
Technika porovnávání vektorových reprezentací textu pro nalezení sémanticky podobných dokumentů nebo pasáží.

### Visual Search
Vizuální rozhraní pro vyhledávání a procházení výsledků, často s grafickými prvky pro lepší uživatelský zážitek.

### Streamlit UI
Python framework pro rychlé vytváření webových aplikací s interaktivními komponenty pro data science a ML projekty.

## Komplexní Vysvětlení Projektu

Scientific Paper Explorer je pokročilý RAG systém navržený specificky pro inženýry a výzkumníky. Projekt řeší problém efektivního vyhledávání a extrakce relevantních informací z obrovského množství vědeckých publikací.

### Hlavní Cíle:
- **Inteligentní vyhledávání**: Najít relevantní články na základě technických dotazů
- **Extrakce metod**: Automaticky identifikovat a extrahovat specifické metodologie
- **Analýza evaluací**: Porovnat výsledky a metriky různých přístupů
- **Vizuální exploraci**: Poskytovat intuitivní rozhraní pro procházení výsledků

### Technické Výzvy:
- Zpracování velkého objemu vědeckých textů
- Sémantické porozumění technickým termínům
- Efektivní indexování a vyhledávání
- Přesná extrakce strukturovaných informací

### Potenciální Dopad:
- Urychlení výzkumného procesu
- Lepší přehled o současném stavu technologií
- Identifikace výzkumných mezer
- Podpora evidence-based rozhodování

## Komplexní Implementace v Pythonu

````python
streamlit==1.29.0
llama-index==0.9.15
openai==1.3.7
arxiv==1.4.8
sentence-transformers==2.2.2
chromadb==0.4.18
plotly==5.17.0
pandas==2.1.4
numpy==1.24.3
python-dotenv==1.0.0
````

````python
import os
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class Config:
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"
    LLM_MODEL: str = "gpt-3.5-turbo"
    CHROMA_PERSIST_DIR: str = "./chroma_db"
    MAX_PAPERS_PER_QUERY: int = 50
    CHUNK_SIZE: int = 1024
    CHUNK_OVERLAP: int = 200
    
    def validate(self) -> bool:
        if not self.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY musí být nastaven")
        return True

CONFIG = Config()
````

````python
import arxiv
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Paper:
    title: str
    authors: List[str]
    abstract: str
    published: datetime
    arxiv_id: str
    pdf_url: str
    categories: List[str]

class ArxivClient:
    def __init__(self, max_results: int = 50):
        self.max_results = max_results
        self.client = arxiv.Client()
        
    def search_papers(self, query: str, categories: Optional[List[str]] = None) -> List[Paper]:
        """Vyhledá články na ArXiv podle dotazu"""
        try:
            # Sestavení vyhledávacího dotazu
            search_query = query
            if categories:
                cat_query = " OR ".join([f"cat:{cat}" for cat in categories])
                search_query = f"({query}) AND ({cat_query})"
            
            search = arxiv.Search(
                query=search_query,
                max_results=self.max_results,
                sort_by=arxiv.SortCriterion.Relevance,
                sort_order=arxiv.SortOrder.Descending
            )
            
            papers = []
            for result in self.client.results(search):
                paper = Paper(
                    title=result.title,
                    authors=[author.name for author in result.authors],
                    abstract=result.summary,
                    published=result.published,
                    arxiv_id=result.entry_id.split('/')[-1],
                    pdf_url=result.pdf_url,
                    categories=[cat for cat in result.categories]
                )
                papers.append(paper)
                
            logging.info(f"Nalezeno {len(papers)} článků pro dotaz: {query}")
            return papers
            
        except Exception as e:
            logging.error(f"Chyba při vyhledávání na ArXiv: {e}")
            return []
    
    def get_engineering_categories(self) -> List[str]:
        """Vrátí seznam inženýrských kategorií na ArXiv"""
        return [
            "cs.AI",  # Artificial Intelligence
            "cs.LG",  # Machine Learning
            "cs.CV",  # Computer Vision
            "cs.RO",  # Robotics
            "cs.SY",  # Systems and Control
            "eess.SP", # Signal Processing
            "math.OC", # Optimization and Control
            "stat.ML"  # Machine Learning (Statistics)
        ]
````

````python
import chromadb
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from llama_index import Document, VectorStoreIndex, ServiceContext
from llama_index.vector_stores import ChromaVectorStore
from llama_index.storage.storage_context import StorageContext
import logging

class EmbeddingManager:
    def __init__(self, model_name: str, persist_dir: str):
        self.model = SentenceTransformer(model_name)
        self.persist_dir = persist_dir
        self.chroma_client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.chroma_client.get_or_create_collection(
            name="scientific_papers",
            metadata={"hnsw:space": "cosine"}
        )
        
    def add_papers(self, papers: List[Any]) -> None:
        """Přidá články do vektorové databáze"""
        try:
            documents = []
            metadatas = []
            ids = []
            
            for i, paper in enumerate(papers):
                # Kombinace title a abstract pro lepší embedding
                content = f"Název: {paper.title}\n\nAbstrakt: {paper.abstract}"
                
                documents.append(content)
                metadatas.append({
                    "title": paper.title,
                    "authors": ", ".join(paper.authors),
                    "arxiv_id": paper.arxiv_id,
                    "categories": ", ".join(paper.categories),
                    "published": paper.published.isoformat(),
                    "pdf_url": paper.pdf_url
                })
                ids.append(f"paper_{paper.arxiv_id}_{i}")
            
            # Generování embeddingů
            embeddings = self.model.encode(documents).tolist()
            
            # Přidání do ChromaDB
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            
            logging.info(f"Přidáno {len(papers)} článků do vektorové databáze")
            
        except Exception as e:
            logging.error(f"Chyba při přidávání článků: {e}")
    
    def search_similar(self, query: str, n_results: int = 5) -> List[Dict]:
        """Vyhledá podobné články na základě dotazu"""
        try:
            query_embedding = self.model.encode([query]).tolist()
            
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=n_results,
                include=['documents', 'metadatas', 'distances']
            )
            
            similar_papers = []
            for i in range(len(results['documents'][0])):
                similar_papers.append({
                    'document': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'similarity': 1 - results['distances'][0][i]  # Konverze distance na similarity
                })
                
            return similar_papers
            
        except Exception as e:
            logging.error(f"Chyba při vyhledávání: {e}")
            return []
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """Vrátí statistiky kolekce"""
        try:
            count = self.collection.count()
            return {
                "total_papers": count,
                "collection_name": self.collection.name
            }
        except Exception as e:
            logging.error(f"Chyba při získávání statistik: {e}")
            return {"total_papers": 0, "collection_name": "unknown"}
````

````python
import openai
from typing import List, Dict, Any, Optional
import json
import logging
from config import CONFIG

class LLMAnalyzer:
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        openai.api_key = api_key
        self.model = model
    
    def extract_methods(self, paper_content: str) -> Dict[str, Any]:
        """Extrahuje metodologie z článku"""
        prompt = f"""
        Analyzuj následující vědecký článek a extrahuj hlavní metodologie a přístupy.
        
        Článek:
        {paper_content[:3000]}...
        
        Vrať odpověď ve formátu JSON s následujícími klíči:
        - "main_methods": seznam hlavních metod
        - "algorithms": seznam algoritmů
        - "technologies": seznam použitých technologií
        - "evaluation_metrics": seznam evaluačních metrik
        
        Odpověz pouze JSON bez dalšího textu.
        """
        
        try:
            response = openai.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logging.error(f"Chyba při extrakci metod: {e}")
            return {
                "main_methods": [],
                "algorithms": [],
                "technologies": [],
                "evaluation_metrics": []
            }
    
    def compare_papers(self, papers: List[Dict]) -> str:
        """Porovná více článků"""
        papers_summary = "\n\n".join([
            f"Článek {i+1}: {paper['metadata']['title']}\n"
            f"Autoři: {paper['metadata']['authors']}\n"
            f"Abstrakt: {paper['document'][:500]}..."
            for i, paper in enumerate(papers[:3])
        ])
        
        prompt = f"""
        Porovnej následující vědecké články z hlediska:
        1. Použitých metod a přístupů
        2. Výsledků a výkonu
        3. Inovací a přínosů
        4. Omezení a nevýhod
        
        Články:
        {papers_summary}
        
        Napiš strukturované porovnání v češtině.
        """
        
        try:
            response = openai.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logging.error(f"Chyba při porovnávání článků: {e}")
            return "Chyba při analýze článků."
    
    def answer_question(self, question: str, context_papers: List[Dict]) -> str:
        """Odpovídá na otázky na základě kontextu článků"""
        context = "\n\n".join([
            f"Článek: {paper['metadata']['title']}\n{paper['document'][:1000]}..."
            for paper in context_papers[:5]
        ])
        
        prompt = f"""
        Na základě následujících vědeckých článků odpověz na otázku:
        
        Otázka: {question}
        
        Kontext z článků:
        {context}
        
        Poskytni podrobnou odpověď v češtině s odkazy na konkrétní články.
        """
        
        try:
            response = openai.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logging.error(f"Chyba při odpovídání na otázku: {e}")
            return "Nepodařilo se zpracovat otázku."
````

````python
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import List, Dict

from config import CONFIG
from arxiv_client import ArxivClient, Paper
from embedding_manager import EmbeddingManager
from llm_analyzer import LLMAnalyzer

# Konfigurace loggingu
logging.basicConfig(level=logging.INFO)

@st.cache_resource
def initialize_components():
    """Inicializuje komponenty aplikace"""
    try:
        CONFIG.validate()
        arxiv_client = ArxivClient(max_results=CONFIG.MAX_PAPERS_PER_QUERY)
        embedding_manager = EmbeddingManager(
            model_name=CONFIG.EMBEDDING_MODEL,
            persist_dir=CONFIG.CHROMA_PERSIST_DIR
        )
        llm_analyzer = LLMAnalyzer(
            api_key=CONFIG.OPENAI_API_KEY,
            model=CONFIG.LLM_MODEL
        )
        return arxiv_client, embedding_manager, llm_analyzer
    except Exception as e:
        st.error(f"Chyba při inicializaci: {e}")
        return None, None, None

def create_papers_dataframe(papers: List[Paper]) -> pd.DataFrame:
    """Vytvoří DataFrame z článků pro vizualizaci"""
    data = []
    for paper in papers:
        data.append({
            'title': paper.title,
            'authors': ', '.join(paper.authors[:3]),  # První 3 autoři
            'published': paper.published.date(),
            'categories': ', '.join(paper.categories),
            'arxiv_id': paper.arxiv_id,
            'year': paper.published.year
        })
    return pd.DataFrame(data)

def visualize_papers_timeline(df: pd.DataFrame):
    """Vytvoří timeline vizualizaci článků"""
    if df.empty:
        return
    
    yearly_counts = df.groupby('year').size().reset_index(name='count')
    
    fig = px.bar(
        yearly_counts, 
        x='year', 
        y='count',
        title='Distribuce článků podle roku publikace',
        labels={'year': 'Rok', 'count': 'Počet článků'}
    )
    
    st.plotly_chart(fig, use_container_width=True)

def visualize_similarity_scores(results: List[Dict]):
    """Vizualizuje skóre podobnosti"""
    if not results:
        return
    
    titles = [r['metadata']['title'][:50] + '...' for r in results]
    similarities = [r['similarity'] for r in results]
    
    fig = go.Figure(data=go.Bar(
        x=similarities,
        y=titles,
        orientation='h',
        text=[f"{s:.3f}" for s in similarities],
        textposition='auto'
    ))
    
    fig.update_layout(
        title='Míra podobnosti nalezených článků',
        xaxis_title='Skóre podobnosti',
        yaxis_title='Články',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)

def main():
    st.set_page_config(
        page_title="Scientific Paper Explorer",
        page_icon="🔬",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("🔬 Scientific Paper Explorer pro Inženýry")
    st.markdown("*Inteligentní vyhledávání a analýza vědeckých publikací*")
    
    # Inicializace komponent
    arxiv_client, embedding_manager, llm_analyzer = initialize_components()
    
    if not all([arxiv_client, embedding_manager, llm_analyzer]):
        st.error("Nepodařilo se inicializovat aplikaci. Zkontrolujte konfiguraci.")
        return
    
    # Sidebar
    with st.sidebar:
        st.header("⚙️ Nastavení")
        
        # Statistiky databáze
        stats = embedding_manager.get_collection_stats()
        st.metric("Články v databázi", stats['total_papers'])
        
        st.markdown("---")
        
        # Kategorie
        categories = arxiv_client.get_engineering_categories()
        selected_categories = st.multiselect(
            "Vyberte kategorie:",
            categories,
            default=["cs.AI", "cs.LG"],
            help="Zvolte oblasti pro vyhledávání"
        )
    
    # Hlavní rozhraní
    col1, col2 = st.columns([2, 1])
    
    with col1:
        search_query = st.text_input(
            "🔍 Vyhledávací dotaz:",
            placeholder="např. 'neural networks for computer vision'",
            help="Zadejte technický dotaz v angličtině"
        )
    
    with col2:
        search_mode = st.selectbox(
            "Režim vyhledávání:",
            ["Sémantické", "ArXiv API"],
            help="Sémantické - v lokální databázi, ArXiv API - nové články"
        )
    
    if st.button("🚀 Vyhledat", type="primary"):
        if search_query:
            with st.spinner("Vyhledávám články..."):
                
                if search_mode == "ArXiv API":
                    # Vyhledání nových článků
                    papers = arxiv_client.search_papers(search_query, selected_categories)
                    
                    if papers:
                        st.success(f"Nalezeno {len(papers)} nových článků")
                        
                        # Přidání do databáze
                        with st.spinner("Přidávám články do databáze..."):
                            embedding_manager.add_papers(papers)
                        
                        # Vytvoření DataFrame pro vizualizaci
                        df = create_papers_dataframe(papers)
                        
                        # Zobrazení timeline
                        st.subheader("📊 Timeline publikací")
                        visualize_papers_timeline(df)
                        
                        # Zobrazení článků
                        st.subheader("📄 Nalezené články")
                        for i, paper in enumerate(papers[:10]):
                            with st.expander(f"{i+1}. {paper.title}"):
                                st.write(f"**Autoři:** {', '.join(paper.authors)}")
                                st.write(f"**Publikováno:** {paper.published.date()}")
                                st.write(f"**Kategorie:** {', '.join(paper.categories)}")
                                st.write(f"**ArXiv ID:** {paper.arxiv_id}")
                                st.write("**Abstrakt:**")
                                st.write(paper.abstract)
                                st.markdown(f"[📑 PDF]({paper.pdf_url})")
                    else:
                        st.warning("Nebyl nalezen žádný článek pro daný dotaz")
                
                else:
                    # Sémantické vyhledávání v databázi
                    results = embedding_manager.search_similar(search_query, n_results=10)
                    
                    if results:
                        st.success(f"Nalezeno {len(results)} podobných článků")
                        
                        # Vizualizace podobnosti
                        st.subheader("📊 Míra podobnosti")
                        visualize_similarity_scores(results)
                        
                        # Zobrazení výsledků
                        st.subheader("🎯 Nejpodobnější články")
                        for i, result in enumerate(results):
                            with st.expander(
                                f"{i+1}. {result['metadata']['title']} "
                                f"(podobnost: {result['similarity']:.3f})"
                            ):
                                st.write(f"**Autoři:** {result['metadata']['authors']}")
                                st.write(f"**ArXiv ID:** {result['metadata']['arxiv_id']}")
                                st.write(f"**Kategorie:** {result['metadata']['categories']}")
                                st.write("**Obsah:**")
                                st.write(result['document'][:1000] + "...")
                                
                                # Analýza metodologií
                                if st.button(f"🔬 Analyzovat metody #{i+1}", key=f"analyze_{i}"):
                                    with st.spinner("Analyzuji metodologie..."):
                                        methods = llm_analyzer.extract_methods(result['document'])
                                        
                                        col_a, col_b = st.columns(2)
                                        with col_a:
                                            if methods['main_methods']:
                                                st.write("**Hlavní metody:**")
                                                for method in methods['main_methods']:
                                                    st.write(f"• {method}")
                                            
                                            if methods['algorithms']:
                                                st.write("**Algoritmy:**")
                                                for algo in methods['algorithms']:
                                                    st.write(f"• {algo}")
                                        
                                        with col_b:
                                            if methods['technologies']:
                                                st.write("**Technologie:**")
                                                for tech in methods['technologies']:
                                                    st.write(f"• {tech}")
                                            
                                            if methods['evaluation_metrics']:
                                                st.write("**Evaluační metriky:**")
                                                for metric in methods['evaluation_metrics']:
                                                    st.write(f"• {metric}")
                        
                        # Porovnání článků
                        if len(results) > 1:
                            st.subheader("⚖️ Porovnání článků")
                            if st.button("📊 Porovnat top 3 články"):
                                with st.spinner("Porovnávám články..."):
                                    comparison = llm_analyzer.compare_papers(results[:3])
                                    st.write(comparison)
                        
                        # Q&A sekce
                        st.subheader("❓ Zeptejte se na články")
                        question = st.text_input(
                            "Položte otázku související s nalezenými články:",
                            placeholder="např. 'Jaké jsou hlavní výhody navržených metod?'"
                        )
                        
                        if question and st.button("💬 Odpovědět"):
                            with st.spinner("Generuji odpověď..."):
                                answer = llm_analyzer.answer_question(question, results)
                                st.write(answer)
                    
                    else:
                        st.warning("Nebyl nalezen žádný podobný článek v databázi")
        else:
            st.warning("Zadejte vyhledávací dotaz")
    
    # Footer
    st.markdown("---")
    st.markdown(
        "**Scientific Paper Explorer** | "
        "Vytvořeno s ❤️ pomocí Streamlit, LlamaIndex a OpenAI"
    )

if __name__ == "__main__":
    main()
````

````python
# Zkopírujte tento soubor jako .env a vyplňte hodnoty
OPENAI_API_KEY=your_openai_api_key_here
````

````python
import subprocess
import sys
import os

def setup_environment():
    """Nastaví prostředí a spustí aplikaci"""
    print("🔧 Nastavuji prostředí...")
    
    # Instalace závislostí
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
    
    # Kontrola .env souboru
    if not os.path.exists(".env"):
        print("⚠️  Vytvořte .env soubor s OPENAI_API_KEY")
        print("Příklad najdete v .env.example")
        return False
    
    return True

def main():
    if setup_environment():
        print("🚀 Spouštím Scientific Paper Explorer...")
        subprocess.run([sys.executable, "-m", "streamlit", "run", "app.py"])
    else:
        print("❌ Nepodařilo se nastavit prostředí")

if __name__ == "__main__":
    main()
````

## Shrnutí Projektu

Scientific Paper Explorer představuje pokročilý RAG systém specificky navržený pro potřeby inženýrů a výzkumníků. Projekt kombinuje sílu moderních AI technologií s intuitivním uživatelským rozhraním.

### Klíčové Hodnoty:
- **Efektivita**: Dramaticky snižuje čas potřebný pro vyhledávání relevantních publikací
- **Přesnost**: Sémantické vyhledávání poskytuje relevantnější výsledky než klasické fulltextové
- **Inteligence**: LLM analýza extrahuje strukturované informace a umožňuje komplexní dotazy
- **Škálovatelnost**: Architektura podporuje růst databáze bez ztráty výkonu

### Technologické Inovace:
- **Hybridní vyhledávání**: Kombinace ArXiv API s lokální vektorovou databází
- **Multimodální analýza**: Zpracování textu, metadat i vizuálních prvků
- **Inteligentní extrakce**: Automatická identifikace metodologií a evaluačních metrik
- **Interaktivní Q&A**: Možnost pokládat komplexní otázky nad kolekcí článků

Projekt demonstruje praktickou aplikaci RAG architektury v reálném prostředí a poskytuje základ pro další rozšíření směrem k plně autonomnímu výzkumnému asistentovi.