<small>Claude Sonnet 4 **(AI Debate Team - Multi-agentnÃ­ systÃ©m pro strukturovanÃ© debaty)**</small>
# AI Debate Team

## KlÃ­ÄovÃ© koncepty

### Multi-Agent Prompt Chaining
**Multi-Agent Prompt Chaining** je technika, kdy se jednotlivÃ© AI agenti postupnÄ› pÅ™edÃ¡vajÃ­ informace a vÃ½stupy svÃ½ch rozhodnutÃ­ dalÅ¡Ã­m agentÅ¯m v Å™etÄ›zci. KaÅ¾dÃ½ agent mÃ¡ specifickou roli a vyuÅ¾Ã­vÃ¡ vÃ½stup pÅ™edchozÃ­ho agenta jako vstup pro svÃ© zpracovÃ¡nÃ­.

### Role-Specific LLMs
**Role-Specific LLMs** jsou jazykovÃ© modely optimalizovanÃ© nebo nakonfigurovanÃ© pro konkrÃ©tnÃ­ role a Ãºkoly. KaÅ¾dÃ½ agent mÃ¡ definovanÃ© chovÃ¡nÃ­, styl komunikace a specializaci podle svÃ© role v systÃ©mu.

### Memory systÃ©m
**Memory** v kontextu AI agentÅ¯ oznaÄuje schopnost uchovat a vyuÅ¾Ã­vat informace z pÅ™edchozÃ­ch interakcÃ­. MÅ¯Å¾e bÃ½t krÃ¡tkodobÃ¡ (v rÃ¡mci konverzace) nebo dlouhodobÃ¡ (perzistentnÃ­ napÅ™Ã­Ä sezenÃ­mi).

### Persuasion Logic
**Persuasion Logic** je logickÃ½ systÃ©m pro konstrukci pÅ™esvÄ›dÄivÃ½ch argumentÅ¯, zahrnujÃ­cÃ­ techniky jako ethos, pathos, logos a strukturovanÃ© argumentaÄnÃ­ vzorce.

## KomplexnÃ­ vysvÄ›tlenÃ­ projektu

AI Debate Team je sofistikovanÃ½ multi-agentnÃ­ systÃ©m navrÅ¾enÃ½ pro vedenÃ­ strukturovanÃ½ch debat na libovolnÃ¡ tÃ©mata. SystÃ©m kombinuje nÄ›kolik specializovanÃ½ch AI agentÅ¯, z nichÅ¾ kaÅ¾dÃ½ mÃ¡ jedineÄnou roli v debatnÃ­m procesu.

### HlavnÃ­ cÃ­le projektu:
- **Automatizace debatnÃ­ch procesÅ¯** s vysokou kvalitou argumentace
- **Simulace reÃ¡lnÃ½ch debat** s rÅ¯znÃ½mi perspektivami a nÃ¡zory  
- **VzdÄ›lÃ¡vacÃ­ nÃ¡stroj** pro pochopenÃ­ rÅ¯znÃ½ch ÃºhlÅ¯ pohledu na kontroverznÃ­ tÃ©mata
- **InteraktivnÃ­ platforma** umoÅ¾ÅˆujÃ­cÃ­ divÃ¡kÅ¯m klÃ¡st otÃ¡zky a moderovat diskusi

### Architektura systÃ©mu:
SystÃ©m se sklÃ¡dÃ¡ z nÃ¡sledujÃ­cÃ­ch agentÅ¯:
- **Pro Agent**: Argumentuje ve prospÄ›ch danÃ©ho tÃ©matu
- **Kontra Agent**: Prezentuje argumenty proti tÃ©matu
- **ModerÃ¡tor**: Å˜Ã­dÃ­ prÅ¯bÄ›h debaty a strukturu
- **Fact-Checker**: OvÄ›Å™uje faktickÃ© tvrzenÃ­
- **Audience Manager**: ZpracovÃ¡vÃ¡ otÃ¡zky z publika

### TechnickÃ© vÃ½zvy:
- **Koordinace mezi agenty** a udrÅ¾enÃ­ koherentnÃ­ho toku debaty
- **SprÃ¡va pamÄ›ti** pro sledovÃ¡nÃ­ argumentÅ¯ a protiargumentÅ¯
- **DynamickÃ© generovÃ¡nÃ­** pÅ™esvÄ›dÄivÃ½ch a fakticky sprÃ¡vnÃ½ch argumentÅ¯
- **Real-time zpracovÃ¡nÃ­** otÃ¡zek z publika

## KomplexnÃ­ pÅ™Ã­klad s Python implementacÃ­

````python
import asyncio
import json
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import openai
from anthropic import Anthropic
import streamlit as st
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage
import logging

# Konfigurace logovÃ¡nÃ­
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AgentRole(Enum):
    PRO = "pro"
    CONTRA = "contra"
    MODERATOR = "moderator"
    FACT_CHECKER = "fact_checker"
    AUDIENCE_MANAGER = "audience_manager"

@dataclass
class DebateStatement:
    agent_role: AgentRole
    content: str
    timestamp: datetime
    argument_type: str  # "opening", "rebuttal", "closing", "fact_check"
    confidence_score: float
    sources: List[str] = None

@dataclass
class DebateContext:
    topic: str
    current_round: int
    max_rounds: int
    statements: List[DebateStatement]
    audience_questions: List[str]
    fact_checks: List[Dict[str, Any]]

class PersuasionEngine:
    """Engine pro generovÃ¡nÃ­ pÅ™esvÄ›dÄivÃ½ch argumentÅ¯"""
    
    def __init__(self):
        self.argument_patterns = {
            "ethos": "Podle odbornÃ­kÅ¯ a uznÃ¡vanÃ½ch autorit...",
            "pathos": "PÅ™edstavte si dopad na...",
            "logos": "Statistiky a data jasnÄ› ukazujÃ­...",
            "analogy": "PodobnÄ› jako v pÅ™Ã­padÄ›...",
            "precedent": "Historie nÃ¡m ukazuje..."
        }
    
    def generate_argument_structure(self, stance: str, topic: str) -> Dict[str, str]:
        """Generuje strukturu argumentu na zÃ¡kladÄ› postoje a tÃ©matu"""
        return {
            "opening": f"HlavnÃ­ bod: {stance} pozice k {topic}",
            "evidence": "PodpÅ¯rnÃ© dÅ¯kazy a data",
            "reasoning": "LogickÃ© propojenÃ­ dÅ¯kazÅ¯ s tvrzenÃ­m",
            "conclusion": "ZÃ¡vÄ›reÄnÃ© shrnutÃ­ argumentu"
        }

class MemoryManager:
    """SprÃ¡vce pamÄ›ti pro tracking argumentÅ¯ a kontextu debaty"""
    
    def __init__(self, window_size: int = 20):
        self.conversation_memory = ConversationBufferWindowMemory(
            k=window_size,
            return_messages=True
        )
        self.argument_history = []
        self.fact_database = {}
        
    def add_statement(self, statement: DebateStatement):
        """PÅ™idÃ¡ vÃ½rok do pamÄ›ti"""
        self.argument_history.append(statement)
        self.conversation_memory.chat_memory.add_message(
            HumanMessage(content=f"{statement.agent_role.value}: {statement.content}")
        )
    
    def get_recent_context(self, num_statements: int = 5) -> List[DebateStatement]:
        """ZÃ­skÃ¡ poslednÃ­ vÃ½roky pro kontext"""
        return self.argument_history[-num_statements:] if self.argument_history else []
    
    def get_opposing_arguments(self, role: AgentRole) -> List[DebateStatement]:
        """ZÃ­skÃ¡ argumenty opozice"""
        opposing_roles = {
            AgentRole.PRO: AgentRole.CONTRA,
            AgentRole.CONTRA: AgentRole.PRO
        }
        
        if role not in opposing_roles:
            return []
            
        opposing_role = opposing_roles[role]
        return [stmt for stmt in self.argument_history if stmt.agent_role == opposing_role]

class BaseDebateAgent:
    """ZÃ¡kladnÃ­ tÅ™Ã­da pro debatnÃ­ agenty"""
    
    def __init__(self, role: AgentRole, api_key: str, model_provider: str = "openai"):
        self.role = role
        self.model_provider = model_provider
        self.memory_manager = MemoryManager()
        self.persuasion_engine = PersuasionEngine()
        
        if model_provider == "openai":
            openai.api_key = api_key
            self.model = "gpt-4"
        elif model_provider == "anthropic":
            self.anthropic_client = Anthropic(api_key=api_key)
            self.model = "claude-3-sonnet-20240229"
    
    async def generate_response(self, prompt: str, context: DebateContext) -> str:
        """Generuje odpovÄ›Ä podle typu modelu"""
        try:
            if self.model_provider == "openai":
                response = await openai.ChatCompletion.acreate(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.get_system_prompt()},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                return response.choices[0].message.content
            
            elif self.model_provider == "anthropic":
                response = await self.anthropic_client.messages.create(
                    model=self.model,
                    max_tokens=500,
                    messages=[
                        {"role": "user", "content": f"{self.get_system_prompt()}\n\n{prompt}"}
                    ]
                )
                return response.content[0].text
                
        except Exception as e:
            logger.error(f"Chyba pÅ™i generovÃ¡nÃ­ odpovÄ›di pro {self.role.value}: {e}")
            return "OmlouvÃ¡m se, doÅ¡lo k technickÃ© chybÄ› pÅ™i generovÃ¡nÃ­ odpovÄ›di."
    
    def get_system_prompt(self) -> str:
        """VracÃ­ systÃ©movÃ½ prompt specifickÃ½ pro roli agenta"""
        prompts = {
            AgentRole.PRO: """Jsi expert debater argumentujÃ­cÃ­ PRO danÃ½ nÃ¡vrh. 
                             TvÃ© argumenty musÃ­ bÃ½t logickÃ©, faktickÃ© a pÅ™esvÄ›dÄivÃ©.
                             PouÅ¾Ã­vej ethos, pathos a logos. BuÄ respektujÃ­cÃ­ k opozici.""",
            
            AgentRole.CONTRA: """Jsi expert debater argumentujÃ­cÃ­ PROTI danÃ©mu nÃ¡vrhu.
                               TvÃ© argumenty musÃ­ bÃ½t logickÃ©, faktickÃ© a pÅ™esvÄ›dÄivÃ©.
                               PouÅ¾Ã­vej ethos, pathos a logos. BuÄ respektujÃ­cÃ­ k opozici.""",
            
            AgentRole.MODERATOR: """Jsi profesionÃ¡lnÃ­ moderÃ¡tor debaty. UdrÅ¾uj neutralitu,
                                   Å™iÄ Äas, zajiÅ¡Å¥uj fair play a strukturuj diskusi.""",
            
            AgentRole.FACT_CHECKER: """Jsi fact-checker. OvÄ›Å™uj faktickÃ¡ tvrzenÃ­ v debatÄ›
                                      a poskytuj objektÃ­vnÃ­ korekce kdyÅ¾ je to potÅ™eba.""",
            
            AgentRole.AUDIENCE_MANAGER: """SpravujeÅ¡ otÃ¡zky z publika. Filtruj relevantnÃ­
                                          otÃ¡zky a formuluj je vhodnÄ› pro debatu."""
        }
        return prompts.get(self.role, "Jsi AI asistent.")

class ProAgent(BaseDebateAgent):
    """Agent argumentujÃ­cÃ­ pro danÃ½ nÃ¡vrh"""
    
    def __init__(self, api_key: str):
        super().__init__(AgentRole.PRO, api_key)
    
    async def create_argument(self, topic: str, context: DebateContext, argument_type: str) -> DebateStatement:
        """VytvoÅ™Ã­ argument pro danÃ½ nÃ¡vrh"""
        
        # ZÃ­skej kontext z opoziÄnÃ­ch argumentÅ¯
        opposing_args = self.memory_manager.get_opposing_arguments(self.role)
        recent_context = self.memory_manager.get_recent_context()
        
        prompt = f"""
        TÃ©ma debaty: {topic}
        Typ argumentu: {argument_type}
        Kolo: {context.current_round}/{context.max_rounds}
        
        OpoziÄnÃ© argumenty: {[arg.content for arg in opposing_args[-2:]] if opposing_args else "ZatÃ­m Å¾Ã¡dnÃ©"}
        PoslednÃ­ kontext: {[stmt.content for stmt in recent_context[-3:]] if recent_context else "ZaÄÃ¡tek debaty"}
        
        VytvoÅ™ silnÃ½, faktickÃ½ argument PRO danÃ½ nÃ¡vrh. PouÅ¾ij pÅ™esvÄ›dÄivÃ© techniky a reaguj na opozici pokud existuje.
        """
        
        content = await self.generate_response(prompt, context)
        
        statement = DebateStatement(
            agent_role=self.role,
            content=content,
            timestamp=datetime.now(),
            argument_type=argument_type,
            confidence_score=0.8,
            sources=[]
        )
        
        self.memory_manager.add_statement(statement)
        return statement

class ContraAgent(BaseDebateAgent):
    """Agent argumentujÃ­cÃ­ proti danÃ©mu nÃ¡vrhu"""
    
    def __init__(self, api_key: str):
        super().__init__(AgentRole.CONTRA, api_key)
    
    async def create_counter_argument(self, topic: str, context: DebateContext, argument_type: str) -> DebateStatement:
        """VytvoÅ™Ã­ protiargument"""
        
        opposing_args = self.memory_manager.get_opposing_arguments(self.role)
        recent_context = self.memory_manager.get_recent_context()
        
        prompt = f"""
        TÃ©ma debaty: {topic}
        Typ argumentu: {argument_type}
        Kolo: {context.current_round}/{context.max_rounds}
        
        PRO argumenty: {[arg.content for arg in opposing_args[-2:]] if opposing_args else "ZatÃ­m Å¾Ã¡dnÃ©"}
        PoslednÃ­ kontext: {[stmt.content for stmt in recent_context[-3:]] if recent_context else "ZaÄÃ¡tek debaty"}
        
        VytvoÅ™ silnÃ½ protiargument PROTI danÃ©mu nÃ¡vrhu. VyvraÅ¥ body opozice a pÅ™edloÅ¾ vlastnÃ­ dÅ¯kazy.
        """
        
        content = await self.generate_response(prompt, context)
        
        statement = DebateStatement(
            agent_role=self.role,
            content=content,
            timestamp=datetime.now(),
            argument_type=argument_type,
            confidence_score=0.8,
            sources=[]
        )
        
        self.memory_manager.add_statement(statement)
        return statement

class ModeratorAgent(BaseDebateAgent):
    """ModerÃ¡tor debaty"""
    
    def __init__(self, api_key: str):
        super().__init__(AgentRole.MODERATOR, api_key)
    
    async def introduce_debate(self, topic: str) -> str:
        """Ãšvod do debaty"""
        prompt = f"""
        ÃšvodnÃ­ slovo k debatÄ› na tÃ©ma: "{topic}"
        
        PÅ™edstav tÃ©ma, formÃ¡t debaty, pravidla a pÅ™edstav ÃºÄastnÃ­ky.
        BuÄ profesionÃ¡lnÃ­ a neutrÃ¡lnÃ­.
        """
        return await self.generate_response(prompt, DebateContext(topic, 0, 3, [], [], []))
    
    async def moderate_round(self, context: DebateContext) -> str:
        """Moderuje kolo debaty"""
        recent_statements = context.statements[-4:] if context.statements else []
        
        prompt = f"""
        ModerujeÅ¡ kolo {context.current_round} debaty na tÃ©ma: {context.topic}
        
        PoslednÃ­ vÃ½roky: {[f"{stmt.agent_role.value}: {stmt.content[:100]}..." for stmt in recent_statements]}
        
        ShrÅˆ dosavadnÃ­ argumenty, pÅ™Ã­padnÄ› poloÅ¾ nÃ¡slednÃ© otÃ¡zky nebo poznamenej klÃ­ÄovÃ© body.
        """
        return await self.generate_response(prompt, context)

class FactCheckerAgent(BaseDebateAgent):
    """Agent pro ovÄ›Å™ovÃ¡nÃ­ faktÅ¯"""
    
    def __init__(self, api_key: str):
        super().__init__(AgentRole.FACT_CHECKER, api_key)
    
    async def verify_statement(self, statement: DebateStatement) -> Dict[str, Any]:
        """OvÄ›Å™Ã­ faktickÃ© tvrzenÃ­"""
        prompt = f"""
        OvÄ›Å™ nÃ¡sledujÃ­cÃ­ tvrzenÃ­ z debaty:
        "{statement.content}"
        
        Analyzuj faktickou sprÃ¡vnost, identifikuj konkrÃ©tnÃ­ tvrzenÃ­ a ohodnoÅ¥ jejich vÄ›rohodnost.
        Pokud najdeÅ¡ nepÅ™esnosti, navrhni korekce.
        """
        
        verification = await self.generate_response(prompt, DebateContext("", 0, 0, [], [], []))
        
        return {
            "original_statement": statement.content,
            "verification_result": verification,
            "timestamp": datetime.now(),
            "agent_checked": statement.agent_role.value
        }

class AudienceManagerAgent(BaseDebateAgent):
    """Agent pro sprÃ¡vu publika a otÃ¡zek"""
    
    def __init__(self, api_key: str):
        super().__init__(AgentRole.AUDIENCE_MANAGER, api_key)
    
    async def process_audience_question(self, question: str, context: DebateContext) -> str:
        """Zpracuje otÃ¡zku z publika"""
        prompt = f"""
        OtÃ¡zka z publika: "{question}"
        TÃ©ma debaty: {context.topic}
        
        Zformuluj otÃ¡zku vhodnÄ› pro debatu, ujisti se, Å¾e je relevantnÃ­ a neutrÃ¡lnÃ­.
        Pokud otÃ¡zka nenÃ­ vhodnÃ¡, navrhni lepÅ¡Ã­ formulaci nebo odmÃ­tni.
        """
        return await self.generate_response(prompt, context)

class DebateOrchestrator:
    """HlavnÃ­ orchestrÃ¡tor pro Å™Ã­zenÃ­ celÃ© debaty"""
    
    def __init__(self, openai_api_key: str, anthropic_api_key: str = None):
        self.pro_agent = ProAgent(openai_api_key)
        self.contra_agent = ContraAgent(anthropic_api_key or openai_api_key)
        self.moderator = ModeratorAgent(openai_api_key)
        self.fact_checker = FactCheckerAgent(openai_api_key)
        self.audience_manager = AudienceManagerAgent(openai_api_key)
        
        # SdÃ­lenÃ¡ pamÄ›Å¥ pro vÅ¡echny agenty
        self.shared_memory = MemoryManager(window_size=30)
        
    async def run_debate(self, topic: str, max_rounds: int = 3) -> DebateContext:
        """SpustÃ­ celou debatu"""
        
        context = DebateContext(
            topic=topic,
            current_round=0,
            max_rounds=max_rounds,
            statements=[],
            audience_questions=[],
            fact_checks=[]
        )
        
        # Ãšvod moderÃ¡tora
        intro = await self.moderator.introduce_debate(topic)
        logger.info(f"ModerÃ¡tor: {intro}")
        
        # HlavnÃ­ debatnÃ­ kola
        for round_num in range(1, max_rounds + 1):
            context.current_round = round_num
            logger.info(f"\n=== KOLO {round_num} ===")
            
            # PRO argument
            pro_statement = await self.pro_agent.create_argument(
                topic, context, "argument" if round_num == 1 else "rebuttal"
            )
            context.statements.append(pro_statement)
            self.shared_memory.add_statement(pro_statement)
            logger.info(f"PRO: {pro_statement.content}")
            
            # CONTRA protiargument
            contra_statement = await self.contra_agent.create_counter_argument(
                topic, context, "counter_argument" if round_num == 1 else "rebuttal"
            )
            context.statements.append(contra_statement)
            self.shared_memory.add_statement(contra_statement)
            logger.info(f"CONTRA: {contra_statement.content}")
            
            # ModerÃ¡tor shrne kolo
            moderation = await self.moderator.moderate_round(context)
            logger.info(f"ModerÃ¡tor: {moderation}")
            
            # Fact-checking (asynchronnÄ›)
            if round_num % 2 == 0:  # KaÅ¾dÃ© druhÃ© kolo
                fact_check_pro = await self.fact_checker.verify_statement(pro_statement)
                fact_check_contra = await self.fact_checker.verify_statement(contra_statement)
                context.fact_checks.extend([fact_check_pro, fact_check_contra])
            
            # Pauza mezi koly
            await asyncio.sleep(1)
        
        # ZÃ¡vÄ›reÄnÃ¡ slova
        logger.info("\n=== ZÃVÄšREÄŒNÃ SLOVA ===")
        
        final_pro = await self.pro_agent.create_argument(topic, context, "closing")
        final_contra = await self.contra_agent.create_counter_argument(topic, context, "closing")
        
        context.statements.extend([final_pro, final_contra])
        
        logger.info(f"PRO (zÃ¡vÄ›r): {final_pro.content}")
        logger.info(f"CONTRA (zÃ¡vÄ›r): {final_contra.content}")
        
        return context
    
    async def handle_audience_question(self, question: str, context: DebateContext) -> str:
        """Zpracuje otÃ¡zku z publika"""
        processed_question = await self.audience_manager.process_audience_question(question, context)
        context.audience_questions.append(processed_question)
        return processed_question

# Streamlit UI pro interaktivnÃ­ debatu
def create_streamlit_interface():
    """VytvoÅ™Ã­ Streamlit rozhranÃ­ pro debatu"""
    
    st.title("ğŸ¯ AI Debate Team - StrukturovanÃ© debaty")
    st.markdown("---")
    
    # Sidebar pro konfiguraci
    with st.sidebar:
        st.header("Konfigurace")
        openai_key = st.text_input("OpenAI API Key", type="password")
        anthropic_key = st.text_input("Anthropic API Key (volitelnÃ©)", type="password")
        
        st.header("NastavenÃ­ debaty")
        max_rounds = st.slider("PoÄet kol", 1, 5, 3)
        
    # HlavnÃ­ rozhranÃ­
    topic = st.text_input("Zadej tÃ©ma debaty:", placeholder="NapÅ™. 'MÄ›ly by bÃ½t kryptomÄ›ny regulovÃ¡ny?'")
    
    col1, col2 = st.columns(2)
    
    with col1:
        start_debate = st.button("ğŸš€ Spustit debatu", type="primary")
    
    with col2:
        if st.button("ğŸ“Š Zobrazit statistiky"):
            st.info("Funkce statistik bude implementovÃ¡na")
    
    # Kontejner pro vÃ½sledky debaty
    debate_container = st.container()
    
    # Sekce pro otÃ¡zky z publika
    st.markdown("---")
    st.subheader("ğŸ’¬ OtÃ¡zky z publika")
    
    audience_question = st.text_input("Tvoje otÃ¡zka k debatÄ›:")
    
    if st.button("Odeslat otÃ¡zku"):
        if audience_question and 'orchestrator' in st.session_state:
            with st.spinner("ZpracovÃ¡vÃ¡m otÃ¡zku..."):
                processed = asyncio.run(
                    st.session_state.orchestrator.handle_audience_question(
                        audience_question, st.session_state.get('context', None)
                    )
                )
                st.success(f"ZpracovanÃ¡ otÃ¡zka: {processed}")
    
    # SpuÅ¡tÄ›nÃ­ debaty
    if start_debate and topic and openai_key:
        with st.spinner("SpouÅ¡tÃ­m debatu... MÅ¯Å¾e to trvat nÄ›kolik minut."):
            
            # Inicializace orchestrÃ¡tora
            orchestrator = DebateOrchestrator(openai_key, anthropic_key)
            st.session_state.orchestrator = orchestrator
            
            # SpuÅ¡tÄ›nÃ­ debaty
            try:
                context = asyncio.run(orchestrator.run_debate(topic, max_rounds))
                st.session_state.context = context
                
                # ZobrazenÃ­ vÃ½sledkÅ¯
                with debate_container:
                    st.success("âœ… Debata dokonÄena!")
                    
                    # TÃ©ma a zÃ¡kladnÃ­ info
                    st.subheader(f"ğŸ“‹ TÃ©ma: {context.topic}")
                    st.info(f"Kola: {context.current_round}, VÃ½roky: {len(context.statements)}")
                    
                    # PrÅ¯bÄ›h debaty
                    st.subheader("ğŸ—£ï¸ PrÅ¯bÄ›h debaty")
                    
                    for i, statement in enumerate(context.statements):
                        # Ikona podle role
                        icons = {
                            AgentRole.PRO: "âœ…",
                            AgentRole.CONTRA: "âŒ", 
                            AgentRole.MODERATOR: "âš–ï¸"
                        }
                        
                        icon = icons.get(statement.agent_role, "ğŸ¤–")
                        role_name = statement.agent_role.value.upper()
                        
                        with st.expander(f"{icon} {role_name} - {statement.argument_type}"):
                            st.write(statement.content)
                            st.caption(f"ÄŒas: {statement.timestamp.strftime('%H:%M:%S')}")
                    
                    # Fact-checks
                    if context.fact_checks:
                        st.subheader("ğŸ” OvÄ›Å™enÃ­ faktÅ¯")
                        for fact_check in context.fact_checks:
                            with st.expander("OvÄ›Å™enÃ­ faktickÃ©ho tvrzenÃ­"):
                                st.write(f"**PÅ¯vodnÃ­ tvrzenÃ­:** {fact_check['original_statement'][:200]}...")
                                st.write(f"**OvÄ›Å™enÃ­:** {fact_check['verification_result']}")
                    
                    # Export vÃ½sledkÅ¯
                    if st.button("ğŸ’¾ Exportovat vÃ½sledky"):
                        debate_data = {
                            "topic": context.topic,
                            "statements": [asdict(stmt) for stmt in context.statements],
                            "fact_checks": context.fact_checks,
                            "timestamp": datetime.now().isoformat()
                        }
                        
                        st.download_button(
                            label="StÃ¡hnout jako JSON",
                            data=json.dumps(debate_data, indent=2, ensure_ascii=False),
                            file_name=f"debate_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                        
            except Exception as e:
                st.error(f"âŒ Chyba pÅ™i spouÅ¡tÄ›nÃ­ debaty: {str(e)}")
                logger.error(f"Debate error: {e}")

# HlavnÃ­ spouÅ¡tÄ›cÃ­ funkce
async def main():
    """HlavnÃ­ funkce pro demonstraci"""
    
    # UkÃ¡zka pouÅ¾itÃ­ pÅ™es CLI
    print("ğŸ¯ AI Debate Team - Demo")
    print("=" * 50)
    
    # Simulace API klÃ­ÄÅ¯ (v reÃ¡lnÃ©m pouÅ¾itÃ­ naÄÃ­st z environment)
    OPENAI_API_KEY = "your-openai-api-key"
    ANTHROPIC_API_KEY = "your-anthropic-api-key"  # volitelnÃ©
    
    # VytvoÅ™enÃ­ orchestrÃ¡tora
    orchestrator = DebateOrchestrator(OPENAI_API_KEY, ANTHROPIC_API_KEY)
    
    # SpuÅ¡tÄ›nÃ­ ukÃ¡zkovÃ© debaty
    topic = "MÄ›la by bÃ½t umÄ›lÃ¡ inteligence regulovÃ¡na vlÃ¡dnÃ­mi orgÃ¡ny?"
    
    print(f"ğŸ“‹ SpouÅ¡tÃ­m debatu na tÃ©ma: {topic}")
    print("-" * 50)
    
    try:
        context = await orchestrator.run_debate(topic, max_rounds=2)
        
        print("\n" + "=" * 50)
        print("âœ… DEBATA DOKONÄŒENA")
        print("=" * 50)
        
        print(f"ğŸ“Š Statistiky:")
        print(f"   â€¢ Celkem vÃ½rokÅ¯: {len(context.statements)}")
        print(f"   â€¢ PRO argumenty: {len([s for s in context.statements if s.agent_role == AgentRole.PRO])}")
        print(f"   â€¢ CONTRA argumenty: {len([s for s in context.statements if s.agent_role == AgentRole.CONTRA])}")
        print(f"   â€¢ Fact-checks: {len(context.fact_checks)}")
        
        # UkÃ¡zka zpracovÃ¡nÃ­ otÃ¡zky z publika
        print("\nğŸ’¬ Demo otÃ¡zky z publika:")
        audience_q = "JakÃ© jsou nejvÄ›tÅ¡Ã­ rizika pÅ™i regulaci AI?"
        processed_q = await orchestrator.handle_audience_question(audience_q, context)
        print(f"PÅ¯vodnÃ­: {audience_q}")
        print(f"ZpracovÃ¡no: {processed_q}")
        
    except Exception as e:
        print(f"âŒ Chyba: {e}")

if __name__ == "__main__":
    # Pro Streamlit UI
    if "streamlit" in str(__file__).lower() or True:  # VÃ½chozÃ­ pro demo
        create_streamlit_interface()
    else:
        # Pro CLI verzi
        asyncio.run(main())
````

````python
# Dependencies pro AI Debate Team
openai>=1.0.0
anthropic>=0.3.0
streamlit>=1.28.0
langchain>=0.0.350
langchain-openai>=0.0.2
python-dotenv>=1.0.0
asyncio>=3.4.3
dataclasses-json>=0.6.0
pydantic>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
plotly>=5.15.0
requests>=2.31.0
aiohttp>=3.8.0
````

````python
import os
from dotenv import load_dotenv

# NaÄtenÃ­ environment variables
load_dotenv()

class DebateConfig:
    """Konfigurace pro AI Debate Team"""
    
    # API klÃ­Äe
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    
    # NastavenÃ­ modelÅ¯
    OPENAI_MODEL = "gpt-4"
    ANTHROPIC_MODEL = "claude-3-sonnet-20240229"
    
    # Parametry debaty
    DEFAULT_MAX_ROUNDS = 3
    DEFAULT_RESPONSE_LENGTH = 500
    MEMORY_WINDOW_SIZE = 20
    
    # Streamlit konfigurace
    PAGE_TITLE = "AI Debate Team"
    PAGE_ICON = "ğŸ¯"
    LAYOUT = "wide"
    
    # LogovÃ¡nÃ­
    LOG_LEVEL = "INFO"
    LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    @classmethod
    def validate_config(cls) -> bool:
        """OvÄ›Å™Ã­, Å¾e jsou dostupnÃ© potÅ™ebnÃ© API klÃ­Äe"""
        if not cls.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY nenÃ­ nastaven")
        return True
````

````bash
#!/usr/bin/env python3
"""
SpouÅ¡tÄ›cÃ­ script pro AI Debate Team
PouÅ¾itÃ­: python run_debate.py [topic] [--rounds N] [--mode cli|web]
"""

import argparse
import asyncio
import sys
from ai_debate_team import DebateOrchestrator, create_streamlit_interface
from config import DebateConfig

def parse_arguments():
    """Parsuje argumenty pÅ™Ã­kazovÃ© Å™Ã¡dky"""
    parser = argparse.ArgumentParser(description='AI Debate Team - StrukturovanÃ© debaty')
    
    parser.add_argument('topic', nargs='?', 
                       default='MÄ›la by bÃ½t umÄ›lÃ¡ inteligence regulovÃ¡na?',
                       help='TÃ©ma debaty')
    
    parser.add_argument('--rounds', '-r', type=int, 
                       default=DebateConfig.DEFAULT_MAX_ROUNDS,
                       help='PoÄet kol debaty')
    
    parser.add_argument('--mode', '-m', choices=['cli', 'web'], 
                       default='web',
                       help='ReÅ¾im spuÅ¡tÄ›nÃ­ (CLI nebo webovÃ© rozhranÃ­)')
    
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='PodrobnÃ½ vÃ½stup')
    
    return parser.parse_args()

async def run_cli_debate(topic: str, rounds: int, verbose: bool = False):
    """SpustÃ­ debatu v CLI reÅ¾imu"""
    try:
        DebateConfig.validate_config()
        
        orchestrator = DebateOrchestrator(
            DebateConfig.OPENAI_API_KEY,
            DebateConfig.ANTHROPIC_API_KEY
        )
        
        print(f"ğŸ¯ SpouÅ¡tÃ­m debatu: {topic}")
        print(f"ğŸ“Š Parametry: {rounds} kol")
        print("-" * 60)
        
        context = await orchestrator.run_debate(topic, rounds)
        
        print("\n" + "=" * 60)
        print("âœ… DEBATA DOKONÄŒENA")
        print("=" * 60)
        
        # Statistiky
        pro_count = len([s for s in context.statements if s.agent_role.name == 'PRO'])
        contra_count = len([s for s in context.statements if s.agent_role.name == 'CONTRA'])
        
        print(f"ğŸ“ˆ VÃ½sledky:")
        print(f"   â€¢ Celkem argumentÅ¯: {len(context.statements)}")
        print(f"   â€¢ PRO argumenty: {pro_count}")
        print(f"   â€¢ CONTRA argumenty: {contra_count}")
        print(f"   â€¢ Fact-checks: {len(context.fact_checks)}")
        
        return context
        
    except Exception as e:
        print(f"âŒ Chyba pÅ™i spouÅ¡tÄ›nÃ­ debaty: {e}")
        sys.exit(1)

def run_web_interface():
    """SpustÃ­ webovÃ© rozhranÃ­ Streamlit"""
    import subprocess
    import sys
    
    print("ğŸŒ SpouÅ¡tÃ­m webovÃ© rozhranÃ­...")
    print("ğŸ“± OtevÅ™e se v prohlÃ­Å¾eÄi na http://localhost:8501")
    
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", 
            "ai_debate_team.py", "--server.port=8501"
        ])
    except KeyboardInterrupt:
        print("\nğŸ‘‹ WebovÃ© rozhranÃ­ ukonÄeno")

def main():
    """HlavnÃ­ funkce"""
    args = parse_arguments()
    
    print("ğŸ¯ AI Debate Team")
    print("=" * 40)
    
    if args.mode == 'cli':
        asyncio.run(run_cli_debate(args.topic, args.rounds, args.verbose))
    else:
        run_web_interface()

if __name__ == "__main__":
    main()
````

## ShrnutÃ­ projektu

AI Debate Team pÅ™edstavuje pokroÄilÃ½ multi-agentnÃ­ systÃ©m pro vedenÃ­ strukturovanÃ½ch debat s nÃ¡sledujÃ­cÃ­mi klÃ­ÄovÃ½mi hodnotami:

### ğŸ¯ KlÃ­ÄovÃ© pÅ™Ã­nosy:
- **Automatizace debatnÃ­ch procesÅ¯** s vysokou kvalitou argumentace
- **VzdÄ›lÃ¡vacÃ­ nÃ¡stroj** pro pochopenÃ­ rÅ¯znÃ½ch perspektiv kontroverznÃ­ch tÃ©mat
- **ScalabilnÃ­ architektura** umoÅ¾ÅˆujÃ­cÃ­ rozÅ¡Ã­Å™enÃ­ o dalÅ¡Ã­ agenty a funkce
- **InteraktivnÃ­ platforma** s real-time zpracovÃ¡nÃ­m otÃ¡zek z publika

### ğŸ’¡ TechnologickÃ© inovace:
- **HybridnÃ­ pouÅ¾itÃ­ LLM** (GPT-4 + Claude) pro rÅ¯znorodÃ© argumentaÄnÃ­ styly
- **PokroÄilÃ½ memory management** pro tracking argumentÅ¯ a kontextu
- **Persuasion engine** implementujÃ­cÃ­ klasickÃ© rÃ©toricÃ© techniky
- **AsynchronnÃ­ zpracovÃ¡nÃ­** pro smooth user experience

### ğŸš€ PotenciÃ¡lnÃ­ rozÅ¡Ã­Å™enÃ­:
- **HlasovÃ© rozhranÃ­** pro audio debaty
- **VÃ­cejazyÄnÃ¡ podpora** pro mezinÃ¡rodnÃ­ debaty  
- **AI hodnocenÃ­** kvality argumentÅ¯ a logickÃ½ch chyb
- **Integration s social media** pro wider audience engagement
- **Expert knowledge base** pro fact-checking s citacemi

SystÃ©m demonstruje sÃ­lu koordinovanÃ½ch AI agentÅ¯ pÅ™i Å™eÅ¡enÃ­ komplexnÃ­ch ÃºkolÅ¯ vyÅ¾adujÃ­cÃ­ch rÅ¯znÃ© perspektivy, kreativitu a logickÃ© myÅ¡lenÃ­.