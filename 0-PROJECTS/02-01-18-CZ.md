<small>Claude Sonnet 4 **(Autonomní Framework pro Testování Software a QA (Multi-Agent Systémy))**</small>
# Autonomous Software Testing and QA Framework

## 1. Klíčové Koncepty

### Multi-Agent Systémy
Systém více nezávislých softwarových agentů, kteří spolupracují na dosažení společného cíle. Každý agent má specifické role a schopnosti, komunikuje s ostatními a přispívá k celkovému řešení.

### Generování Testovacích Případů
Automatické vytváření testovacích scénářů na základě analýzy kódu, specifikací a požadavků. Zahrnuje pozitivní i negativní testovací případy pokrývající různé execution paths.

### Detekce Chyb
Automatické vyhledávání a identifikace defektů v software pomocí statické a dynamické analýzy kódu, pattern matching a heuristických metod.

### Performance Testing
Měření a analýza výkonu aplikace pod různými zátěžemi, včetně load testingu, stress testingu a endurance testingu.

### Skenování Bezpečnostních Zranitelností
Automatické vyhledávání potenciálních bezpečnostních rizik jako SQL injection, XSS útoky, neautorizovaný přístup k datům.

### Regresní Testování
Ověřování, že nové změny v kódu neporušily existující funkcionalitu pomocí opětovného spuštění dříve úspěšných testů.

## 2. Komplexní Vysvětlení Projektu

### Cíle Projektu
Tento framework představuje revoluční přístup k automatizaci testování software pomocí koordinovaného týmu AI agentů. Každý agent se specializuje na specifickou oblast testování a společně vytvářejí komplexní QA ekosystém.

### Hlavní Výzvy
- **Koordinace Agentů**: Synchronizace práce mezi různými specializovanými agenty
- **Inteligentní Analýza**: Schopnost porozumět složitým codebases a generovat relevantní testy
- **Falešné Pozitivy**: Minimalizace false positive výsledků při detekci chyb
- **Škálování**: Efektivní práce s velkými projekty a komplexními aplikacemi

### Potenciální Dopad
Framework může dramaticky snížit čas a náklady na QA, zvýšit pokrytí testů a odhalit skryté problémy dříve, než se dostanou do produkce.

## 3. Komplexní Implementace s Pythonem

````python
# requirements.txt
"""
crewai>=0.28.0
langchain>=0.1.0
openai>=1.0.0
ast-tools>=0.1.0
pytest>=7.0.0
coverage>=7.0.0
bandit>=1.7.0
locust>=2.0.0
selenium>=4.0.0
requests>=2.28.0
python-dotenv>=1.0.0
"""
````

````python
import ast
import os
import subprocess
import time
import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

from crewai import Agent, Task, Crew
from langchain.llms import OpenAI
from langchain.tools import Tool
from langchain.schema import BaseRetriever
import pytest
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Konfigurace loggingu
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class TestResult:
    """Struktura pro výsledky testování"""
    test_type: str
    status: str
    details: Dict[str, Any]
    timestamp: float
    duration: float

@dataclass
class VulnerabilityReport:
    """Struktura pro bezpečnostní zranitelnosti"""
    severity: str
    category: str
    description: str
    file_path: str
    line_number: int
    recommendation: str

class CodeAnalyzer:
    """Analyzátor kódu pro extrakci funkcionalit"""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
    
    def extract_functions(self, file_path: str) -> List[Dict[str, Any]]:
        """Extrakce funkcí z Python souboru"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                tree = ast.parse(file.read())
            
            functions = []
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append({
                        'name': node.name,
                        'args': [arg.arg for arg in node.args.args],
                        'line_number': node.lineno,
                        'docstring': ast.get_docstring(node)
                    })
            return functions
        except Exception as e:
            logger.error(f"Chyba při analýze souboru {file_path}: {e}")
            return []
    
    def get_project_structure(self) -> Dict[str, List[str]]:
        """Získání struktury projektu"""
        structure = {}
        for py_file in self.project_path.rglob("*.py"):
            if '__pycache__' not in str(py_file):
                functions = self.extract_functions(str(py_file))
                structure[str(py_file)] = functions
        return structure

class TestCaseGenerator:
    """Agent pro generování testovacích případů"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def generate_unit_tests(self, function_info: Dict[str, Any]) -> str:
        """Generování unit testů pro funkci"""
        prompt = f"""
        Vytvoř komplexní unit testy pro funkci:
        Název: {function_info['name']}
        Argumenty: {function_info['args']}
        Dokumentace: {function_info.get('docstring', 'Není k dispozici')}
        
        Zahrň:
        - Pozitivní testovací případy
        - Negativní testovací případy
        - Edge cases
        - Parametrizované testy
        
        Formát odpovědi: Čistý Python kód s pytest.
        """
        
        try:
            response = self.llm.predict(prompt)
            return response
        except Exception as e:
            logger.error(f"Chyba při generování testů: {e}")
            return f"# Chyba při generování testů pro {function_info['name']}"
    
    def generate_integration_tests(self, module_info: Dict[str, Any]) -> str:
        """Generování integračních testů"""
        prompt = f"""
        Vytvoř integrační testy pro modul s funkcemi:
        {[func['name'] for func in module_info]}
        
        Zahrň:
        - Testování interakcí mezi funkcemi
        - End-to-end scénáře
        - Data flow testování
        
        Formát: Python kód s pytest a fixtures.
        """
        
        try:
            response = self.llm.predict(prompt)
            return response
        except Exception as e:
            logger.error(f"Chyba při generování integračních testů: {e}")
            return "# Chyba při generování integračních testů"

class BugDetector:
    """Agent pro detekci chyb"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def analyze_code_patterns(self, file_path: str) -> List[Dict[str, Any]]:
        """Analýza kódu pro detekci možných chyb"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                code = file.read()
            
            prompt = f"""
            Analyzuj následující Python kód a identifikuj možné problémy:
            
            {code}
            
            Hledej:
            - Potenciální runtime chyby
            - Neošetřené výjimky
            - Memory leaks
            - Performance problémy
            - Logické chyby
            
            Formát odpovědi: JSON seznam s detaily problémů.
            """
            
            response = self.llm.predict(prompt)
            # Parsování odpovědi (zjednodušené)
            return [{"type": "analysis", "details": response}]
            
        except Exception as e:
            logger.error(f"Chyba při analýze souboru {file_path}: {e}")
            return []
    
    def run_static_analysis(self, project_path: str) -> List[Dict[str, Any]]:
        """Spuštění statické analýzy pomocí externích nástrojů"""
        results = []
        
        try:
            # Flake8 analýza
            result = subprocess.run(
                ['flake8', project_path, '--format=json'],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.stdout:
                try:
                    flake8_issues = json.loads(result.stdout)
                    results.extend(flake8_issues)
                except json.JSONDecodeError:
                    logger.warning("Nelze parsovat flake8 výsledky")
            
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.warning(f"Flake8 analýza selhala: {e}")
        
        return results

class SecurityScanner:
    """Agent pro bezpečnostní skenování"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def scan_vulnerabilities(self, project_path: str) -> List[VulnerabilityReport]:
        """Skenování bezpečnostních zranitelností"""
        vulnerabilities = []
        
        try:
            # Bandit skenování
            result = subprocess.run(
                ['bandit', '-r', project_path, '-f', 'json'],
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.stdout:
                try:
                    bandit_data = json.loads(result.stdout)
                    for issue in bandit_data.get('results', []):
                        vulnerability = VulnerabilityReport(
                            severity=issue.get('issue_severity', 'UNKNOWN'),
                            category=issue.get('test_name', 'General'),
                            description=issue.get('issue_text', ''),
                            file_path=issue.get('filename', ''),
                            line_number=issue.get('line_number', 0),
                            recommendation=issue.get('issue_confidence', '')
                        )
                        vulnerabilities.append(vulnerability)
                        
                except json.JSONDecodeError:
                    logger.warning("Nelze parsovat bandit výsledky")
                    
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.warning(f"Bandit skenování selhalo: {e}")
        
        return vulnerabilities
    
    def analyze_dependencies(self, requirements_file: str) -> List[Dict[str, Any]]:
        """Analýza bezpečnosti závislostí"""
        try:
            # Safety check (pokud je nainstalovaný)
            result = subprocess.run(
                ['safety', 'check', '-r', requirements_file, '--json'],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.stdout:
                return json.loads(result.stdout)
                
        except (subprocess.TimeoutExpired, FileNotFoundError, json.JSONDecodeError) as e:
            logger.warning(f"Safety analýza selhala: {e}")
        
        return []

class PerformanceTester:
    """Agent pro testování výkonu"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def run_load_tests(self, target_url: str, concurrent_users: int = 10) -> Dict[str, Any]:
        """Spuštění zátěžových testů"""
        try:
            # Simulace load testu pomocí requests
            results = {
                'total_requests': 0,
                'successful_requests': 0,
                'failed_requests': 0,
                'average_response_time': 0,
                'max_response_time': 0,
                'min_response_time': float('inf')
            }
            
            response_times = []
            
            def make_request():
                try:
                    start_time = time.time()
                    response = requests.get(target_url, timeout=10)
                    end_time = time.time()
                    
                    response_time = end_time - start_time
                    response_times.append(response_time)
                    
                    if response.status_code == 200:
                        return {'success': True, 'response_time': response_time}
                    else:
                        return {'success': False, 'response_time': response_time}
                        
                except Exception as e:
                    return {'success': False, 'error': str(e)}
            
            # Paralelní požadavky
            with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
                futures = [executor.submit(make_request) for _ in range(100)]
                
                for future in futures:
                    result = future.result()
                    results['total_requests'] += 1
                    
                    if result.get('success'):
                        results['successful_requests'] += 1
                    else:
                        results['failed_requests'] += 1
            
            if response_times:
                results['average_response_time'] = sum(response_times) / len(response_times)
                results['max_response_time'] = max(response_times)
                results['min_response_time'] = min(response_times)
            
            return results
            
        except Exception as e:
            logger.error(f"Chyba při load testování: {e}")
            return {'error': str(e)}
    
    def profile_function_performance(self, function_code: str) -> Dict[str, Any]:
        """Profilování výkonu funkcí"""
        prompt = f"""
        Analyzuj výkon následující funkce a navrhni optimalizace:
        
        {function_code}
        
        Zaměř se na:
        - Časovou složitost
        - Paměťovou složitost
        - Možné optimalizace
        - Bottlenecks
        
        Formát: JSON s analýzou a doporučeními.
        """
        
        try:
            response = self.llm.predict(prompt)
            return {'analysis': response}
        except Exception as e:
            logger.error(f"Chyba při profilování: {e}")
            return {'error': str(e)}

class RegressionTester:
    """Agent pro regresní testování"""
    
    def __init__(self, llm):
        self.llm = llm
        self.baseline_results = {}
    
    def run_regression_tests(self, test_directory: str) -> Dict[str, Any]:
        """Spuštění regresních testů"""
        try:
            # Spuštění pytest s coverage
            result = subprocess.run(
                ['pytest', test_directory, '--cov=.', '--cov-report=json', '-v'],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            return {
                'exit_code': result.returncode,
                'stdout': result.stdout,
                'stderr': result.stderr,
                'passed': result.returncode == 0
            }
            
        except subprocess.TimeoutExpired:
            return {'error': 'Testy překročily časový limit'}
        except Exception as e:
            return {'error': str(e)}
    
    def compare_with_baseline(self, current_results: Dict[str, Any]) -> Dict[str, Any]:
        """Porovnání s baseline výsledky"""
        if not self.baseline_results:
            self.baseline_results = current_results
            return {'status': 'baseline_set', 'message': 'Baseline výsledky nastaveny'}
        
        comparison = {
            'performance_regression': False,
            'test_failures': [],
            'coverage_change': 0
        }
        
        # Porovnání výkonnostních metrik
        baseline_time = self.baseline_results.get('execution_time', 0)
        current_time = current_results.get('execution_time', 0)
        
        if current_time > baseline_time * 1.2:  # 20% zhoršení
            comparison['performance_regression'] = True
        
        return comparison

class QAOrchestrator:
    """Hlavní orchestrátor celého QA procesu"""
    
    def __init__(self, openai_api_key: str, project_path: str):
        self.project_path = project_path
        self.llm = OpenAI(openai_api_key=openai_api_key, temperature=0.1)
        
        # Inicializace agentů
        self.code_analyzer = CodeAnalyzer(project_path)
        self.test_generator = TestCaseGenerator(self.llm)
        self.bug_detector = BugDetector(self.llm)
        self.security_scanner = SecurityScanner(self.llm)
        self.performance_tester = PerformanceTester(self.llm)
        self.regression_tester = RegressionTester(self.llm)
        
        self.results = []
    
    def create_crew_agents(self):
        """Vytvoření CrewAI agentů"""
        
        test_generation_agent = Agent(
            role='Test Generator Specialist',
            goal='Generovat komplexní a efektivní testovací případy',
            backstory='Expertní agent specializující se na vytváření kvalitních testů pro všechny typy aplikací.',
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        security_agent = Agent(
            role='Security Specialist',
            goal='Identifikovat a analyzovat bezpečnostní zranitelnosti',
            backstory='Bezpečnostní expert s hlubokými znalostmi cyber security a best practices.',
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        performance_agent = Agent(
            role='Performance Engineer',
            goal='Optimalizovat výkon aplikací a identifikovat bottlenecks',
            backstory='Výkonnostní inženýr s expertízou v profilování a optimalizaci.',
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        return [test_generation_agent, security_agent, performance_agent]
    
    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """Spuštění kompletní analýzy projektu"""
        logger.info("Zahajuji komplexní QA analýzu...")
        
        start_time = time.time()
        
        # 1. Analýza struktury projektu
        logger.info("Analyzuji strukturu projektu...")
        project_structure = self.code_analyzer.get_project_structure()
        
        # 2. Generování testů
        logger.info("Generuji testovací případy...")
        generated_tests = {}
        for file_path, functions in project_structure.items():
            for function in functions:
                test_code = self.test_generator.generate_unit_tests(function)
                generated_tests[f"{function['name']}_test"] = test_code
        
        # 3. Detekce chyb
        logger.info("Detekuji možné chyby...")
        bug_reports = []
        for file_path in project_structure.keys():
            bugs = self.bug_detector.analyze_code_patterns(file_path)
            bug_reports.extend(bugs)
        
        static_analysis = self.bug_detector.run_static_analysis(self.project_path)
        bug_reports.extend(static_analysis)
        
        # 4. Bezpečnostní skenování
        logger.info("Provádím bezpečnostní skenování...")
        vulnerabilities = self.security_scanner.scan_vulnerabilities(self.project_path)
        
        # 5. Testování výkonu (pokud je k dispozici webová aplikace)
        performance_results = {}
        
        # 6. Regresní testování
        logger.info("Spouštím regresní testy...")
        test_dir = os.path.join(self.project_path, 'tests')
        if os.path.exists(test_dir):
            regression_results = self.regression_tester.run_regression_tests(test_dir)
        else:
            regression_results = {'message': 'Testovací adresář nenalezen'}
        
        end_time = time.time()
        
        # Sestavení finálního reportu
        report = {
            'execution_time': end_time - start_time,
            'project_structure': project_structure,
            'generated_tests': generated_tests,
            'bug_reports': bug_reports,
            'security_vulnerabilities': [
                {
                    'severity': vuln.severity,
                    'category': vuln.category,
                    'description': vuln.description,
                    'file': vuln.file_path,
                    'line': vuln.line_number
                } for vuln in vulnerabilities
            ],
            'performance_results': performance_results,
            'regression_results': regression_results,
            'timestamp': time.time()
        }
        
        self.results.append(report)
        logger.info(f"QA analýza dokončena za {end_time - start_time:.2f} sekund")
        
        return report
    
    def generate_detailed_report(self) -> str:
        """Generování detailního reportu"""
        if not self.results:
            return "Žádné výsledky k zobrazení"
        
        latest_result = self.results[-1]
        
        report = f"""
# QA Analýza Reportu

## Přehled
- **Doba provedení**: {latest_result['execution_time']:.2f} sekund
- **Analyzované soubory**: {len(latest_result['project_structure'])}
- **Generované testy**: {len(latest_result['generated_tests'])}
- **Detekované problémy**: {len(latest_result['bug_reports'])}
- **Bezpečnostní zranitelnosti**: {len(latest_result['security_vulnerabilities'])}

## Bezpečnostní Zranitelnosti
"""
        
        for vuln in latest_result['security_vulnerabilities']:
            report += f"""
### {vuln['severity']} - {vuln['category']}
- **Soubor**: {vuln['file']}
- **Řádek**: {vuln['line']}
- **Popis**: {vuln['description']}
"""
        
        report += f"""
## Regresní Testování
- **Status**: {'✅ Úspěšné' if latest_result['regression_results'].get('passed') else '❌ Neúspěšné'}
- **Detaily**: {latest_result['regression_results'].get('stdout', 'N/A')}

## Doporučení
1. Implementujte generované unit testy
2. Opravte identifikované bezpečnostní zranitelnosti
3. Proveďte refactoring problematických částí kódu
4. Nastavte CI/CD pipeline s automatickým QA
"""
        
        return report

# Demonstrační použití
def create_sample_project():
    """Vytvoření ukázkového projektu pro testování"""
    sample_code = """
# sample_app.py
def calculate_factorial(n):
    \"\"\"Výpočet faktoriálu čísla\"\"\"
    if n < 0:
        raise ValueError("Faktoriál nelze vypočítat pro záporná čísla")
    if n == 0 or n == 1:
        return 1
    result = 1
    for i in range(2, n + 1):
        result *= i
    return result

def divide_numbers(a, b):
    \"\"\"Dělení dvou čísel\"\"\"
    # Potenciální bug - chybí kontrola dělení nulou
    return a / b

def process_user_input(user_data):
    \"\"\"Zpracování uživatelských dat\"\"\"
    # Bezpečnostní riziko - nevalidovaný input
    eval(user_data)  # Nebezpečné použití eval
    return user_data

class UserManager:
    def __init__(self):
        self.users = {}
    
    def add_user(self, username, password):
        # Bezpečnostní riziko - ukládání hesla v plain text
        self.users[username] = password
    
    def authenticate(self, username, password):
        return self.users.get(username) == password
"""
    
    # Vytvoření ukázkového souboru
    os.makedirs('sample_project', exist_ok=True)
    with open('sample_project/sample_app.py', 'w', encoding='utf-8') as f:
        f.write(sample_code)
    
    # Vytvoření requirements.txt
    with open('sample_project/requirements.txt', 'w') as f:
        f.write("requests==2.25.1\nflask==1.1.2\n")

def main():
    """Hlavní funkce pro demonstraci"""
    # Nastavení API klíče (v produkci použijte environment variables)
    api_key = os.getenv('OPENAI_API_KEY', 'your-openai-api-key-here')
    
    if api_key == 'your-openai-api-key-here':
        print("⚠️  Nastavte OPENAI_API_KEY environment variable")
        return
    
    # Vytvoření ukázkového projektu
    create_sample_project()
    
    # Inicializace QA orchestrátoru
    qa_framework = QAOrchestrator(
        openai_api_key=api_key,
        project_path='sample_project'
    )
    
    # Spuštění analýzy
    try:
        results = qa_framework.run_comprehensive_analysis()
        
        # Generování reportu
        report = qa_framework.generate_detailed_report()
        
        print("="*80)
        print("🤖 AUTONOMNÍ QA FRAMEWORK - VÝSLEDKY")
        print("="*80)
        print(report)
        
        # Uložení detailních výsledků
        with open('qa_analysis_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\n📊 Detailní výsledky uloženy do 'qa_analysis_results.json'")
        
    except Exception as e:
        logger.error(f"Chyba při spuštění QA analýzy: {e}")
        print(f"❌ Chyba: {e}")

if __name__ == "__main__":
    main()
````

## 4. Shrnutí Projektu

### Hodnota Projektu
Autonomní QA Framework představuje průlomové řešení pro automatizaci testování software. Kombinuje sílu multi-agent systémů s pokročilými AI technikami pro vytvoření komplexního testovacího ekosystému.

### Klíčové Výhody
- **Automatizace**: Minimalizace manuální práce v QA procesech
- **Komplexnost**: Pokrytí všech aspektů testování od unit testů po bezpečnost
- **Škálovatelnost**: Efektivní práce s projekty všech velikostí
- **Inteligence**: AI-powered analýza a generování testů
- **Rychlost**: Paralelní zpracování pomocí specializovaných agentů

### Technologické Inovace
Framework využívá nejmodernější technologie včetně CrewAI pro orchestraci agentů, LangChain pro AI workflows a integraci s etablovanými testovacími nástroji.

### Budoucí Rozšíření
- Integrace s CI/CD pipelines
- Podpora více programovacích jazyků
- Advanced ML modely pro predikci chyb
- Grafické uživatelské rozhraní
- Cloud-native deployment

Tento framework představuje budoucnost automatizovaného testování software a může výrazně zvýšit kvalitu a rychlost vývoje aplikací.