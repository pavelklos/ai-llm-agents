<small>Claude Sonnet 4 **(N√°stroj pro Podporu L√©ka≈ôsk√© Diagnostiky s RAG)**</small>
# Medical Diagnosis Support Tool

## Kl√≠ƒçov√© Koncepty

### **RAG (Retrieval-Augmented Generation)**
RAG je hybridn√≠ p≈ô√≠stup umƒõl√© inteligence, kter√Ω kombinuje vyhled√°v√°n√≠ relevantn√≠ch informac√≠ z datab√°ze s generativn√≠mi schopnostmi velk√Ωch jazykov√Ωch model≈Ø. Syst√©m nejprve vyhled√° souvisej√≠c√≠ dokumenty a pot√© vygeneruje odpovƒõƒè zalo≈æenou na tƒõchto informac√≠ch.

### **PubMed/Klinick√© Studie**
PubMed je rozs√°hl√° datab√°ze biomedic√≠nsk√© literatury spravovan√° americk√Ωmi n√°rodn√≠mi zdravotnick√Ωmi √∫stavy. Obsahuje miliony ƒçl√°nk≈Ø o l√©ka≈ôsk√©m v√Ωzkumu, klinick√Ωch studi√≠ch a medic√≠nsk√Ωch objevech.

### **BioBERT**
BioBERT je specializovan√° verze BERT modelu tr√©novan√° na biomedic√≠nsk√Ωch textech. L√©pe rozum√≠ l√©ka≈ôsk√© terminologii a kontextu ve srovn√°n√≠ s obecn√Ωmi jazykov√Ωmi modely.

### **Pinecone**
Pinecone je cloudov√° vektorov√° datab√°ze optimalizovan√° pro ukl√°d√°n√≠ a rychl√© vyhled√°v√°n√≠ vektorov√Ωch embeddings. Umo≈æ≈àuje efektivn√≠ s√©mantick√© vyhled√°v√°n√≠ ve velk√Ωch kolekc√≠ch dokument≈Ø.

### **Llama-3**
Llama-3 je pokroƒçil√Ω open-source velk√Ω jazykov√Ω model vyvinut√Ω spoleƒçnost√≠ Meta, kter√Ω vynik√° v porozumƒõn√≠ a generov√°n√≠ textu v r≈Øzn√Ωch dom√©n√°ch vƒçetnƒõ medic√≠ny.

## Komplexn√≠ Vysvƒõtlen√≠ Projektu

### **C√≠le Projektu**
Tento projekt vytv√°≈ô√≠ inteligentn√≠ syst√©m pro podporu l√©ka≈ôsk√© diagnostiky, kter√Ω:
- Analyzuje symptomy pacient≈Ø a vyhled√°v√° relevantn√≠ medic√≠nskou literaturu
- Poskytuje potenci√°ln√≠ diagn√≥zy podlo≈æen√© vƒõdeck√Ωmi zdroji
- Umo≈æ≈àuje l√©ka≈ô≈Øm rychl√Ω p≈ô√≠stup k aktu√°ln√≠m v√Ωzkum≈Øm
- Minimalizuje riziko p≈ôehl√©dnut√≠ vz√°cn√Ωch onemocnƒõn√≠

### **V√Ωzvy a ≈òe≈°en√≠**
1. **P≈ôesnost medic√≠nsk√Ωch informac√≠**: Pou≈æit√≠ BioBERT pro lep≈°√≠ porozumƒõn√≠ l√©ka≈ôsk√© terminologii
2. **Rychlost vyhled√°v√°n√≠**: Implementace vektorov√© datab√°ze Pinecone pro efektivn√≠ s√©mantick√© vyhled√°v√°n√≠
3. **Spolehlivost zdroj≈Ø**: Zamƒõ≈ôen√≠ pouze na peer-reviewed ƒçl√°nky z PubMed
4. **Etick√© aspekty**: Jasn√© oznaƒçen√≠, ≈æe se jedn√° o podporn√Ω n√°stroj, ne n√°hradu za l√©ka≈ôskou expertizu

### **Potenci√°ln√≠ Dopad**
- Zkr√°cen√≠ ƒçasu diagnostiky vz√°cn√Ωch onemocnƒõn√≠
- Zlep≈°en√≠ p≈ôesnosti diagnostick√Ωch rozhodnut√≠
- Podpora m√©nƒõ zku≈°en√Ωch l√©ka≈ô≈Ø
- Redukce chyb zp≈Øsoben√Ωch p≈ôehl√©dnut√≠m relevantn√≠ literatury

## Komplexn√≠ Implementace v Pythonu

### **Z√°vislosti a Instalace**

````python
# requirements.txt
langchain==0.1.16
llama-index==0.10.30
transformers==4.40.0
torch==2.2.0
pinecone-client==3.2.2
sentence-transformers==2.7.0
requests==2.31.0
beautifulsoup4==4.12.3
python-dotenv==1.0.1
pydantic==2.7.0
````

### **Hlavn√≠ Implementace**

````python
import os
import json
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

import torch
from transformers import AutoTokenizer, AutoModel
import pinecone
from sentence_transformers import SentenceTransformer
import requests
from bs4 import BeautifulSoup
from langchain.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from dotenv import load_dotenv

# Naƒçten√≠ promƒõnn√Ωch prost≈ôed√≠
load_dotenv()

# Konfigurace logov√°n√≠
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MedicalDocument:
    """Reprezentace l√©ka≈ôsk√©ho dokumentu"""
    pmid: str
    title: str
    abstract: str
    authors: List[str]
    journal: str
    publication_date: str
    doi: str
    keywords: List[str]

@dataclass
class DiagnosisResult:
    """V√Ωsledek diagnostick√©ho procesu"""
    potential_diagnosis: str
    confidence_score: float
    supporting_evidence: List[str]
    cited_papers: List[MedicalDocument]
    reasoning: str

class PubMedRetriever:
    """T≈ô√≠da pro naƒç√≠t√°n√≠ ƒçl√°nk≈Ø z PubMed"""
    
    def __init__(self):
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        
    def search_articles(self, query: str, max_results: int = 10) -> List[str]:
        """Vyhled√° ƒçl√°nky v PubMed podle dotazu"""
        try:
            search_url = f"{self.base_url}esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': query,
                'retmax': max_results,
                'retmode': 'json'
            }
            
            response = requests.get(search_url, params=params)
            response.raise_for_status()
            
            data = response.json()
            return data.get('esearchresult', {}).get('idlist', [])
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi vyhled√°v√°n√≠ v PubMed: {e}")
            return []
    
    def fetch_article_details(self, pmids: List[str]) -> List[MedicalDocument]:
        """Naƒçte detaily ƒçl√°nk≈Ø podle PMID"""
        documents = []
        
        try:
            # Simulace dat pro demonstraci (v re√°ln√©m pou≈æit√≠ by se naƒç√≠tala z PubMed API)
            sample_data = [
                {
                    'pmid': '12345678',
                    'title': 'Chronick√° √∫nava a jej√≠ diagnostick√© v√Ωzvy',
                    'abstract': 'Studie zkoumaj√≠c√≠ p≈ô√≠ƒçiny chronick√© √∫navy u pacient≈Ø s nespecifick√Ωmi symptomy...',
                    'authors': ['Dr. Jan Nov√°k', 'Prof. Marie Svobodov√°'],
                    'journal': 'Journal of Internal Medicine',
                    'date': '2024-01-15',
                    'doi': '10.1001/jama.2024.12345',
                    'keywords': ['chronick√° √∫nava', 'diagnostika', 'biomarkery']
                },
                {
                    'pmid': '87654321',
                    'title': 'Bolesti hlavy a migr√©ny: modern√≠ p≈ô√≠stupy k l√©ƒçbƒõ',
                    'abstract': 'Komplexn√≠ p≈ôehled souƒçasn√Ωch metod diagnostiky a l√©ƒçby migr√©n...',
                    'authors': ['Dr. Petr ƒåern√Ω', 'Dr. Anna Kr√°sn√°'],
                    'journal': 'Neurology Research',
                    'date': '2024-02-20',
                    'doi': '10.1002/neur.2024.87654',
                    'keywords': ['migr√©na', 'bolest hlavy', 'neurologick√© vy≈°et≈ôen√≠']
                }
            ]
            
            for data in sample_data:
                doc = MedicalDocument(
                    pmid=data['pmid'],
                    title=data['title'],
                    abstract=data['abstract'],
                    authors=data['authors'],
                    journal=data['journal'],
                    publication_date=data['date'],
                    doi=data['doi'],
                    keywords=data['keywords']
                )
                documents.append(doc)
                
        except Exception as e:
            logger.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ detail≈Ø ƒçl√°nk≈Ø: {e}")
            
        return documents

class BioBERTEmbedder:
    """T≈ô√≠da pro vytv√°≈ôen√≠ embeddings pomoc√≠ BioBERT"""
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        logger.info(f"Naƒçten model: {model_name}")
    
    def embed_text(self, text: str) -> List[float]:
        """Vytvo≈ô√≠ embedding pro text"""
        try:
            embedding = self.model.encode(text)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Chyba p≈ôi vytv√°≈ôen√≠ embedding: {e}")
            return []
    
    def embed_documents(self, documents: List[MedicalDocument]) -> List[Dict]:
        """Vytvo≈ô√≠ embeddings pro kolekci dokument≈Ø"""
        embedded_docs = []
        
        for doc in documents:
            try:
                # Kombinace titulu a abstraktu pro embedding
                combined_text = f"{doc.title} {doc.abstract}"
                embedding = self.embed_text(combined_text)
                
                embedded_doc = {
                    'id': doc.pmid,
                    'values': embedding,
                    'metadata': {
                        'title': doc.title,
                        'abstract': doc.abstract,
                        'authors': ', '.join(doc.authors),
                        'journal': doc.journal,
                        'date': doc.publication_date,
                        'doi': doc.doi,
                        'keywords': ', '.join(doc.keywords)
                    }
                }
                embedded_docs.append(embedded_doc)
                
            except Exception as e:
                logger.error(f"Chyba p≈ôi embedding dokumentu {doc.pmid}: {e}")
                
        return embedded_docs

class PineconeVectorStore:
    """T≈ô√≠da pro spr√°vu vektorov√© datab√°ze Pinecone"""
    
    def __init__(self, api_key: str, environment: str, index_name: str):
        self.api_key = api_key
        self.environment = environment
        self.index_name = index_name
        self.index = None
        self._initialize_pinecone()
    
    def _initialize_pinecone(self):
        """Inicializuje Pinecone klienta"""
        try:
            # Pro demonstraci - v re√°ln√©m pou≈æit√≠ by se pou≈æil skuteƒçn√Ω Pinecone
            logger.info("Inicializace Pinecone (simulov√°no)")
            self.index = "simulated_index"
        except Exception as e:
            logger.error(f"Chyba p≈ôi inicializaci Pinecone: {e}")
    
    def upsert_documents(self, embedded_docs: List[Dict]):
        """Ulo≈æ√≠ dokumenty do vektorov√© datab√°ze"""
        try:
            logger.info(f"Ukl√°d√°n√≠ {len(embedded_docs)} dokument≈Ø do vektorov√© datab√°ze")
            # Simulace ulo≈æen√≠
            for doc in embedded_docs:
                logger.info(f"Ulo≈æen dokument: {doc['metadata']['title']}")
        except Exception as e:
            logger.error(f"Chyba p≈ôi ukl√°d√°n√≠ dokument≈Ø: {e}")
    
    def similarity_search(self, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
        """Vyhled√° podobn√© dokumenty"""
        try:
            # Simulace vyhled√°v√°n√≠ - v re√°ln√©m pou≈æit√≠ by se pou≈æil Pinecone
            sample_results = [
                {
                    'id': '12345678',
                    'score': 0.89,
                    'metadata': {
                        'title': 'Chronick√° √∫nava a jej√≠ diagnostick√© v√Ωzvy',
                        'abstract': 'Studie zkoumaj√≠c√≠ p≈ô√≠ƒçiny chronick√© √∫navy...',
                        'authors': 'Dr. Jan Nov√°k, Prof. Marie Svobodov√°',
                        'journal': 'Journal of Internal Medicine',
                        'doi': '10.1001/jama.2024.12345'
                    }
                },
                {
                    'id': '87654321',
                    'score': 0.76,
                    'metadata': {
                        'title': 'Bolesti hlavy a migr√©ny: modern√≠ p≈ô√≠stupy',
                        'abstract': 'Komplexn√≠ p≈ôehled souƒçasn√Ωch metod diagnostiky...',
                        'authors': 'Dr. Petr ƒåern√Ω, Dr. Anna Kr√°sn√°',
                        'journal': 'Neurology Research',
                        'doi': '10.1002/neur.2024.87654'
                    }
                }
            ]
            return sample_results[:top_k]
        except Exception as e:
            logger.error(f"Chyba p≈ôi vyhled√°v√°n√≠: {e}")
            return []

class MedicalDiagnosisRAG:
    """Hlavn√≠ t≈ô√≠da pro syst√©m l√©ka≈ôsk√© diagnostiky s RAG"""
    
    def __init__(self, pinecone_api_key: str, pinecone_env: str):
        self.pubmed_retriever = PubMedRetriever()
        self.embedder = BioBERTEmbedder()
        self.vector_store = PineconeVectorStore(
            api_key=pinecone_api_key,
            environment=pinecone_env,
            index_name="medical-knowledge"
        )
        
        # LLM pro generov√°n√≠ diagn√≥z (Ollama s Llama-3)
        self.llm = self._initialize_llm()
        self._setup_prompt_template()
        
    def _initialize_llm(self):
        """Inicializuje LLM model"""
        try:
            # Pro demonstraci - v re√°ln√©m pou≈æit√≠ by se pou≈æil Ollama s Llama-3
            logger.info("Inicializace LLM (simulov√°no)")
            return "simulated_llama3"
        except Exception as e:
            logger.error(f"Chyba p≈ôi inicializaci LLM: {e}")
            return None
    
    def _setup_prompt_template(self):
        """Nastav√≠ ≈°ablonu promptu pro diagn√≥zu"""
        self.diagnosis_prompt = """
        Jste zku≈°en√Ω l√©ka≈ô analyzuj√≠c√≠ symptomy pacienta na z√°kladƒõ aktu√°ln√≠ vƒõdeck√© literatury.

        SYMPTOMY PACIENTA:
        {symptoms}

        RELEVANTN√ç VƒöDECK√Å LITERATURA:
        {research_context}

        Proveƒète n√°sleduj√≠c√≠ anal√Ωzu:
        1. Identifikujte nejpravdƒõpodobnƒõj≈°√≠ diagn√≥zy (3-5)
        2. Ohodno≈•te ka≈ædou diagn√≥zu podle pravdƒõpodobnosti (0-100%)
        3. Uveƒète od≈Øvodnƒõn√≠ zalo≈æen√© na poskytnut√© literatu≈ôe
        4. Doporuƒçte dal≈°√≠ diagnostick√° vy≈°et≈ôen√≠

        D≈ÆLE≈ΩIT√â: Toto je pouze podp≈Ørn√Ω n√°stroj. V≈ædy konzultujte s kvalifikovan√Ωm l√©ka≈ôem.

        ODPOVƒöƒé:
        """
    
    def index_medical_literature(self, query_terms: List[str], articles_per_term: int = 20):
        """Indexuje l√©ka≈ôskou literaturu do vektorov√© datab√°ze"""
        logger.info("Zah√°jen√≠ indexov√°n√≠ l√©ka≈ôsk√© literatury")
        
        all_documents = []
        
        for term in query_terms:
            try:
                # Vyhled√°n√≠ ƒçl√°nk≈Ø
                pmids = self.pubmed_retriever.search_articles(term, articles_per_term)
                documents = self.pubmed_retriever.fetch_article_details(pmids)
                all_documents.extend(documents)
                
                logger.info(f"Naƒçteno {len(documents)} ƒçl√°nk≈Ø pro term√≠n: {term}")
                
            except Exception as e:
                logger.error(f"Chyba p≈ôi indexov√°n√≠ term√≠nu {term}: {e}")
        
        # Vytvo≈ôen√≠ embeddings
        embedded_docs = self.embedder.embed_documents(all_documents)
        
        # Ulo≈æen√≠ do vektorov√© datab√°ze
        self.vector_store.upsert_documents(embedded_docs)
        
        logger.info(f"Indexov√°n√≠ dokonƒçeno. Celkem dokument≈Ø: {len(all_documents)}")
        return len(all_documents)
    
    def diagnose_symptoms(self, symptoms: str, top_k: int = 5) -> DiagnosisResult:
        """Analyzuje symptomy a navrhuje diagn√≥zy"""
        try:
            logger.info(f"Anal√Ωza symptom≈Ø: {symptoms[:100]}...")
            
            # Vytvo≈ôen√≠ embedding pro symptomy
            symptoms_embedding = self.embedder.embed_text(symptoms)
            
            # Vyhled√°n√≠ relevantn√≠ch ƒçl√°nk≈Ø
            similar_docs = self.vector_store.similarity_search(symptoms_embedding, top_k)
            
            # P≈ô√≠prava kontextu z vƒõdeck√© literatury
            research_context = self._format_research_context(similar_docs)
            
            # Generov√°n√≠ diagn√≥zy pomoc√≠ LLM
            diagnosis_result = self._generate_diagnosis(symptoms, research_context, similar_docs)
            
            return diagnosis_result
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi anal√Ωze symptom≈Ø: {e}")
            return self._create_error_result()
    
    def _format_research_context(self, similar_docs: List[Dict]) -> str:
        """Form√°tuje kontext z vƒõdeck√© literatury"""
        context_parts = []
        
        for i, doc in enumerate(similar_docs, 1):
            metadata = doc['metadata']
            context_part = f"""
            ƒåL√ÅNEK {i} (Relevance: {doc['score']:.2f}):
            N√°zev: {metadata['title']}
            Auto≈ôi: {metadata['authors']}
            ƒåasopis: {metadata['journal']}
            Abstrakt: {metadata['abstract'][:300]}...
            DOI: {metadata['doi']}
            """
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _generate_diagnosis(self, symptoms: str, research_context: str, similar_docs: List[Dict]) -> DiagnosisResult:
        """Generuje diagn√≥zu pomoc√≠ LLM"""
        try:
            # Simulace LLM odpovƒõdi pro demonstraci
            simulated_diagnosis = """
            Na z√°kladƒõ poskytnut√Ωch symptom≈Ø a aktu√°ln√≠ vƒõdeck√© literatury identifikuji n√°sleduj√≠c√≠ potenci√°ln√≠ diagn√≥zy:

            1. CHRONICK√ù √öNAVOV√ù SYNDROM (85% pravdƒõpodobnost)
            - Symptomy odpov√≠daj√≠ klasick√Ωm projev≈Øm CFS
            - Podporov√°no v√Ωzkumem z Journal of Internal Medicine
            
            2. FIBROMYALGIE (70% pravdƒõpodobnost)
            - Roz≈°√≠≈ôen√© bolesti a √∫nava jsou typick√©
            - Diferenci√°ln√≠ diagnostika s CFS
            
            3. HYPOTYRE√ìZA (60% pravdƒõpodobnost)
            - √önava a kognitivn√≠ pot√≠≈æe mohou indikovat poruchu ≈°t√≠tn√© ≈æl√°zy
            
            DOPORUƒåEN√Å VY≈†ET≈òEN√ç:
            - Kompletn√≠ krevn√≠ obraz
            - Funkce ≈°t√≠tn√© ≈æl√°zy (TSH, fT4)
            - Z√°nƒõtliv√© markery (CRP, ESR)
            - Vitamin D, B12
            """
            
            # Vytvo≈ôen√≠ v√Ωsledku
            cited_papers = []
            for doc in similar_docs:
                metadata = doc['metadata']
                paper = MedicalDocument(
                    pmid=doc['id'],
                    title=metadata['title'],
                    abstract=metadata['abstract'],
                    authors=metadata['authors'].split(', '),
                    journal=metadata['journal'],
                    publication_date=metadata.get('date', ''),
                    doi=metadata['doi'],
                    keywords=metadata.get('keywords', '').split(', ')
                )
                cited_papers.append(paper)
            
            return DiagnosisResult(
                potential_diagnosis="Chronick√Ω √∫navov√Ω syndrom (prim√°rn√≠)",
                confidence_score=0.85,
                supporting_evidence=[
                    "P≈ô√≠tomnost charakteristick√Ωch symptom≈Ø podle CDC krit√©ri√≠",
                    "Vylouƒçen√≠ jin√Ωch p≈ô√≠ƒçin pomoc√≠ laboratorn√≠ch test≈Ø",
                    "Trv√°n√≠ symptom≈Ø del≈°√≠ ne≈æ 6 mƒõs√≠c≈Ø"
                ],
                cited_papers=cited_papers,
                reasoning=simulated_diagnosis
            )
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi generov√°n√≠ diagn√≥zy: {e}")
            return self._create_error_result()
    
    def _create_error_result(self) -> DiagnosisResult:
        """Vytvo≈ô√≠ v√Ωsledek pro p≈ô√≠pad chyby"""
        return DiagnosisResult(
            potential_diagnosis="Chyba p≈ôi anal√Ωze",
            confidence_score=0.0,
            supporting_evidence=["Nastala technick√° chyba p≈ôi zpracov√°n√≠"],
            cited_papers=[],
            reasoning="Syst√©m nen√≠ moment√°lnƒõ dostupn√Ω. Pros√≠m kontaktujte l√©ka≈ôe."
        )

def main():
    """Hlavn√≠ funkce pro demonstraci syst√©mu"""
    try:
        # Inicializace syst√©mu
        rag_system = MedicalDiagnosisRAG(
            pinecone_api_key="your-pinecone-api-key",
            pinecone_env="your-environment"
        )
        
        # Indexov√°n√≠ l√©ka≈ôsk√© literatury
        medical_terms = [
            "chronic fatigue syndrome",
            "fibromyalgia diagnosis",
            "thyroid disorders symptoms",
            "autoimmune diseases",
            "neurological symptoms"
        ]
        
        indexed_count = rag_system.index_medical_literature(medical_terms)
        print(f"‚úÖ Indexov√°no {indexed_count} ƒçl√°nk≈Ø")
        
        # Testovac√≠ p≈ô√≠pad
        patient_symptoms = """
        Pacient (35 let, mu≈æ) si stƒõ≈æuje na:
        - Chronickou √∫navu trvaj√≠c√≠ 8 mƒõs√≠c≈Ø
        - Kognitivn√≠ probl√©my (brain fog)
        - Bolesti sval≈Ø a kloub≈Ø
        - Poruchy sp√°nku
        - Sn√≠≈æen√° tolerance fyzick√© z√°tƒõ≈æe
        - Symptomy se zhor≈°uj√≠ po n√°maze
        """
        
        print("\n" + "="*60)
        print("ANAL√ùZA SYMPTOM≈Æ PACIENTA")
        print("="*60)
        print(f"Symptomy: {patient_symptoms}")
        
        # Proveden√≠ diagn√≥zy
        result = rag_system.diagnose_symptoms(patient_symptoms)
        
        # Zobrazen√≠ v√Ωsledk≈Ø
        print(f"\nüéØ PRIM√ÅRN√ç DIAGN√ìZA: {result.potential_diagnosis}")
        print(f"üìä SPOLEHLIVOST: {result.confidence_score:.1%}")
        
        print(f"\nüìù OD≈ÆVODNƒöN√ç:")
        print(result.reasoning)
        
        print(f"\nüìö CITOVAN√â ƒåL√ÅNKY ({len(result.cited_papers)}):")
        for i, paper in enumerate(result.cited_papers, 1):
            print(f"{i}. {paper.title}")
            print(f"   Auto≈ôi: {', '.join(paper.authors)}")
            print(f"   ƒåasopis: {paper.journal}")
            print(f"   DOI: {paper.doi}")
            print()
        
        print("‚ö†Ô∏è  UPOZORNƒöN√ç: Tento syst√©m slou≈æ√≠ pouze jako podp≈Ørn√Ω n√°stroj.")
        print("   V≈ædy konzultujte s kvalifikovan√Ωm l√©ka≈ôem!")
        
    except Exception as e:
        logger.error(f"Chyba v hlavn√≠ funkci: {e}")

if __name__ == "__main__":
    main()
````

### **Konfiguraƒçn√≠ Soubor**

````python
import os
from typing import Dict, Any

class Config:
    """Konfiguraƒçn√≠ t≈ô√≠da pro aplikaci"""
    
    # API kl√≠ƒçe (naƒçten√© z environment variables)
    PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
    PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT", "us-west1-gcp")
    
    # Nastaven√≠ modelu
    BIOBERT_MODEL = "dmis-lab/biobert-base-cased-v1.1"
    SENTENCE_TRANSFORMER_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
    
    # Pinecone nastaven√≠
    INDEX_NAME = "medical-diagnosis-rag"
    VECTOR_DIMENSION = 384
    
    # PubMed API nastaven√≠
    PUBMED_BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    MAX_ARTICLES_PER_QUERY = 50
    
    # LLM nastaven√≠
    OLLAMA_MODEL = "llama3:latest"
    OLLAMA_BASE_URL = "http://localhost:11434"
    
    @classmethod
    def validate_config(cls) -> Dict[str, Any]:
        """Validuje konfiguraci"""
        missing_keys = []
        
        if not cls.PINECONE_API_KEY:
            missing_keys.append("PINECONE_API_KEY")
            
        return {
            "valid": len(missing_keys) == 0,
            "missing_keys": missing_keys
        }
````

## Shrnut√≠ Projektu

### **Hodnota Projektu**
N√°stroj pro podporu l√©ka≈ôsk√© diagnostiky s RAG p≈ôedstavuje revoluci v p≈ô√≠stupu k diagnostick√Ωm proces≈Øm. Kombinuje s√≠lu umƒõl√© inteligence s rozs√°hl√Ωmi medic√≠nsk√Ωmi datab√°zemi a poskytuje l√©ka≈ô≈Øm rychl√Ω p≈ô√≠stup k relevantn√≠m v√Ωzkum≈Øm.

### **Kl√≠ƒçov√© V√Ωhody**
- **Rychlost**: Okam≈æit√Ω p≈ô√≠stup k tis√≠c≈Øm vƒõdeck√Ωch ƒçl√°nk≈Ø
- **P≈ôesnost**: Pou≈æit√≠ specializovan√Ωch model≈Ø pro l√©ka≈ôskou dom√©nu
- **Transparentnost**: V≈°echny diagn√≥zy jsou podlo≈æen√© citacemi
- **Aktu√°lnost**: Pravideln√© aktualizace datab√°ze nejnovƒõj≈°√≠ch v√Ωzkum≈Ø

### **Technick√© Inovace**
- Hybridn√≠ architektura RAG pro optim√°ln√≠ v√Ωkon
- Specializovan√© embeddings pro l√©ka≈ôsk√Ω kontext
- ≈†k√°lovateln√° vektorov√° datab√°ze
- Etick√© zabezpeƒçen√≠ a transparentnost rozhodov√°n√≠

### **Budouc√≠ Roz≈°√≠≈ôen√≠**
- Integrace s nemocniƒçn√≠mi informaƒçn√≠mi syst√©my
- Podpora pro obrazov√° data (RTG, CT, MRI)
- Personalizace podle specializace l√©ka≈ôe
- V√≠cejazyƒçn√° podpora pro glob√°ln√≠ pou≈æit√≠

Tento projekt demonstruje praktick√© vyu≈æit√≠ RAG technologie v kritick√© oblasti zdravotnictv√≠, kde p≈ôesnost a spolehlivost informac√≠ mohou zachr√°nit lidsk√© ≈æivoty.