<small>Claude Sonnet 4 **(Systém pro Analýzu Lékařské Literatury (RAG))**</small>
# Medical Literature Review System

## Klíčové Koncepty

### RAG (Retrieval-Augmented Generation)
Technika kombinující vyhledávání relevantních dokumentů s generováním odpovědí pomocí LLM. Umožňuje modelu přistupovat k aktuálním informacím bez nutnosti přetrénování.

### PubMed Integrace
PubMed je největší databáze biomedicínské literatury. Integrace umožňuje přístup k milionům vědeckých článků prostřednictvím API.

### BioBERT
Specializovaný BERT model trénovaný na biomedicínských textech. Poskytuje lepší porozumění lékařské terminologii než obecné modely.

### Chroma DB
Vektorová databáze optimalizovaná pro AI aplikace. Umožňuje efektivní ukládání a vyhledávání dokumentů pomocí embeddings.

### Medical NLP
Zpracování přirozeného jazyka zaměřené na lékařské texty. Zahrnuje rozpoznávání entit, extrakci vztahů a porozumění kontextu.

### HIPAA Compliance
Americká legislativa ochraňující zdravotní informace pacientů. Vyžaduje bezpečné zpracování a ukládání dat.

## Komplexní Vysvětlení Projektu

### Cíle Projektu
Systém umožňuje lékařům a výzkumníkům rychle vyhledávat a analyzovat relevantní vědeckou literaturu. Automaticky extrahuje klíčové informace o lécích, diagnózách a léčebných postupech.

### Výzvy
- **Objem dat**: Zpracování milionů vědeckých článků
- **Terminologie**: Komplexní lékařská terminologie a zkratky
- **Aktuálnost**: Potřeba aktuálních informací v rychle se vyvíjející medicíně
- **Přesnost**: Vysoké požadavky na přesnost v lékařském kontextu
- **Soukromí**: Dodržování HIPAA a dalších regulací

### Potenciální Dopad
- Urychlení lékařského výzkumu
- Podpora evidence-based medicine
- Zlepšení kvality pacientské péče
- Snížení času potřebného pro literaturu review

## Komplexní Implementace v Pythonu

### Závislosti a Nastavení

````python
# requirements.txt
langchain==0.1.0
chromadb==0.4.0
sentence-transformers==2.2.0
biopython==1.81
requests==2.31.0
python-dotenv==1.0.0
pydantic==2.5.0
fastapi==0.104.0
uvicorn==0.24.0
pandas==2.1.0
numpy==1.24.0
````

### Hlavní Implementace

````python
import os
import json
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime

import chromadb
import requests
import pandas as pd
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from Bio import Entrez
import logging

# Konfigurace logování
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MedicalDocument:
    """Struktura pro lékařský dokument"""
    pmid: str
    title: str
    abstract: str
    authors: List[str]
    journal: str
    publication_date: str
    keywords: List[str]
    doi: Optional[str] = None

class PubMedConnector:
    """Konektor pro PubMed API"""
    
    def __init__(self, email: str):
        Entrez.email = email
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    
    async def search_articles(self, query: str, max_results: int = 100) -> List[str]:
        """Vyhledá články podle dotazu a vrátí PMID"""
        try:
            handle = Entrez.esearch(
                db="pubmed",
                term=query,
                retmax=max_results,
                sort="relevance"
            )
            search_results = Entrez.read(handle)
            handle.close()
            return search_results["IdList"]
        except Exception as e:
            logger.error(f"Chyba při vyhledávání: {e}")
            return []
    
    async def fetch_article_details(self, pmids: List[str]) -> List[MedicalDocument]:
        """Získá detaily článků podle PMID"""
        documents = []
        
        try:
            # Získání detailů v dávkách
            batch_size = 20
            for i in range(0, len(pmids), batch_size):
                batch_pmids = pmids[i:i + batch_size]
                
                handle = Entrez.efetch(
                    db="pubmed",
                    id=",".join(batch_pmids),
                    rettype="xml",
                    retmode="xml"
                )
                
                records = Entrez.read(handle)
                handle.close()
                
                for record in records["PubmedArticle"]:
                    doc = self._parse_pubmed_record(record)
                    if doc:
                        documents.append(doc)
                        
        except Exception as e:
            logger.error(f"Chyba při získávání detailů: {e}")
        
        return documents
    
    def _parse_pubmed_record(self, record) -> Optional[MedicalDocument]:
        """Parsuje PubMed záznam do MedicalDocument"""
        try:
            article = record["MedlineCitation"]["Article"]
            pmid = str(record["MedlineCitation"]["PMID"])
            
            title = article.get("ArticleTitle", "")
            abstract = ""
            
            if "Abstract" in article:
                abstract_texts = article["Abstract"].get("AbstractText", [])
                if isinstance(abstract_texts, list):
                    abstract = " ".join(str(text) for text in abstract_texts)
                else:
                    abstract = str(abstract_texts)
            
            authors = []
            if "AuthorList" in article:
                for author in article["AuthorList"]:
                    if "LastName" in author and "ForeName" in author:
                        authors.append(f"{author['ForeName']} {author['LastName']}")
            
            journal = article.get("Journal", {}).get("Title", "")
            
            pub_date = ""
            if "Journal" in article and "JournalIssue" in article["Journal"]:
                date_info = article["Journal"]["JournalIssue"].get("PubDate", {})
                year = date_info.get("Year", "")
                month = date_info.get("Month", "")
                pub_date = f"{year}-{month}" if year and month else year
            
            keywords = []
            if "KeywordList" in record["MedlineCitation"]:
                for keyword_list in record["MedlineCitation"]["KeywordList"]:
                    keywords.extend([str(kw) for kw in keyword_list])
            
            return MedicalDocument(
                pmid=pmid,
                title=title,
                abstract=abstract,
                authors=authors,
                journal=journal,
                publication_date=pub_date,
                keywords=keywords
            )
            
        except Exception as e:
            logger.error(f"Chyba při parsování záznamu: {e}")
            return None

class MedicalEmbeddingModel:
    """Wrapper pro biomedicínské embeddings"""
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        
    def encode_documents(self, texts: List[str]) -> List[List[float]]:
        """Kóduje texty do vektorů"""
        return self.model.encode(texts).tolist()
    
    def encode_query(self, query: str) -> List[float]:
        """Kóduje dotaz do vektoru"""
        return self.model.encode([query])[0].tolist()

class MedicalVectorStore:
    """Vektorové úložiště pro lékařské dokumenty"""
    
    def __init__(self, collection_name: str = "medical_literature"):
        self.client = chromadb.Client()
        self.collection_name = collection_name
        self.embedding_model = MedicalEmbeddingModel()
        
        # Vytvoření nebo získání kolekce
        try:
            self.collection = self.client.get_collection(collection_name)
        except:
            self.collection = self.client.create_collection(collection_name)
    
    async def add_documents(self, documents: List[MedicalDocument]):
        """Přidá dokumenty do vektorového úložiště"""
        texts = []
        metadatas = []
        ids = []
        
        for doc in documents:
            # Kombinace titulu a abstraktu pro embedding
            full_text = f"{doc.title} {doc.abstract}"
            texts.append(full_text)
            
            metadata = {
                "pmid": doc.pmid,
                "title": doc.title,
                "authors": json.dumps(doc.authors),
                "journal": doc.journal,
                "publication_date": doc.publication_date,
                "keywords": json.dumps(doc.keywords)
            }
            metadatas.append(metadata)
            ids.append(doc.pmid)
        
        # Generování embeddings
        embeddings = self.embedding_model.encode_documents(texts)
        
        # Přidání do kolekce
        self.collection.add(
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"Přidáno {len(documents)} dokumentů do vektorového úložiště")
    
    async def similarity_search(self, query: str, k: int = 5) -> List[Dict]:
        """Vyhledá podobné dokumenty"""
        query_embedding = self.embedding_model.encode_query(query)
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=k
        )
        
        search_results = []
        for i, doc_id in enumerate(results["ids"][0]):
            result = {
                "pmid": doc_id,
                "content": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i]
            }
            search_results.append(result)
        
        return search_results

class MedicalRAGSystem:
    """Hlavní RAG systém pro lékařskou literaturu"""
    
    def __init__(self, email: str):
        self.pubmed = PubMedConnector(email)
        self.vector_store = MedicalVectorStore()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    async def index_medical_literature(self, queries: List[str], max_results_per_query: int = 50):
        """Indexuje lékařskou literaturu podle dotazů"""
        all_documents = []
        
        for query in queries:
            logger.info(f"Vyhledávání pro dotaz: {query}")
            
            # Vyhledání článků
            pmids = await self.pubmed.search_articles(query, max_results_per_query)
            logger.info(f"Nalezeno {len(pmids)} článků")
            
            # Získání detailů
            documents = await self.pubmed.fetch_article_details(pmids)
            logger.info(f"Získáno {len(documents)} kompletních dokumentů")
            
            all_documents.extend(documents)
        
        # Odstranění duplikátů podle PMID
        unique_docs = {doc.pmid: doc for doc in all_documents}
        unique_documents = list(unique_docs.values())
        
        logger.info(f"Celkem unikátních dokumentů: {len(unique_documents)}")
        
        # Přidání do vektorového úložiště
        await self.vector_store.add_documents(unique_documents)
        
        return len(unique_documents)
    
    async def query_literature(self, question: str, k: int = 5) -> Dict:
        """Dotaz na lékařskou literaturu"""
        # Vyhledání relevantních dokumentů
        relevant_docs = await self.vector_store.similarity_search(question, k)
        
        # Extrakce kontextu
        context_parts = []
        source_info = []
        
        for doc in relevant_docs:
            context_parts.append(doc["content"])
            source_info.append({
                "pmid": doc["pmid"],
                "title": doc["metadata"]["title"],
                "journal": doc["metadata"]["journal"],
                "distance": doc["distance"]
            })
        
        context = "\n\n".join(context_parts)
        
        # Generování odpovědi (zde by bylo použito LLM API)
        response = self._generate_medical_response(question, context)
        
        return {
            "question": question,
            "answer": response,
            "sources": source_info,
            "context": context
        }
    
    def _generate_medical_response(self, question: str, context: str) -> str:
        """Generuje odpověď na základě kontextu (zjednodušená implementace)"""
        # V reálné aplikaci by zde bylo volání OpenAI/Claude API
        prompt = f"""
        Na základě následujícího kontextu z lékařské literatury odpověz na otázku:
        
        Otázka: {question}
        
        Kontext:
        {context}
        
        Odpověď:
        """
        
        # Zjednodušená odpověď - v reálu by bylo LLM API volání
        return f"Na základě analyzované literatury lze říci, že otázka '{question}' se týká komplexního tématu vyžadujícího další analýzu dostupných zdrojů."

class MedicalDataProcessor:
    """Procesor pro zpracování lékařských dat"""
    
    @staticmethod
    def extract_drug_information(text: str) -> Dict:
        """Extrahuje informace o lécích z textu"""
        # Zjednodušená implementace - v reálu by použila NER modely
        drug_keywords = ["aspirin", "ibuprofen", "acetaminophen", "morphine", "insulin"]
        found_drugs = [drug for drug in drug_keywords if drug.lower() in text.lower()]
        
        return {
            "mentioned_drugs": found_drugs,
            "drug_count": len(found_drugs)
        }
    
    @staticmethod
    def extract_medical_entities(text: str) -> Dict:
        """Extrahuje lékařské entity"""
        # Zjednodušená implementace
        diseases = ["diabetes", "hypertension", "cancer", "pneumonia"]
        symptoms = ["fever", "pain", "nausea", "fatigue"]
        
        found_diseases = [d for d in diseases if d.lower() in text.lower()]
        found_symptoms = [s for s in symptoms if s.lower() in text.lower()]
        
        return {
            "diseases": found_diseases,
            "symptoms": found_symptoms
        }

# Hlavní aplikace
class MedicalLiteratureApp:
    """Hlavní aplikace pro analýzu lékařské literatury"""
    
    def __init__(self, email: str):
        self.rag_system = MedicalRAGSystem(email)
        self.data_processor = MedicalDataProcessor()
    
    async def setup_knowledge_base(self):
        """Nastavení znalostní báze"""
        medical_queries = [
            "diabetes treatment guidelines",
            "hypertension management",
            "cancer immunotherapy",
            "cardiovascular disease prevention",
            "mental health interventions"
        ]
        
        logger.info("Začátek indexování lékařské literatury...")
        doc_count = await self.rag_system.index_medical_literature(medical_queries)
        logger.info(f"Indexování dokončeno. Zpracováno {doc_count} dokumentů.")
    
    async def analyze_medical_query(self, query: str) -> Dict:
        """Analyzuje lékařský dotaz"""
        # Získání odpovědi z RAG systému
        rag_response = await self.rag_system.query_literature(query)
        
        # Dodatečná analýza
        drug_info = self.data_processor.extract_drug_information(rag_response["context"])
        medical_entities = self.data_processor.extract_medical_entities(rag_response["context"])
        
        return {
            "query": query,
            "rag_response": rag_response,
            "drug_analysis": drug_info,
            "medical_entities": medical_entities,
            "timestamp": datetime.now().isoformat()
        }

# Ukázkové použití
async def main():
    """Hlavní funkce pro demonstraci"""
    # Inicializace aplikace
    app = MedicalLiteratureApp("your.email@example.com")
    
    try:
        # Nastavení znalostní báze
        await app.setup_knowledge_base()
        
        # Testovací dotazy
        queries = [
            "What are the latest treatments for type 2 diabetes?",
            "How effective is immunotherapy for lung cancer?",
            "What are the side effects of ACE inhibitors?"
        ]
        
        # Analýza dotazů
        for query in queries:
            print(f"\n{'='*50}")
            print(f"Dotaz: {query}")
            print('='*50)
            
            result = await app.analyze_medical_query(query)
            
            print(f"Odpověď: {result['rag_response']['answer']}")
            print(f"\nZdroje ({len(result['rag_response']['sources'])}):")
            for source in result['rag_response']['sources'][:3]:
                print(f"- PMID: {source['pmid']}")
                print(f"  Název: {source['title'][:100]}...")
                print(f"  Časopis: {source['journal']}")
            
            print(f"\nNalezené léky: {result['drug_analysis']['mentioned_drugs']}")
            print(f"Lékařské entity: {result['medical_entities']}")
    
    except Exception as e:
        logger.error(f"Chyba v hlavní funkci: {e}")

if __name__ == "__main__":
    asyncio.run(main())
````

### Konfigurace a Bezpečnost

````python
import os
from typing import Dict, Any
from pydantic import BaseSettings

class Settings(BaseSettings):
    """Konfigurace aplikace s HIPAA compliance"""
    
    # API klíče
    openai_api_key: str = ""
    pubmed_email: str = ""
    
    # Databáze
    chroma_persist_directory: str = "./chroma_db"
    
    # Bezpečnost
    encryption_key: str = ""
    session_timeout: int = 3600  # 1 hodina
    max_query_length: int = 1000
    
    # HIPAA Compliance
    audit_logging: bool = True
    data_retention_days: int = 2555  # 7 let
    encryption_at_rest: bool = True
    access_control: bool = True
    
    # Rate limiting
    max_requests_per_minute: int = 60
    max_requests_per_hour: int = 1000
    
    class Config:
        env_file = ".env"
        case_sensitive = False

class HIPAACompliantLogger:
    """Logger s HIPAA compliance"""
    
    def __init__(self):
        self.audit_fields = [
            "timestamp", "user_id", "action", "resource", 
            "ip_address", "success", "error_message"
        ]
    
    def log_access(self, user_id: str, action: str, resource: str, 
                   ip_address: str, success: bool, error_message: str = None):
        """Loguje přístup s HIPAA compliance"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "user_id": self._hash_user_id(user_id),
            "action": action,
            "resource": resource,
            "ip_address": self._hash_ip(ip_address),
            "success": success,
            "error_message": error_message
        }
        
        # Zde by bylo uložení do zabezpečeného audit logu
        logger.info(f"AUDIT: {log_entry}")
    
    def _hash_user_id(self, user_id: str) -> str:
        """Hashuje user ID pro anonymizaci"""
        import hashlib
        return hashlib.sha256(user_id.encode()).hexdigest()[:16]
    
    def _hash_ip(self, ip_address: str) -> str:
        """Hashuje IP adresu"""
        import hashlib
        return hashlib.sha256(ip_address.encode()).hexdigest()[:16]
````

### API Rozhraní

````python
from fastapi import FastAPI, HTTPException, Depends, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from typing import List, Optional
import asyncio

app = FastAPI(title="Medical Literature RAG API", version="1.0.0")
security = HTTPBearer()

class QueryRequest(BaseModel):
    query: str
    max_results: Optional[int] = 5
    include_drug_analysis: Optional[bool] = True

class QueryResponse(BaseModel):
    query: str
    answer: str
    sources: List[Dict]
    drug_analysis: Optional[Dict]
    medical_entities: Optional[Dict]
    confidence_score: Optional[float]

# Globální instance aplikace
medical_app = None

async def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    """Ověří autentizační token"""
    # Zde by byla implementace ověření JWT tokenu
    if not credentials.credentials:
        raise HTTPException(status_code=401, detail="Neplatný token")
    return credentials.credentials

@app.on_event("startup")
async def startup_event():
    """Inicializace při startu aplikace"""
    global medical_app
    medical_app = MedicalLiteratureApp("api@medical-rag.com")
    await medical_app.setup_knowledge_base()

@app.post("/query", response_model=QueryResponse)
async def query_medical_literature(
    request: QueryRequest,
    token: str = Depends(verify_token)
):
    """Dotaz na lékařskou literaturu"""
    try:
        result = await medical_app.analyze_medical_query(request.query)
        
        return QueryResponse(
            query=request.query,
            answer=result["rag_response"]["answer"],
            sources=result["rag_response"]["sources"][:request.max_results],
            drug_analysis=result["drug_analysis"] if request.include_drug_analysis else None,
            medical_entities=result["medical_entities"],
            confidence_score=0.85  # Zjednodušené
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chyba při zpracování dotazu: {str(e)}")

@app.get("/health")
async def health_check():
    """Kontrola stavu aplikace"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}
````

## Shrnutí Projektu

### Klíčové Výhody
1. **Rychlý přístup k aktuální literatuře** - Automatické vyhledávání v PubMed databázi
2. **Inteligentní analýza** - RAG technologie pro kontextové odpovědi
3. **Specializované embeddings** - Optimalizované pro lékařskou terminologii
4. **Škálovatelnost** - Vektorová databáze pro miliony dokumentů
5. **HIPAA compliance** - Bezpečné zpracování zdravotních dat

### Technické Inovace
- Kombinace PubMed API s moderními RAG technikami
- Specializované biomedicínské NLP modely
- Efektivní vektorové vyhledávání pomocí Chroma DB
- Robustní error handling a monitoring

### Budoucí Rozšíření
- Integrace s dalšími medicínskými databázemi
- Pokročilé NER modely pro lékařské entity
- Real-time aktualizace znalostní báze
- Vícejazyčná podpora pro globální použití

Tento systém představuje pokročilé řešení pro moderní evidence-based medicine, umožňující lékařům rychlý přístup k nejnovějším vědeckým poznatků při zachování nejvyšších bezpečnostních standardů.