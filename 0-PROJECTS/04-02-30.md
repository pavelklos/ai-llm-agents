<small>Claude Sonnet 4 **(Interactive Data Explorer using LLM)**</small>
# Interactive Data Explorer using LLM

## Key Concepts Explanation

### Data Analysis Automation
Intelligent automation of data exploration tasks using natural language processing to interpret user queries and automatically generate appropriate pandas operations, statistical analyses, and data transformations without requiring manual coding expertise.

### Pandas Agent
AI-powered agent that translates natural language queries into pandas DataFrame operations, enabling users to perform complex data manipulations, filtering, aggregations, and transformations through conversational interfaces rather than traditional programming syntax.

### CSV Question Answering
Natural language interface for querying CSV data where users can ask questions in plain English and receive accurate answers based on data analysis, pattern recognition, and statistical computations performed on the underlying dataset.

### Chart Generation
Automated visualization creation that interprets user intent and data characteristics to generate appropriate charts, graphs, and plots using libraries like Matplotlib, Plotly, and Seaborn, with intelligent selection of visualization types based on data types and query context.

### Interactive Data Exploration
Conversational data analysis workflow that allows users to iteratively explore datasets through natural language queries, follow-up questions, and dynamic visualization generation while maintaining context and analysis history.

## Comprehensive Project Explanation

### Objectives
The Interactive Data Explorer aims to democratize data analysis by providing an intelligent, conversational interface that enables users of all technical levels to explore, analyze, and visualize data through natural language interactions, eliminating traditional barriers to data insights.

### Key Features
- **Natural Language Querying**: Plain English data questions and analysis requests
- **Automated Code Generation**: Smart pandas operation creation from user intent
- **Dynamic Visualization**: Context-aware chart and graph generation
- **Statistical Analysis**: Automated statistical computation and interpretation
- **Data Quality Assessment**: Intelligent data profiling and quality reporting
- **Export Capabilities**: Multiple format export options for results and visualizations

### Challenges
- **Query Ambiguity**: Interpreting vague or incomplete natural language requests
- **Code Safety**: Ensuring generated code is secure and won't harm systems
- **Performance Optimization**: Handling large datasets efficiently
- **Context Maintenance**: Preserving analysis context across multiple interactions
- **Visualization Selection**: Choosing appropriate chart types for different data scenarios

### Potential Impact
This system can significantly reduce the barrier to data analysis, enable faster insights generation, improve decision-making processes, and make data-driven approaches accessible to non-technical stakeholders across organizations.

## Comprehensive Project Example with Python Implementation

### Dependencies and Setup

````python
# requirements.txt
streamlit==1.29.0
openai==1.6.1
langchain==0.1.0
langchain-openai==0.0.5
langchain-experimental==0.0.47
pandas==2.1.4
numpy==1.24.3
matplotlib==3.8.2
seaborn==0.13.0
plotly==5.17.0
scipy==1.11.4
scikit-learn==1.3.2
yfinance==0.2.18
requests==2.31.0
altair==5.2.0
datetime
logging
re
json
io
base64
typing
````

### Core Implementation

````python
import os
import json
import logging
import re
import io
import base64
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# LangChain components
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType

# Data sources
import yfinance as yf
import requests

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataExplorer:
    """Main class for interactive data exploration."""
    
    def __init__(self, openai_api_key: str = None):
        self.openai_api_key = openai_api_key
        if openai_api_key:
            self.llm = ChatOpenAI(
                temperature=0,
                model_name="gpt-4",
                openai_api_key=openai_api_key
            )
        else:
            self.llm = None
        
        self.current_data = None
        self.analysis_history = []
        self.generated_charts = []
        
        # Initialize prompts
        self._initialize_prompts()
        
        # Set plotting style
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
    
    def _initialize_prompts(self):
        """Initialize LLM prompts for different tasks."""
        self.analysis_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are an expert data analyst. Analyze the provided data and respond to user queries.
            
            Guidelines:
            1. Provide clear, actionable insights
            2. Suggest appropriate visualizations
            3. Explain statistical concepts in simple terms
            4. Recommend follow-up analyses
            5. Be concise but comprehensive
            
            Data info: {data_info}
            Query: {query}
            """),
            ("human", "{query}")
        ])
        
        self.chart_suggestion_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template("""
            You are a data visualization expert. Suggest the most appropriate chart type
            for the given data and user query.
            
            Available chart types:
            - line: for time series or continuous data
            - bar: for categorical comparisons
            - scatter: for correlation analysis
            - histogram: for distribution analysis
            - box: for outlier detection and distribution
            - heatmap: for correlation matrices
            - pie: for part-to-whole relationships
            
            Data columns: {columns}
            Data types: {dtypes}
            Query: {query}
            
            Respond with only the chart type name.
            """),
            ("human", "What chart type should I use?")
        ])
    
    def load_data(self, data_source: Union[str, pd.DataFrame], source_type: str = "csv") -> bool:
        """Load data from various sources."""
        try:
            if source_type == "csv" and isinstance(data_source, str):
                self.current_data = pd.read_csv(data_source)
            elif source_type == "sample":
                self.current_data = self._generate_sample_data(data_source)
            elif source_type == "stock":
                self.current_data = self._fetch_stock_data(data_source)
            elif isinstance(data_source, pd.DataFrame):
                self.current_data = data_source.copy()
            else:
                return False
            
            # Basic data cleaning
            self.current_data = self._clean_data(self.current_data)
            
            logger.info(f"Data loaded successfully: {self.current_data.shape}")
            return True
            
        except Exception as e:
            logger.error(f"Data loading error: {e}")
            return False
    
    def _generate_sample_data(self, dataset_name: str) -> pd.DataFrame:
        """Generate sample datasets for demonstration."""
        np.random.seed(42)
        
        if dataset_name == "sales":
            dates = pd.date_range('2023-01-01', periods=365, freq='D')
            data = pd.DataFrame({
                'date': dates,
                'sales': np.random.normal(1000, 200, 365) + 
                       50 * np.sin(np.arange(365) * 2 * np.pi / 365),
                'region': np.random.choice(['North', 'South', 'East', 'West'], 365),
                'product': np.random.choice(['A', 'B', 'C', 'D'], 365),
                'customers': np.random.poisson(50, 365),
                'marketing_spend': np.random.uniform(100, 500, 365)
            })
            
        elif dataset_name == "employees":
            n = 1000
            data = pd.DataFrame({
                'employee_id': range(1, n + 1),
                'age': np.random.normal(35, 10, n),
                'salary': np.random.normal(60000, 15000, n),
                'department': np.random.choice(['IT', 'Sales', 'HR', 'Finance'], n),
                'experience_years': np.random.normal(8, 5, n),
                'satisfaction_score': np.random.uniform(1, 10, n),
                'performance_rating': np.random.choice(['Poor', 'Average', 'Good', 'Excellent'], n)
            })
            
        elif dataset_name == "customers":
            n = 2000
            data = pd.DataFrame({
                'customer_id': range(1, n + 1),
                'age': np.random.normal(40, 15, n),
                'income': np.random.lognormal(10.5, 0.5, n),
                'spending_score': np.random.uniform(1, 100, n),
                'gender': np.random.choice(['Male', 'Female'], n),
                'city': np.random.choice(['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix'], n),
                'loyalty_years': np.random.exponential(3, n)
            })
            
        else:  # Default iris-like dataset
            n = 150
            data = pd.DataFrame({
                'sepal_length': np.random.normal(5.8, 0.8, n),
                'sepal_width': np.random.normal(3.1, 0.4, n),
                'petal_length': np.random.normal(3.8, 1.8, n),
                'petal_width': np.random.normal(1.2, 0.8, n),
                'species': np.random.choice(['setosa', 'versicolor', 'virginica'], n)
            })
        
        return data
    
    def _fetch_stock_data(self, symbol: str) -> pd.DataFrame:
        """Fetch stock data using yfinance."""
        try:
            stock = yf.Ticker(symbol)
            data = stock.history(period="1y")
            data.reset_index(inplace=True)
            data.columns = [col.lower().replace(' ', '_') for col in data.columns]
            return data
        except Exception as e:
            logger.error(f"Stock data fetch error: {e}")
            return pd.DataFrame()
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Basic data cleaning operations."""
        # Convert date columns
        for col in df.columns:
            if 'date' in col.lower() or 'time' in col.lower():
                try:
                    df[col] = pd.to_datetime(df[col])
                except:
                    pass
        
        # Handle numeric columns
        for col in df.select_dtypes(include=[np.number]).columns:
            # Remove extreme outliers (3 standard deviations)
            mean = df[col].mean()
            std = df[col].std()
            df[col] = df[col].clip(lower=mean - 3*std, upper=mean + 3*std)
        
        return df
    
    def get_data_summary(self) -> Dict[str, Any]:
        """Get comprehensive data summary."""
        if self.current_data is None:
            return {}
        
        df = self.current_data
        
        summary = {
            'shape': df.shape,
            'columns': list(df.columns),
            'dtypes': df.dtypes.to_dict(),
            'missing_values': df.isnull().sum().to_dict(),
            'memory_usage': df.memory_usage(deep=True).sum(),
            'numeric_columns': list(df.select_dtypes(include=[np.number]).columns),
            'categorical_columns': list(df.select_dtypes(include=['object']).columns),
            'datetime_columns': list(df.select_dtypes(include=['datetime64']).columns)
        }
        
        # Statistical summary for numeric columns
        if summary['numeric_columns']:
            summary['statistics'] = df[summary['numeric_columns']].describe().to_dict()
        
        return summary
    
    def analyze_query(self, query: str) -> Dict[str, Any]:
        """Analyze user query and generate response."""
        try:
            if self.current_data is None:
                return {'error': 'No data loaded. Please load data first.'}
            
            # Create pandas agent if LLM is available
            if self.llm:
                agent = create_pandas_dataframe_agent(
                    self.llm,
                    self.current_data,
                    verbose=True,
                    agent_type=AgentType.OPENAI_FUNCTIONS,
                    handle_parsing_errors=True
                )
                
                # Get agent response
                try:
                    agent_response = agent.run(query)
                except Exception as e:
                    agent_response = f"Agent error: {str(e)}"
            else:
                agent_response = "LLM not available. Using rule-based analysis."
            
            # Rule-based analysis as fallback
            rule_response = self._rule_based_analysis(query)
            
            # Suggest visualization
            chart_suggestion = self._suggest_chart(query)
            
            result = {
                'agent_response': agent_response,
                'rule_response': rule_response,
                'chart_suggestion': chart_suggestion,
                'query': query,
                'timestamp': datetime.now()
            }
            
            self.analysis_history.append(result)
            return result
            
        except Exception as e:
            logger.error(f"Query analysis error: {e}")
            return {'error': f'Analysis failed: {str(e)}'}
    
    def _rule_based_analysis(self, query: str) -> str:
        """Rule-based analysis for common queries."""
        query_lower = query.lower()
        df = self.current_data
        
        # Statistical queries
        if any(word in query_lower for word in ['mean', 'average']):
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                means = df[numeric_cols].mean()
                return f"Average values:\n{means.to_string()}"
        
        if any(word in query_lower for word in ['max', 'maximum', 'highest']):
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                maxes = df[numeric_cols].max()
                return f"Maximum values:\n{maxes.to_string()}"
        
        if any(word in query_lower for word in ['min', 'minimum', 'lowest']):
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                mins = df[numeric_cols].min()
                return f"Minimum values:\n{mins.to_string()}"
        
        if 'correlation' in query_lower:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                corr = df[numeric_cols].corr()
                return f"Correlation matrix:\n{corr.to_string()}"
        
        if any(word in query_lower for word in ['missing', 'null', 'nan']):
            missing = df.isnull().sum()
            missing = missing[missing > 0]
            if len(missing) > 0:
                return f"Missing values:\n{missing.to_string()}"
            else:
                return "No missing values found."
        
        if 'shape' in query_lower or 'size' in query_lower:
            return f"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns"
        
        if 'describe' in query_lower or 'summary' in query_lower:
            return f"Dataset summary:\n{df.describe().to_string()}"
        
        return "I understand your query. Please try a more specific question or use the chart generation feature."
    
    def _suggest_chart(self, query: str) -> str:
        """Suggest appropriate chart type based on query."""
        if self.llm:
            try:
                data_info = {
                    'columns': list(self.current_data.columns),
                    'dtypes': self.current_data.dtypes.astype(str).to_dict()
                }
                
                response = self.llm.invoke(
                    self.chart_suggestion_prompt.format(
                        columns=data_info['columns'],
                        dtypes=data_info['dtypes'],
                        query=query
                    )
                )
                return response.content.strip().lower()
            except:
                pass
        
        # Rule-based chart suggestion
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['trend', 'time', 'over time']):
            return 'line'
        elif any(word in query_lower for word in ['compare', 'comparison', 'between']):
            return 'bar'
        elif any(word in query_lower for word in ['relationship', 'correlation']):
            return 'scatter'
        elif any(word in query_lower for word in ['distribution', 'histogram']):
            return 'histogram'
        elif any(word in query_lower for word in ['outlier', 'box']):
            return 'box'
        else:
            return 'bar'  # Default
    
    def generate_chart(self, chart_type: str, x_col: str = None, y_col: str = None,
                      color_col: str = None, title: str = None) -> go.Figure:
        """Generate interactive charts using Plotly."""
        try:
            df = self.current_data
            
            if chart_type == 'line':
                if x_col and y_col:
                    fig = px.line(df, x=x_col, y=y_col, color=color_col, title=title)
                else:
                    # Auto-select columns
                    date_cols = df.select_dtypes(include=['datetime64']).columns
                    numeric_cols = df.select_dtypes(include=[np.number]).columns
                    
                    if len(date_cols) > 0 and len(numeric_cols) > 0:
                        fig = px.line(df, x=date_cols[0], y=numeric_cols[0], title=title)
                    else:
                        fig = px.line(df, y=numeric_cols[0] if len(numeric_cols) > 0 else df.columns[0], title=title)
            
            elif chart_type == 'bar':
                if x_col and y_col:
                    fig = px.bar(df, x=x_col, y=y_col, color=color_col, title=title)
                else:
                    # Auto-select columns
                    cat_cols = df.select_dtypes(include=['object']).columns
                    numeric_cols = df.select_dtypes(include=[np.number]).columns
                    
                    if len(cat_cols) > 0 and len(numeric_cols) > 0:
                        # Group by categorical and sum numeric
                        grouped = df.groupby(cat_cols[0])[numeric_cols[0]].sum().reset_index()
                        fig = px.bar(grouped, x=cat_cols[0], y=numeric_cols[0], title=title)
                    else:
                        fig = px.bar(df, x=df.columns[0], y=df.columns[1] if len(df.columns) > 1 else df.columns[0], title=title)
            
            elif chart_type == 'scatter':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) >= 2:
                    fig = px.scatter(df, x=x_col or numeric_cols[0], y=y_col or numeric_cols[1], 
                                   color=color_col, title=title)
                else:
                    fig = px.scatter(df, x=df.index, y=numeric_cols[0] if len(numeric_cols) > 0 else df.columns[0], title=title)
            
            elif chart_type == 'histogram':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    fig = px.histogram(df, x=x_col or numeric_cols[0], color=color_col, title=title)
                else:
                    fig = px.histogram(df, x=df.columns[0], title=title)
            
            elif chart_type == 'box':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    fig = px.box(df, y=y_col or numeric_cols[0], x=x_col, color=color_col, title=title)
                else:
                    fig = px.box(df, y=df.columns[0], title=title)
            
            elif chart_type == 'heatmap':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 1:
                    corr_matrix = df[numeric_cols].corr()
                    fig = px.imshow(corr_matrix, text_auto=True, title=title or "Correlation Heatmap")
                else:
                    return None
            
            elif chart_type == 'pie':
                cat_cols = df.select_dtypes(include=['object']).columns
                if len(cat_cols) > 0:
                    value_counts = df[cat_cols[0]].value_counts()
                    fig = px.pie(values=value_counts.values, names=value_counts.index, title=title)
                else:
                    return None
            
            else:
                return None
            
            # Customize layout
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(size=12)
            )
            
            self.generated_charts.append({
                'figure': fig,
                'type': chart_type,
                'timestamp': datetime.now()
            })
            
            return fig
            
        except Exception as e:
            logger.error(f"Chart generation error: {e}")
            return None
    
    def get_advanced_analysis(self, analysis_type: str) -> Dict[str, Any]:
        """Perform advanced statistical analysis."""
        try:
            df = self.current_data
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if analysis_type == 'clustering':
                if len(numeric_cols) >= 2:
                    # Prepare data
                    X = df[numeric_cols].dropna()
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    # Perform clustering
                    kmeans = KMeans(n_clusters=3, random_state=42)
                    clusters = kmeans.fit_predict(X_scaled)
                    
                    return {
                        'clusters': clusters.tolist(),
                        'centers': kmeans.cluster_centers_.tolist(),
                        'inertia': kmeans.inertia_,
                        'n_clusters': 3
                    }
            
            elif analysis_type == 'pca':
                if len(numeric_cols) >= 2:
                    X = df[numeric_cols].dropna()
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    pca = PCA(n_components=2)
                    X_pca = pca.fit_transform(X_scaled)
                    
                    return {
                        'explained_variance_ratio': pca.explained_variance_ratio_.tolist(),
                        'components': X_pca.tolist(),
                        'feature_importance': pca.components_.tolist()
                    }
            
            elif analysis_type == 'outliers':
                outliers = {}
                for col in numeric_cols:
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    outlier_mask = (df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))
                    outliers[col] = df[outlier_mask].index.tolist()
                
                return {'outliers': outliers}
            
            return {'error': 'Analysis type not supported'}
            
        except Exception as e:
            logger.error(f"Advanced analysis error: {e}")
            return {'error': str(e)}
    
    def export_results(self, format_type: str = 'csv') -> bytes:
        """Export current data and analysis results."""
        try:
            if format_type == 'csv':
                buffer = io.StringIO()
                self.current_data.to_csv(buffer, index=False)
                return buffer.getvalue().encode('utf-8')
            
            elif format_type == 'json':
                export_data = {
                    'data': self.current_data.to_dict('records'),
                    'summary': self.get_data_summary(),
                    'analysis_history': [
                        {k: v for k, v in item.items() if k != 'timestamp'} 
                        for item in self.analysis_history
                    ]
                }
                return json.dumps(export_data, indent=2).encode('utf-8')
            
            return b''
            
        except Exception as e:
            logger.error(f"Export error: {e}")
            return b''

def main():
    """Main Streamlit application."""
    st.set_page_config(
        page_title="Interactive Data Explorer",
        page_icon="ðŸ“Š",
        layout="wide"
    )
    
    st.title("ðŸ“Š Interactive Data Explorer using LLM")
    st.markdown("Ask questions about your data in natural language and get instant insights!")
    
    # Initialize session state
    if 'explorer' not in st.session_state:
        st.session_state['explorer'] = None
    if 'data_loaded' not in st.session_state:
        st.session_state['data_loaded'] = False
    
    # Sidebar for data loading and configuration
    with st.sidebar:
        st.header("ðŸ”§ Configuration")
        
        # OpenAI API Key
        openai_key = st.text_input("OpenAI API Key (Optional)", type="password",
                                 help="Required for advanced LLM features")
        
        if st.button("Initialize Explorer") or st.session_state['explorer'] is None:
            with st.spinner("Initializing..."):
                st.session_state['explorer'] = DataExplorer(openai_key)
                st.success("Explorer initialized!")
        
        st.header("ðŸ“ Data Loading")
        
        # Data source selection
        data_source = st.selectbox(
            "Select Data Source",
            ["Upload CSV", "Sample Dataset", "Stock Data", "Demo Data"]
        )
        
        if data_source == "Upload CSV":
            uploaded_file = st.file_uploader("Choose CSV file", type="csv")
            if uploaded_file and st.button("Load CSV"):
                with st.spinner("Loading data..."):
                    # Save uploaded file temporarily
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    success = st.session_state['explorer'].load_data(temp_path, "csv")
                    os.remove(temp_path)  # Clean up
                    
                    if success:
                        st.session_state['data_loaded'] = True
                        st.success("Data loaded successfully!")
                        st.rerun()
                    else:
                        st.error("Failed to load data")
        
        elif data_source == "Sample Dataset":
            dataset_type = st.selectbox(
                "Choose Sample Dataset",
                ["sales", "employees", "customers", "iris"]
            )
            if st.button("Load Sample Data"):
                with st.spinner("Generating sample data..."):
                    success = st.session_state['explorer'].load_data(dataset_type, "sample")
                    if success:
                        st.session_state['data_loaded'] = True
                        st.success("Sample data loaded!")
                        st.rerun()
        
        elif data_source == "Stock Data":
            symbol = st.text_input("Stock Symbol", placeholder="AAPL")
            if symbol and st.button("Load Stock Data"):
                with st.spinner(f"Fetching {symbol} data..."):
                    success = st.session_state['explorer'].load_data(symbol, "stock")
                    if success:
                        st.session_state['data_loaded'] = True
                        st.success(f"{symbol} data loaded!")
                        st.rerun()
                    else:
                        st.error("Failed to fetch stock data")
        
        elif data_source == "Demo Data":
            if st.button("Load Demo Data"):
                with st.spinner("Loading demo data..."):
                    # Create demo sales data
                    demo_data = st.session_state['explorer']._generate_sample_data("sales")
                    success = st.session_state['explorer'].load_data(demo_data)
                    if success:
                        st.session_state['data_loaded'] = True
                        st.success("Demo data loaded!")
                        st.rerun()
    
    # Main content
    if not st.session_state['data_loaded']:
        st.info("ðŸ‘ˆ Please load data using the sidebar to get started")
        
        # Show feature overview
        st.subheader("ðŸš€ Features")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **ðŸ“Š Natural Language Queries**
            - Ask questions in plain English
            - Get instant statistical insights
            - Automated analysis recommendations
            """)
        
        with col2:
            st.markdown("""
            **ðŸ“ˆ Smart Visualizations**
            - Automatic chart type selection
            - Interactive Plotly charts
            - Custom visualization options
            """)
        
        with col3:
            st.markdown("""
            **ðŸ” Advanced Analytics**
            - Clustering analysis
            - PCA dimensionality reduction
            - Outlier detection
            """)
        
        return
    
    explorer = st.session_state['explorer']
    
    # Create tabs for different functionalities
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ” Explore", "ðŸ“Š Visualize", "ðŸ§  Advanced", "ðŸ“‹ Summary"])
    
    with tab1:
        st.header("ðŸ” Ask Questions About Your Data")
        
        # Display current data info
        summary = explorer.get_data_summary()
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Rows", summary['shape'][0])
        with col2:
            st.metric("Columns", summary['shape'][1])
        with col3:
            st.metric("Numeric Cols", len(summary['numeric_columns']))
        with col4:
            st.metric("Missing Values", sum(summary['missing_values'].values()))
        
        # Query interface
        st.subheader("ðŸ’¬ Natural Language Query")
        
        # Sample questions
        sample_questions = [
            "What is the average of numeric columns?",
            "Show me the correlation between variables",
            "Are there any missing values?",
            "What are the maximum and minimum values?",
            "Describe the data distribution",
            "Find outliers in the data"
        ]
        
        selected_question = st.selectbox("Select a sample question or type your own:", 
                                       [""] + sample_questions)
        
        user_query = st.text_area("Your Question:", 
                                value=selected_question,
                                placeholder="Ask anything about your data...")
        
        if st.button("ðŸ” Analyze") and user_query:
            with st.spinner("Analyzing your question..."):
                result = explorer.analyze_query(user_query)
                
                if 'error' in result:
                    st.error(result['error'])
                else:
                    # Display agent response
                    if result.get('agent_response') and "Agent error" not in result['agent_response']:
                        st.subheader("ðŸ¤– AI Agent Response")
                        st.write(result['agent_response'])
                    
                    # Display rule-based response
                    st.subheader("ðŸ“Š Analysis Result")
                    st.write(result['rule_response'])
                    
                    # Chart suggestion
                    if result.get('chart_suggestion'):
                        st.subheader("ðŸ“ˆ Suggested Visualization")
                        st.info(f"Recommended chart type: **{result['chart_suggestion']}**")
                        
                        if st.button("Generate Suggested Chart"):
                            fig = explorer.generate_chart(result['chart_suggestion'])
                            if fig:
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.warning("Could not generate the suggested chart")
        
        # Query history
        if explorer.analysis_history:
            st.subheader("ðŸ“ Query History")
            for i, item in enumerate(reversed(explorer.analysis_history[-5:])):
                with st.expander(f"Query {len(explorer.analysis_history) - i}: {item['query'][:50]}..."):
                    st.write(f"**Question:** {item['query']}")
                    st.write(f"**Response:** {item['rule_response']}")
                    if item.get('chart_suggestion'):
                        st.write(f"**Suggested Chart:** {item['chart_suggestion']}")
    
    with tab2:
        st.header("ðŸ“Š Create Custom Visualizations")
        
        # Chart configuration
        col1, col2 = st.columns([1, 2])
        
        with col1:
            chart_type = st.selectbox(
                "Chart Type",
                ["line", "bar", "scatter", "histogram", "box", "heatmap", "pie"]
            )
            
            # Column selection based on data
            columns = list(explorer.current_data.columns)
            numeric_cols = summary['numeric_columns']
            categorical_cols = summary['categorical_columns']
            datetime_cols = summary['datetime_columns']
            
            x_col = st.selectbox("X-axis", [None] + columns, 
                               help="Select column for X-axis")
            y_col = st.selectbox("Y-axis", [None] + columns,
                               help="Select column for Y-axis")
            color_col = st.selectbox("Color by", [None] + categorical_cols,
                                   help="Optional: Color by categorical column")
            
            title = st.text_input("Chart Title", placeholder="Enter chart title...")
            
            if st.button("ðŸ“ˆ Generate Chart"):
                with st.spinner("Creating visualization..."):
                    fig = explorer.generate_chart(chart_type, x_col, y_col, color_col, title)
                    if fig:
                        st.session_state['current_chart'] = fig
                    else:
                        st.error("Could not generate chart with current settings")
        
        with col2:
            if 'current_chart' in st.session_state:
                st.plotly_chart(st.session_state['current_chart'], use_container_width=True)
            else:
                st.info("Configure chart settings and click 'Generate Chart'")
        
        # Chart gallery
        if explorer.generated_charts:
            st.subheader("ðŸ–¼ï¸ Chart Gallery")
            
            # Display recent charts
            for i, chart_info in enumerate(reversed(explorer.generated_charts[-3:])):
                st.write(f"**Chart {len(explorer.generated_charts) - i}** ({chart_info['type']})")
                st.plotly_chart(chart_info['figure'], use_container_width=True)
    
    with tab3:
        st.header("ðŸ§  Advanced Analytics")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ðŸ”¬ Statistical Analysis")
            
            analysis_type = st.selectbox(
                "Analysis Type",
                ["clustering", "pca", "outliers"]
            )
            
            if st.button("Run Advanced Analysis"):
                with st.spinner(f"Running {analysis_type} analysis..."):
                    result = explorer.get_advanced_analysis(analysis_type)
                    
                    if 'error' in result:
                        st.error(result['error'])
                    else:
                        st.success(f"{analysis_type.title()} analysis completed!")
                        
                        if analysis_type == 'clustering':
                            st.write(f"**Number of clusters:** {result['n_clusters']}")
                            st.write(f"**Inertia:** {result['inertia']:.2f}")
                            
                            # Visualize clusters if we have 2D data
                            if len(summary['numeric_columns']) >= 2:
                                df_plot = explorer.current_data[summary['numeric_columns'][:2]].copy()
                                df_plot['cluster'] = result['clusters']
                                
                                fig = px.scatter(df_plot, 
                                               x=summary['numeric_columns'][0],
                                               y=summary['numeric_columns'][1],
                                               color='cluster',
                                               title="Clustering Results")
                                st.plotly_chart(fig, use_container_width=True)
                        
                        elif analysis_type == 'pca':
                            st.write(f"**Explained Variance Ratio:** {result['explained_variance_ratio']}")
                            
                            # Plot PCA results
                            pca_df = pd.DataFrame(result['components'], columns=['PC1', 'PC2'])
                            fig = px.scatter(pca_df, x='PC1', y='PC2', title="PCA Results")
                            st.plotly_chart(fig, use_container_width=True)
                        
                        elif analysis_type == 'outliers':
                            st.write("**Outliers detected:**")
                            for col, outlier_indices in result['outliers'].items():
                                if outlier_indices:
                                    st.write(f"- {col}: {len(outlier_indices)} outliers")
                                else:
                                    st.write(f"- {col}: No outliers")
        
        with col2:
            st.subheader("ðŸ“Š Data Quality Report")
            
            # Missing values visualization
            missing_data = pd.Series(summary['missing_values'])
            missing_data = missing_data[missing_data > 0]
            
            if not missing_data.empty:
                fig = px.bar(x=missing_data.index, y=missing_data.values,
                           title="Missing Values by Column")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("âœ… No missing values detected!")
            
            # Data types
            st.write("**Data Types:**")
            for col, dtype in summary['dtypes'].items():
                st.write(f"- {col}: {dtype}")
            
            # Memory usage
            memory_mb = summary['memory_usage'] / (1024 * 1024)
            st.metric("Memory Usage", f"{memory_mb:.2f} MB")
    
    with tab4:
        st.header("ðŸ“‹ Data Summary & Export")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ðŸ“Š Dataset Overview")
            st.dataframe(explorer.current_data.head(10), use_container_width=True)
            
            st.subheader("ðŸ“ˆ Statistical Summary")
            if summary['numeric_columns']:
                st.dataframe(explorer.current_data[summary['numeric_columns']].describe(), 
                           use_container_width=True)
        
        with col2:
            st.subheader("ðŸ’¾ Export Options")
            
            export_format = st.selectbox("Export Format", ["csv", "json"])
            
            if st.button("ðŸ“¥ Generate Export"):
                export_data = explorer.export_results(export_format)
                
                if export_data:
                    st.download_button(
                        label=f"Download {export_format.upper()}",
                        data=export_data,
                        file_name=f"data_analysis.{export_format}",
                        mime=f"text/{export_format}"
                    )
                else:
                    st.error("Export failed")
            
            st.subheader("ðŸ“Š Session Statistics")
            st.metric("Queries Asked", len(explorer.analysis_history))
            st.metric("Charts Generated", len(explorer.generated_charts))
            
            if explorer.analysis_history:
                last_query_time = explorer.analysis_history[-1]['timestamp']
                st.write(f"**Last Query:** {last_query_time.strftime('%H:%M:%S')}")

if __name__ == "__main__":
    main()
````

## Project Summary

The Interactive Data Explorer using LLM revolutionizes data analysis by providing an intelligent, conversational interface that enables users to explore, analyze, and visualize data through natural language queries, eliminating traditional programming barriers and democratizing access to data insights across all skill levels.

### Key Value Propositions:
- **Natural Language Data Analysis**: Conversational interface that translates plain English questions into sophisticated pandas operations and statistical analyses without requiring programming knowledge
- **Intelligent Visualization Engine**: Automated chart generation with context-aware visualization selection, interactive Plotly charts, and customizable visual exploration capabilities
- **Advanced Analytics Integration**: Seamless access to clustering, PCA, outlier detection, and statistical modeling through simple natural language commands and automated interpretation
- **Multi-Source Data Support**: Comprehensive data loading capabilities including CSV uploads, stock market data integration, and sample dataset generation for immediate exploration
- **Export and Collaboration Features**: Multiple format export options, analysis history tracking, and shareable insights for enhanced collaborative data exploration

### Technical Highlights:
- LangChain pandas agent integration with OpenAI GPT-4 for sophisticated natural language to code translation and intelligent query interpretation
- Comprehensive data processing pipeline with automated cleaning, type inference, and quality assessment for robust data handling
- Interactive Streamlit interface with tabbed exploration, real-time chart generation, and advanced analytics visualization for enhanced user experience
- Multi-format data source support including CSV, JSON, stock APIs (yfinance), and programmatic sample data generation for versatile data access
- Advanced statistical analysis integration with scikit-learn for clustering, PCA, outlier detection, and automated insight generation with visual interpretation

This system transforms data exploration from a technical skill to an accessible conversation, enabling faster insights, improved decision-making, and democratized data analysis capabilities for organizations and individuals across all technical backgrounds.