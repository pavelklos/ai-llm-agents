<small>Claude Sonnet 4 **(Smart Code Assistant - AI-LLM MCP Integration)**</small>
# Smart Code Assistant

## Key Concepts Explanation

### Model Context Protocol (MCP)
MCP is a standardized protocol for connecting Large Language Models with external tools and data sources. It enables secure, structured communication between AI models and various systems like IDEs, databases, and APIs.

### IDE Integration
Deep integration with development environments to provide contextual assistance, real-time code analysis, and intelligent suggestions based on the current codebase and development context.

### Code Analysis
Automated examination of source code to identify patterns, detect issues, suggest improvements, and understand code structure and dependencies across repositories.

### Git Repository Management
Integration with version control systems to understand code history, analyze changes, and provide context-aware assistance based on repository structure and commit patterns.

### Documentation Generation
Automated creation of technical documentation from code analysis, including API docs, README files, and inline comments based on code behavior and patterns.

## Comprehensive Project Explanation

The Smart Code Assistant project represents a revolutionary approach to developer productivity by creating an AI-powered assistant that deeply understands code context through the Model Context Protocol. This system goes beyond simple code completion to provide intelligent, context-aware assistance that adapts to individual coding styles and project requirements.

### Objectives
- **Enhanced Developer Productivity**: Reduce time spent on routine coding tasks and debugging
- **Intelligent Code Understanding**: Provide deep contextual analysis of codebases
- **Seamless Integration**: Work naturally within existing development workflows
- **Knowledge Management**: Automatically maintain and update project documentation
- **Quality Assurance**: Identify potential issues and suggest improvements proactively

### Challenges
- **Context Management**: Maintaining relevant context across large codebases
- **Real-time Performance**: Providing instant responses without impacting IDE performance
- **Code Security**: Ensuring sensitive code remains protected during analysis
- **Multi-language Support**: Handling diverse programming languages and frameworks
- **Scalability**: Managing analysis across enterprise-scale repositories

### Potential Impact
This system could transform software development by making AI assistance as natural as syntax highlighting, reducing onboarding time for new developers, and significantly improving code quality across organizations.

## Comprehensive Project Example with Python Implementation

````python
import asyncio
import json
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import git
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import DirectoryLoader, TextLoader
import tree_sitter
from tree_sitter import Language, Parser
import requests
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MCPMessage:
    """Model Context Protocol message structure"""
    id: str
    method: str
    params: Dict[str, Any]
    timestamp: float

@dataclass
class CodeContext:
    """Code context information"""
    file_path: str
    language: str
    content: str
    dependencies: List[str]
    functions: List[Dict[str, Any]]
    classes: List[Dict[str, Any]]

class GitAnalyzer:
    """Analyzes Git repositories for context"""
    
    def __init__(self, repo_path: str):
        self.repo_path = repo_path
        self.repo = git.Repo(repo_path)
    
    def get_recent_changes(self, days: int = 7) -> List[Dict[str, Any]]:
        """Get recent commits and changes"""
        try:
            commits = list(self.repo.iter_commits(max_count=50))
            recent_changes = []
            
            for commit in commits:
                if (commit.committed_datetime.timestamp() > 
                    (asyncio.get_event_loop().time() - days * 86400)):
                    
                    files_changed = []
                    try:
                        for item in commit.stats.files:
                            files_changed.append({
                                'file': item,
                                'insertions': commit.stats.files[item]['insertions'],
                                'deletions': commit.stats.files[item]['deletions']
                            })
                    except Exception as e:
                        logger.warning(f"Error analyzing commit stats: {e}")
                    
                    recent_changes.append({
                        'hash': commit.hexsha,
                        'message': commit.message.strip(),
                        'author': commit.author.name,
                        'date': commit.committed_datetime.isoformat(),
                        'files_changed': files_changed
                    })
            
            return recent_changes
        except Exception as e:
            logger.error(f"Error analyzing Git repository: {e}")
            return []

class CodeParser:
    """Parses code using Tree-sitter for structural analysis"""
    
    def __init__(self):
        self.parsers = {}
        self._setup_parsers()
    
    def _setup_parsers(self):
        """Setup Tree-sitter parsers for different languages"""
        try:
            # Note: In a real implementation, you'd need to build Tree-sitter languages
            # This is a simplified version
            self.language_extensions = {
                '.py': 'python',
                '.js': 'javascript',
                '.ts': 'typescript',
                '.java': 'java',
                '.cpp': 'cpp',
                '.c': 'c'
            }
        except Exception as e:
            logger.error(f"Error setting up parsers: {e}")
    
    def parse_file(self, file_path: str) -> Optional[CodeContext]:
        """Parse a code file and extract structure"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            ext = Path(file_path).suffix
            language = self.language_extensions.get(ext, 'unknown')
            
            # Simplified parsing - in reality, you'd use Tree-sitter
            functions = self._extract_functions(content, language)
            classes = self._extract_classes(content, language)
            dependencies = self._extract_dependencies(content, language)
            
            return CodeContext(
                file_path=file_path,
                language=language,
                content=content,
                dependencies=dependencies,
                functions=functions,
                classes=classes
            )
        except Exception as e:
            logger.error(f"Error parsing file {file_path}: {e}")
            return None
    
    def _extract_functions(self, content: str, language: str) -> List[Dict[str, Any]]:
        """Extract function definitions (simplified)"""
        functions = []
        if language == 'python':
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith('def '):
                    func_name = line.split('def ')[1].split('(')[0].strip()
                    functions.append({
                        'name': func_name,
                        'line': i + 1,
                        'signature': line.strip()
                    })
        return functions
    
    def _extract_classes(self, content: str, language: str) -> List[Dict[str, Any]]:
        """Extract class definitions (simplified)"""
        classes = []
        if language == 'python':
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith('class '):
                    class_name = line.split('class ')[1].split('(')[0].split(':')[0].strip()
                    classes.append({
                        'name': class_name,
                        'line': i + 1,
                        'signature': line.strip()
                    })
        return classes
    
    def _extract_dependencies(self, content: str, language: str) -> List[str]:
        """Extract import statements and dependencies"""
        dependencies = []
        if language == 'python':
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('import ') or line.startswith('from '):
                    dependencies.append(line)
        return dependencies

class VectorStore:
    """Vector database for code embeddings"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    def index_codebase(self, codebase_path: str):
        """Index an entire codebase"""
        try:
            # Load code files
            loader = DirectoryLoader(
                codebase_path, 
                glob="**/*.py",
                loader_cls=TextLoader,
                loader_kwargs={'encoding': 'utf-8'}
            )
            documents = loader.load()
            
            # Split documents
            texts = self.text_splitter.split_documents(documents)
            
            # Create vector store
            self.vectorstore = Chroma.from_documents(
                documents=texts,
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
            
            logger.info(f"Indexed {len(texts)} code chunks")
            
        except Exception as e:
            logger.error(f"Error indexing codebase: {e}")
    
    def search_similar_code(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Search for similar code snippets"""
        if not self.vectorstore:
            return []
        
        try:
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            return [
                {
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'similarity': score
                }
                for doc, score in results
            ]
        except Exception as e:
            logger.error(f"Error searching code: {e}")
            return []

class MCPServer:
    """Model Context Protocol server for IDE integration"""
    
    def __init__(self, port: int = 8080):
        self.port = port
        self.connections = {}
        self.handlers = {
            'get_code_context': self.handle_get_code_context,
            'analyze_file': self.handle_analyze_file,
            'suggest_improvements': self.handle_suggest_improvements,
            'generate_docs': self.handle_generate_docs
        }
    
    async def handle_get_code_context(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Handle code context requests"""
        file_path = params.get('file_path')
        if not file_path:
            return {'error': 'file_path is required'}
        
        parser = CodeParser()
        context = parser.parse_file(file_path)
        
        if context:
            return {
                'context': {
                    'file_path': context.file_path,
                    'language': context.language,
                    'functions': context.functions,
                    'classes': context.classes,
                    'dependencies': context.dependencies
                }
            }
        return {'error': 'Failed to parse file'}
    
    async def handle_analyze_file(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze a specific file"""
        file_path = params.get('file_path')
        analysis_type = params.get('type', 'structure')
        
        if not file_path:
            return {'error': 'file_path is required'}
        
        parser = CodeParser()
        context = parser.parse_file(file_path)
        
        if not context:
            return {'error': 'Failed to parse file'}
        
        # Perform analysis based on type
        if analysis_type == 'complexity':
            complexity_score = self._calculate_complexity(context.content)
            return {'complexity_score': complexity_score}
        
        elif analysis_type == 'structure':
            return {
                'structure': {
                    'functions': len(context.functions),
                    'classes': len(context.classes),
                    'lines_of_code': len(context.content.split('\n')),
                    'dependencies': len(context.dependencies)
                }
            }
        
        return {'error': 'Unknown analysis type'}
    
    def _calculate_complexity(self, content: str) -> int:
        """Calculate cyclomatic complexity (simplified)"""
        complexity_keywords = [
            'if ', 'elif ', 'else:', 'for ', 'while ', 
            'try:', 'except:', 'finally:', 'with '
        ]
        
        complexity = 1  # Base complexity
        for keyword in complexity_keywords:
            complexity += content.count(keyword)
        
        return complexity
    
    async def handle_suggest_improvements(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Suggest code improvements"""
        code = params.get('code')
        if not code:
            return {'error': 'code is required'}
        
        # Use LLM to suggest improvements
        llm = OpenAI(temperature=0.3)
        
        prompt = f"""
        Analyze the following code and suggest improvements:
        
        {code}
        
        Please provide specific suggestions for:
        1. Code efficiency
        2. Readability
        3. Best practices
        4. Potential bugs
        """
        
        try:
            suggestions = llm(prompt)
            return {'suggestions': suggestions}
        except Exception as e:
            logger.error(f"Error generating suggestions: {e}")
            return {'error': 'Failed to generate suggestions'}
    
    async def handle_generate_docs(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Generate documentation for code"""
        code = params.get('code')
        doc_type = params.get('type', 'docstring')
        
        if not code:
            return {'error': 'code is required'}
        
        llm = OpenAI(temperature=0.2)
        
        if doc_type == 'docstring':
            prompt = f"""
            Generate a comprehensive docstring for the following code:
            
            {code}
            
            Include description, parameters, return values, and examples.
            """
        else:
            prompt = f"""
            Generate comprehensive documentation for the following code:
            
            {code}
            
            Include overview, usage examples, and API reference.
            """
        
        try:
            documentation = llm(prompt)
            return {'documentation': documentation}
        except Exception as e:
            logger.error(f"Error generating documentation: {e}")
            return {'error': 'Failed to generate documentation'}

class SmartCodeAssistant:
    """Main Smart Code Assistant class"""
    
    def __init__(self, workspace_path: str):
        self.workspace_path = workspace_path
        self.git_analyzer = GitAnalyzer(workspace_path)
        self.code_parser = CodeParser()
        self.vector_store = VectorStore()
        self.mcp_server = MCPServer()
        
        # Initialize vector store with workspace
        self.vector_store.index_codebase(workspace_path)
    
    async def analyze_workspace(self) -> Dict[str, Any]:
        """Analyze the entire workspace"""
        try:
            # Get Git information
            recent_changes = self.git_analyzer.get_recent_changes()
            
            # Analyze code structure
            code_files = []
            for root, dirs, files in os.walk(self.workspace_path):
                for file in files:
                    if file.endswith(('.py', '.js', '.ts', '.java')):
                        file_path = os.path.join(root, file)
                        context = self.code_parser.parse_file(file_path)
                        if context:
                            code_files.append(context)
            
            # Generate workspace summary
            total_files = len(code_files)
            total_functions = sum(len(f.functions) for f in code_files)
            total_classes = sum(len(f.classes) for f in code_files)
            
            return {
                'workspace_path': self.workspace_path,
                'total_files': total_files,
                'total_functions': total_functions,
                'total_classes': total_classes,
                'recent_changes': recent_changes[:5],  # Last 5 changes
                'languages': list(set(f.language for f in code_files))
            }
            
        except Exception as e:
            logger.error(f"Error analyzing workspace: {e}")
            return {'error': str(e)}
    
    async def get_contextual_suggestions(self, 
                                       current_file: str, 
                                       cursor_position: int) -> List[str]:
        """Get contextual code suggestions"""
        try:
            # Parse current file
            context = self.code_parser.parse_file(current_file)
            if not context:
                return []
            
            # Get current line context
            lines = context.content.split('\n')
            current_line = cursor_position
            
            if current_line < len(lines):
                current_code = lines[current_line]
                
                # Search for similar code patterns
                similar_code = self.vector_store.search_similar_code(
                    current_code, k=3
                )
                
                suggestions = []
                for result in similar_code:
                    suggestions.append(f"Similar pattern: {result['content'][:100]}...")
                
                return suggestions
            
            return []
            
        except Exception as e:
            logger.error(f"Error getting suggestions: {e}")
            return []

# Sample usage and testing
async def main():
    """Main function to demonstrate the Smart Code Assistant"""
    
    # Create sample workspace structure
    workspace_path = "./sample_workspace"
    os.makedirs(workspace_path, exist_ok=True)
    
    # Create sample Python files
    sample_files = {
        "main.py": '''
def calculate_fibonacci(n):
    """Calculate Fibonacci number"""
    if n <= 1:
        return n
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

class MathUtils:
    @staticmethod
    def factorial(n):
        if n <= 1:
            return 1
        return n * MathUtils.factorial(n-1)

if __name__ == "__main__":
    print(calculate_fibonacci(10))
    print(MathUtils.factorial(5))
''',
        
        "utils.py": '''
import json
import logging
from typing import Dict, Any

def load_config(file_path: str) -> Dict[str, Any]:
    """Load configuration from JSON file"""
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except Exception as e:
        logging.error(f"Error loading config: {e}")
        return {}

class DataProcessor:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    def process_data(self, data: list) -> list:
        """Process data according to configuration"""
        processed = []
        for item in data:
            if self.config.get('filter_enabled', False):
                if item.get('status') == 'active':
                    processed.append(item)
            else:
                processed.append(item)
        return processed
'''
    }
    
    # Write sample files
    for filename, content in sample_files.items():
        with open(os.path.join(workspace_path, filename), 'w') as f:
            f.write(content)
    
    # Initialize Git repository
    try:
        repo = git.Repo.init(workspace_path)
        repo.index.add(['main.py', 'utils.py'])
        repo.index.commit("Initial commit")
        print("✓ Created sample Git repository")
    except Exception as e:
        print(f"⚠ Git initialization failed: {e}")
    
    # Initialize Smart Code Assistant
    try:
        assistant = SmartCodeAssistant(workspace_path)
        print("✓ Smart Code Assistant initialized")
        
        # Analyze workspace
        analysis = await assistant.analyze_workspace()
        print("\n📊 Workspace Analysis:")
        print(json.dumps(analysis, indent=2))
        
        # Get contextual suggestions
        suggestions = await assistant.get_contextual_suggestions(
            os.path.join(workspace_path, "main.py"), 
            5
        )
        print(f"\n💡 Contextual Suggestions: {suggestions}")
        
        # Test MCP server handlers
        print("\n🔧 Testing MCP Server functionality:")
        
        # Test file analysis
        analysis_result = await assistant.mcp_server.handle_analyze_file({
            'file_path': os.path.join(workspace_path, "main.py"),
            'type': 'structure'
        })
        print(f"File Structure Analysis: {analysis_result}")
        
        # Test improvement suggestions
        with open(os.path.join(workspace_path, "main.py"), 'r') as f:
            code_content = f.read()
        
        improvement_result = await assistant.mcp_server.handle_suggest_improvements({
            'code': code_content[:500]  # First 500 chars
        })
        print(f"Improvement Suggestions: {improvement_result}")
        
        print("\n✅ Smart Code Assistant demo completed successfully!")
        
    except Exception as e:
        print(f"❌ Error running demo: {e}")
        logger.error(f"Demo error: {e}")

if __name__ == "__main__":
    # Set up environment variables (you'll need to add your own API keys)
    os.environ.setdefault('OPENAI_API_KEY', 'your-openai-api-key-here')
    
    asyncio.run(main())
````

### Setup and Dependencies

````bash
# Install required dependencies
pip install langchain openai chromadb tree-sitter gitpython asyncio

# For Tree-sitter language support (optional)
pip install tree-sitter-languages

# Set environment variables
export OPENAI_API_KEY="your-openai-api-key"
````

### Configuration File

````json
{
  "mcp_server": {
    "port": 8080,
    "max_connections": 100
  },
  "vector_store": {
    "persist_directory": "./chroma_db",
    "chunk_size": 1000,
    "chunk_overlap": 200
  },
  "git_analysis": {
    "max_commits": 50,
    "days_to_analyze": 7
  },
  "supported_languages": [
    "python",
    "javascript",
    "typescript",
    "java",
    "cpp"
  ]
}
````

## Project Summary

The Smart Code Assistant represents a significant advancement in developer tooling by combining the power of Large Language Models with the Model Context Protocol to create a truly intelligent coding companion. This system provides deep understanding of codebases, real-time assistance, and automated documentation generation.

### Key Value Propositions

1. **Contextual Intelligence**: Unlike simple code completion tools, this assistant understands the broader context of your project, including Git history, file relationships, and coding patterns.

2. **Seamless Integration**: Through MCP, the assistant integrates naturally with existing IDEs and development workflows without disrupting established practices.

3. **Continuous Learning**: The system builds knowledge about your codebase over time, becoming more effective as it learns your coding patterns and project structure.

4. **Multi-dimensional Analysis**: Combines static code analysis, version control history, and AI-powered insights to provide comprehensive assistance.

### Key Takeaways

- **Scalable Architecture**: The modular design allows for easy extension and integration with additional tools and languages
- **Privacy-Conscious**: Local vector storage and configurable data handling ensure sensitive code remains protected
- **Performance-Optimized**: Asynchronous processing and efficient caching minimize impact on development workflow
- **Future-Ready**: Built on standard protocols (MCP) that ensure compatibility with emerging AI development tools

This Smart Code Assistant transforms the traditional IDE experience into an AI-enhanced development environment that understands, learns, and evolves with your projects, making every developer more productive and every codebase more maintainable.