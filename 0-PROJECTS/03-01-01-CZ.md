<small>Claude Sonnet 4 **(Inteligentn√≠ Asistent pro Dokumenty s RAG)**</small>
# Intelligent Document Assistant

## Kl√≠ƒçov√© Koncepty

### RAG (Retrieval-Augmented Generation)
Technika kombinuj√≠c√≠ vyhled√°v√°n√≠ relevantn√≠ch informac√≠ z datab√°ze znalost√≠ s generativn√≠mi schopnostmi velk√Ωch jazykov√Ωch model≈Ø. RAG umo≈æ≈àuje AI model≈Øm poskytovat p≈ôesnƒõj≈°√≠ a aktu√°lnƒõj≈°√≠ odpovƒõdi zalo≈æen√© na specifick√Ωch dokumentech.

### Zpracov√°n√≠ Dokument≈Ø
Proces extrakce, ƒçi≈°tƒõn√≠ a strukturov√°n√≠ textu z r≈Øzn√Ωch form√°t≈Ø dokument≈Ø (PDF, DOCX, HTML) pro dal≈°√≠ anal√Ωzu a indexov√°n√≠.

### Vektorov√© Embeddingy
Numerick√© reprezentace textu v mnohodimenzion√°ln√≠m prostoru, kde podobn√© texty maj√≠ podobn√© vektory. Umo≈æ≈àuj√≠ s√©mantick√© vyhled√°v√°n√≠ zalo≈æen√© na v√Ωznamu, ne pouze na kl√≠ƒçov√Ωch slovech.

### S√©mantick√© Vyhled√°v√°n√≠
Pokroƒçil√° technika vyhled√°v√°n√≠, kter√° rozum√≠ kontextu a v√Ωznamu dotaz≈Ø, m√≠sto pouze shody kl√≠ƒçov√Ωch slov.

### FAISS (Facebook AI Similarity Search)
Vysoce v√Ωkonn√° knihovna pro efektivn√≠ vyhled√°v√°n√≠ podobnosti ve vektorov√Ωch datab√°z√≠ch, optimalizovan√° pro velk√© objemy dat.

### LangChain
Framework pro v√Ωvoj aplikac√≠ vyu≈æ√≠vaj√≠c√≠ch jazykov√© modely, poskytuje n√°stroje pro ≈ôetƒõzen√≠ operac√≠, spr√°vu pamƒõti a integraci s extern√≠mi zdroji dat.

## Komprehensivn√≠ Vysvƒõtlen√≠ Projektu

### C√≠le Projektu
Vytvo≈ôen√≠ inteligentn√≠ho asistenta schopn√©ho odpov√≠dat na ot√°zky zalo≈æen√© na obsahu nahran√Ωch dokument≈Ø. Syst√©m kombinuje pokroƒçil√© techniky zpracov√°n√≠ p≈ôirozen√©ho jazyka s efektivn√≠m vyhled√°v√°n√≠m pro poskytov√°n√≠ p≈ôesn√Ωch, kontextovƒõ relevantn√≠ch odpovƒõd√≠.

### Hlavn√≠ V√Ωzvy
- **≈†k√°lovatelnost**: Efektivn√≠ zpracov√°n√≠ velk√Ωch objem≈Ø dokument≈Ø
- **P≈ôesnost**: Zachov√°n√≠ kontextu a relevance p≈ôi vyhled√°v√°n√≠
- **Rychlost**: Optimalizace pro real-time odpovƒõdi
- **Multimod√°lnost**: Podpora r≈Øzn√Ωch form√°t≈Ø dokument≈Ø

### Potenci√°ln√≠ Dopad
Revoluƒçn√≠ zmƒõna ve zp≈Øsobu, jak organizace pracuj√≠ s informacemi - od pr√°vn√≠ch firem analyzuj√≠c√≠ch smlouvy po v√Ωzkumn√© instituce proch√°zej√≠c√≠ odbornou literaturu.

## Komprehensivn√≠ P≈ô√≠klad s Python Implementac√≠

### Instalace Z√°vislost√≠

````python
# requirements.txt
langchain==0.1.0
openai==1.10.0
faiss-cpu==1.7.4
pypdf2==3.0.1
python-docx==0.8.11
tiktoken==0.5.2
streamlit==1.29.0
python-dotenv==1.0.0
sentence-transformers==2.2.2
````

### Hlavn√≠ Implementace

````python
import os
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv

# LangChain imports
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document

# Additional imports
import PyPDF2
import docx
import tiktoken

load_dotenv()

# Konfigurace loggingu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DocumentProcessor:
    """T≈ô√≠da pro zpracov√°n√≠ r≈Øzn√Ωch form√°t≈Ø dokument≈Ø"""
    
    def __init__(self):
        self.supported_formats = ['.pdf', '.docx', '.txt']
    
    def load_document(self, file_path: str) -> List[Document]:
        """Naƒçte dokument podle jeho form√°tu"""
        try:
            file_extension = Path(file_path).suffix.lower()
            
            if file_extension == '.pdf':
                return self._load_pdf(file_path)
            elif file_extension == '.docx':
                return self._load_docx(file_path)
            elif file_extension == '.txt':
                return self._load_txt(file_path)
            else:
                raise ValueError(f"Nepodporovan√Ω form√°t: {file_extension}")
                
        except Exception as e:
            logger.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ dokumentu {file_path}: {e}")
            return []
    
    def _load_pdf(self, file_path: str) -> List[Document]:
        """Naƒçte PDF dokument"""
        loader = PyPDFLoader(file_path)
        return loader.load()
    
    def _load_docx(self, file_path: str) -> List[Document]:
        """Naƒçte DOCX dokument"""
        loader = Docx2txtLoader(file_path)
        return loader.load()
    
    def _load_txt(self, file_path: str) -> List[Document]:
        """Naƒçte textov√Ω soubor"""
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        return [Document(page_content=content, metadata={"source": file_path})]

class VectorStoreManager:
    """Spr√°vce vektorov√© datab√°ze"""
    
    def __init__(self, openai_api_key: str):
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        self.vector_store: Optional[FAISS] = None
    
    def create_vector_store(self, documents: List[Document]) -> FAISS:
        """Vytvo≈ô√≠ vektorovou datab√°zi z dokument≈Ø"""
        try:
            # Rozdƒõlen√≠ dokument≈Ø na men≈°√≠ ƒç√°sti
            texts = self.text_splitter.split_documents(documents)
            
            if not texts:
                raise ValueError("≈Ω√°dn√© texty k indexov√°n√≠")
            
            # Vytvo≈ôen√≠ vektorov√© datab√°ze
            self.vector_store = FAISS.from_documents(texts, self.embeddings)
            logger.info(f"Vytvo≈ôena vektorov√° datab√°ze s {len(texts)} ƒç√°stmi textu")
            
            return self.vector_store
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi vytv√°≈ôen√≠ vektorov√© datab√°ze: {e}")
            raise
    
    def save_vector_store(self, path: str):
        """Ulo≈æ√≠ vektorovou datab√°zi"""
        if self.vector_store:
            self.vector_store.save_local(path)
            logger.info(f"Vektorov√° datab√°ze ulo≈æena do {path}")
    
    def load_vector_store(self, path: str) -> FAISS:
        """Naƒçte ulo≈æenou vektorovou datab√°zi"""
        try:
            self.vector_store = FAISS.load_local(path, self.embeddings)
            logger.info(f"Vektorov√° datab√°ze naƒçtena z {path}")
            return self.vector_store
        except Exception as e:
            logger.error(f"Chyba p≈ôi naƒç√≠t√°n√≠ vektorov√© datab√°ze: {e}")
            raise

class RAGAssistant:
    """Hlavn√≠ t≈ô√≠da RAG asistenta"""
    
    def __init__(self, openai_api_key: str, model_name: str = "gpt-3.5-turbo"):
        self.openai_api_key = openai_api_key
        self.model_name = model_name
        self.document_processor = DocumentProcessor()
        self.vector_manager = VectorStoreManager(openai_api_key)
        self.qa_chain: Optional[RetrievalQA] = None
        
        # Nastaven√≠ LLM
        self.llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            model_name=model_name,
            temperature=0.1
        )
        
        # ƒåesk√Ω prompt template
        self.prompt_template = PromptTemplate(
            template="""Jsi inteligentn√≠ asistent specializuj√≠c√≠ se na anal√Ωzu dokument≈Ø. 
            Odpov√≠dej v ƒçe≈°tinƒõ a buƒè p≈ôesn√Ω a faktick√Ω.
            
            Kontext z dokument≈Ø:
            {context}
            
            Ot√°zka: {question}
            
            Odpovƒõƒè zalo≈æen√° na poskytnut√©m kontextu:""",
            input_variables=["context", "question"]
        )
    
    def process_documents(self, file_paths: List[str]) -> bool:
        """Zpracuje seznam dokument≈Ø a vytvo≈ô√≠ vektorovou datab√°zi"""
        try:
            all_documents = []
            
            for file_path in file_paths:
                documents = self.document_processor.load_document(file_path)
                all_documents.extend(documents)
                logger.info(f"Zpracov√°n dokument: {file_path}")
            
            if not all_documents:
                logger.error("≈Ω√°dn√© dokumenty k zpracov√°n√≠")
                return False
            
            # Vytvo≈ôen√≠ vektorov√© datab√°ze
            vector_store = self.vector_manager.create_vector_store(all_documents)
            
            # Vytvo≈ôen√≠ QA ≈ôetƒõzu
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
                chain_type_kwargs={"prompt": self.prompt_template}
            )
            
            logger.info("RAG asistent √∫spƒõ≈°nƒõ inicializov√°n")
            return True
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ dokument≈Ø: {e}")
            return False
    
    def ask_question(self, question: str) -> Dict[str, Any]:
        """Polo≈æ√≠ ot√°zku a vr√°t√≠ odpovƒõƒè s kontextem"""
        if not self.qa_chain:
            return {
                "answer": "Chyba: RAG asistent nen√≠ inicializov√°n",
                "success": False
            }
        
        try:
            result = self.qa_chain({"query": question})
            
            return {
                "answer": result["result"],
                "question": question,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi zpracov√°n√≠ ot√°zky: {e}")
            return {
                "answer": f"Chyba p≈ôi zpracov√°n√≠ ot√°zky: {str(e)}",
                "success": False
            }

def create_sample_documents():
    """Vytvo≈ô√≠ uk√°zkov√© dokumenty pro testov√°n√≠"""
    sample_docs = {
        "ai_overview.txt": """
        Umƒõl√° inteligence (AI) je technologie, kter√° umo≈æ≈àuje stroj≈Øm simulovat lidskou inteligenci.
        Hlavn√≠ oblasti AI zahrnuj√≠:
        
        1. Machine Learning - uƒçen√≠ ze dat
        2. Deep Learning - neuronov√© s√≠tƒõ
        3. Natural Language Processing - zpracov√°n√≠ p≈ôirozen√©ho jazyka
        4. Computer Vision - poƒç√≠taƒçov√© vidƒõn√≠
        5. Robotika - autonomn√≠ syst√©my
        
        AI aplikace:
        - Autonomn√≠ vozidla
        - Zdravotn√≠ diagnostika
        - Finanƒçn√≠ anal√Ωzy
        - P≈ôekladaƒçe
        - Chatboti a virtu√°ln√≠ asistenti
        """,
        
        "python_basics.txt": """
        Python je vysoko√∫rov≈àov√Ω programovac√≠ jazyk zn√°m√Ω svou jednoduchost√≠ a ƒçitelnost√≠.
        
        Z√°kladn√≠ datov√© typy:
        - int: cel√° ƒç√≠sla
        - float: desetinn√° ƒç√≠sla
        - str: ≈ôetƒõzce
        - bool: boolean hodnoty
        - list: seznamy
        - dict: slovn√≠ky
        
        Popul√°rn√≠ knihovny:
        - NumPy: numerick√© v√Ωpoƒçty
        - Pandas: anal√Ωza dat
        - Matplotlib: vizualizace
        - Scikit-learn: machine learning
        - TensorFlow/PyTorch: deep learning
        """
    }
    
    # Vytvo≈ôen√≠ uk√°zkov√Ωch soubor≈Ø
    for filename, content in sample_docs.items():
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    return list(sample_docs.keys())

def main():
    """Hlavn√≠ funkce pro spu≈°tƒõn√≠ aplikace"""
    st.set_page_config(
        page_title="Inteligentn√≠ Asistent pro Dokumenty",
        page_icon="üìö",
        layout="wide"
    )
    
    st.title("üìö Inteligentn√≠ Asistent pro Dokumenty s RAG")
    st.markdown("*Pokroƒçil√Ω syst√©m pro anal√Ωzu a dotazov√°n√≠ dokument≈Ø*")
    
    # Sidebar pro konfiguraci
    with st.sidebar:
        st.header("Konfigurace")
        
        # API kl√≠ƒç
        api_key = st.text_input(
            "OpenAI API kl√≠ƒç:",
            type="password",
            value=os.getenv("OPENAI_API_KEY", "")
        )
        
        # V√Ωbƒõr modelu
        model = st.selectbox(
            "Model:",
            ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"]
        )
        
        # Tlaƒç√≠tko pro vytvo≈ôen√≠ uk√°zkov√Ωch dokument≈Ø
        if st.button("Vytvo≈ôit uk√°zkov√© dokumenty"):
            sample_files = create_sample_documents()
            st.success(f"Vytvo≈ôeny soubory: {', '.join(sample_files)}")
    
    # Hlavn√≠ obsah
    if not api_key:
        st.warning("Pros√≠m, zadejte OpenAI API kl√≠ƒç v lev√©m panelu.")
        return
    
    # Inicializace asistenta
    if 'rag_assistant' not in st.session_state:
        st.session_state.rag_assistant = RAGAssistant(api_key, model)
        st.session_state.documents_processed = False
    
    # Upload dokument≈Ø
    st.header("1. Nahr√°n√≠ dokument≈Ø")
    uploaded_files = st.file_uploader(
        "Nahrajte dokumenty (PDF, DOCX, TXT):",
        type=['pdf', 'docx', 'txt'],
        accept_multiple_files=True
    )
    
    # Zpracov√°n√≠ nahran√Ωch dokument≈Ø
    if uploaded_files and st.button("Zpracovat dokumenty"):
        with st.spinner("Zpracov√°n√≠ dokument≈Ø..."):
            file_paths = []
            
            # Ulo≈æen√≠ nahran√Ωch soubor≈Ø
            for uploaded_file in uploaded_files:
                with open(uploaded_file.name, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                file_paths.append(uploaded_file.name)
            
            # Zpracov√°n√≠ dokument≈Ø
            success = st.session_state.rag_assistant.process_documents(file_paths)
            
            if success:
                st.session_state.documents_processed = True
                st.success(f"√öspƒõ≈°nƒõ zpracov√°no {len(file_paths)} dokument≈Ø!")
            else:
                st.error("Chyba p≈ôi zpracov√°n√≠ dokument≈Ø.")
    
    # Sekce pro kladen√≠ ot√°zek
    if st.session_state.documents_processed:
        st.header("2. Kladen√≠ ot√°zek")
        
        # Historie konverzace
        if 'conversation_history' not in st.session_state:
            st.session_state.conversation_history = []
        
        # Input pro ot√°zku
        question = st.text_input("Polo≈æte ot√°zku o dokumentech:")
        
        if question and st.button("Zeptat se"):
            with st.spinner("Hled√°n√≠ odpovƒõdi..."):
                result = st.session_state.rag_assistant.ask_question(question)
                
                if result["success"]:
                    # P≈ôid√°n√≠ do historie
                    st.session_state.conversation_history.append({
                        "question": question,
                        "answer": result["answer"]
                    })
                    
                    # Zobrazen√≠ odpovƒõdi
                    st.success("Odpovƒõƒè:")
                    st.write(result["answer"])
                else:
                    st.error(result["answer"])
        
        # Zobrazen√≠ historie konverzace
        if st.session_state.conversation_history:
            st.header("3. Historie konverzace")
            for i, entry in enumerate(reversed(st.session_state.conversation_history)):
                with st.expander(f"Ot√°zka {len(st.session_state.conversation_history) - i}"):
                    st.write(f"**Q:** {entry['question']}")
                    st.write(f"**A:** {entry['answer']}")

if __name__ == "__main__":
    main()
````

### Spu≈°tƒõn√≠ Aplikace

````bash
# Instalace z√°vislost√≠
pip install -r requirements.txt

# Nastaven√≠ environment promƒõnn√©
echo "OPENAI_API_KEY=your_api_key_here" > .env

# Spu≈°tƒõn√≠ Streamlit aplikace
streamlit run rag_document_assistant.py
````

## Shrnut√≠ Projektu

Inteligentn√≠ Asistent pro Dokumenty s RAG p≈ôedstavuje pokroƒçil√© ≈ôe≈°en√≠ pro efektivn√≠ pr√°ci s velk√Ωmi objemy textov√Ωch informac√≠. Projekt kombinuje nejmodernƒõj≈°√≠ technologie AI pro vytvo≈ôen√≠ syst√©mu schopn√©ho:

- **Automatick√©ho zpracov√°n√≠** r≈Øzn√Ωch form√°t≈Ø dokument≈Ø
- **S√©mantick√©ho vyhled√°v√°n√≠** zalo≈æen√©ho na v√Ωznamu, ne pouze kl√≠ƒçov√Ωch slovech
- **Kontextovƒõ relevantn√≠ch odpovƒõd√≠** vyu≈æ√≠vaj√≠c√≠ch obsah specifick√Ωch dokument≈Ø
- **≈†k√°lovateln√© architektury** p≈ôipraven√© pro produkƒçn√≠ nasazen√≠

Kl√≠ƒçov√© v√Ωhody tohoto ≈ôe≈°en√≠ zahrnuj√≠ v√Ωznamnou √∫sporu ƒçasu p≈ôi anal√Ωze dokument≈Ø, zv√Ω≈°en√≠ p≈ôesnosti vyhled√°v√°n√≠ informac√≠ a mo≈ænost demokratizace p≈ô√≠stupu k slo≈æit√Ωm znalostem. Syst√©m je ide√°ln√≠ pro pr√°vn√≠ firmy, v√Ωzkumn√© instituce, korpor√°tn√≠ prost≈ôed√≠ a jak√©koli organizace pracuj√≠c√≠ s rozs√°hl√Ωmi dokumenty.