<small>Claude Sonnet 4 **(AI-LLM MCP: AnalyzÃ¡tor sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­)**</small>
# Social Media Sentiment Analyzer

## KlÃ­ÄovÃ© koncepty

### Model Context Protocol (MCP)
**MCP** je standardizovanÃ½ protokol pro komunikaci mezi AI modely a externÃ­mi nÃ¡stroji Äi datovÃ½mi zdroji. UmoÅ¾Åˆuje AI systÃ©mÅ¯m dynamicky pÅ™istupovat k funkcionalitÃ¡m a datÅ¯m bez pevnÄ› zakÃ³dovanÃ½ch integracÃ­.

### AnalÃ½za sentimentu
**Sentiment analysis** je proces automatickÃ©ho rozpoznÃ¡vÃ¡nÃ­ emoÄnÃ­ho zabarvenÃ­ textu (pozitivnÃ­, negativnÃ­, neutrÃ¡lnÃ­). VyuÅ¾Ã­vÃ¡ NLP techniky a strojovÃ© uÄenÃ­ k pochopenÃ­ nÃ¡zorÅ¯ a emocÃ­ vyjÃ¡dÅ™enÃ½ch v textovÃ½ch datech.

### MonitorovÃ¡nÃ­ znaÄky (Brand monitoring)
SystematickÃ© sledovÃ¡nÃ­ a analÃ½za zmÃ­nek o znaÄce, produktu nebo sluÅ¾bÄ› napÅ™Ã­Ä digitÃ¡lnÃ­mi platformami. PomÃ¡hÃ¡ spoleÄnostem pochopit vnÃ­mÃ¡nÃ­ jejich znaÄky a reagovat na feedback zÃ¡kaznÃ­kÅ¯.

### AnalÃ½za trendÅ¯
Identifikace vzorcÅ¯ a tendencÃ­ v datech sociÃ¡lnÃ­ch mÃ©diÃ­ v Äase. UmoÅ¾Åˆuje pÅ™edpovÃ­dat budoucÃ­ vÃ½voj a pÅ™izpÅ¯sobit marketingovÃ© strategie.

### Identifikace influencerÅ¯
Proces nalezenÃ­ a hodnocenÃ­ osob s vÃ½znamnÃ½m vlivem na sociÃ¡lnÃ­ch sÃ­tÃ­ch v urÄitÃ© oblasti nebo komunitÄ›. KlÃ­ÄovÃ© pro influencer marketing kampanÄ›.

### Crisis management
Å˜Ã­zenÃ­ komunikaÄnÃ­ krize zahrnujÃ­cÃ­ rychlou detekci negativnÃ­ch trendÅ¯ a koordinovanou odpovÄ›Ä k minimalizaci poÅ¡kozenÃ­ povÄ›sti znaÄky.

## KomplexnÃ­ vysvÄ›tlenÃ­ projektu

Tento projekt pÅ™edstavuje pokroÄilÃ½ systÃ©m pro analÃ½zu sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­ vyuÅ¾Ã­vajÃ­cÃ­ Model Context Protocol. SystÃ©m je navrÅ¾en pro automatickÃ© monitorovÃ¡nÃ­, analÃ½zu a reporting sentimentu znaÄky napÅ™Ã­Ä platformami jako Twitter/X a Instagram.

### CÃ­le projektu
- **AutomatizovanÃ© monitorovÃ¡nÃ­**: KontinuÃ¡lnÃ­ sledovÃ¡nÃ­ zmÃ­nek o znaÄce v reÃ¡lnÃ©m Äase
- **InteligentnÃ­ analÃ½za**: VyuÅ¾itÃ­ LLM pro hlubÅ¡Ã­ pochopenÃ­ kontextu a sentimentu
- **PrediktivnÃ­ analytics**: Identifikace trendÅ¯ a moÅ¾nÃ½ch krizovÃ½ch situacÃ­
- **Actionable insights**: PoskytovÃ¡nÃ­ konkrÃ©tnÃ­ch doporuÄenÃ­ pro marketingovÃ© tÃ½my

### TechnickÃ© vÃ½zvy
- **Rate limiting**: SprÃ¡va omezenÃ­ API sociÃ¡lnÃ­ch sÃ­tÃ­
- **Data quality**: FiltrovÃ¡nÃ­ spamu a irelevantnÃ­ho obsahu
- **Real-time processing**: ZpracovÃ¡nÃ­ velkÃ½ch objemÅ¯ dat v reÃ¡lnÃ©m Äase
- **Sentiment accuracy**: DosaÅ¾enÃ­ vysokÃ© pÅ™esnosti v kontextuÃ¡lnÃ­m porozumÄ›nÃ­

### PotenciÃ¡lnÃ­ dopad
SystÃ©m umoÅ¾Åˆuje spoleÄnostem proaktivnÄ› Å™Ã­dit svou online povÄ›st, rychle reagovat na krize a optimalizovat marketingovÃ© strategie na zÃ¡kladÄ› real-time dat.

## KomplexnÃ­ implementace v Pythonu

````python
langchain==0.1.0
openai==1.0.0
tweepy==4.14.0
instagrapi==1.19.0
pandas==2.0.0
numpy==1.24.0
plotly==5.17.0
streamlit==1.28.0
python-dotenv==1.0.0
textblob==0.17.1
vaderSentiment==3.3.2
schedule==1.2.0
sqlalchemy==2.0.0
redis==4.6.0
fastapi==0.104.0
uvicorn==0.24.0
````

````python
import os
from dotenv import load_dotenv
from typing import Dict, Any

load_dotenv()

class Config:
    # API Keys
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    TWITTER_BEARER_TOKEN = os.getenv("TWITTER_BEARER_TOKEN")
    TWITTER_API_KEY = os.getenv("TWITTER_API_KEY")
    TWITTER_API_SECRET = os.getenv("TWITTER_API_SECRET")
    INSTAGRAM_USERNAME = os.getenv("INSTAGRAM_USERNAME")
    INSTAGRAM_PASSWORD = os.getenv("INSTAGRAM_PASSWORD")
    
    # Database
    DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///sentiment_analyzer.db")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
    
    # MCP Settings
    MCP_SERVER_HOST = "localhost"
    MCP_SERVER_PORT = 8000
    
    # Analysis Settings
    SENTIMENT_THRESHOLD_POSITIVE = 0.6
    SENTIMENT_THRESHOLD_NEGATIVE = -0.6
    CRISIS_ALERT_THRESHOLD = -0.8
    
    # Monitoring Keywords
    DEFAULT_KEYWORDS = ["vaÅ¡e_znaÄka", "vÃ¡Å¡_produkt", "@vÃ¡Å¡_account"]

CONFIG = Config()
````

````python
from sqlalchemy import Column, Integer, String, Float, DateTime, Text, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from datetime import datetime
from typing import Optional

Base = declarative_base()

class SocialMediaPost(Base):
    __tablename__ = "social_media_posts"
    
    id = Column(Integer, primary_key=True, index=True)
    platform = Column(String, index=True)  # "twitter", "instagram"
    post_id = Column(String, unique=True, index=True)
    content = Column(Text)
    author = Column(String)
    author_followers = Column(Integer, default=0)
    created_at = Column(DateTime)
    sentiment_score = Column(Float)
    sentiment_label = Column(String)  # "positive", "negative", "neutral"
    keywords_matched = Column(String)  # JSON string
    is_crisis_alert = Column(Boolean, default=False)
    processed_at = Column(DateTime, default=datetime.utcnow)

class BrandMention(Base):
    __tablename__ = "brand_mentions"
    
    id = Column(Integer, primary_key=True, index=True)
    brand_name = Column(String, index=True)
    mention_count = Column(Integer)
    avg_sentiment = Column(Float)
    date = Column(DateTime, index=True)
    platform = Column(String)

class Influencer(Base):
    __tablename__ = "influencers"
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    platform = Column(String)
    followers_count = Column(Integer)
    engagement_rate = Column(Float)
    sentiment_impact = Column(Float)
    last_updated = Column(DateTime, default=datetime.utcnow)
````

````python
import json
import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class MCPMessageType(Enum):
    REQUEST = "request"
    RESPONSE = "response"
    NOTIFICATION = "notification"

@dataclass
class MCPMessage:
    jsonrpc: str = "2.0"
    method: Optional[str] = None
    params: Optional[Dict[str, Any]] = None
    id: Optional[str] = None
    result: Optional[Any] = None
    error: Optional[Dict[str, Any]] = None

class MCPServer:
    def __init__(self):
        self.tools = {}
        self.resources = {}
        
    def register_tool(self, name: str, func, description: str, parameters: Dict):
        """Registrace nÃ¡stroje pro MCP"""
        self.tools[name] = {
            "function": func,
            "description": description,
            "parameters": parameters
        }
    
    def register_resource(self, name: str, handler, description: str):
        """Registrace zdroje dat pro MCP"""
        self.resources[name] = {
            "handler": handler,
            "description": description
        }
    
    async def handle_request(self, message: MCPMessage) -> MCPMessage:
        """ZpracovÃ¡nÃ­ MCP poÅ¾adavku"""
        try:
            if message.method == "tools/list":
                return MCPMessage(
                    id=message.id,
                    result={"tools": list(self.tools.keys())}
                )
            
            elif message.method == "tools/call":
                tool_name = message.params.get("name")
                arguments = message.params.get("arguments", {})
                
                if tool_name in self.tools:
                    result = await self.tools[tool_name]["function"](**arguments)
                    return MCPMessage(
                        id=message.id,
                        result={"content": result}
                    )
                else:
                    return MCPMessage(
                        id=message.id,
                        error={"code": -32601, "message": f"Tool {tool_name} not found"}
                    )
            
            elif message.method == "resources/list":
                return MCPMessage(
                    id=message.id,
                    result={"resources": list(self.resources.keys())}
                )
            
            else:
                return MCPMessage(
                    id=message.id,
                    error={"code": -32601, "message": "Method not found"}
                )
                
        except Exception as e:
            return MCPMessage(
                id=message.id,
                error={"code": -32603, "message": str(e)}
            )
````

````python
import tweepy
from instagrapi import Client
import asyncio
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any
from src.config import CONFIG
from src.models import SocialMediaPost

class TwitterCollector:
    def __init__(self):
        self.client = tweepy.Client(bearer_token=CONFIG.TWITTER_BEARER_TOKEN)
    
    async def collect_mentions(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """SbÄ›r zmÃ­nek z Twitteru"""
        query = " OR ".join([f'"{keyword}"' for keyword in keywords])
        query += " -is:retweet lang:cs"
        
        try:
            tweets = self.client.search_recent_tweets(
                query=query,
                max_results=limit,
                tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations']
            )
            
            posts = []
            if tweets.data:
                for tweet in tweets.data:
                    post_data = {
                        'platform': 'twitter',
                        'post_id': str(tweet.id),
                        'content': tweet.text,
                        'author': str(tweet.author_id),
                        'created_at': tweet.created_at,
                        'author_followers': tweet.public_metrics.get('retweet_count', 0),
                        'keywords_matched': json.dumps(keywords)
                    }
                    posts.append(post_data)
            
            return posts
            
        except Exception as e:
            print(f"Chyba pÅ™i sbÄ›ru dat z Twitteru: {e}")
            return []

class InstagramCollector:
    def __init__(self):
        self.client = Client()
        try:
            self.client.login(CONFIG.INSTAGRAM_USERNAME, CONFIG.INSTAGRAM_PASSWORD)
        except Exception as e:
            print(f"Chyba pÅ™i pÅ™ihlÃ¡Å¡enÃ­ na Instagram: {e}")
    
    async def collect_hashtag_posts(self, hashtags: List[str], limit: int = 50) -> List[Dict]:
        """SbÄ›r pÅ™Ã­spÄ›vkÅ¯ podle hashtagÅ¯"""
        posts = []
        
        for hashtag in hashtags:
            try:
                medias = self.client.hashtag_medias_recent(hashtag, amount=limit)
                
                for media in medias:
                    post_data = {
                        'platform': 'instagram',
                        'post_id': str(media.id),
                        'content': media.caption_text or "",
                        'author': media.user.username,
                        'created_at': media.taken_at,
                        'author_followers': media.user.follower_count or 0,
                        'keywords_matched': json.dumps([hashtag])
                    }
                    posts.append(post_data)
                    
            except Exception as e:
                print(f"Chyba pÅ™i sbÄ›ru dat z Instagramu pro #{hashtag}: {e}")
        
        return posts
````

````python
import openai
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import numpy as np
from typing import Dict, List, Tuple
from src.config import CONFIG

class AdvancedSentimentAnalyzer:
    def __init__(self):
        openai.api_key = CONFIG.OPENAI_API_KEY
        self.llm = OpenAI(temperature=0.3)
        self.vader = SentimentIntensityAnalyzer()
        self.setup_llm_chain()
    
    def setup_llm_chain(self):
        """NastavenÃ­ LangChain pro pokroÄilou analÃ½zu sentimentu"""
        template = """
        Analyzuj sentiment nÃ¡sledujÃ­cÃ­ho textu z ÄeskÃ½ch sociÃ¡lnÃ­ch mÃ©diÃ­:
        
        Text: {text}
        
        Poskytni:
        1. Sentiment score (-1 aÅ¾ 1): 
        2. Sentiment label (pozitivnÃ­/negativnÃ­/neutrÃ¡lnÃ­):
        3. KlÃ­ÄovÃ© emoce:
        4. DÅ¯vÄ›ra v analÃ½zu (0-1):
        5. Kontext a dÅ¯vod hodnocenÃ­:
        
        OdpovÄ›Ä ve formÃ¡tu JSON:
        """
        
        self.prompt = PromptTemplate(
            input_variables=["text"],
            template=template
        )
        
        self.sentiment_chain = LLMChain(
            llm=self.llm,
            prompt=self.prompt
        )
    
    async def analyze_sentiment(self, text: str) -> Dict:
        """KombinovanÃ¡ analÃ½za sentimentu"""
        # TextBlob analÃ½za
        blob = TextBlob(text)
        textblob_score = blob.sentiment.polarity
        
        # VADER analÃ½za
        vader_scores = self.vader.polarity_scores(text)
        vader_score = vader_scores['compound']
        
        # LLM analÃ½za
        try:
            llm_result = await self.sentiment_chain.arun(text=text)
            # ParsovÃ¡nÃ­ JSON odpovÄ›di z LLM
            import json
            try:
                llm_analysis = json.loads(llm_result)
                llm_score = float(llm_analysis.get('sentiment_score', 0))
                confidence = float(llm_analysis.get('confidence', 0.5))
            except:
                llm_score = 0
                confidence = 0.3
        except Exception as e:
            print(f"Chyba LLM analÃ½zy: {e}")
            llm_score = 0
            confidence = 0.3
        
        # Kombinace vÃ½sledkÅ¯ s vÃ¡hami
        weights = [0.3, 0.3, 0.4]  # TextBlob, VADER, LLM
        combined_score = np.average([textblob_score, vader_score, llm_score], weights=weights)
        
        # UrÄenÃ­ labelu
        if combined_score > CONFIG.SENTIMENT_THRESHOLD_POSITIVE:
            label = "pozitivnÃ­"
        elif combined_score < CONFIG.SENTIMENT_THRESHOLD_NEGATIVE:
            label = "negativnÃ­"
        else:
            label = "neutrÃ¡lnÃ­"
        
        # Crisis alert
        is_crisis = combined_score < CONFIG.CRISIS_ALERT_THRESHOLD
        
        return {
            'sentiment_score': float(combined_score),
            'sentiment_label': label,
            'confidence': confidence,
            'is_crisis_alert': is_crisis,
            'individual_scores': {
                'textblob': textblob_score,
                'vader': vader_score,
                'llm': llm_score
            }
        }
    
    async def batch_analyze(self, texts: List[str]) -> List[Dict]:
        """DÃ¡vkovÃ¡ analÃ½za textÅ¯"""
        results = []
        for text in texts:
            result = await self.analyze_sentiment(text)
            results.append(result)
        return results
````

````python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class TrendAnalyzer:
    def __init__(self):
        self.scaler = StandardScaler()
    
    def analyze_sentiment_trends(self, data: pd.DataFrame, period: str = 'daily') -> Dict:
        """AnalÃ½za trendÅ¯ sentimentu v Äase"""
        # PÅ™evod dat na ÄasovÃ© Å™ady
        data['created_at'] = pd.to_datetime(data['created_at'])
        data.set_index('created_at', inplace=True)
        
        # Agregace podle obdobÃ­
        if period == 'hourly':
            resampled = data.resample('H')
        elif period == 'daily':
            resampled = data.resample('D')
        else:
            resampled = data.resample('W')
        
        trend_data = resampled.agg({
            'sentiment_score': ['mean', 'std', 'count'],
            'is_crisis_alert': 'sum'
        }).round(3)
        
        # VÃ½poÄet trendÅ¯
        sentiment_values = trend_data['sentiment_score']['mean'].values
        trend_direction = self._calculate_trend_direction(sentiment_values)
        volatility = np.std(sentiment_values)
        
        # Detekce anomÃ¡liÃ­
        anomalies = self._detect_anomalies(sentiment_values)
        
        return {
            'trend_direction': trend_direction,
            'volatility': volatility,
            'anomalies': anomalies,
            'data': trend_data.to_dict(),
            'summary': {
                'avg_sentiment': np.mean(sentiment_values),
                'min_sentiment': np.min(sentiment_values),
                'max_sentiment': np.max(sentiment_values),
                'total_posts': int(trend_data['sentiment_score']['count'].sum())
            }
        }
    
    def _calculate_trend_direction(self, values: np.ndarray) -> str:
        """VÃ½poÄet smÄ›ru trendu"""
        if len(values) < 3:
            return "nedostatek_dat"
        
        # LineÃ¡rnÃ­ regrese pro trend
        x = np.arange(len(values))
        coeffs = np.polyfit(x, values, 1)
        slope = coeffs[0]
        
        if slope > 0.01:
            return "rostoucÃ­"
        elif slope < -0.01:
            return "klesajÃ­cÃ­"
        else:
            return "stabilnÃ­"
    
    def _detect_anomalies(self, values: np.ndarray) -> List[int]:
        """Detekce anomÃ¡liÃ­ v datech"""
        if len(values) < 5:
            return []
        
        # Z-score metoda
        z_scores = np.abs((values - np.mean(values)) / np.std(values))
        anomaly_threshold = 2.5
        
        return [i for i, z in enumerate(z_scores) if z > anomaly_threshold]
    
    def identify_viral_content(self, data: pd.DataFrame, threshold_percentile: int = 95) -> pd.DataFrame:
        """Identifikace virÃ¡lnÃ­ho obsahu"""
        # VÃ½poÄet engagement score
        data['engagement_score'] = (
            data['author_followers'] * 
            abs(data['sentiment_score']) * 
            (1 if data['sentiment_label'] != 'neutrÃ¡lnÃ­' else 0.5)
        )
        
        # Top percentil
        threshold = np.percentile(data['engagement_score'], threshold_percentile)
        viral_content = data[data['engagement_score'] >= threshold]
        
        return viral_content.sort_values('engagement_score', ascending=False)
    
    def generate_insights_report(self, trend_data: Dict, viral_content: pd.DataFrame) -> Dict:
        """GenerovÃ¡nÃ­ pÅ™ehledu insights"""
        insights = {
            'sentiment_summary': {
                'overall_trend': trend_data['trend_direction'],
                'volatility_level': 'vysokÃ¡' if trend_data['volatility'] > 0.3 else 'stÅ™ednÃ­' if trend_data['volatility'] > 0.1 else 'nÃ­zkÃ¡',
                'crisis_alerts': trend_data['summary'].get('crisis_count', 0)
            },
            'viral_content_summary': {
                'count': len(viral_content),
                'avg_sentiment': viral_content['sentiment_score'].mean() if len(viral_content) > 0 else 0,
                'top_authors': viral_content['author'].value_counts().head(3).to_dict() if len(viral_content) > 0 else {}
            },
            'recommendations': self._generate_recommendations(trend_data, viral_content)
        }
        
        return insights
    
    def _generate_recommendations(self, trend_data: Dict, viral_content: pd.DataFrame) -> List[str]:
        """GenerovÃ¡nÃ­ doporuÄenÃ­ na zÃ¡kladÄ› analÃ½zy"""
        recommendations = []
        
        # Trend-based recommendations
        if trend_data['trend_direction'] == 'klesajÃ­cÃ­':
            recommendations.append("ZvÃ¡Å¾it PR kampaÅˆ pro zlepÅ¡enÃ­ image znaÄky")
        elif trend_data['trend_direction'] == 'rostoucÃ­':
            recommendations.append("VyuÅ¾Ã­t pozitivnÃ­ momentum pro marketingovÃ© aktivity")
        
        # Volatility-based recommendations
        if trend_data['volatility'] > 0.3:
            recommendations.append("Implementovat ÄastÄ›jÅ¡Ã­ monitoring kvÅ¯li vysokÃ© volatilitÄ›")
        
        # Viral content recommendations
        if len(viral_content) > 0:
            positive_viral = viral_content[viral_content['sentiment_score'] > 0]
            if len(positive_viral) > 0:
                recommendations.append("Engage s pozitivnÃ­m virÃ¡lnÃ­m obsahem")
        
        return recommendations
````

````python
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
import json
from enum import Enum

class AlertLevel(Enum):
    LOW = "nÃ­zkÃ¡"
    MEDIUM = "stÅ™ednÃ­"
    HIGH = "vysokÃ¡"
    CRITICAL = "kritickÃ¡"

@dataclass
class CrisisAlert:
    id: str
    level: AlertLevel
    message: str
    timestamp: datetime
    affected_posts: List[str]
    recommended_actions: List[str]
    auto_resolved: bool = False

class CrisisManager:
    def __init__(self):
        self.active_alerts = {}
        self.alert_history = []
        self.escalation_rules = self._setup_escalation_rules()
    
    def _setup_escalation_rules(self) -> Dict:
        """NastavenÃ­ pravidel eskalace"""
        return {
            'sentiment_threshold': -0.7,
            'volume_multiplier': 3.0,  # nÃ¡sobek normÃ¡lnÃ­ho objemu
            'time_window_minutes': 30,
            'min_posts_for_alert': 5,
            'influencer_threshold': 10000  # followers
        }
    
    async def evaluate_crisis_potential(self, recent_posts: List[Dict]) -> Optional[CrisisAlert]:
        """VyhodnocenÃ­ potenciÃ¡lu krize"""
        if len(recent_posts) < self.escalation_rules['min_posts_for_alert']:
            return None
        
        # AnalÃ½za sentimentu
        negative_posts = [p for p in recent_posts if p['sentiment_score'] < self.escalation_rules['sentiment_threshold']]
        negative_ratio = len(negative_posts) / len(recent_posts)
        
        # AnalÃ½za objemu
        current_volume = len(recent_posts)
        historical_avg = await self._get_historical_average_volume()
        volume_ratio = current_volume / historical_avg if historical_avg > 0 else 1
        
        # AnalÃ½za vlivu autorÅ¯
        high_influence_posts = [p for p in recent_posts if p['author_followers'] > self.escalation_rules['influencer_threshold']]
        
        # UrÄenÃ­ ÃºrovnÄ› alertu
        alert_level = self._calculate_alert_level(negative_ratio, volume_ratio, len(high_influence_posts))
        
        if alert_level != AlertLevel.LOW:
            alert = CrisisAlert(
                id=f"crisis_{datetime.now().isoformat()}",
                level=alert_level,
                message=self._generate_alert_message(negative_ratio, volume_ratio, len(high_influence_posts)),
                timestamp=datetime.now(),
                affected_posts=[p['post_id'] for p in negative_posts],
                recommended_actions=self._generate_recommended_actions(alert_level)
            )
            
            self.active_alerts[alert.id] = alert
            self.alert_history.append(alert)
            
            return alert
        
        return None
    
    def _calculate_alert_level(self, negative_ratio: float, volume_ratio: float, influencer_count: int) -> AlertLevel:
        """VÃ½poÄet ÃºrovnÄ› alertu"""
        score = 0
        
        # Sentiment score
        if negative_ratio > 0.7:
            score += 3
        elif negative_ratio > 0.5:
            score += 2
        elif negative_ratio > 0.3:
            score += 1
        
        # Volume score
        if volume_ratio > 5:
            score += 3
        elif volume_ratio > 3:
            score += 2
        elif volume_ratio > 2:
            score += 1
        
        # Influencer score
        if influencer_count > 3:
            score += 2
        elif influencer_count > 1:
            score += 1
        
        if score >= 6:
            return AlertLevel.CRITICAL
        elif score >= 4:
            return AlertLevel.HIGH
        elif score >= 2:
            return AlertLevel.MEDIUM
        else:
            return AlertLevel.LOW
    
    def _generate_alert_message(self, negative_ratio: float, volume_ratio: float, influencer_count: int) -> str:
        """GenerovÃ¡nÃ­ zprÃ¡vy alertu"""
        message_parts = []
        
        message_parts.append(f"DetekovÃ¡na moÅ¾nÃ¡ krize:")
        message_parts.append(f"â€¢ {negative_ratio:.1%} negativnÃ­ch pÅ™Ã­spÄ›vkÅ¯")
        message_parts.append(f"â€¢ {volume_ratio:.1f}x vyÅ¡Å¡Ã­ objem neÅ¾ obvykle")
        
        if influencer_count > 0:
            message_parts.append(f"â€¢ {influencer_count} pÅ™Ã­spÄ›vkÅ¯ od influencerÅ¯")
        
        return "\n".join(message_parts)
    
    def _generate_recommended_actions(self, level: AlertLevel) -> List[str]:
        """GenerovÃ¡nÃ­ doporuÄenÃ½ch akcÃ­"""
        actions = {
            AlertLevel.MEDIUM: [
                "ZvÃ½Å¡it frekvenci monitoringu",
                "PÅ™ipravit standardnÃ­ odpovÄ›Ä",
                "Informovat PR tÃ½m"
            ],
            AlertLevel.HIGH: [
                "Aktivovat krizovÃ½ tÃ½m",
                "PÅ™ipravit oficiÃ¡lnÃ­ prohlÃ¡Å¡enÃ­",
                "Kontaktovat klÃ­ÄovÃ© stakeholdery",
                "ZvÃ¡Å¾it pozastavenÃ­ plÃ¡novanÃ½ch kampanÃ­"
            ],
            AlertLevel.CRITICAL: [
                "OkamÅ¾itÄ› svolat krizovÃ½ Å¡tÃ¡b",
                "Aktivovat krizovÃ½ komunikaÄnÃ­ plÃ¡n",
                "Kontaktovat vedenÃ­ spoleÄnosti",
                "PÅ™ipravit se na mediÃ¡lnÃ­ dotazy",
                "Pozastavit vÅ¡echny marketingovÃ© aktivity"
            ]
        }
        
        return actions.get(level, [])
    
    async def _get_historical_average_volume(self) -> float:
        """ZÃ­skÃ¡nÃ­ historickÃ©ho prÅ¯mÄ›ru objemu pÅ™Ã­spÄ›vkÅ¯"""
        # V reÃ¡lnÃ© implementaci by se zÃ­skalo z databÃ¡ze
        return 50.0  # Mock hodnota
    
    def get_active_alerts(self) -> List[CrisisAlert]:
        """ZÃ­skÃ¡nÃ­ aktivnÃ­ch alertÅ¯"""
        return list(self.active_alerts.values())
    
    def resolve_alert(self, alert_id: str, auto_resolved: bool = False) -> bool:
        """VyÅ™eÅ¡enÃ­ alertu"""
        if alert_id in self.active_alerts:
            self.active_alerts[alert_id].auto_resolved = auto_resolved
            del self.active_alerts[alert_id]
            return True
        return False
````

````python
import asyncio
from datetime import datetime, timedelta
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.config import CONFIG
from src.models import Base, SocialMediaPost
from src.mcp_protocol import MCPServer
from src.social_media_collector import TwitterCollector, InstagramCollector
from src.sentiment_analyzer import AdvancedSentimentAnalyzer
from src.trend_analyzer import TrendAnalyzer
from src.crisis_manager import CrisisManager

class SocialMediaSentimentAnalyzer:
    def __init__(self):
        # Database setup
        self.engine = create_engine(CONFIG.DATABASE_URL)
        Base.metadata.create_all(bind=self.engine)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        self.db = SessionLocal()
        
        # Components
        self.twitter_collector = TwitterCollector()
        self.instagram_collector = InstagramCollector()
        self.sentiment_analyzer = AdvancedSentimentAnalyzer()
        self.trend_analyzer = TrendAnalyzer()
        self.crisis_manager = CrisisManager()
        
        # MCP Server
        self.mcp_server = MCPServer()
        self._register_mcp_tools()
    
    def _register_mcp_tools(self):
        """Registrace MCP nÃ¡strojÅ¯"""
        self.mcp_server.register_tool(
            "analyze_brand_sentiment",
            self.analyze_brand_sentiment,
            "Analyzuje sentiment znaÄky na sociÃ¡lnÃ­ch mÃ©diÃ­ch",
            {
                "type": "object",
                "properties": {
                    "keywords": {"type": "array", "items": {"type": "string"}},
                    "platforms": {"type": "array", "items": {"type": "string"}},
                    "hours_back": {"type": "integer", "default": 24}
                }
            }
        )
        
        self.mcp_server.register_tool(
            "get_crisis_alerts",
            self.get_crisis_alerts,
            "ZÃ­skÃ¡ aktuÃ¡lnÃ­ krizovÃ© alerty",
            {"type": "object", "properties": {}}
        )
        
        self.mcp_server.register_tool(
            "generate_sentiment_report",
            self.generate_sentiment_report,
            "Vygeneruje komplexnÃ­ sentiment report",
            {
                "type": "object",
                "properties": {
                    "period": {"type": "string", "enum": ["daily", "weekly", "monthly"]},
                    "include_trends": {"type": "boolean", "default": True}
                }
            }
        )
    
    async def collect_and_analyze(self, keywords: List[str], platforms: List[str] = ["twitter", "instagram"]):
        """HlavnÃ­ metoda pro sbÄ›r a analÃ½zu dat"""
        all_posts = []
        
        # SbÄ›r dat z platforem
        if "twitter" in platforms:
            twitter_posts = await self.twitter_collector.collect_mentions(keywords)
            all_posts.extend(twitter_posts)
        
        if "instagram" in platforms:
            instagram_posts = await self.instagram_collector.collect_hashtag_posts(keywords)
            all_posts.extend(instagram_posts)
        
        # AnalÃ½za sentimentu
        for post_data in all_posts:
            sentiment_result = await self.sentiment_analyzer.analyze_sentiment(post_data['content'])
            post_data.update(sentiment_result)
            
            # UloÅ¾enÃ­ do databÃ¡ze
            post = SocialMediaPost(**post_data)
            self.db.add(post)
        
        self.db.commit()
        
        # Kontrola krizÃ­
        recent_posts = [p for p in all_posts if isinstance(p.get('created_at'), datetime) and 
                       p['created_at'] > datetime.now() - timedelta(hours=1)]
        
        crisis_alert = await self.crisis_manager.evaluate_crisis_potential(recent_posts)
        
        return {
            "collected_posts": len(all_posts),
            "crisis_alert": crisis_alert.message if crisis_alert else None,
            "summary": self._generate_collection_summary(all_posts)
        }
    
    async def analyze_brand_sentiment(self, keywords: List[str], platforms: List[str] = ["twitter", "instagram"], hours_back: int = 24):
        """MCP tool: AnalÃ½za sentimentu znaÄky"""
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        
        # ZÃ­skÃ¡nÃ­ dat z databÃ¡ze
        posts_query = self.db.query(SocialMediaPost).filter(
            SocialMediaPost.processed_at >= cutoff_time
        )
        
        if platforms:
            posts_query = posts_query.filter(SocialMediaPost.platform.in_(platforms))
        
        posts = posts_query.all()
        
        if not posts:
            return {"error": "Å½Ã¡dnÃ¡ data nebyla nalezena pro zadanÃ© parametry"}
        
        # AnalÃ½za
        df = pd.DataFrame([{
            'platform': p.platform,
            'sentiment_score': p.sentiment_score,
            'sentiment_label': p.sentiment_label,
            'created_at': p.created_at,
            'author_followers': p.author_followers,
            'is_crisis_alert': p.is_crisis_alert
        } for p in posts])
        
        analysis_result = {
            "total_posts": len(posts),
            "average_sentiment": df['sentiment_score'].mean(),
            "sentiment_distribution": df['sentiment_label'].value_counts().to_dict(),
            "platform_breakdown": df.groupby('platform')['sentiment_score'].mean().to_dict(),
            "crisis_posts": df['is_crisis_alert'].sum(),
            "timeframe": f"PoslednÃ­ch {hours_back} hodin"
        }
        
        return analysis_result
    
    async def get_crisis_alerts(self):
        """MCP tool: ZÃ­skÃ¡nÃ­ krizovÃ½ch alertÅ¯"""
        active_alerts = self.crisis_manager.get_active_alerts()
        
        return {
            "active_alerts_count": len(active_alerts),
            "alerts": [
                {
                    "id": alert.id,
                    "level": alert.level.value,
                    "message": alert.message,
                    "timestamp": alert.timestamp.isoformat(),
                    "affected_posts_count": len(alert.affected_posts),
                    "recommended_actions": alert.recommended_actions
                }
                for alert in active_alerts
            ]
        }
    
    async def generate_sentiment_report(self, period: str = "daily", include_trends: bool = True):
        """MCP tool: GenerovÃ¡nÃ­ sentiment reportu"""
        # ZÃ­skÃ¡nÃ­ dat podle obdobÃ­
        if period == "daily":
            cutoff_time = datetime.now() - timedelta(days=1)
        elif period == "weekly":
            cutoff_time = datetime.now() - timedelta(weeks=1)
        else:  # monthly
            cutoff_time = datetime.now() - timedelta(days=30)
        
        posts = self.db.query(SocialMediaPost).filter(
            SocialMediaPost.processed_at >= cutoff_time
        ).all()
        
        if not posts:
            return {"error": "Å½Ã¡dnÃ¡ data pro reporting"}
        
        df = pd.DataFrame([{
            'platform': p.platform,
            'sentiment_score': p.sentiment_score,
            'sentiment_label': p.sentiment_label,
            'created_at': p.created_at,
            'author_followers': p.author_followers,
            'is_crisis_alert': p.is_crisis_alert
        } for p in posts])
        
        report = {
            "period": period,
            "total_posts": len(posts),
            "sentiment_summary": {
                "average_score": df['sentiment_score'].mean(),
                "median_score": df['sentiment_score'].median(),
                "distribution": df['sentiment_label'].value_counts().to_dict()
            },
            "platform_analysis": df.groupby('platform').agg({
                'sentiment_score': ['mean', 'count'],
                'is_crisis_alert': 'sum'
            }).to_dict(),
            "crisis_summary": {
                "total_alerts": df['is_crisis_alert'].sum(),
                "crisis_rate": df['is_crisis_alert'].mean()
            }
        }
        
        if include_trends:
            trend_analysis = self.trend_analyzer.analyze_sentiment_trends(df.copy(), period='daily')
            report["trends"] = trend_analysis
        
        return report
    
    def _generate_collection_summary(self, posts: List[Dict]) -> Dict:
        """GenerovÃ¡nÃ­ souhrnu sbÄ›ru dat"""
        if not posts:
            return {"message": "Å½Ã¡dnÃ© pÅ™Ã­spÄ›vky nebyly shromÃ¡Å¾dÄ›ny"}
        
        sentiments = [p.get('sentiment_score', 0) for p in posts]
        platforms = [p.get('platform', 'unknown') for p in posts]
        
        return {
            "total_posts": len(posts),
            "average_sentiment": sum(sentiments) / len(sentiments) if sentiments else 0,
            "platforms": list(set(platforms)),
            "crisis_posts": sum(1 for p in posts if p.get('is_crisis_alert', False))
        }

# HlavnÃ­ spouÅ¡tÄ›cÃ­ funkce
async def main():
    analyzer = SocialMediaSentimentAnalyzer()
    
    # PÅ™Ã­klad pouÅ¾itÃ­
    keywords = ["vaÅ¡e_znaÄka", "#vÃ¡Å¡_hashtag", "@vÃ¡Å¡_account"]
    
    print("SpouÅ¡tÃ­m analÃ½zu sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­...")
    result = await analyzer.collect_and_analyze(keywords)
    print(f"VÃ½sledek: {result}")
    
    # GenerovÃ¡nÃ­ reportu
    report = await analyzer.generate_sentiment_report(period="daily")
    print(f"DennÃ­ report: {report}")

if __name__ == "__main__":
    asyncio.run(main())
````

````python
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta
import asyncio
from src.main_analyzer import SocialMediaSentimentAnalyzer

class SentimentDashboard:
    def __init__(self):
        self.analyzer = SocialMediaSentimentAnalyzer()
    
    def run_dashboard(self):
        """SpuÅ¡tÄ›nÃ­ Streamlit dashboardu"""
        st.set_page_config(
            page_title="AnalyzÃ¡tor sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­",
            page_icon="ğŸ“Š",
            layout="wide"
        )
        
        st.title("ğŸ” AI-LLM MCP: AnalyzÃ¡tor sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­")
        
        # Sidebar
        st.sidebar.header("NastavenÃ­")
        keywords = st.sidebar.text_input(
            "KlÃ­ÄovÃ¡ slova (oddÄ›lenÃ¡ ÄÃ¡rkou)",
            value="vaÅ¡e_znaÄka, #vÃ¡Å¡_hashtag"
        ).split(",")
        keywords = [k.strip() for k in keywords if k.strip()]
        
        platforms = st.sidebar.multiselect(
            "Platformy",
            ["twitter", "instagram"],
            default=["twitter", "instagram"]
        )
        
        period = st.sidebar.selectbox(
            "ObdobÃ­ analÃ½zy",
            ["daily", "weekly", "monthly"],
            index=0
        )
        
        # HlavnÃ­ obsah
        col1, col2, col3, col4 = st.columns(4)
        
        # ZÃ­skÃ¡nÃ­ dat
        if st.sidebar.button("Spustit analÃ½zu"):
            with st.spinner("ProbÃ­hÃ¡ analÃ½za..."):
                try:
                    # Async volÃ¡nÃ­
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    result = loop.run_until_complete(
                        self.analyzer.analyze_brand_sentiment(keywords, platforms, 24)
                    )
                    loop.close()
                    
                    if "error" not in result:
                        self._display_metrics(result, col1, col2, col3, col4)
                        self._display_charts(result)
                        self._display_crisis_alerts()
                    else:
                        st.error(result["error"])
                        
                except Exception as e:
                    st.error(f"Chyba pÅ™i analÃ½ze: {str(e)}")
    
    def _display_metrics(self, result, col1, col2, col3, col4):
        """ZobrazenÃ­ klÃ­ÄovÃ½ch metrik"""
        with col1:
            st.metric(
                "Celkem pÅ™Ã­spÄ›vkÅ¯",
                result["total_posts"]
            )
        
        with col2:
            sentiment_score = result["average_sentiment"]
            sentiment_color = "normal"
            if sentiment_score > 0.2:
                sentiment_color = "inverse"
            elif sentiment_score < -0.2:
                sentiment_color = "off"
            
            st.metric(
                "PrÅ¯mÄ›rnÃ½ sentiment",
                f"{sentiment_score:.2f}",
                delta=None
            )
        
        with col3:
            st.metric(
                "KrizovÃ© pÅ™Ã­spÄ›vky",
                result["crisis_posts"]
            )
        
        with col4:
            positive_ratio = result["sentiment_distribution"].get("pozitivnÃ­", 0) / result["total_posts"] * 100
            st.metric(
                "% pozitivnÃ­ch",
                f"{positive_ratio:.1f}%"
            )
    
    def _display_charts(self, result):
        """ZobrazenÃ­ grafÅ¯"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distribuce sentimentu")
            sentiment_dist = result["sentiment_distribution"]
            
            fig_pie = go.Figure(data=[go.Pie(
                labels=list(sentiment_dist.keys()),
                values=list(sentiment_dist.values()),
                hole=0.3
            )])
            fig_pie.update_layout(height=400)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            st.subheader("Sentiment podle platforem")
            platform_data = result["platform_breakdown"]
            
            fig_bar = go.Figure(data=[go.Bar(
                x=list(platform_data.keys()),
                y=list(platform_data.values()),
                marker_color=['#ff6b6b' if v < 0 else '#51cf66' for v in platform_data.values()]
            )])
            fig_bar.update_layout(
                height=400,
                yaxis_title="PrÅ¯mÄ›rnÃ½ sentiment",
                xaxis_title="Platforma"
            )
            st.plotly_chart(fig_bar, use_container_width=True)
    
    def _display_crisis_alerts(self):
        """ZobrazenÃ­ krizovÃ½ch alertÅ¯"""
        st.subheader("ğŸš¨ KrizovÃ© alerty")
        
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            alerts_result = loop.run_until_complete(
                self.analyzer.get_crisis_alerts()
            )
            loop.close()
            
            if alerts_result["active_alerts_count"] > 0:
                for alert in alerts_result["alerts"]:
                    level_color = {
                        "nÃ­zkÃ¡": "ğŸŸ¢",
                        "stÅ™ednÃ­": "ğŸŸ¡", 
                        "vysokÃ¡": "ğŸŸ ",
                        "kritickÃ¡": "ğŸ”´"
                    }.get(alert["level"], "âšª")
                    
                    with st.expander(f"{level_color} Alert ID: {alert['id']} - {alert['level']}"):
                        st.write(f"**ZprÃ¡va:** {alert['message']}")
                        st.write(f"**ÄŒas:** {alert['timestamp']}")
                        st.write(f"**DotÄenÃ© pÅ™Ã­spÄ›vky:** {alert['affected_posts_count']}")
                        st.write("**DoporuÄenÃ© akce:**")
                        for action in alert["recommended_actions"]:
                            st.write(f"â€¢ {action}")
            else:
                st.success("âœ… Å½Ã¡dnÃ© aktivnÃ­ krizovÃ© alerty")
                
        except Exception as e:
            st.error(f"Chyba pÅ™i naÄÃ­tÃ¡nÃ­ alertÅ¯: {str(e)}")

if __name__ == "__main__":
    dashboard = SentimentDashboard()
    dashboard.run_dashboard()
````

## ShrnutÃ­ projektu

**AnalyzÃ¡tor sentimentu sociÃ¡lnÃ­ch mÃ©diÃ­** s Model Context Protocol pÅ™edstavuje komplexnÃ­ Å™eÅ¡enÃ­ pro modernÃ­ brand management a crisis communication. Projekt kombinuje pokroÄilÃ© AI technologie s praktickÃ½mi business potÅ™ebami.

### KlÃ­ÄovÃ© pÅ™Ã­nosy:
- **ProaktivnÃ­ monitoring**: KontinuÃ¡lnÃ­ sledovÃ¡nÃ­ online povÄ›sti znaÄky
- **InteligentnÃ­ analÃ½za**: Kombinace multiple AI modelÅ¯ pro pÅ™esnou analÃ½zu sentimentu
- **Real-time alerting**: OkamÅ¾itÃ© upozornÄ›nÃ­ na potenciÃ¡lnÃ­ krize
- **Actionable insights**: KonkrÃ©tnÃ­ doporuÄenÃ­ pro marketingovÃ© tÃ½my

### TechnickÃ© pÅ™ednosti:
- **MCP architektura**: ModulÃ¡rnÃ­ a rozÅ¡iÅ™itelnÃ¡ struktura
- **Multi-platform support**: Twitter, Instagram s moÅ¾nostÃ­ rozÅ¡Ã­Å™enÃ­
- **Scalable design**: PÅ™ipraveno pro high-volume data processing
- **Modern stack**: LangChain, OpenAI, Streamlit pro uÅ¾ivatelsky pÅ™Ã­vÄ›tivÃ© rozhranÃ­

### Business hodnota:
SystÃ©m umoÅ¾Åˆuje spoleÄnostem pÅ™ejÃ­t od reaktivnÃ­ho k proaktivnÃ­mu pÅ™Ã­stupu v online komunikaci, coÅ¾ mÅ¯Å¾e vÃ½znamnÄ› snÃ­Å¾it rizika poÅ¡kozenÃ­ povÄ›sti a zvÃ½Å¡it efektivitu marketingovÃ½ch investic.