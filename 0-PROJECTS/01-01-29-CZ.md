<small>Claude Sonnet 4 **(AI-LLM MCP: Analyzátor sentimentu sociálních médií)**</small>
# Social Media Sentiment Analyzer

## Klíčové koncepty

### Model Context Protocol (MCP)
**MCP** je standardizovaný protokol pro komunikaci mezi AI modely a externími nástroji či datovými zdroji. Umožňuje AI systémům dynamicky přistupovat k funkcionalitám a datům bez pevně zakódovaných integrací.

### Analýza sentimentu
**Sentiment analysis** je proces automatického rozpoznávání emočního zabarvení textu (pozitivní, negativní, neutrální). Využívá NLP techniky a strojové učení k pochopení názorů a emocí vyjádřených v textových datech.

### Monitorování značky (Brand monitoring)
Systematické sledování a analýza zmínek o značce, produktu nebo službě napříč digitálními platformami. Pomáhá společnostem pochopit vnímání jejich značky a reagovat na feedback zákazníků.

### Analýza trendů
Identifikace vzorců a tendencí v datech sociálních médií v čase. Umožňuje předpovídat budoucí vývoj a přizpůsobit marketingové strategie.

### Identifikace influencerů
Proces nalezení a hodnocení osob s významným vlivem na sociálních sítích v určité oblasti nebo komunitě. Klíčové pro influencer marketing kampaně.

### Crisis management
Řízení komunikační krize zahrnující rychlou detekci negativních trendů a koordinovanou odpověď k minimalizaci poškození pověsti značky.

## Komplexní vysvětlení projektu

Tento projekt představuje pokročilý systém pro analýzu sentimentu sociálních médií využívající Model Context Protocol. Systém je navržen pro automatické monitorování, analýzu a reporting sentimentu značky napříč platformami jako Twitter/X a Instagram.

### Cíle projektu
- **Automatizované monitorování**: Kontinuální sledování zmínek o značce v reálném čase
- **Inteligentní analýza**: Využití LLM pro hlubší pochopení kontextu a sentimentu
- **Prediktivní analytics**: Identifikace trendů a možných krizových situací
- **Actionable insights**: Poskytování konkrétních doporučení pro marketingové týmy

### Technické výzvy
- **Rate limiting**: Správa omezení API sociálních sítí
- **Data quality**: Filtrování spamu a irelevantního obsahu
- **Real-time processing**: Zpracování velkých objemů dat v reálném čase
- **Sentiment accuracy**: Dosažení vysoké přesnosti v kontextuálním porozumění

### Potenciální dopad
Systém umožňuje společnostem proaktivně řídit svou online pověst, rychle reagovat na krize a optimalizovat marketingové strategie na základě real-time dat.

## Komplexní implementace v Pythonu

````python
langchain==0.1.0
openai==1.0.0
tweepy==4.14.0
instagrapi==1.19.0
pandas==2.0.0
numpy==1.24.0
plotly==5.17.0
streamlit==1.28.0
python-dotenv==1.0.0
textblob==0.17.1
vaderSentiment==3.3.2
schedule==1.2.0
sqlalchemy==2.0.0
redis==4.6.0
fastapi==0.104.0
uvicorn==0.24.0
````

````python
import os
from dotenv import load_dotenv
from typing import Dict, Any

load_dotenv()

class Config:
    # API Keys
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    TWITTER_BEARER_TOKEN = os.getenv("TWITTER_BEARER_TOKEN")
    TWITTER_API_KEY = os.getenv("TWITTER_API_KEY")
    TWITTER_API_SECRET = os.getenv("TWITTER_API_SECRET")
    INSTAGRAM_USERNAME = os.getenv("INSTAGRAM_USERNAME")
    INSTAGRAM_PASSWORD = os.getenv("INSTAGRAM_PASSWORD")
    
    # Database
    DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///sentiment_analyzer.db")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
    
    # MCP Settings
    MCP_SERVER_HOST = "localhost"
    MCP_SERVER_PORT = 8000
    
    # Analysis Settings
    SENTIMENT_THRESHOLD_POSITIVE = 0.6
    SENTIMENT_THRESHOLD_NEGATIVE = -0.6
    CRISIS_ALERT_THRESHOLD = -0.8
    
    # Monitoring Keywords
    DEFAULT_KEYWORDS = ["vaše_značka", "váš_produkt", "@váš_account"]

CONFIG = Config()
````

````python
from sqlalchemy import Column, Integer, String, Float, DateTime, Text, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from datetime import datetime
from typing import Optional

Base = declarative_base()

class SocialMediaPost(Base):
    __tablename__ = "social_media_posts"
    
    id = Column(Integer, primary_key=True, index=True)
    platform = Column(String, index=True)  # "twitter", "instagram"
    post_id = Column(String, unique=True, index=True)
    content = Column(Text)
    author = Column(String)
    author_followers = Column(Integer, default=0)
    created_at = Column(DateTime)
    sentiment_score = Column(Float)
    sentiment_label = Column(String)  # "positive", "negative", "neutral"
    keywords_matched = Column(String)  # JSON string
    is_crisis_alert = Column(Boolean, default=False)
    processed_at = Column(DateTime, default=datetime.utcnow)

class BrandMention(Base):
    __tablename__ = "brand_mentions"
    
    id = Column(Integer, primary_key=True, index=True)
    brand_name = Column(String, index=True)
    mention_count = Column(Integer)
    avg_sentiment = Column(Float)
    date = Column(DateTime, index=True)
    platform = Column(String)

class Influencer(Base):
    __tablename__ = "influencers"
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    platform = Column(String)
    followers_count = Column(Integer)
    engagement_rate = Column(Float)
    sentiment_impact = Column(Float)
    last_updated = Column(DateTime, default=datetime.utcnow)
````

````python
import json
import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class MCPMessageType(Enum):
    REQUEST = "request"
    RESPONSE = "response"
    NOTIFICATION = "notification"

@dataclass
class MCPMessage:
    jsonrpc: str = "2.0"
    method: Optional[str] = None
    params: Optional[Dict[str, Any]] = None
    id: Optional[str] = None
    result: Optional[Any] = None
    error: Optional[Dict[str, Any]] = None

class MCPServer:
    def __init__(self):
        self.tools = {}
        self.resources = {}
        
    def register_tool(self, name: str, func, description: str, parameters: Dict):
        """Registrace nástroje pro MCP"""
        self.tools[name] = {
            "function": func,
            "description": description,
            "parameters": parameters
        }
    
    def register_resource(self, name: str, handler, description: str):
        """Registrace zdroje dat pro MCP"""
        self.resources[name] = {
            "handler": handler,
            "description": description
        }
    
    async def handle_request(self, message: MCPMessage) -> MCPMessage:
        """Zpracování MCP požadavku"""
        try:
            if message.method == "tools/list":
                return MCPMessage(
                    id=message.id,
                    result={"tools": list(self.tools.keys())}
                )
            
            elif message.method == "tools/call":
                tool_name = message.params.get("name")
                arguments = message.params.get("arguments", {})
                
                if tool_name in self.tools:
                    result = await self.tools[tool_name]["function"](**arguments)
                    return MCPMessage(
                        id=message.id,
                        result={"content": result}
                    )
                else:
                    return MCPMessage(
                        id=message.id,
                        error={"code": -32601, "message": f"Tool {tool_name} not found"}
                    )
            
            elif message.method == "resources/list":
                return MCPMessage(
                    id=message.id,
                    result={"resources": list(self.resources.keys())}
                )
            
            else:
                return MCPMessage(
                    id=message.id,
                    error={"code": -32601, "message": "Method not found"}
                )
                
        except Exception as e:
            return MCPMessage(
                id=message.id,
                error={"code": -32603, "message": str(e)}
            )
````

````python
import tweepy
from instagrapi import Client
import asyncio
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any
from src.config import CONFIG
from src.models import SocialMediaPost

class TwitterCollector:
    def __init__(self):
        self.client = tweepy.Client(bearer_token=CONFIG.TWITTER_BEARER_TOKEN)
    
    async def collect_mentions(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """Sběr zmínek z Twitteru"""
        query = " OR ".join([f'"{keyword}"' for keyword in keywords])
        query += " -is:retweet lang:cs"
        
        try:
            tweets = self.client.search_recent_tweets(
                query=query,
                max_results=limit,
                tweet_fields=['created_at', 'author_id', 'public_metrics', 'context_annotations']
            )
            
            posts = []
            if tweets.data:
                for tweet in tweets.data:
                    post_data = {
                        'platform': 'twitter',
                        'post_id': str(tweet.id),
                        'content': tweet.text,
                        'author': str(tweet.author_id),
                        'created_at': tweet.created_at,
                        'author_followers': tweet.public_metrics.get('retweet_count', 0),
                        'keywords_matched': json.dumps(keywords)
                    }
                    posts.append(post_data)
            
            return posts
            
        except Exception as e:
            print(f"Chyba při sběru dat z Twitteru: {e}")
            return []

class InstagramCollector:
    def __init__(self):
        self.client = Client()
        try:
            self.client.login(CONFIG.INSTAGRAM_USERNAME, CONFIG.INSTAGRAM_PASSWORD)
        except Exception as e:
            print(f"Chyba při přihlášení na Instagram: {e}")
    
    async def collect_hashtag_posts(self, hashtags: List[str], limit: int = 50) -> List[Dict]:
        """Sběr příspěvků podle hashtagů"""
        posts = []
        
        for hashtag in hashtags:
            try:
                medias = self.client.hashtag_medias_recent(hashtag, amount=limit)
                
                for media in medias:
                    post_data = {
                        'platform': 'instagram',
                        'post_id': str(media.id),
                        'content': media.caption_text or "",
                        'author': media.user.username,
                        'created_at': media.taken_at,
                        'author_followers': media.user.follower_count or 0,
                        'keywords_matched': json.dumps([hashtag])
                    }
                    posts.append(post_data)
                    
            except Exception as e:
                print(f"Chyba při sběru dat z Instagramu pro #{hashtag}: {e}")
        
        return posts
````

````python
import openai
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import numpy as np
from typing import Dict, List, Tuple
from src.config import CONFIG

class AdvancedSentimentAnalyzer:
    def __init__(self):
        openai.api_key = CONFIG.OPENAI_API_KEY
        self.llm = OpenAI(temperature=0.3)
        self.vader = SentimentIntensityAnalyzer()
        self.setup_llm_chain()
    
    def setup_llm_chain(self):
        """Nastavení LangChain pro pokročilou analýzu sentimentu"""
        template = """
        Analyzuj sentiment následujícího textu z českých sociálních médií:
        
        Text: {text}
        
        Poskytni:
        1. Sentiment score (-1 až 1): 
        2. Sentiment label (pozitivní/negativní/neutrální):
        3. Klíčové emoce:
        4. Důvěra v analýzu (0-1):
        5. Kontext a důvod hodnocení:
        
        Odpověď ve formátu JSON:
        """
        
        self.prompt = PromptTemplate(
            input_variables=["text"],
            template=template
        )
        
        self.sentiment_chain = LLMChain(
            llm=self.llm,
            prompt=self.prompt
        )
    
    async def analyze_sentiment(self, text: str) -> Dict:
        """Kombinovaná analýza sentimentu"""
        # TextBlob analýza
        blob = TextBlob(text)
        textblob_score = blob.sentiment.polarity
        
        # VADER analýza
        vader_scores = self.vader.polarity_scores(text)
        vader_score = vader_scores['compound']
        
        # LLM analýza
        try:
            llm_result = await self.sentiment_chain.arun(text=text)
            # Parsování JSON odpovědi z LLM
            import json
            try:
                llm_analysis = json.loads(llm_result)
                llm_score = float(llm_analysis.get('sentiment_score', 0))
                confidence = float(llm_analysis.get('confidence', 0.5))
            except:
                llm_score = 0
                confidence = 0.3
        except Exception as e:
            print(f"Chyba LLM analýzy: {e}")
            llm_score = 0
            confidence = 0.3
        
        # Kombinace výsledků s váhami
        weights = [0.3, 0.3, 0.4]  # TextBlob, VADER, LLM
        combined_score = np.average([textblob_score, vader_score, llm_score], weights=weights)
        
        # Určení labelu
        if combined_score > CONFIG.SENTIMENT_THRESHOLD_POSITIVE:
            label = "pozitivní"
        elif combined_score < CONFIG.SENTIMENT_THRESHOLD_NEGATIVE:
            label = "negativní"
        else:
            label = "neutrální"
        
        # Crisis alert
        is_crisis = combined_score < CONFIG.CRISIS_ALERT_THRESHOLD
        
        return {
            'sentiment_score': float(combined_score),
            'sentiment_label': label,
            'confidence': confidence,
            'is_crisis_alert': is_crisis,
            'individual_scores': {
                'textblob': textblob_score,
                'vader': vader_score,
                'llm': llm_score
            }
        }
    
    async def batch_analyze(self, texts: List[str]) -> List[Dict]:
        """Dávková analýza textů"""
        results = []
        for text in texts:
            result = await self.analyze_sentiment(text)
            results.append(result)
        return results
````

````python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class TrendAnalyzer:
    def __init__(self):
        self.scaler = StandardScaler()
    
    def analyze_sentiment_trends(self, data: pd.DataFrame, period: str = 'daily') -> Dict:
        """Analýza trendů sentimentu v čase"""
        # Převod dat na časové řady
        data['created_at'] = pd.to_datetime(data['created_at'])
        data.set_index('created_at', inplace=True)
        
        # Agregace podle období
        if period == 'hourly':
            resampled = data.resample('H')
        elif period == 'daily':
            resampled = data.resample('D')
        else:
            resampled = data.resample('W')
        
        trend_data = resampled.agg({
            'sentiment_score': ['mean', 'std', 'count'],
            'is_crisis_alert': 'sum'
        }).round(3)
        
        # Výpočet trendů
        sentiment_values = trend_data['sentiment_score']['mean'].values
        trend_direction = self._calculate_trend_direction(sentiment_values)
        volatility = np.std(sentiment_values)
        
        # Detekce anomálií
        anomalies = self._detect_anomalies(sentiment_values)
        
        return {
            'trend_direction': trend_direction,
            'volatility': volatility,
            'anomalies': anomalies,
            'data': trend_data.to_dict(),
            'summary': {
                'avg_sentiment': np.mean(sentiment_values),
                'min_sentiment': np.min(sentiment_values),
                'max_sentiment': np.max(sentiment_values),
                'total_posts': int(trend_data['sentiment_score']['count'].sum())
            }
        }
    
    def _calculate_trend_direction(self, values: np.ndarray) -> str:
        """Výpočet směru trendu"""
        if len(values) < 3:
            return "nedostatek_dat"
        
        # Lineární regrese pro trend
        x = np.arange(len(values))
        coeffs = np.polyfit(x, values, 1)
        slope = coeffs[0]
        
        if slope > 0.01:
            return "rostoucí"
        elif slope < -0.01:
            return "klesající"
        else:
            return "stabilní"
    
    def _detect_anomalies(self, values: np.ndarray) -> List[int]:
        """Detekce anomálií v datech"""
        if len(values) < 5:
            return []
        
        # Z-score metoda
        z_scores = np.abs((values - np.mean(values)) / np.std(values))
        anomaly_threshold = 2.5
        
        return [i for i, z in enumerate(z_scores) if z > anomaly_threshold]
    
    def identify_viral_content(self, data: pd.DataFrame, threshold_percentile: int = 95) -> pd.DataFrame:
        """Identifikace virálního obsahu"""
        # Výpočet engagement score
        data['engagement_score'] = (
            data['author_followers'] * 
            abs(data['sentiment_score']) * 
            (1 if data['sentiment_label'] != 'neutrální' else 0.5)
        )
        
        # Top percentil
        threshold = np.percentile(data['engagement_score'], threshold_percentile)
        viral_content = data[data['engagement_score'] >= threshold]
        
        return viral_content.sort_values('engagement_score', ascending=False)
    
    def generate_insights_report(self, trend_data: Dict, viral_content: pd.DataFrame) -> Dict:
        """Generování přehledu insights"""
        insights = {
            'sentiment_summary': {
                'overall_trend': trend_data['trend_direction'],
                'volatility_level': 'vysoká' if trend_data['volatility'] > 0.3 else 'střední' if trend_data['volatility'] > 0.1 else 'nízká',
                'crisis_alerts': trend_data['summary'].get('crisis_count', 0)
            },
            'viral_content_summary': {
                'count': len(viral_content),
                'avg_sentiment': viral_content['sentiment_score'].mean() if len(viral_content) > 0 else 0,
                'top_authors': viral_content['author'].value_counts().head(3).to_dict() if len(viral_content) > 0 else {}
            },
            'recommendations': self._generate_recommendations(trend_data, viral_content)
        }
        
        return insights
    
    def _generate_recommendations(self, trend_data: Dict, viral_content: pd.DataFrame) -> List[str]:
        """Generování doporučení na základě analýzy"""
        recommendations = []
        
        # Trend-based recommendations
        if trend_data['trend_direction'] == 'klesající':
            recommendations.append("Zvážit PR kampaň pro zlepšení image značky")
        elif trend_data['trend_direction'] == 'rostoucí':
            recommendations.append("Využít pozitivní momentum pro marketingové aktivity")
        
        # Volatility-based recommendations
        if trend_data['volatility'] > 0.3:
            recommendations.append("Implementovat častější monitoring kvůli vysoké volatilitě")
        
        # Viral content recommendations
        if len(viral_content) > 0:
            positive_viral = viral_content[viral_content['sentiment_score'] > 0]
            if len(positive_viral) > 0:
                recommendations.append("Engage s pozitivním virálním obsahem")
        
        return recommendations
````

````python
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
import json
from enum import Enum

class AlertLevel(Enum):
    LOW = "nízká"
    MEDIUM = "střední"
    HIGH = "vysoká"
    CRITICAL = "kritická"

@dataclass
class CrisisAlert:
    id: str
    level: AlertLevel
    message: str
    timestamp: datetime
    affected_posts: List[str]
    recommended_actions: List[str]
    auto_resolved: bool = False

class CrisisManager:
    def __init__(self):
        self.active_alerts = {}
        self.alert_history = []
        self.escalation_rules = self._setup_escalation_rules()
    
    def _setup_escalation_rules(self) -> Dict:
        """Nastavení pravidel eskalace"""
        return {
            'sentiment_threshold': -0.7,
            'volume_multiplier': 3.0,  # násobek normálního objemu
            'time_window_minutes': 30,
            'min_posts_for_alert': 5,
            'influencer_threshold': 10000  # followers
        }
    
    async def evaluate_crisis_potential(self, recent_posts: List[Dict]) -> Optional[CrisisAlert]:
        """Vyhodnocení potenciálu krize"""
        if len(recent_posts) < self.escalation_rules['min_posts_for_alert']:
            return None
        
        # Analýza sentimentu
        negative_posts = [p for p in recent_posts if p['sentiment_score'] < self.escalation_rules['sentiment_threshold']]
        negative_ratio = len(negative_posts) / len(recent_posts)
        
        # Analýza objemu
        current_volume = len(recent_posts)
        historical_avg = await self._get_historical_average_volume()
        volume_ratio = current_volume / historical_avg if historical_avg > 0 else 1
        
        # Analýza vlivu autorů
        high_influence_posts = [p for p in recent_posts if p['author_followers'] > self.escalation_rules['influencer_threshold']]
        
        # Určení úrovně alertu
        alert_level = self._calculate_alert_level(negative_ratio, volume_ratio, len(high_influence_posts))
        
        if alert_level != AlertLevel.LOW:
            alert = CrisisAlert(
                id=f"crisis_{datetime.now().isoformat()}",
                level=alert_level,
                message=self._generate_alert_message(negative_ratio, volume_ratio, len(high_influence_posts)),
                timestamp=datetime.now(),
                affected_posts=[p['post_id'] for p in negative_posts],
                recommended_actions=self._generate_recommended_actions(alert_level)
            )
            
            self.active_alerts[alert.id] = alert
            self.alert_history.append(alert)
            
            return alert
        
        return None
    
    def _calculate_alert_level(self, negative_ratio: float, volume_ratio: float, influencer_count: int) -> AlertLevel:
        """Výpočet úrovně alertu"""
        score = 0
        
        # Sentiment score
        if negative_ratio > 0.7:
            score += 3
        elif negative_ratio > 0.5:
            score += 2
        elif negative_ratio > 0.3:
            score += 1
        
        # Volume score
        if volume_ratio > 5:
            score += 3
        elif volume_ratio > 3:
            score += 2
        elif volume_ratio > 2:
            score += 1
        
        # Influencer score
        if influencer_count > 3:
            score += 2
        elif influencer_count > 1:
            score += 1
        
        if score >= 6:
            return AlertLevel.CRITICAL
        elif score >= 4:
            return AlertLevel.HIGH
        elif score >= 2:
            return AlertLevel.MEDIUM
        else:
            return AlertLevel.LOW
    
    def _generate_alert_message(self, negative_ratio: float, volume_ratio: float, influencer_count: int) -> str:
        """Generování zprávy alertu"""
        message_parts = []
        
        message_parts.append(f"Detekována možná krize:")
        message_parts.append(f"• {negative_ratio:.1%} negativních příspěvků")
        message_parts.append(f"• {volume_ratio:.1f}x vyšší objem než obvykle")
        
        if influencer_count > 0:
            message_parts.append(f"• {influencer_count} příspěvků od influencerů")
        
        return "\n".join(message_parts)
    
    def _generate_recommended_actions(self, level: AlertLevel) -> List[str]:
        """Generování doporučených akcí"""
        actions = {
            AlertLevel.MEDIUM: [
                "Zvýšit frekvenci monitoringu",
                "Připravit standardní odpověď",
                "Informovat PR tým"
            ],
            AlertLevel.HIGH: [
                "Aktivovat krizový tým",
                "Připravit oficiální prohlášení",
                "Kontaktovat klíčové stakeholdery",
                "Zvážit pozastavení plánovaných kampaní"
            ],
            AlertLevel.CRITICAL: [
                "Okamžitě svolat krizový štáb",
                "Aktivovat krizový komunikační plán",
                "Kontaktovat vedení společnosti",
                "Připravit se na mediální dotazy",
                "Pozastavit všechny marketingové aktivity"
            ]
        }
        
        return actions.get(level, [])
    
    async def _get_historical_average_volume(self) -> float:
        """Získání historického průměru objemu příspěvků"""
        # V reálné implementaci by se získalo z databáze
        return 50.0  # Mock hodnota
    
    def get_active_alerts(self) -> List[CrisisAlert]:
        """Získání aktivních alertů"""
        return list(self.active_alerts.values())
    
    def resolve_alert(self, alert_id: str, auto_resolved: bool = False) -> bool:
        """Vyřešení alertu"""
        if alert_id in self.active_alerts:
            self.active_alerts[alert_id].auto_resolved = auto_resolved
            del self.active_alerts[alert_id]
            return True
        return False
````

````python
import asyncio
from datetime import datetime, timedelta
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.config import CONFIG
from src.models import Base, SocialMediaPost
from src.mcp_protocol import MCPServer
from src.social_media_collector import TwitterCollector, InstagramCollector
from src.sentiment_analyzer import AdvancedSentimentAnalyzer
from src.trend_analyzer import TrendAnalyzer
from src.crisis_manager import CrisisManager

class SocialMediaSentimentAnalyzer:
    def __init__(self):
        # Database setup
        self.engine = create_engine(CONFIG.DATABASE_URL)
        Base.metadata.create_all(bind=self.engine)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        self.db = SessionLocal()
        
        # Components
        self.twitter_collector = TwitterCollector()
        self.instagram_collector = InstagramCollector()
        self.sentiment_analyzer = AdvancedSentimentAnalyzer()
        self.trend_analyzer = TrendAnalyzer()
        self.crisis_manager = CrisisManager()
        
        # MCP Server
        self.mcp_server = MCPServer()
        self._register_mcp_tools()
    
    def _register_mcp_tools(self):
        """Registrace MCP nástrojů"""
        self.mcp_server.register_tool(
            "analyze_brand_sentiment",
            self.analyze_brand_sentiment,
            "Analyzuje sentiment značky na sociálních médiích",
            {
                "type": "object",
                "properties": {
                    "keywords": {"type": "array", "items": {"type": "string"}},
                    "platforms": {"type": "array", "items": {"type": "string"}},
                    "hours_back": {"type": "integer", "default": 24}
                }
            }
        )
        
        self.mcp_server.register_tool(
            "get_crisis_alerts",
            self.get_crisis_alerts,
            "Získá aktuální krizové alerty",
            {"type": "object", "properties": {}}
        )
        
        self.mcp_server.register_tool(
            "generate_sentiment_report",
            self.generate_sentiment_report,
            "Vygeneruje komplexní sentiment report",
            {
                "type": "object",
                "properties": {
                    "period": {"type": "string", "enum": ["daily", "weekly", "monthly"]},
                    "include_trends": {"type": "boolean", "default": True}
                }
            }
        )
    
    async def collect_and_analyze(self, keywords: List[str], platforms: List[str] = ["twitter", "instagram"]):
        """Hlavní metoda pro sběr a analýzu dat"""
        all_posts = []
        
        # Sběr dat z platforem
        if "twitter" in platforms:
            twitter_posts = await self.twitter_collector.collect_mentions(keywords)
            all_posts.extend(twitter_posts)
        
        if "instagram" in platforms:
            instagram_posts = await self.instagram_collector.collect_hashtag_posts(keywords)
            all_posts.extend(instagram_posts)
        
        # Analýza sentimentu
        for post_data in all_posts:
            sentiment_result = await self.sentiment_analyzer.analyze_sentiment(post_data['content'])
            post_data.update(sentiment_result)
            
            # Uložení do databáze
            post = SocialMediaPost(**post_data)
            self.db.add(post)
        
        self.db.commit()
        
        # Kontrola krizí
        recent_posts = [p for p in all_posts if isinstance(p.get('created_at'), datetime) and 
                       p['created_at'] > datetime.now() - timedelta(hours=1)]
        
        crisis_alert = await self.crisis_manager.evaluate_crisis_potential(recent_posts)
        
        return {
            "collected_posts": len(all_posts),
            "crisis_alert": crisis_alert.message if crisis_alert else None,
            "summary": self._generate_collection_summary(all_posts)
        }
    
    async def analyze_brand_sentiment(self, keywords: List[str], platforms: List[str] = ["twitter", "instagram"], hours_back: int = 24):
        """MCP tool: Analýza sentimentu značky"""
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        
        # Získání dat z databáze
        posts_query = self.db.query(SocialMediaPost).filter(
            SocialMediaPost.processed_at >= cutoff_time
        )
        
        if platforms:
            posts_query = posts_query.filter(SocialMediaPost.platform.in_(platforms))
        
        posts = posts_query.all()
        
        if not posts:
            return {"error": "Žádná data nebyla nalezena pro zadané parametry"}
        
        # Analýza
        df = pd.DataFrame([{
            'platform': p.platform,
            'sentiment_score': p.sentiment_score,
            'sentiment_label': p.sentiment_label,
            'created_at': p.created_at,
            'author_followers': p.author_followers,
            'is_crisis_alert': p.is_crisis_alert
        } for p in posts])
        
        analysis_result = {
            "total_posts": len(posts),
            "average_sentiment": df['sentiment_score'].mean(),
            "sentiment_distribution": df['sentiment_label'].value_counts().to_dict(),
            "platform_breakdown": df.groupby('platform')['sentiment_score'].mean().to_dict(),
            "crisis_posts": df['is_crisis_alert'].sum(),
            "timeframe": f"Posledních {hours_back} hodin"
        }
        
        return analysis_result
    
    async def get_crisis_alerts(self):
        """MCP tool: Získání krizových alertů"""
        active_alerts = self.crisis_manager.get_active_alerts()
        
        return {
            "active_alerts_count": len(active_alerts),
            "alerts": [
                {
                    "id": alert.id,
                    "level": alert.level.value,
                    "message": alert.message,
                    "timestamp": alert.timestamp.isoformat(),
                    "affected_posts_count": len(alert.affected_posts),
                    "recommended_actions": alert.recommended_actions
                }
                for alert in active_alerts
            ]
        }
    
    async def generate_sentiment_report(self, period: str = "daily", include_trends: bool = True):
        """MCP tool: Generování sentiment reportu"""
        # Získání dat podle období
        if period == "daily":
            cutoff_time = datetime.now() - timedelta(days=1)
        elif period == "weekly":
            cutoff_time = datetime.now() - timedelta(weeks=1)
        else:  # monthly
            cutoff_time = datetime.now() - timedelta(days=30)
        
        posts = self.db.query(SocialMediaPost).filter(
            SocialMediaPost.processed_at >= cutoff_time
        ).all()
        
        if not posts:
            return {"error": "Žádná data pro reporting"}
        
        df = pd.DataFrame([{
            'platform': p.platform,
            'sentiment_score': p.sentiment_score,
            'sentiment_label': p.sentiment_label,
            'created_at': p.created_at,
            'author_followers': p.author_followers,
            'is_crisis_alert': p.is_crisis_alert
        } for p in posts])
        
        report = {
            "period": period,
            "total_posts": len(posts),
            "sentiment_summary": {
                "average_score": df['sentiment_score'].mean(),
                "median_score": df['sentiment_score'].median(),
                "distribution": df['sentiment_label'].value_counts().to_dict()
            },
            "platform_analysis": df.groupby('platform').agg({
                'sentiment_score': ['mean', 'count'],
                'is_crisis_alert': 'sum'
            }).to_dict(),
            "crisis_summary": {
                "total_alerts": df['is_crisis_alert'].sum(),
                "crisis_rate": df['is_crisis_alert'].mean()
            }
        }
        
        if include_trends:
            trend_analysis = self.trend_analyzer.analyze_sentiment_trends(df.copy(), period='daily')
            report["trends"] = trend_analysis
        
        return report
    
    def _generate_collection_summary(self, posts: List[Dict]) -> Dict:
        """Generování souhrnu sběru dat"""
        if not posts:
            return {"message": "Žádné příspěvky nebyly shromážděny"}
        
        sentiments = [p.get('sentiment_score', 0) for p in posts]
        platforms = [p.get('platform', 'unknown') for p in posts]
        
        return {
            "total_posts": len(posts),
            "average_sentiment": sum(sentiments) / len(sentiments) if sentiments else 0,
            "platforms": list(set(platforms)),
            "crisis_posts": sum(1 for p in posts if p.get('is_crisis_alert', False))
        }

# Hlavní spouštěcí funkce
async def main():
    analyzer = SocialMediaSentimentAnalyzer()
    
    # Příklad použití
    keywords = ["vaše_značka", "#váš_hashtag", "@váš_account"]
    
    print("Spouštím analýzu sentimentu sociálních médií...")
    result = await analyzer.collect_and_analyze(keywords)
    print(f"Výsledek: {result}")
    
    # Generování reportu
    report = await analyzer.generate_sentiment_report(period="daily")
    print(f"Denní report: {report}")

if __name__ == "__main__":
    asyncio.run(main())
````

````python
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta
import asyncio
from src.main_analyzer import SocialMediaSentimentAnalyzer

class SentimentDashboard:
    def __init__(self):
        self.analyzer = SocialMediaSentimentAnalyzer()
    
    def run_dashboard(self):
        """Spuštění Streamlit dashboardu"""
        st.set_page_config(
            page_title="Analyzátor sentimentu sociálních médií",
            page_icon="📊",
            layout="wide"
        )
        
        st.title("🔍 AI-LLM MCP: Analyzátor sentimentu sociálních médií")
        
        # Sidebar
        st.sidebar.header("Nastavení")
        keywords = st.sidebar.text_input(
            "Klíčová slova (oddělená čárkou)",
            value="vaše_značka, #váš_hashtag"
        ).split(",")
        keywords = [k.strip() for k in keywords if k.strip()]
        
        platforms = st.sidebar.multiselect(
            "Platformy",
            ["twitter", "instagram"],
            default=["twitter", "instagram"]
        )
        
        period = st.sidebar.selectbox(
            "Období analýzy",
            ["daily", "weekly", "monthly"],
            index=0
        )
        
        # Hlavní obsah
        col1, col2, col3, col4 = st.columns(4)
        
        # Získání dat
        if st.sidebar.button("Spustit analýzu"):
            with st.spinner("Probíhá analýza..."):
                try:
                    # Async volání
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    result = loop.run_until_complete(
                        self.analyzer.analyze_brand_sentiment(keywords, platforms, 24)
                    )
                    loop.close()
                    
                    if "error" not in result:
                        self._display_metrics(result, col1, col2, col3, col4)
                        self._display_charts(result)
                        self._display_crisis_alerts()
                    else:
                        st.error(result["error"])
                        
                except Exception as e:
                    st.error(f"Chyba při analýze: {str(e)}")
    
    def _display_metrics(self, result, col1, col2, col3, col4):
        """Zobrazení klíčových metrik"""
        with col1:
            st.metric(
                "Celkem příspěvků",
                result["total_posts"]
            )
        
        with col2:
            sentiment_score = result["average_sentiment"]
            sentiment_color = "normal"
            if sentiment_score > 0.2:
                sentiment_color = "inverse"
            elif sentiment_score < -0.2:
                sentiment_color = "off"
            
            st.metric(
                "Průměrný sentiment",
                f"{sentiment_score:.2f}",
                delta=None
            )
        
        with col3:
            st.metric(
                "Krizové příspěvky",
                result["crisis_posts"]
            )
        
        with col4:
            positive_ratio = result["sentiment_distribution"].get("pozitivní", 0) / result["total_posts"] * 100
            st.metric(
                "% pozitivních",
                f"{positive_ratio:.1f}%"
            )
    
    def _display_charts(self, result):
        """Zobrazení grafů"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distribuce sentimentu")
            sentiment_dist = result["sentiment_distribution"]
            
            fig_pie = go.Figure(data=[go.Pie(
                labels=list(sentiment_dist.keys()),
                values=list(sentiment_dist.values()),
                hole=0.3
            )])
            fig_pie.update_layout(height=400)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            st.subheader("Sentiment podle platforem")
            platform_data = result["platform_breakdown"]
            
            fig_bar = go.Figure(data=[go.Bar(
                x=list(platform_data.keys()),
                y=list(platform_data.values()),
                marker_color=['#ff6b6b' if v < 0 else '#51cf66' for v in platform_data.values()]
            )])
            fig_bar.update_layout(
                height=400,
                yaxis_title="Průměrný sentiment",
                xaxis_title="Platforma"
            )
            st.plotly_chart(fig_bar, use_container_width=True)
    
    def _display_crisis_alerts(self):
        """Zobrazení krizových alertů"""
        st.subheader("🚨 Krizové alerty")
        
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            alerts_result = loop.run_until_complete(
                self.analyzer.get_crisis_alerts()
            )
            loop.close()
            
            if alerts_result["active_alerts_count"] > 0:
                for alert in alerts_result["alerts"]:
                    level_color = {
                        "nízká": "🟢",
                        "střední": "🟡", 
                        "vysoká": "🟠",
                        "kritická": "🔴"
                    }.get(alert["level"], "⚪")
                    
                    with st.expander(f"{level_color} Alert ID: {alert['id']} - {alert['level']}"):
                        st.write(f"**Zpráva:** {alert['message']}")
                        st.write(f"**Čas:** {alert['timestamp']}")
                        st.write(f"**Dotčené příspěvky:** {alert['affected_posts_count']}")
                        st.write("**Doporučené akce:**")
                        for action in alert["recommended_actions"]:
                            st.write(f"• {action}")
            else:
                st.success("✅ Žádné aktivní krizové alerty")
                
        except Exception as e:
            st.error(f"Chyba při načítání alertů: {str(e)}")

if __name__ == "__main__":
    dashboard = SentimentDashboard()
    dashboard.run_dashboard()
````

## Shrnutí projektu

**Analyzátor sentimentu sociálních médií** s Model Context Protocol představuje komplexní řešení pro moderní brand management a crisis communication. Projekt kombinuje pokročilé AI technologie s praktickými business potřebami.

### Klíčové přínosy:
- **Proaktivní monitoring**: Kontinuální sledování online pověsti značky
- **Inteligentní analýza**: Kombinace multiple AI modelů pro přesnou analýzu sentimentu
- **Real-time alerting**: Okamžité upozornění na potenciální krize
- **Actionable insights**: Konkrétní doporučení pro marketingové týmy

### Technické přednosti:
- **MCP architektura**: Modulární a rozšiřitelná struktura
- **Multi-platform support**: Twitter, Instagram s možností rozšíření
- **Scalable design**: Připraveno pro high-volume data processing
- **Modern stack**: LangChain, OpenAI, Streamlit pro uživatelsky přívětivé rozhraní

### Business hodnota:
Systém umožňuje společnostem přejít od reaktivního k proaktivnímu přístupu v online komunikaci, což může významně snížit rizika poškození pověsti a zvýšit efektivitu marketingových investic.