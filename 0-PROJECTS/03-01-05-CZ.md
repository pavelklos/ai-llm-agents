<small>Claude Sonnet 4 **(Asistent pro Dokumentaci K칩du a 콎e코en칤 Chyb)**</small>
# Code Documentation and Bug Resolution Assistant

## Kl칤캜ov칠 Koncepty

### RAG (Retrieval-Augmented Generation)
Technika kombinuj칤c칤 vyhled치v치n칤 relevantn칤ch informac칤 z datab치ze znalost칤 s generativn칤mi schopnostmi velk칳ch jazykov칳ch model콢 pro p콏esn캩j코칤 a kontextov캩 spr치vn칠 odpov캩di.

### GitHub Integration
Integrace s GitHub API pro p콏칤stup k reposit치콏콢m, pull request콢m, issues a k칩du za 칰캜elem automatizovan칠 anal칳zy a dokumentace.

### Stack Overflow
Platforma ot치zek a odpov캩d칤 pro program치tory, kter치 slou쮂 jako zdroj znalost칤 pro 콏e코en칤 b캩쬹칳ch program치torsk칳ch probl칠m콢.

### Technical Documentation
Strukturovan치 dokumentace k칩du, API a architektonick칳ch rozhodnut칤 pro lep코칤 porozum캩n칤 a 칰dr쬭u softwarov칳ch projekt콢.

### Code Embeddings
Vektorov칠 reprezentace k칩du umo쮄갓j칤c칤 s칠mantick칠 vyhled치v치n칤 a porovn치v치n칤 k칩dov칳ch fragment콢.

### Weaviate
Vektorov치 datab치ze s vestav캩n칳mi ML mo쬹ostmi pro ukl치d치n칤 a vyhled치v치n칤 embeddings dokument콢 a k칩du.

### GitHub Copilot API
API pro integraci AI-powered asistenta pro psan칤 k칩du a automatick칠 dokon캜ov치n칤.

## Komplexn칤 Vysv캩tlen칤 Projektu

### C칤le Projektu
Vytvo콏it inteligentn칤ho asistenta, kter칳 pom치h치 v칳voj치콏콢m s:
- Automatickou dokumentac칤 k칩du
- Identifikac칤 a 콏e코en칤m chyb
- Vyhled치v치n칤m podobn칳ch probl칠m콢 na Stack Overflow
- Generov치n칤m kontextov캩 relevantn칤ch n치vrh콢

### V칳zvy
- **Kontextov칠 porozum캩n칤**: Pochopen칤 komplexn칤ho k칩du a jeho architektury
- **Relevance v칳sledk콢**: Filtrov치n칤 a hodnocen칤 vyhledan칳ch informac칤
- **Integrace zdroj콢**: Kombinov치n칤 informac칤 z r콢zn칳ch zdroj콢 (GitHub, Stack Overflow, dokumentace)
- **맒치lovatelnost**: Efektivn칤 zpracov치n칤 velk칳ch k칩dov칳ch b치zi

### Potenci치ln칤 Dopad
- Zrychlen칤 v칳voje software
- Zlep코en칤 kvality dokumentace
- Sn칤쬰n칤 캜asu str치ven칠ho debugging
- Sd칤len칤 znalost칤 v t칳mu

## Komplexn칤 Implementace

````python
langchain==0.1.0
weaviate-client==3.25.0
openai==1.3.0
github3.py==4.0.1
requests==2.31.0
python-dotenv==1.0.0
tiktoken==0.5.0
numpy==1.24.0
pandas==2.0.0
streamlit==1.28.0
````

````python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
    WEAVIATE_URL = os.getenv("WEAVIATE_URL", "http://localhost:8080")
    STACK_OVERFLOW_API_KEY = os.getenv("STACK_OVERFLOW_API_KEY")
    
    # Embedding nastaven칤
    EMBEDDING_MODEL = "text-embedding-ada-002"
    EMBEDDING_DIMENSION = 1536
    
    # GitHub nastaven칤
    MAX_FILE_SIZE = 100000  # bytes
    SUPPORTED_EXTENSIONS = ['.py', '.js', '.java', '.cpp', '.c', '.go', '.rs']
````

````python
import requests
import github3
from typing import List, Dict, Optional
import time

class GitHubDataSource:
    def __init__(self, token: str):
        self.github = github3.login(token=token)
    
    def extract_repository_files(self, repo_name: str, owner: str) -> List[Dict]:
        """Extrakce soubor콢 z GitHub reposit치콏e"""
        try:
            repo = self.github.repository(owner, repo_name)
            files = []
            
            def traverse_tree(tree, path=""):
                for item in tree.tree:
                    if item.type == "blob" and any(item.path.endswith(ext) for ext in Config.SUPPORTED_EXTENSIONS):
                        if item.size < Config.MAX_FILE_SIZE:
                            content = repo.file_contents(f"{path}/{item.path}" if path else item.path)
                            files.append({
                                'path': f"{path}/{item.path}" if path else item.path,
                                'content': content.decoded.decode('utf-8'),
                                'size': item.size,
                                'sha': item.sha
                            })
                    elif item.type == "tree":
                        traverse_tree(item, f"{path}/{item.path}" if path else item.path)
            
            traverse_tree(repo.tree())
            return files
            
        except Exception as e:
            print(f"Chyba p콏i extrakci z GitHub: {e}")
            return []

class StackOverflowDataSource:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.base_url = "https://api.stackexchange.com/2.3"
    
    def search_questions(self, tags: List[str], query: str, max_results: int = 50) -> List[Dict]:
        """Vyhled치n칤 ot치zek na Stack Overflow"""
        try:
            url = f"{self.base_url}/search/advanced"
            params = {
                'order': 'desc',
                'sort': 'relevance',
                'q': query,
                'tagged': ';'.join(tags),
                'site': 'stackoverflow',
                'pagesize': max_results,
                'filter': 'withbody'
            }
            
            if self.api_key:
                params['key'] = self.api_key
            
            response = requests.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            return data.get('items', [])
            
        except Exception as e:
            print(f"Chyba p콏i vyhled치v치n칤 na Stack Overflow: {e}")
            return []
    
    def get_answers(self, question_id: int) -> List[Dict]:
        """Z칤sk치n칤 odpov캩d칤 na ot치zku"""
        try:
            url = f"{self.base_url}/questions/{question_id}/answers"
            params = {
                'order': 'desc',
                'sort': 'votes',
                'site': 'stackoverflow',
                'filter': 'withbody'
            }
            
            if self.api_key:
                params['key'] = self.api_key
            
            response = requests.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            return data.get('items', [])
            
        except Exception as e:
            print(f"Chyba p콏i z칤sk치v치n칤 odpov캩d칤: {e}")
            return []
````

````python
import weaviate
from typing import List, Dict, Optional
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np

class WeaviateVectorStore:
    def __init__(self, url: str, openai_api_key: str):
        self.client = weaviate.Client(url)
        openai.api_key = openai_api_key
        self.setup_schema()
    
    def setup_schema(self):
        """Nastaven칤 sch칠matu pro Weaviate"""
        schema = {
            "classes": [
                {
                    "class": "CodeDocument",
                    "properties": [
                        {"name": "content", "dataType": ["text"]},
                        {"name": "file_path", "dataType": ["string"]},
                        {"name": "repository", "dataType": ["string"]},
                        {"name": "language", "dataType": ["string"]},
                        {"name": "chunk_index", "dataType": ["int"]},
                    ],
                    "vectorizer": "text2vec-openai",
                    "moduleConfig": {
                        "text2vec-openai": {
                            "model": "ada",
                            "modelVersion": "002",
                            "type": "text"
                        }
                    }
                },
                {
                    "class": "StackOverflowPost",
                    "properties": [
                        {"name": "title", "dataType": ["text"]},
                        {"name": "body", "dataType": ["text"]},
                        {"name": "tags", "dataType": ["string[]"]},
                        {"name": "score", "dataType": ["int"]},
                        {"name": "post_type", "dataType": ["string"]},
                        {"name": "question_id", "dataType": ["int"]},
                    ],
                    "vectorizer": "text2vec-openai"
                }
            ]
        }
        
        try:
            self.client.schema.create(schema)
        except Exception as e:
            print(f"Schema ji existuje nebo chyba: {e}")
    
    def add_code_documents(self, files: List[Dict], repository: str):
        """P콏id치n칤 k칩dov칳ch dokument콢 do vektorov칠 datab치ze"""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        for file in files:
            language = self._detect_language(file['path'])
            chunks = text_splitter.split_text(file['content'])
            
            for i, chunk in enumerate(chunks):
                doc_obj = {
                    "content": chunk,
                    "file_path": file['path'],
                    "repository": repository,
                    "language": language,
                    "chunk_index": i
                }
                
                try:
                    self.client.data_object.create(
                        doc_obj,
                        "CodeDocument"
                    )
                except Exception as e:
                    print(f"Chyba p콏i p콏id치v치n칤 dokumentu: {e}")
    
    def add_stackoverflow_posts(self, posts: List[Dict]):
        """P콏id치n칤 Stack Overflow p콏칤sp캩vk콢"""
        for post in posts:
            post_obj = {
                "title": post.get('title', ''),
                "body": post.get('body', ''),
                "tags": post.get('tags', []),
                "score": post.get('score', 0),
                "post_type": "question",
                "question_id": post.get('question_id', 0)
            }
            
            try:
                self.client.data_object.create(
                    post_obj,
                    "StackOverflowPost"
                )
            except Exception as e:
                print(f"Chyba p콏i p콏id치v치n칤 SO p콏칤sp캩vku: {e}")
    
    def search_similar_code(self, query: str, limit: int = 5) -> List[Dict]:
        """Vyhled치n칤 podobn칠ho k칩du"""
        try:
            result = (
                self.client.query
                .get("CodeDocument", ["content", "file_path", "repository", "language"])
                .with_near_text({"concepts": [query]})
                .with_limit(limit)
                .do()
            )
            
            return result.get("data", {}).get("Get", {}).get("CodeDocument", [])
        except Exception as e:
            print(f"Chyba p콏i vyhled치v치n칤 k칩du: {e}")
            return []
    
    def search_stackoverflow_solutions(self, query: str, limit: int = 3) -> List[Dict]:
        """Vyhled치n칤 콏e코en칤 na Stack Overflow"""
        try:
            result = (
                self.client.query
                .get("StackOverflowPost", ["title", "body", "tags", "score"])
                .with_near_text({"concepts": [query]})
                .with_limit(limit)
                .do()
            )
            
            return result.get("data", {}).get("Get", {}).get("StackOverflowPost", [])
        except Exception as e:
            print(f"Chyba p콏i vyhled치v치n칤 SO: {e}")
            return []
    
    def _detect_language(self, file_path: str) -> str:
        """Detekce programovac칤ho jazyka podle p콏칤pony"""
        ext_to_lang = {
            '.py': 'python',
            '.js': 'javascript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.go': 'go',
            '.rs': 'rust'
        }
        
        for ext, lang in ext_to_lang.items():
            if file_path.endswith(ext):
                return lang
        return 'unknown'
````

````python
from typing import List, Dict, Optional
import openai
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import re

class CodeDocumentationAssistant:
    def __init__(self, openai_api_key: str, vector_store):
        openai.api_key = openai_api_key
        self.llm = OpenAI(temperature=0.1)
        self.vector_store = vector_store
        self.setup_prompts()
    
    def setup_prompts(self):
        """Nastaven칤 prompt 코ablon"""
        self.documentation_prompt = PromptTemplate(
            input_variables=["code", "context"],
            template="""
Vytvo콏 komprehensivn칤 dokumentaci pro n치sleduj칤c칤 k칩d.

Kontext z podobn칠ho k칩du:
{context}

K칩d k dokumentaci:
{code}

Zahr켿:
1. Stru캜n칳 popis funkcionality
2. Parametry a jejich v칳znam
3. N치vratov칠 hodnoty
4. P콏칤klady pou쬴t칤
5. Mo쬹칠 v칳jimky

Dokumentace:
"""
        )
        
        self.bug_analysis_prompt = PromptTemplate(
            input_variables=["code", "error", "similar_solutions"],
            template="""
Analyzuj n치sleduj칤c칤 chybu v k칩du a navrhni 콏e코en칤.

K칩d s chybou:
{code}

Chybov치 zpr치va:
{error}

Podobn치 콏e코en칤 ze Stack Overflow:
{similar_solutions}

Poskytni:
1. Identifikaci p콏칤캜iny chyby
2. Navrhovan칠 콏e코en칤
3. Vysv캩tlen칤 pro캜 k chyb캩 do코lo
4. Tipy pro prevenci

Anal칳za:
"""
        )
        
        self.code_review_prompt = PromptTemplate(
            input_variables=["code", "best_practices"],
            template="""
Prove캞 code review n치sleduj칤c칤ho k칩du.

K칩d:
{code}

Referen캜n칤 best practices:
{best_practices}

Zam캩콏 se na:
1. 캛itelnost k칩du
2. Performance
3. Bezpe캜nost
4. Dodr쬺v치n칤 best practices
5. Mo쬹치 vylep코en칤

Code Review:
"""
        )
    
    def generate_documentation(self, code: str, file_path: str) -> str:
        """Generov치n칤 dokumentace pro k칩d"""
        # Vyhled치n칤 podobn칠ho k칩du pro kontext
        similar_code = self.vector_store.search_similar_code(code, limit=3)
        context = "\n".join([item.get('content', '') for item in similar_code])
        
        chain = LLMChain(llm=self.llm, prompt=self.documentation_prompt)
        documentation = chain.run(code=code, context=context)
        
        return documentation
    
    def analyze_bug(self, code: str, error_message: str) -> str:
        """Anal칳za chyby a n치vrh 콏e코en칤"""
        # Extrakce kl칤캜ov칳ch slov z chyby pro vyhled치v치n칤
        keywords = self._extract_error_keywords(error_message)
        query = f"{' '.join(keywords)} {self._detect_language_from_code(code)}"
        
        # Vyhled치n칤 콏e코en칤 na Stack Overflow
        so_solutions = self.vector_store.search_stackoverflow_solutions(query, limit=3)
        solutions_text = "\n".join([
            f"N치zev: {item.get('title', '')}\n콎e코en칤: {item.get('body', '')[:500]}..."
            for item in so_solutions
        ])
        
        chain = LLMChain(llm=self.llm, prompt=self.bug_analysis_prompt)
        analysis = chain.run(
            code=code,
            error=error_message,
            similar_solutions=solutions_text
        )
        
        return analysis
    
    def review_code(self, code: str) -> str:
        """Code review s doporu캜en칤mi"""
        language = self._detect_language_from_code(code)
        
        # Vyhled치n칤 best practices pro dan칳 jazyk
        best_practices_query = f"{language} best practices coding standards"
        practices = self.vector_store.search_similar_code(best_practices_query, limit=5)
        practices_text = "\n".join([item.get('content', '') for item in practices])
        
        chain = LLMChain(llm=self.llm, prompt=self.code_review_prompt)
        review = chain.run(code=code, best_practices=practices_text)
        
        return review
    
    def suggest_improvements(self, code: str) -> Dict[str, str]:
        """N치vrh vylep코en칤 k칩du"""
        documentation = self.generate_documentation(code, "")
        review = self.review_code(code)
        
        # Detekce mo쬹칳ch chyb
        potential_issues = self._detect_potential_issues(code)
        
        return {
            "documentation": documentation,
            "code_review": review,
            "potential_issues": potential_issues,
            "suggested_refactoring": self._suggest_refactoring(code)
        }
    
    def _extract_error_keywords(self, error_message: str) -> List[str]:
        """Extrakce kl칤캜ov칳ch slov z chybov칠 zpr치vy"""
        # Odstran캩n칤 b캩쬹칳ch slov a ponech치n칤 d콢le쬴t칳ch term칤n콢
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        words = re.findall(r'\w+', error_message.lower())
        return [word for word in words if word not in stop_words and len(word) > 2]
    
    def _detect_language_from_code(self, code: str) -> str:
        """Detekce programovac칤ho jazyka z k칩du"""
        patterns = {
            'python': [r'def ', r'import ', r'from .* import', r'print\('],
            'javascript': [r'function ', r'const ', r'let ', r'console\.log'],
            'java': [r'public class', r'public static void main', r'System\.out\.println'],
            'cpp': [r'#include', r'int main\(', r'std::'],
        }
        
        for lang, pattern_list in patterns.items():
            if any(re.search(pattern, code) for pattern in pattern_list):
                return lang
        return 'unknown'
    
    def _detect_potential_issues(self, code: str) -> str:
        """Detekce potenci치ln칤ch probl칠m콢 v k칩du"""
        issues = []
        
        # Kontrola z치kladn칤ch probl칠m콢
        if 'password' in code.lower() and any(op in code for op in ['=', '==']):
            issues.append("Mo쬹칠 hardcoded heslo - bezpe캜nostn칤 riziko")
        
        if re.search(r'except:\s*pass', code):
            issues.append("Pr치zdn칳 except blok - m콢쬰 skr칳vat chyby")
        
        if 'eval(' in code:
            issues.append("Pou쬴t칤 eval() - bezpe캜nostn칤 riziko")
        
        return "\n".join(issues) if issues else "콯치dn칠 z콏ejm칠 probl칠my nenalezeny"
    
    def _suggest_refactoring(self, code: str) -> str:
        """N치vrh refaktoringu"""
        suggestions = []
        
        # Kontrola d칠lky funkc칤
        functions = re.findall(r'def \w+\([^)]*\):[^def]*', code, re.MULTILINE)
        for func in functions:
            if func.count('\n') > 20:
                suggestions.append("Dlouh칠 funkce - zva쬾e rozd캩len칤 na men코칤 캜치sti")
        
        # Kontrola duplicitn칤ho k칩du
        lines = code.split('\n')
        if len(lines) != len(set(lines)):
            suggestions.append("Mo쬹칳 duplicitn칤 k칩d - zva쬾e extrakci do funkc칤")
        
        return "\n".join(suggestions) if suggestions else "K칩d vypad치 dob콏e strukturovan캩"
````

````python
import streamlit as st
from config import Config
from data_sources import GitHubDataSource, StackOverflowDataSource
from vector_store import WeaviateVectorStore
from code_assistant import CodeDocumentationAssistant
import time

def initialize_components():
    """Inicializace v코ech komponent"""
    try:
        # Inicializace vector store
        vector_store = WeaviateVectorStore(Config.WEAVIATE_URL, Config.OPENAI_API_KEY)
        
        # Inicializace data sources
        github_source = GitHubDataSource(Config.GITHUB_TOKEN)
        so_source = StackOverflowDataSource(Config.STACK_OVERFLOW_API_KEY)
        
        # Inicializace asistenta
        assistant = CodeDocumentationAssistant(Config.OPENAI_API_KEY, vector_store)
        
        return vector_store, github_source, so_source, assistant
        
    except Exception as e:
        st.error(f"Chyba p콏i inicializaci: {e}")
        return None, None, None, None

def load_sample_data(vector_store, github_source, so_source):
    """Na캜ten칤 uk치zkov칳ch dat"""
    if st.button("Na캜칤st uk치zkov치 data"):
        with st.spinner("Na캜칤t치n칤 dat z GitHub..."):
            # Na캜ten칤 uk치zkov칠ho reposit치콏e
            files = github_source.extract_repository_files("python", "cpython")
            if files:
                vector_store.add_code_documents(files[:10], "cpython")  # Pouze prvn칤ch 10 soubor콢
                st.success(f"Na캜teno {len(files[:10])} soubor콢 z GitHub")
        
        with st.spinner("Na캜칤t치n칤 dat ze Stack Overflow..."):
            # Na캜ten칤 Stack Overflow ot치zek
            posts = so_source.search_questions(['python'], 'error debugging', 20)
            if posts:
                vector_store.add_stackoverflow_posts(posts)
                st.success(f"Na캜teno {len(posts)} p콏칤sp캩vk콢 ze Stack Overflow")

def main():
    st.title("游뱄 Asistent pro Dokumentaci K칩du a 콎e코en칤 Chyb")
    st.markdown("AI-powered asistent pro automatickou dokumentaci a debugging")
    
    # Inicializace komponent
    vector_store, github_source, so_source, assistant = initialize_components()
    
    if not all([vector_store, github_source, so_source, assistant]):
        st.error("Nepoda콏ilo se inicializovat komponenty. Zkontrolujte konfiguraci.")
        return
    
    # Sidebar pro na캜칤t치n칤 dat
    st.sidebar.header("游늵 Spr치va Dat")
    load_sample_data(vector_store, github_source, so_source)
    
    # Hlavn칤 funkcionalita
    tab1, tab2, tab3, tab4 = st.tabs([
        "游닇 Dokumentace", 
        "游냍 Anal칳za Chyb", 
        "游댌 Code Review", 
        "游눠 Vylep코en칤"
    ])
    
    with tab1:
        st.header("Generov치n칤 Dokumentace")
        code_input = st.text_area(
            "Vlo쬾e k칩d pro dokumentaci:",
            height=200,
            placeholder="def my_function(param1, param2):\n    # V치코 k칩d zde\n    return result"
        )
        
        if st.button("Generovat Dokumentaci") and code_input:
            with st.spinner("Generov치n칤 dokumentace..."):
                documentation = assistant.generate_documentation(code_input, "user_input.py")
                st.markdown("### 游닀 Vygenerovan치 Dokumentace")
                st.markdown(documentation)
    
    with tab2:
        st.header("Anal칳za Chyb a Debugging")
        col1, col2 = st.columns(2)
        
        with col1:
            error_code = st.text_area(
                "K칩d s chybou:",
                height=150,
                placeholder="# Problematick칳 k칩d\nresult = 1/0"
            )
        
        with col2:
            error_message = st.text_area(
                "Chybov치 zpr치va:",
                height=150,
                placeholder="ZeroDivisionError: division by zero"
            )
        
        if st.button("Analyzovat Chybu") and error_code and error_message:
            with st.spinner("Analyzov치n칤 chyby..."):
                analysis = assistant.analyze_bug(error_code, error_message)
                st.markdown("### 游댢 Anal칳za a 콎e코en칤")
                st.markdown(analysis)
    
    with tab3:
        st.header("Code Review")
        review_code = st.text_area(
            "K칩d pro review:",
            height=200,
            placeholder="# V치코 k칩d pro review\nclass MyClass:\n    def __init__(self):\n        pass"
        )
        
        if st.button("Prov칠st Code Review") and review_code:
            with st.spinner("Prov치d캩n칤 code review..."):
                review = assistant.review_code(review_code)
                st.markdown("### 游늵 Code Review")
                st.markdown(review)
    
    with tab4:
        st.header("N치vrhy Vylep코en칤")
        improvement_code = st.text_area(
            "K칩d pro vylep코en칤:",
            height=200,
            placeholder="# K칩d k vylep코en칤\ndef process_data(data):\n    # implementation\n    return processed_data"
        )
        
        if st.button("Analyzovat a Navrhnout Vylep코en칤") and improvement_code:
            with st.spinner("Analyzov치n칤 k칩du..."):
                improvements = assistant.suggest_improvements(improvement_code)
                
                st.markdown("### 游닇 Dokumentace")
                st.markdown(improvements["documentation"])
                
                st.markdown("### 游댌 Code Review")
                st.markdown(improvements["code_review"])
                
                st.markdown("### 丘멆잺 Potenci치ln칤 Probl칠my")
                st.markdown(improvements["potential_issues"])
                
                st.markdown("### 游댃 N치vrhy Refaktoringu")
                st.markdown(improvements["suggested_refactoring"])

if __name__ == "__main__":
    main()
````

````python
OPENAI_API_KEY=sk-your-openai-api-key
GITHUB_TOKEN=ghp_your-github-token
WEAVIATE_URL=http://localhost:8080
STACK_OVERFLOW_API_KEY=your-stack-overflow-key
````

````python
version: '3.8'
services:
  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai'
    volumes:
      - weaviate_data:/var/lib/weaviate

volumes:
  weaviate_data:
````

## Shrnut칤 Projektu

### Kl칤캜ov칠 Hodnoty
- **Automatizace**: Redukce manu치ln칤 pr치ce p콏i dokumentaci a debugging
- **Kontextov칠 콏e코en칤**: Vyu쬴t칤 RAG pro relevantn칤 odpov캩di
- **Integrace zdroj콢**: Kombinov치n칤 GitHub, Stack Overflow a technick칠 dokumentace
- **맒치lovatelnost**: Modul치rn칤 architektura umo쮄갓j칤c칤 roz코칤콏en칤

### Hlavn칤 V칳hody
- Rychl칠 generov치n칤 kvalitn칤 dokumentace
- Inteligentn칤 anal칳za chyb s n치vrhy 콏e코en칤
- Automatizovan칠 code review s best practices
- U캜en칤 se z existuj칤c칤ch 콏e코en칤 komunity

### Technick칠 Kl칤캜ov칠 Prvky
- **RAG architektura** pro kontextov캩 spr치vn칠 odpov캩di
- **Vektorov치 datab치ze** pro efektivn칤 vyhled치v치n칤
- **Multi-source integrace** (GitHub, Stack Overflow)
- **Modul치rn칤 design** pro snadnou 칰dr쬭u a roz코칤콏en칤

Tento projekt p콏edstavuje komplexn칤 콏e코en칤 pro v칳voj치콏e, kter칠 kombinuje s칤lu AI s praktick칳mi n치stroji pro ka쬯odenn칤 v칳voj software.