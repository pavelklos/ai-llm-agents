<small>Claude 3.7 Sonnet Thinking</small>
# 01. Introduction to AI Assistants and Creating Your First GPT Assistant

## Key Terms

- **Large Language Model (LLM)**: Neural network trained on vast text data to understand and generate human-like text
- **GPT (Generative Pre-trained Transformer)**: Family of LLMs developed by OpenAI
- **Prompt Engineering**: Technique of crafting effective inputs to guide LLM responses
- **Context Window**: Maximum amount of text an LLM can process in a single interaction
- **API (Application Programming Interface)**: Protocol allowing applications to communicate with LLMs
- **Token**: Basic unit of text processing in LLMs (roughly 4 characters in English)

## Introduction to AI Assistants

AI assistants powered by LLMs represent a revolutionary advancement in human-computer interaction. These systems understand natural language queries and generate contextually relevant responses by processing vast amounts of training data through transformer-based neural networks.

Modern LLM-based assistants like those built on GPT models operate by:

1. Processing input text as tokens
2. Analyzing patterns and contextual relationships
3. Generating probabilistic outputs based on learned patterns
4. Maintaining conversational state through context management

Their capabilities extend beyond simple question-answering to include:

- Natural language understanding and generation
- Context retention across multiple exchanges
- Domain-specific knowledge application
- Information synthesis and summarization
- Creative content generation
- Code interpretation and generation

## Types of Applications

AI assistant applications span numerous domains and use cases:

### Customer Service
- 24/7 frontline support for common queries
- Ticket triage and routing to appropriate human agents
- Guided troubleshooting for technical issues

### Knowledge Management
- Document analysis and information extraction
- FAQ automation and knowledge base querying
- Research assistance and literature review

### Personal Productivity
- Email drafting and communication assistance
- Meeting summarization and follow-up generation
- Task management and scheduling assistance

### Content Creation
- Copy generation for marketing materials
- Content ideation and outline development
- Multilingual translation and localization

### Programming Assistance
- Code generation and explanation
- Debugging assistance
- Documentation creation

### Domain-Specific Applications
- Legal document analysis and contract review
- Healthcare symptom analysis and triage
- Educational tutoring and personalized learning

## Creating a Basic GPT Assistant

Let's implement a basic GPT assistant using the OpenAI API and Python. We'll create a modular solution that handles conversation history and configurable parameters.

First, let's set up our environment:

```python
import os
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
import openai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure OpenAI API
openai.api_key = os.getenv("OPENAI_API_KEY")

class Message:
    """Class representing a message in the conversation."""
    
    def __init__(self, role: str, content: str, timestamp: Optional[datetime] = None):
        """
        Initialize a message.
        
        Args:
            role: The role of the message sender (system, user, assistant)
            content: The content of the message
            timestamp: When the message was created (defaults to now)
        """
        self.role = role
        self.content = content
        self.timestamp = timestamp or datetime.now()
    
    def to_dict(self) -> Dict[str, str]:
        """Convert message to dictionary format for API."""
        return {"role": self.role, "content": self.content}
    
    def __str__(self) -> str:
        """String representation of message."""
        return f"[{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}] {self.role.upper()}: {self.content}"


class Conversation:
    """Class managing conversation history."""
    
    def __init__(self, system_message: str = "You are a helpful assistant."):
        """
        Initialize a conversation.
        
        Args:
            system_message: The system message that defines assistant behavior
        """
        self.messages: List[Message] = [Message("system", system_message)]
    
    def add_message(self, role: str, content: str) -> None:
        """
        Add a message to the conversation.
        
        Args:
            role: The role of the message sender
            content: The content of the message
        """
        self.messages.append(Message(role, content))
    
    def get_messages_for_api(self) -> List[Dict[str, str]]:
        """Get messages in format required by OpenAI API."""
        return [msg.to_dict() for msg in self.messages]
    
    def clear_history(self, keep_system_message: bool = True) -> None:
        """
        Clear conversation history.
        
        Args:
            keep_system_message: Whether to keep the system message
        """
        if keep_system_message and self.messages and self.messages[0].role == "system":
            system_message = self.messages[0]
            self.messages = [system_message]
        else:
            self.messages = []
    
    def save_to_file(self, filename: str) -> None:
        """
        Save conversation to a file.
        
        Args:
            filename: Path to the file
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json_data = []
            for msg in self.messages:
                msg_dict = msg.to_dict()
                msg_dict['timestamp'] = msg.timestamp.isoformat()
                json_data.append(msg_dict)
            json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    def load_from_file(self, filename: str) -> None:
        """
        Load conversation from a file.
        
        Args:
            filename: Path to the file
        """
        with open(filename, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
            self.messages = []
            for msg_dict in json_data:
                timestamp = datetime.fromisoformat(msg_dict['timestamp']) if 'timestamp' in msg_dict else None
                self.messages.append(Message(msg_dict['role'], msg_dict['content'], timestamp))


class GPTAssistant:
    """Class implementing a GPT-based assistant."""
    
    def __init__(
        self,
        system_message: str = "You are a helpful assistant.",
        model: str = "gpt-4o",
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ):
        """
        Initialize a GPT assistant.
        
        Args:
            system_message: The system message that defines assistant behavior
            model: The OpenAI model to use
            temperature: Controls randomness (0-1, lower is more deterministic)
            max_tokens: Maximum number of tokens in the response
        """
        self.conversation = Conversation(system_message)
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
    
    def ask(self, query: str) -> str:
        """
        Ask the assistant a question and get a response.
        
        Args:
            query: The user's question or prompt
            
        Returns:
            The assistant's response
        """
        # Add user query to conversation
        self.conversation.add_message("user", query)
        
        # Prepare API call parameters
        params = {
            "model": self.model,
            "messages": self.conversation.get_messages_for_api(),
            "temperature": self.temperature
        }
        
        if self.max_tokens:
            params["max_tokens"] = self.max_tokens
        
        # Call OpenAI API
        try:
            response = openai.chat.completions.create(**params)
            assistant_response = response.choices[0].message.content
            
            # Add assistant response to conversation
            self.conversation.add_message("assistant", assistant_response)
            
            return assistant_response
        except Exception as e:
            error_msg = f"Error communicating with OpenAI API: {str(e)}"
            self.conversation.add_message("system", error_msg)
            return error_msg
    
    def save_conversation(self, filename: str) -> None:
        """
        Save the current conversation to a file.
        
        Args:
            filename: Path to the file
        """
        self.conversation.save_to_file(filename)
    
    def load_conversation(self, filename: str) -> None:
        """
        Load a conversation from a file.
        
        Args:
            filename: Path to the file
        """
        self.conversation.load_from_file(filename)
    
    def clear_conversation(self, keep_system_message: bool = True) -> None:
        """
        Clear the conversation history.
        
        Args:
            keep_system_message: Whether to keep the system message
        """
        self.conversation.clear_history(keep_system_message)


# Example usage
if __name__ == "__main__":
    # Initialize an assistant for technical support
    tech_assistant = GPTAssistant(
        system_message="You are a technical support specialist for a software company. "
                       "You help users troubleshoot issues with their software applications. "
                       "Be concise but thorough, and always ask for clarification if needed.",
        temperature=0.5
    )
    
    # Interactive chat loop
    print("Technical Support Assistant (type 'exit' to quit)")
    print("------------------------------------------------")
    
    while True:
        user_input = input("\nYou: ")
        
        if user_input.lower() in ['exit', 'quit', 'bye']:
            print("\nAssistant: Thank you for using our technical support. Goodbye!")
            break
        
        print("\nAssistant is thinking...")
        response = tech_assistant.ask(user_input)
        print(f"\nAssistant: {response}")
```

Let's also create a simple web interface using Streamlit for a more user-friendly experience:

```python
import streamlit as st
from assistant import GPTAssistant
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="GPT Assistant",
    page_icon="🤖",
    layout="wide"
)

# Initialize session state variables
if "assistant" not in st.session_state:
    st.session_state.assistant = GPTAssistant(
        system_message="You are a helpful assistant that provides accurate and concise information.",
        model="gpt-4o"
    )

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Application header
st.title("🤖 GPT Assistant")

# Sidebar for configuration
with st.sidebar:
    st.header("Configuration")
    
    system_message = st.text_area(
        "System Message",
        "You are a helpful assistant that provides accurate and concise information."
    )
    
    model = st.selectbox(
        "Model",
        ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"]
    )
    
    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    
    if st.button("Update Assistant"):
        st.session_state.assistant = GPTAssistant(
            system_message=system_message,
            model=model,
            temperature=temperature
        )
        st.success("Assistant updated!")
    
    if st.button("Clear Conversation"):
        st.session_state.chat_history = []
        st.session_state.assistant.clear_conversation()
        st.success("Conversation cleared!")

# Display chat history
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Chat input
user_input = st.chat_input("Ask something...")

if user_input:
    # Add user message to chat history
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    
    # Display user message
    with st.chat_message("user"):
        st.write(user_input)
    
    # Get assistant response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = st.session_state.assistant.ask(user_input)
            st.write(response)
    
    # Add assistant response to chat history
    st.session_state.chat_history.append({"role": "assistant", "content": response})
```

## Practical Exercise: Building a Simple GPT Assistant

Now, let's build a simple FAQ assistant for a fictional company. This assistant will answer questions about the company's services, pricing, and policies.

```python
from assistant import GPTAssistant
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Company information
COMPANY_INFO = """
Company Name: TechSolutions Inc.
Founded: 2010
Headquarters: San Francisco, CA

Products and Services:
1. CloudSync - Cloud storage and synchronization service
   - Pricing: $5/month for 100GB, $10/month for 500GB, $15/month for 1TB
   - Features: File sharing, automatic backup, cross-platform sync

2. DataGuard - Data protection and security software
   - Pricing: $20/month per user
   - Features: Encryption, threat detection, secure backups

3. WorkFlow - Project management software
   - Pricing: Free tier, $12/month per user for Pro, $25/month per user for Enterprise
   - Features: Task tracking, team collaboration, reporting

Return Policy: 30-day money-back guarantee for all products.
Support Hours: 24/7 technical support via chat, email support within 24 hours.
"""

# Create the assistant
def create_faq_assistant():
    system_message = f"""
    You are a customer support assistant for TechSolutions Inc. 
    Use the following company information to answer customer questions:
    
    {COMPANY_INFO}
    
    Keep your answers friendly, professional, and concise. If you don't know the answer to a question, 
    suggest that the customer contact human support at support@techsolutions.example.com.
    
    Don't make up information that isn't provided above.
    """
    
    return GPTAssistant(
        system_message=system_message,
        model="gpt-3.5-turbo",  # Using a less expensive model for a simple FAQ bot
        temperature=0.3  # Lower temperature for more consistent, factual responses
    )

def main():
    print("TechSolutions Customer Support Assistant")
    print("----------------------------------------")
    print("Ask questions about our products, pricing, or policies. Type 'exit' to quit.")
    
    assistant = create_faq_assistant()
    
    while True:
        user_input = input("\nYou: ")
        
        if user_input.lower() in ['exit', 'quit', 'bye']:
            print("\nAssistant: Thank you for contacting TechSolutions support. Have a great day!")
            break
        
        print("\nAssistant is thinking...")
        response = assistant.ask(user_input)
        print(f"\nAssistant: {response}")

if __name__ == "__main__":
    main()
```

To run this example:
1. Create a `.env` file with your OpenAI API key: `OPENAI_API_KEY=your_api_key_here`
2. Install required packages: `pip install openai python-dotenv streamlit`
3. Run the command-line version: `python faq_assistant.py`
4. Or run the web interface: `streamlit run app.py`

## Conclusion

In this introduction to AI assistants, we've explored the fundamental concepts behind LLM-powered conversational agents and implemented a practical GPT assistant framework. We've covered:

- The technical foundations of AI assistants and their capabilities
- Various application types across different domains
- Building a modular assistant with conversation management
- Creating a simple web interface for user interaction
- Implementing a domain-specific FAQ assistant

This foundation serves as a starting point for more complex implementations. As you continue, you'll be able to enhance your assistants with memory systems, external knowledge retrieval, and more sophisticated reasoning capabilities.

The real power of GPT assistants comes from thoughtful system design and prompt engineering. With the basic architecture established, you can now experiment with different system messages, temperature settings, and interaction patterns to create assistants tailored to specific use cases.