<small>Claude 3.7 Sonnet Thinking</small>
# 04. Automation and Workflow with n8n

## Key Terms

- **n8n**: An open-source workflow automation tool that connects apps, services, and APIs.
- **Workflow**: A sequence of automated tasks triggered by events or run on a schedule.
- **Node**: A functional unit in n8n that represents an action, trigger, or service.
- **Trigger Node**: A special node that initiates a workflow based on an event or schedule.
- **Webhook**: HTTP endpoint that listens for incoming data to trigger workflows.
- **Expression**: Code-like syntax used in n8n to manipulate data between nodes.
- **Credentials**: Securely stored authentication details for connecting to services.
- **JSON**: JavaScript Object Notation, the primary data format used in n8n workflows.
- **Parameter**: Configurable settings within nodes that define behavior.

## Introduction to n8n for AI Automation

n8n is a powerful, node-based workflow automation platform that enables the creation of complex automated processes without extensive coding. Unlike many automation tools, n8n is self-hostable and provides extensive customization options, making it ideal for building AI-powered workflows and agents that require flexible integration with various services.

## Process Visualization and Workflow Design

n8n represents processes as connected nodes in a visual interface. Each workflow consists of:

1. **Trigger nodes** that start the workflow (HTTP requests, webhooks, schedules)
2. **Processing nodes** that transform, filter, or manipulate data
3. **Action nodes** that interact with external services or APIs
4. **Flow control nodes** that implement logic like conditions and loops

Workflows are created through an intuitive drag-and-drop interface, allowing for visual representation of complex processes that would otherwise require significant programming effort.

## Working with Nodes, Variables, Databases and APIs

### Node Types and Basic Operations

```python
# This Python code demonstrates how to interact with n8n's REST API
# to programmatically create nodes in a workflow
# filepath: n8n_workflow_creator.py

import requests
import json
import os
from typing import Dict, List, Any
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class N8nWorkflowManager:
    """Class to programmatically manage n8n workflows"""
    
    def __init__(self):
        self.base_url = os.getenv("N8N_BASE_URL", "http://localhost:5678")
        self.api_key = os.getenv("N8N_API_KEY")
        self.headers = {
            "X-N8N-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
    
    def create_workflow(self, name: str, nodes: List[Dict[str, Any]], 
                       connections: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create a new workflow with specified nodes and connections"""
        workflow_data = {
            "name": name,
            "nodes": nodes,
            "connections": connections,
            "active": False,  # Create inactive by default
            "settings": {
                "saveExecutionProgress": True,
                "saveManualExecutions": True,
                "callerPolicy": "any"
            }
        }
        
        response = requests.post(
            f"{self.base_url}/api/v1/workflows",
            headers=self.headers,
            json=workflow_data
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Failed to create workflow: {response.text}")
    
    def create_basic_llm_agent_workflow(self, name: str) -> Dict[str, Any]:
        """Create a basic LLM agent workflow with predefined nodes"""
        # Define positions for visual layout
        positions = {
            "webhook": {"x": 0, "y": 0},
            "openai": {"x": 280, "y": 0},
            "function": {"x": 560, "y": 0},
            "respond": {"x": 840, "y": 0}
        }
        
        # Define nodes
        nodes = [
            {
                "name": "Webhook",
                "type": "n8n-nodes-base.webhook",
                "position": positions["webhook"],
                "parameters": {
                    "path": "llm-agent",
                    "responseMode": "lastNode",
                    "responseData": "json"
                }
            },
            {
                "name": "OpenAI",
                "type": "n8n-nodes-base.openAi",
                "position": positions["openai"],
                "parameters": {
                    "authentication": "serviceAccount",
                    "operation": "completion",
                    "model": "gpt-4",
                    "prompt": "={{ $json.body.query }}",
                    "options": {
                        "temperature": 0.7,
                        "maxTokens": 500
                    }
                },
                "credentials": {
                    "openAiApi": {
                        "name": "OpenAI Account"
                    }
                }
            },
            {
                "name": "Function",
                "type": "n8n-nodes-base.function",
                "position": positions["function"],
                "parameters": {
                    "functionCode": """
// Parse the OpenAI response and look for potential actions
const response = items[0].json.choices[0].text.trim();
const possibleActions = [
  { keyword: "search", action: "search_operation" },
  { keyword: "database", action: "database_query" },
  { keyword: "calculate", action: "perform_calculation" }
];

// Detect if the response indicates an action
let detectedAction = null;
for (const {keyword, action} of possibleActions) {
  if (response.toLowerCase().includes(keyword)) {
    detectedAction = action;
    break;
  }
}

// Return enriched data
return [{
  json: {
    original_query: $node["Webhook"].json.body.query,
    llm_response: response,
    detected_action: detectedAction,
    timestamp: new Date().toISOString()
  }
}];
                    """
                }
            },
            {
                "name": "Respond",
                "type": "n8n-nodes-base.respondToWebhook",
                "position": positions["respond"],
                "parameters": {}
            }
        ]
        
        # Define connections
        connections = [
            {
                "node": "Webhook",
                "type": "main",
                "index": 0,
                "target": "OpenAI"
            },
            {
                "node": "OpenAI",
                "type": "main",
                "index": 0,
                "target": "Function"
            },
            {
                "node": "Function",
                "type": "main",
                "index": 0,
                "target": "Respond"
            }
        ]
        
        # Create the workflow
        return self.create_workflow(name, nodes, connections)

# Example usage
if __name__ == "__main__":
    manager = N8nWorkflowManager()
    workflow = manager.create_basic_llm_agent_workflow("Simple LLM Agent")
    print(f"Created workflow with ID: {workflow['id']}")
```

### Working with Variables and Data Flow

In n8n, data flows between nodes as JSON objects. The platform provides several ways to manipulate this data:

1. **Expressions:** Using `={{ $json.fieldName }}` to reference data from previous nodes
2. **Function nodes:** For complex data transformations using JavaScript
3. **JSON node:** For direct JSON manipulation

Data from one node is accessible in subsequent nodes, allowing for progressive enrichment of information throughout the workflow.

### Database Integration

n8n supports various database systems including MySQL, PostgreSQL, MongoDB, and others. Below is an example of integrating a database query into a workflow using custom Python code:

```python
# This can be used in n8n's Python node or as a custom n8n node

import psycopg2
import os
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def query_database(query_text, parameters=None):
    """
    Execute a database query based on natural language instructions
    This function would be called from within an n8n Python node
    """
    # Connect to database
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST'),
        database=os.getenv('DB_NAME'),
        user=os.getenv('DB_USER'),
        password=os.getenv('DB_PASSWORD')
    )
    
    # Create cursor and execute query
    cursor = conn.cursor()
    try:
        cursor.execute(query_text, parameters)
        
        # For SELECT queries, fetch results
        if query_text.strip().upper().startswith('SELECT'):
            columns = [desc[0] for desc in cursor.description]
            results = cursor.fetchall()
            
            # Format results as list of dictionaries
            formatted_results = []
            for row in results:
                formatted_results.append(dict(zip(columns, row)))
                
            return {"success": True, "data": formatted_results}
        else:
            # For other queries (INSERT, UPDATE, DELETE)
            conn.commit()
            return {"success": True, "rows_affected": cursor.rowcount}
            
    except Exception as e:
        conn.rollback()
        return {"success": False, "error": str(e)}
    finally:
        cursor.close()
        conn.close()

# In n8n, this function would be called with:
# query_text = items[0].json.query
# parameters = items[0].json.parameters if 'parameters' in items[0].json else None
# return [{"json": query_database(query_text, parameters)}]
```

## LLM Integration in n8n Workflows

n8n offers several methods to integrate large language models into workflows:

1. **Built-in nodes:** Using the OpenAI, Anthropic, or HuggingFace nodes
2. **HTTP Request nodes:** For direct API calls to any LLM provider
3. **Custom code nodes:** For more complex LLM interactions

A key advantage of using n8n for LLM integration is the ability to orchestrate complex workflows around model calls, including pre-processing inputs, handling responses, and implementing logic based on model outputs.

### Creating an AI Agent in n8n

To create an agent in n8n, we combine multiple capabilities:

1. **Input handling:** Process and validate user inputs
2. **Context management:** Maintain conversation history
3. **Tool calling:** Enable the agent to use external tools
4. **Response generation:** Process model responses and format outputs

The following example demonstrates a complete AI agent implementation in n8n using a combination of nodes and custom code:

```javascript
// This is JavaScript code for an n8n Function Node
// that implements a key part of an AI agent's reasoning system

// Parse incoming data
const userInput = items[0].json.input;
const conversationHistory = items[0].json.history || [];
const availableTools = [
  {
    name: "search_weather",
    description: "Get current weather for a location",
    parameters: {
      type: "object",
      properties: {
        location: {
          type: "string",
          description: "City name"
        }
      },
      required: ["location"]
    }
  },
  {
    name: "query_database",
    description: "Query product information from database",
    parameters: {
      type: "object",
      properties: {
        product_id: {
          type: "string",
          description: "Product identifier"
        }
      },
      required: ["product_id"]
    }
  },
  {
    name: "calculate",
    description: "Perform mathematical calculation",
    parameters: {
      type: "object",
      properties: {
        expression: {
          type: "string",
          description: "Mathematical expression to evaluate"
        }
      },
      required: ["expression"]
    }
  }
];

// Build system message with tool descriptions
const systemMessage = `You are a helpful AI assistant with access to external tools.
To use a tool, respond with JSON in the following format:
{
  "thought": "your reasoning about what to do",
  "action": "tool_name",
  "action_input": { "parameter": "value" }
}

If you don't need to use a tool, respond directly to the user.

Available tools:
${JSON.stringify(availableTools, null, 2)}`;

// Build messages array for the LLM
const messages = [
  { role: "system", content: systemMessage },
  ...conversationHistory,
  { role: "user", content: userInput }
];

// Set up the next node (OpenAI) input
return [{
  json: {
    model: "gpt-4-0613",
    messages: messages,
    temperature: 0.2,
    tools: availableTools
  }
}];
```

## Practical Exercise: Building a Complete AI Agent in n8n

Let's create a complete n8n workflow for an AI agent that can:
- Process natural language requests
- Access and query databases
- Execute web searches
- Perform calculations
- Maintain conversation state

This requires several connected workflows and custom code nodes:

```python
# Python components that would be used in n8n's Python nodes

import os
import json
import requests
import sqlite3
from datetime import datetime
from dotenv import load_dotenv
import openai

# Load environment variables
load_dotenv()

# Initialize OpenAI client
openai.api_key = os.getenv("OPENAI_API_KEY")

class AgentMemory:
    """Memory manager for the n8n agent"""
    
    def __init__(self, db_path="agent_memory.db"):
        """Initialize with path to SQLite database"""
        self.db_path = db_path
        self._initialize_db()
    
    def _initialize_db(self):
        """Create database tables if they don't exist"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Table for conversation history
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversations (
            id TEXT PRIMARY KEY,
            user_id TEXT,
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        )
        ''')
        
        # Table for messages within conversations
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id TEXT PRIMARY KEY,
            conversation_id TEXT,
            role TEXT,
            content TEXT,
            timestamp TIMESTAMP,
            FOREIGN KEY (conversation_id) REFERENCES conversations (id)
        )
        ''')
        
        # Table for agent's working memory
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS memory_items (
            id TEXT PRIMARY KEY,
            conversation_id TEXT,
            key TEXT,
            value TEXT,
            created_at TIMESTAMP,
            FOREIGN KEY (conversation_id) REFERENCES conversations (id)
        )
        ''')
        
        conn.commit()
        conn.close()
    
    def create_conversation(self, user_id):
        """Create a new conversation"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        conversation_id = f"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{user_id}"
        now = datetime.now().isoformat()
        
        cursor.execute(
            "INSERT INTO conversations (id, user_id, created_at, updated_at) VALUES (?, ?, ?, ?)",
            (conversation_id, user_id, now, now)
        )
        
        conn.commit()
        conn.close()
        
        return conversation_id
    
    def add_message(self, conversation_id, role, content):
        """Add a message to the conversation history"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        message_id = f"msg_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        now = datetime.now().isoformat()
        
        cursor.execute(
            "INSERT INTO messages (id, conversation_id, role, content, timestamp) VALUES (?, ?, ?, ?, ?)",
            (message_id, conversation_id, role, content, now)
        )
        
        # Update conversation last modified time
        cursor.execute(
            "UPDATE conversations SET updated_at = ? WHERE id = ?",
            (now, conversation_id)
        )
        
        conn.commit()
        conn.close()
        
        return message_id
    
    def get_conversation_messages(self, conversation_id, limit=10):
        """Retrieve recent messages from a conversation"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            """
            SELECT role, content FROM messages 
            WHERE conversation_id = ? 
            ORDER BY timestamp DESC LIMIT ?
            """,
            (conversation_id, limit)
        )
        
        messages = [{"role": role, "content": content} for role, content in cursor.fetchall()]
        messages.reverse()  # Chronological order
        
        conn.close()
        
        return messages
    
    def store_memory_item(self, conversation_id, key, value):
        """Store an item in the agent's working memory"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        item_id = f"mem_{datetime.now().strftime('%Y%m%d%H%M%S%f')}"
        now = datetime.now().isoformat()
        
        # Convert value to JSON string if it's not already a string
        if not isinstance(value, str):
            value = json.dumps(value)
        
        cursor.execute(
            """
            INSERT INTO memory_items (id, conversation_id, key, value, created_at)
            VALUES (?, ?, ?, ?, ?)
            """,
            (item_id, conversation_id, key, value, now)
        )
        
        conn.commit()
        conn.close()
        
        return item_id
    
    def get_memory_item(self, conversation_id, key):
        """Retrieve a memory item by key"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT value FROM memory_items WHERE conversation_id = ? AND key = ? ORDER BY created_at DESC LIMIT 1",
            (conversation_id, key)
        )
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            value = result[0]
            try:
                # Attempt to parse as JSON
                return json.loads(value)
            except json.JSONDecodeError:
                return value
        else:
            return None

class AgentTools:
    """Tools that can be called by the n8n agent"""
    
    @staticmethod
    def search_weather(location):
        """Get current weather for a location"""
        api_key = os.getenv("WEATHERAPI_KEY")
        url = f"http://api.weatherapi.com/v1/current.json?key={api_key}&q={location}&aqi=no"
        
        try:
            response = requests.get(url)
            data = response.json()
            
            if "error" in data:
                return {
                    "success": False,
                    "error": data["error"]["message"]
                }
            
            return {
                "success": True,
                "location": data["location"]["name"],
                "country": data["location"]["country"],
                "temperature_c": data["current"]["temp_c"],
                "temperature_f": data["current"]["temp_f"],
                "condition": data["current"]["condition"]["text"],
                "wind_kph": data["current"]["wind_kph"],
                "humidity": data["current"]["humidity"]
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def query_database(query, parameters=None):
        """Execute a database query"""
        # For this example, we'll use a simple SQLite database
        # In production, you might connect to a more robust database
        conn = sqlite3.connect("agent_database.db")
        cursor = conn.cursor()
        
        try:
            if parameters:
                cursor.execute(query, parameters)
            else:
                cursor.execute(query)
            
            # For SELECT queries
            if query.strip().lower().startswith("select"):
                columns = [description[0] for description in cursor.description]
                results = cursor.fetchall()
                
                formatted_results = []
                for row in results:
                    formatted_results.append(dict(zip(columns, row)))
                
                return {
                    "success": True,
                    "data": formatted_results
                }
            else:
                # For INSERT, UPDATE, DELETE
                conn.commit()
                return {
                    "success": True,
                    "rows_affected": cursor.rowcount
                }
                
        except Exception as e:
            conn.rollback()
            return {
                "success": False,
                "error": str(e)
            }
        finally:
            cursor.close()
            conn.close()
    
    @staticmethod
    def calculate(expression):
        """Safely evaluate a mathematical expression"""
        # We'll use OpenAI for safe calculation instead of eval()
        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a calculator. Calculate the result of the expression provided. Return ONLY the numerical result with no explanation."},
                    {"role": "user", "content": f"Calculate: {expression}"}
                ],
                temperature=0
            )
            
            result = response.choices[0].message.content.strip()
            
            # Try to convert to number
            try:
                if '.' in result:
                    result = float(result)
                else:
                    result = int(result)
            except ValueError:
                pass
                
            return {
                "success": True,
                "expression": expression,
                "result": result
            }
            
        except Exception as e:
            return {
                "success": False,
                "expression": expression,
                "error": str(e)
            }
```

## Setting Up an AI Agent Workflow in n8n

To set up a complete AI agent workflow in n8n:

1. **Create a webhook trigger** to receive incoming requests
2. **Add a Function node** for initial request processing
3. **Set up a Switch node** to handle different request types
4. **Add Database nodes** to store and retrieve conversation history
5. **Integrate OpenAI nodes** for LLM processing
6. **Add HTTP Request nodes** for external API calls
7. **Create a final Function node** to format responses

Key workflow steps:

1. Receive input via webhook
2. Load conversation history from database
3. Process input with LLM to determine required actions
4. Execute actions through appropriate nodes
5. Send results back to LLM for final response generation
6. Save conversation history
7. Return response to the user

## Conclusion

n8n provides a powerful visual programming environment for creating AI agents and automated workflows. By combining the intuitive node-based interface with custom code, you can build sophisticated agents that leverage LLM capabilities alongside database operations, API calls, and complex business logic.

The key advantages of using n8n for AI agent development include:

1. **Visual workflow design** makes complex process flows more understandable
2. **Low-code approach** reduces development time while maintaining flexibility
3. **Extensive integration options** allow agents to interact with virtually any system
4. **Built-in error handling and retry mechanisms** improve reliability
5. **Self-hostable architecture** gives you control over data and processing

When building AI agents with n8n, focus on creating modular workflows that separate concerns like input processing, LLM interaction, tool calling, and response handling. This approach makes your agents easier to maintain and extend over time.

By combining n8n's workflow capabilities with the power of large language models, you can create AI agents that automate complex tasks, integrate with existing systems, and deliver sophisticated responses based on both structured and unstructured data.