<small>Claude 3.7 Sonnet Thinking</small>
# 04. Multi-Agent Orchestration with LangGraph

## Key Terms

- **LangGraph**: Framework for building stateful, multi-agent applications as directed graphs
- **Agent**: Software entity capable of perception, reasoning, and autonomous action
- **Orchestration**: Coordination of multiple agents to execute complex workflows
- **State Machine**: Computational model defining discrete states and transitions between them
- **Directed Graph**: Data structure with nodes and directed edges representing workflow steps
- **LCEL (LangChain Expression Language)**: Domain-specific language for describing LLM chains
- **Message Passing**: Communication mechanism between agents in multi-agent systems
- **Node**: Processing unit in a graph that executes specific functions
- **Edge**: Connection between nodes that defines the flow of information
- **Thread**: Persistent conversation context that maintains state between interactions

## Introduction to LangGraph and Comparison with LangChain

LangGraph extends LangChain by introducing stateful, cyclic processing flows where traditional LangChain offers primarily linear, stateless chains. Built on top of LangChain, LangGraph provides a graph-based framework specifically designed for orchestrating multi-agent systems with complex decision flows.

Key differences between LangGraph and LangChain:

1. **Stateful vs. Stateless**:
   - LangChain: Primarily designed for stateless, linear processing
   - LangGraph: Designed for persistent state management across multiple interactions

2. **Flow Structure**:
   - LangChain: Linear chains of components
   - LangGraph: Directed graphs with cycles, branches, and conditional logic

3. **Agent Interaction**:
   - LangChain: Single agent workflows or simple agent interactions
   - LangGraph: Native support for complex multi-agent systems with defined communication patterns

4. **Persistence**:
   - LangChain: Limited built-in persistence capabilities
   - LangGraph: Thread-based persistent memory with state tracking

LangGraph implements its workflows as state machines, which makes it particularly well-suited for applications requiring:
- Multi-step reasoning
- Agent collaboration with specialized roles
- Iterative refinement processes
- Complex decision trees with conditional branching

## Agent Role Distribution and Orchestration Logic

Effective multi-agent systems require thoughtful design of roles, responsibilities, and interaction patterns. LangGraph provides the architecture to implement various collaboration patterns:

### Role Specialization Patterns

1. **Functional Specialization**: Agents specialize in specific tasks (research, coding, analysis)
2. **Domain Specialization**: Agents with expertise in particular knowledge domains
3. **Process Specialization**: Agents focused on specific workflow stages (planning, execution, verification)
4. **Meta-Roles**: Supervisory agents that coordinate other agents

### Orchestration Patterns

1. **Hub-and-Spoke**: Central orchestrator agent delegates to specialist agents
2. **Chain of Responsibility**: Sequential processing with handoffs between agents
3. **Peer-to-Peer**: Direct communication between agents with minimal centralization
4. **Hierarchical**: Multi-level structure with supervisory relationships

Let's implement a basic multi-agent system using LangGraph that demonstrates these concepts:

```python
from typing import Dict, List, Tuple, Any, Annotated, TypedDict, Literal
from dotenv import load_dotenv
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, FunctionMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain.agents import Tool
import operator
import json
import langsmith
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

# Load environment variables
load_dotenv()

# Configure LangSmith for tracing (optional)
langsmith.api_key = os.getenv("LANGSMITH_API_KEY")
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "multi_agent_orchestration"

# Initialize the LLM
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.7,
    api_key=os.getenv("OPENAI_API_KEY")
)

# Define the state structure for our graph
class AgentState(TypedDict):
    messages: List[Dict]
    task: str
    research_results: List[Dict]
    analysis_results: Dict
    decision: str
    next_steps: List[str]
    final_output: str

# Define agent roles and their system prompts
AGENT_ROLES = {
    "orchestrator": """You are the Orchestrator Agent responsible for managing the workflow.
You analyze the user's task, determine what steps are needed, and coordinate the other agents.
Your job is to decide which agent should work next based on the current state and task requirements.
Available agents: Research Agent, Analysis Agent, Decision Agent, and Implementation Agent.
""",
    
    "research": """You are the Research Agent specialized in gathering information.
Your role is to collect facts, data, and background information relevant to the task.
Focus on being thorough and factual, and organize your findings clearly.
""",
    
    "analysis": """You are the Analysis Agent specialized in critical examination of information.
Your role is to evaluate research findings, identify patterns, and draw insights.
Focus on logical reasoning and highlight important implications of the data.
Respond with analysis structured as a JSON with "key_insights", "patterns", and "implications" keys.
""",
    
    "decision": """You are the Decision Agent specialized in making recommendations.
Based on the research and analysis provided, your role is to recommend specific actions.
Weigh pros and cons and clearly state your rationale for each recommendation.
Your output should be actionable and specific.
""",
    
    "implementation": """You are the Implementation Agent specialized in execution plans.
Your role is to create detailed action plans for implementing decisions.
Break down complex tasks into smaller, manageable steps with clear instructions.
Focus on practical, achievable steps that lead to successful implementation.
"""
}

# Define agent functions
def create_agent_node(role: str):
    """Create a node for a specific agent role."""
    system_prompt = AGENT_ROLES[role]
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("placeholder", "{chat_history}"),
        ("human", "{input}")
    ])
    
    chain = prompt | llm
    
    def agent_function(state: AgentState):
        # Extract the chat history
        chat_history = state["messages"]
        
        # Determine the input based on the agent role
        if role == "research":
            input_text = f"Task: {state['task']}\nResearch this topic thoroughly."
        elif role == "analysis":
            input_text = f"Task: {state['task']}\nResearch results: {json.dumps(state['research_results'])}\nProvide analysis."
        elif role == "decision":
            input_text = f"Task: {state['task']}\nResearch results: {json.dumps(state['research_results'])}\nAnalysis: {json.dumps(state['analysis_results'])}\nMake a decision."
        elif role == "implementation":
            input_text = f"Task: {state['task']}\nDecision: {state['decision']}\nCreate an implementation plan."
        else:  # orchestrator
            input_text = f"Current task: {state['task']}\nCurrent state: {json.dumps(state)}\nDecide which agent should work next."
        
        # Run the chain
        result = chain.invoke({"chat_history": chat_history, "input": input_text})
        
        # Update the state based on the agent role
        updated_state = state.copy()
        updated_state["messages"] = chat_history + [
            {"role": "human", "content": input_text},
            {"role": "ai", "content": result.content}
        ]
        
        if role == "research":
            # Parse research results
            try:
                # Assume the research agent outputs structured content or parse it
                updated_state["research_results"] = [{"content": result.content}]
            except:
                updated_state["research_results"] = [{"content": result.content}]
        elif role == "analysis":
            # Parse analysis results
            try:
                # Attempt to extract JSON if present
                import re
                json_match = re.search(r'```json\n(.*?)\n```', result.content, re.DOTALL)
                if json_match:
                    analysis_json = json.loads(json_match.group(1))
                else:
                    analysis_json = {"content": result.content}
                updated_state["analysis_results"] = analysis_json
            except:
                updated_state["analysis_results"] = {"content": result.content}
        elif role == "decision":
            updated_state["decision"] = result.content
        elif role == "implementation":
            updated_state["next_steps"] = result.content.split("\n")
            # Also set final output if this is the last step
            updated_state["final_output"] = result.content
        
        return updated_state
    
    return agent_function

# Define the orchestrator's routing logic
def route_agent(state: AgentState) -> str:
    """Determine the next agent to call based on state."""
    messages = state["messages"]
    last_message = messages[-1] if messages else None
    
    # If there's no last message or the last message isn't from the orchestrator, call the orchestrator
    if not last_message or last_message.get("role") != "ai":
        return "orchestrator"
    
    # Extract the orchestrator's decision from the last message
    orchestrator_decision = last_message.get("content", "").strip().lower()
    
    # Map keywords to agent destinations
    if "research" in orchestrator_decision:
        return "research"
    elif "analysis" in orchestrator_decision:
        return "analysis"
    elif "decision" in orchestrator_decision:
        return "decision"
    elif "implementation" in orchestrator_decision or "execute" in orchestrator_decision:
        return "implementation"
    elif "complete" in orchestrator_decision or "finished" in orchestrator_decision:
        return END
    else:
        # Default to orchestrator if decision is unclear
        return "orchestrator"

# Create agent nodes
orchestrator_node = create_agent_node("orchestrator")
research_node = create_agent_node("research")
analysis_node = create_agent_node("analysis")
decision_node = create_agent_node("decision")
implementation_node = create_agent_node("implementation")

# Build the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("orchestrator", orchestrator_node)
workflow.add_node("research", research_node)
workflow.add_node("analysis", analysis_node)
workflow.add_node("decision", decision_node)
workflow.add_node("implementation", implementation_node)

# Add edges with conditional routing
workflow.add_conditional_edges(
    "orchestrator",
    route_agent
)

# Add edges from each agent back to the orchestrator
workflow.add_edge("research", "orchestrator")
workflow.add_edge("analysis", "orchestrator")
workflow.add_edge("decision", "orchestrator")
workflow.add_edge("implementation", "orchestrator")

# Compile the graph
graph = workflow.compile()

# Function to process a user task through the multi-agent system
def process_task(task: str) -> Dict[str, Any]:
    """
    Process a user task through the multi-agent workflow.
    
    Args:
        task: The user's task or question
        
    Returns:
        The final state of the workflow
    """
    # Initialize the state
    initial_state = {
        "messages": [],
        "task": task,
        "research_results": [],
        "analysis_results": {},
        "decision": "",
        "next_steps": [],
        "final_output": ""
    }
    
    # Execute the graph
    result = graph.invoke(initial_state)
    
    return result

# Example usage
if __name__ == "__main__":
    user_task = "Develop a marketing strategy for a new eco-friendly water bottle targeting health-conscious millennials."
    result = process_task(user_task)
    
    print("=== MULTI-AGENT WORKFLOW RESULT ===")
    print(f"Task: {result['task']}")
    print("\nFinal Output:")
    print(result["final_output"])
    
    # Optionally print the full conversation trace
    print("\n=== CONVERSATION TRACE ===")
    for msg in result["messages"]:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        print(f"\n[{role.upper()}]:\n{content[:200]}..." if len(content) > 200 else content)
```

## Creating Multi-Step Workflows

LangGraph excels at implementing complex multi-step workflows where each step may involve different reasoning processes or specialized knowledge. The core concept is modeling workflows as directed graphs with nodes (processing steps) and edges (transitions between steps).

Let's explore how to build a more sophisticated workflow using LangGraph's advanced features:

```python
from typing import Dict, List, Tuple, Any, TypedDict, Literal, Optional, Union, Annotated
from enum import Enum
import os
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import json
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, FunctionMessage
from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser
from langchain.agents import AgentExecutor, Tool
from langgraph.graph import StateGraph, END
from langgraph.checkpoint import MemorySaver
from langgraph.prebuilt import ToolNode
import operator

# Load environment variables
load_dotenv()

# Initialize the LLM
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.5,
    api_key=os.getenv("OPENAI_API_KEY")
)

# Define structured output schemas
class ResearchFindings(BaseModel):
    key_facts: List[str] = Field(..., description="Key facts discovered during research")
    sources: List[str] = Field(..., description="Sources of information")
    additional_questions: List[str] = Field(..., description="Questions that emerged during research")

class AnalysisResult(BaseModel):
    strengths: List[str] = Field(..., description="Strengths identified in the analysis")
    weaknesses: List[str] = Field(..., description="Weaknesses or challenges identified")
    opportunities: List[str] = Field(..., description="Opportunities for improvement or growth")
    threats: List[str] = Field(..., description="Potential threats or risks")
    confidence_score: float = Field(..., description="Confidence in the analysis (0-1)")

class Decision(BaseModel):
    recommended_action: str = Field(..., description="The recommended course of action")
    alternatives: List[str] = Field(..., description="Alternative actions considered")
    rationale: str = Field(..., description="Reasoning behind the recommendation")
    risks: List[str] = Field(..., description="Potential risks of this decision")
    timeline: str = Field(..., description="Suggested timeline for implementation")

class ImplementationStep(BaseModel):
    step_number: int = Field(..., description="Step number in sequence")
    description: str = Field(..., description="Description of the implementation step")
    resources_needed: List[str] = Field(..., description="Resources required for this step")
    expected_outcome: str = Field(..., description="Expected outcome of this step")
    estimated_time: str = Field(..., description="Estimated time to complete this step")

class TaskState(BaseModel):
    """Complete workflow state including all agent outputs"""
    task_description: str = Field(..., description="Original task description")
    status: str = Field(default="initialized", description="Current status of the workflow")
    current_agent: str = Field(default="orchestrator", description="Currently active agent")
    history: List[Dict] = Field(default_factory=list, description="Conversation history")
    research_findings: Optional[ResearchFindings] = Field(default=None, description="Research agent findings")
    analysis_result: Optional[AnalysisResult] = Field(default=None, description="Analysis agent results")
    decision: Optional[Decision] = Field(default=None, description="Decision agent output")
    implementation_plan: List[ImplementationStep] = Field(default_factory=list, description="Implementation plan steps")
    critique: Optional[str] = Field(default=None, description="Critique of the process and results")
    final_output: Optional[str] = Field(default=None, description="Final summarized output")

# Define workflow stages as an Enum for type safety
class WorkflowStage(str, Enum):
    ORCHESTRATION = "orchestrator"
    RESEARCH = "research"
    ANALYSIS = "analysis"
    DECISION = "decision"
    IMPLEMENTATION = "implementation"
    CRITIQUE = "critique"
    FINALIZATION = "finalization"
    END = "end"

# Agent prompt templates
AGENT_PROMPTS = {
    WorkflowStage.ORCHESTRATION: """You are the Orchestrator Agent that manages the workflow.
Your job is to track progress and determine which agent should work next based on the current state.

Current workflow state:
- Task: {task_description}
- Status: {status}
- Research completed: {research_completed}
- Analysis completed: {analysis_completed}
- Decision made: {decision_completed}
- Implementation plan created: {implementation_completed}
- Critique provided: {critique_completed}

Based on this state, determine which agent should run next:
- Research Agent: Gathers information (should run first)
- Analysis Agent: Analyzes the research using SWOT framework
- Decision Agent: Makes recommendations based on the analysis
- Implementation Agent: Creates detailed implementation steps
- Critique Agent: Reviews the entire process and suggests improvements
- Finalization: Summarizes everything (should run last)

Respond with only one of: "research", "analysis", "decision", "implementation", "critique", "finalization", or "end" if complete.
""",

    WorkflowStage.RESEARCH: """You are the Research Agent specialized in information gathering.
Your task is to research the following topic thoroughly:

{task_description}

Provide comprehensive research findings that include:
1. Key facts and information relevant to the task
2. Sources of information (be specific where possible)
3. Additional questions that emerged during your research

Format your response as a structured JSON object matching the ResearchFindings schema.
""",

    WorkflowStage.ANALYSIS: """You are the Analysis Agent specialized in critical examination using SWOT analysis.
Based on the following research findings:

{research_json}

Analyze this information for the task: {task_description}

Provide a comprehensive SWOT analysis:
- Strengths: What advantages or positive aspects exist?
- Weaknesses: What limitations or challenges are present?
- Opportunities: What favorable circumstances could be leveraged?
- Threats: What potential obstacles or risks exist?

Also provide a confidence score (0-1) indicating your confidence in this analysis.

Format your response as a structured JSON object matching the AnalysisResult schema.
""",

    WorkflowStage.DECISION: """You are the Decision Agent specialized in making recommendations.
Based on the following research and analysis:

Research: {research_json}
Analysis: {analysis_json}

For the task: {task_description}

Make a decision that includes:
1. A recommended course of action
2. Alternative actions that were considered
3. Rationale for your recommendation
4. Potential risks of this decision
5. A suggested timeline for implementation

Format your response as a structured JSON object matching the Decision schema.
""",

    WorkflowStage.IMPLEMENTATION: """You are the Implementation Agent specialized in execution planning.
Based on the following decision:

{decision_json}

For the task: {task_description}

Create a detailed implementation plan with sequential steps. For each step include:
1. Step number
2. Description of what needs to be done
3. Resources needed for this step
4. Expected outcome of this step
5. Estimated time to complete

Format each step as a structured JSON object matching the ImplementationStep schema.
Return a list of these step objects.
""",

    WorkflowStage.CRITIQUE: """You are the Critique Agent specialized in critical review.
Review the entire process and its outputs:

Task: {task_description}
Research: {research_json}
Analysis: {analysis_json}
Decision: {decision_json}
Implementation Plan: {implementation_json}

Provide a thorough critique that:
1. Identifies any gaps, inconsistencies, or weaknesses in the process
2. Suggests specific improvements for each stage
3. Evaluates whether the final plan effectively addresses the original task
4. Offers alternative perspectives that might have been overlooked

Be constructive but honest in your assessment.
""",

    WorkflowStage.FINALIZATION: """You are the Finalization Agent responsible for summarizing the complete workflow.
Synthesize the entire process into a comprehensive final report:

Task: {task_description}
Research: {research_json}
Analysis: {analysis_json}
Decision: {decision_json}
Implementation Plan: {implementation_json}
Critique: {critique}

Your final report should:
1. Summarize the original task and its context
2. Present key findings from the research phase
3. Highlight the most important points from the analysis
4. Clearly state the recommended decision and rationale
5. Outline the implementation plan with timeline
6. Address the main points from the critique
7. Provide any final observations or recommendations

This report should be comprehensive yet concise, suitable for presentation to stakeholders.
"""
}

# Create agent nodes for each workflow stage
def create_agent_node(stage: WorkflowStage):
    """Create a function for a specific agent node"""
    
    # Define the prompt for this agent
    prompt = ChatPromptTemplate.from_messages([
        ("system", AGENT_PROMPTS[stage]),
        MessagesPlaceholder(variable_name="history")
    ])
    
    # Create output parser based on the agent type
    if stage == WorkflowStage.RESEARCH:
        parser = PydanticOutputParser(pydantic_object=ResearchFindings)
    elif stage == WorkflowStage.ANALYSIS:
        parser = PydanticOutputParser(pydantic_object=AnalysisResult)
    elif stage == WorkflowStage.DECISION:
        parser = PydanticOutputParser(pydantic_object=Decision)
    elif stage == WorkflowStage.IMPLEMENTATION:
        parser = JsonOutputParser()  # Parse as JSON list
    else:
        parser = None  # Some agents don't need structured output parsing
    
    # Create the agent function
    def agent_function(state: Dict[str, Any]) -> Dict[str, Any]:
        # Create a copy of the state to modify
        new_state = state.copy()
        
        # Prepare the agent-specific input variables
        input_variables = {
            "task_description": state["task_description"],
            "history": state["history"]
        }
        
        # Add stage-specific variables
        if stage != WorkflowStage.RESEARCH:
            if state.get("research_findings"):
                input_variables["research_json"] = json.dumps(state["research_findings"])
                
        if stage in [WorkflowStage.DECISION, WorkflowStage.IMPLEMENTATION, 
                     WorkflowStage.CRITIQUE, WorkflowStage.FINALIZATION]:
            if state.get("analysis_result"):
                input_variables["analysis_json"] = json.dumps(state["analysis_result"])
                
        if stage in [WorkflowStage.IMPLEMENTATION, WorkflowStage.CRITIQUE, WorkflowStage.FINALIZATION]:
            if state.get("decision"):
                input_variables["decision_json"] = json.dumps(state["decision"])
                
        if stage in [WorkflowStage.CRITIQUE, WorkflowStage.FINALIZATION]:
            if state.get("implementation_plan"):
                input_variables["implementation_json"] = json.dumps(state["implementation_plan"])
                
        if stage == WorkflowStage.FINALIZATION:
            if state.get("critique"):
                input_variables["critique"] = state["critique"]
                
        if stage == WorkflowStage.ORCHESTRATION:
            input_variables.update({
                "status": state["status"],
                "research_completed": state["research_findings"] is not None,
                "analysis_completed": state["analysis_result"] is not None,
                "decision_completed": state["decision"] is not None,
                "implementation_completed": len(state["implementation_plan"]) > 0,
                "critique_completed": state["critique"] is not None
            })
                
        # Execute the agent
        if parser:
            # For agents with structured output
            chain = prompt | llm | parser
            try:
                result = chain.invoke(input_variables)
                
                # Update state with the structured result
                if stage == WorkflowStage.RESEARCH:
                    new_state["research_findings"] = result.dict()
                elif stage == WorkflowStage.ANALYSIS:
                    new_state["analysis_result"] = result.dict()
                elif stage == WorkflowStage.DECISION:
                    new_state["decision"] = result.dict()
                elif stage == WorkflowStage.IMPLEMENTATION:
                    # Convert list items to dicts if they're already ImplementationStep objects
                    steps = [step.dict() if hasattr(step, "dict") else step for step in result]
                    new_state["implementation_plan"] = steps
                    
                # For debugging and history, also include the string representation
                result_str = str(result)
                
            except Exception as e:
                # Handle parsing errors gracefully
                print(f"Error parsing output for {stage}: {e}")
                # Use the raw output as a fallback
                backup_chain = prompt | llm
                result = backup_chain.invoke(input_variables)
                result_str = result.content
                
                # Try to extract JSON manually as a fallback
                try:
                    import re
                    json_match = re.search(r'```json\n(.*?)\n```', result.content, re.DOTALL)
                    if json_match:
                        extracted_json = json.loads(json_match.group(1))
                        
                        if stage == WorkflowStage.RESEARCH:
                            new_state["research_findings"] = extracted_json
                        elif stage == WorkflowStage.ANALYSIS:
                            new_state["analysis_result"] = extracted_json
                        elif stage == WorkflowStage.DECISION:
                            new_state["decision"] = extracted_json
                        elif stage == WorkflowStage.IMPLEMENTATION:
                            new_state["implementation_plan"] = extracted_json
                except:
                    # If all else fails, store the raw text
                    if stage == WorkflowStage.RESEARCH:
                        new_state["research_findings"] = {"key_facts": [result.content], "sources": [], "additional_questions": []}
                    elif stage == WorkflowStage.ANALYSIS:
                        new_state["analysis_result"] = {"content": result.content}
                    elif stage == WorkflowStage.DECISION:
                        new_state["decision"] = {"content": result.content}
                    elif stage == WorkflowStage.IMPLEMENTATION:
                        new_state["implementation_plan"] = [{"step_number": 1, "description": result.content}]
        else:
            # For agents without structured output
            chain = prompt | llm
            result = chain.invoke(input_variables)
            result_str = result.content
            
            # Update state based on agent type
            if stage == WorkflowStage.CRITIQUE:
                new_state["critique"] = result_str
            elif stage == WorkflowStage.FINALIZATION:
                new_state["final_output"] = result_str
        
        # Update history and status
        human_message = HumanMessage(content=f"Please perform your role as the {stage.value} agent.")
        ai_message = AIMessage(content=result_str)
        
        new_state["history"] = state["history"] + [
            {"role": "human", "content": human_message.content},
            {"role": "ai", "content": ai_message.content}
        ]
        
        new_state["status"] = f"Completed {stage.value}"
        new_state["current_agent"] = stage.value
        
        return new_state
    
    return agent_function

# Define the orchestrator's routing logic
def route_next_agent(state: Dict[str, Any]) -> str:
    """Determine which agent should run next based on the current state"""
    
    # If we're in the orchestration phase, extract the decision
    if state["current_agent"] == WorkflowStage.ORCHESTRATION.value:
        # Get the last message from the orchestrator
        last_message = state["history"][-1] if state["history"] else None
        if last_message and last_message.get("role") == "ai":
            next_agent = last_message["content"].strip().lower()
            
            # Map the text decision to a workflow stage
            if "research" in next_agent:
                return WorkflowStage.RESEARCH.value
            elif "analysis" in next_agent:
                return WorkflowStage.ANALYSIS.value
            elif "decision" in next_agent:
                return WorkflowStage.DECISION.value
            elif "implementation" in next_agent:
                return WorkflowStage.IMPLEMENTATION.value
            elif "critique" in next_agent:
                return WorkflowStage.CRITIQUE.value
            elif "finalization" in next_agent:
                return WorkflowStage.FINALIZATION.value
            elif "end" in next_agent or "complete" in next_agent or "finished" in next_agent:
                return END
    
    # Default progression logic (if not from orchestrator)
    # This provides a linear fallback path
    if state["research_findings"] is None:
        return WorkflowStage.RESEARCH.value
    elif state["analysis_result"] is None:
        return WorkflowStage.ANALYSIS.value
    elif state["decision"] is None:
        return WorkflowStage.DECISION.value
    elif not state["implementation_plan"]:
        return WorkflowStage.IMPLEMENTATION.value
    elif state["critique"] is None:
        return WorkflowStage.CRITIQUE.value
    elif state["final_output"] is None:
        return WorkflowStage.FINALIZATION.value
    else:
        # If everything is complete, return to orchestrator for final decision
        return WorkflowStage.ORCHESTRATION.value

# Create all agent nodes
orchestrator_node = create_agent_node(WorkflowStage.ORCHESTRATION)
research_node = create_agent_node(WorkflowStage.RESEARCH)
analysis_node = create_agent_node(WorkflowStage.ANALYSIS)
decision_node = create_agent_node(WorkflowStage.DECISION)
implementation_node = create_agent_node(WorkflowStage.IMPLEMENTATION)
critique_node = create_agent_node(WorkflowStage.CRITIQUE)
finalization_node = create_agent_node(WorkflowStage.FINALIZATION)

# Build the workflow graph
workflow = StateGraph(TaskState)

# Add all nodes
workflow.add_node(WorkflowStage.ORCHESTRATION.value, orchestrator_node)
workflow.add_node(WorkflowStage.RESEARCH.value, research_node)
workflow.add_node(WorkflowStage.ANALYSIS.value, analysis_node)
workflow.add_node(WorkflowStage.DECISION.value, decision_node)
workflow.add_node(WorkflowStage.IMPLEMENTATION.value, implementation_node)
workflow.add_node(WorkflowStage.CRITIQUE.value, critique_node)
workflow.add_node(WorkflowStage.FINALIZATION.value, finalization_node)

# Add conditional edges from the orchestrator to all other nodes
workflow.add_conditional_edges(
    WorkflowStage.ORCHESTRATION.value,
    route_next_agent
)

# Add edges from all agent nodes back to the orchestrator
workflow.add_edge(WorkflowStage.RESEARCH.value, WorkflowStage.ORCHESTRATION.value)
workflow.add_edge(WorkflowStage.ANALYSIS.value, WorkflowStage.ORCHESTRATION.value)
workflow.add_edge(WorkflowStage.DECISION.value, WorkflowStage.ORCHESTRATION.value)
workflow.add_edge(WorkflowStage.IMPLEMENTATION.value, WorkflowStage.ORCHESTRATION.value)
workflow.add_edge(WorkflowStage.CRITIQUE.value, WorkflowStage.ORCHESTRATION.value)
workflow.add_edge(WorkflowStage.FINALIZATION.value, WorkflowStage.ORCHESTRATION.value)

# Compile the graph
memory = MemorySaver()
graph = workflow.compile(checkpointer=memory)

# Function to process a task through the workflow
def process_task(task_description: str) -> Dict[str, Any]:
    """
    Process a task through the multi-agent workflow
    
    Args:
        task_description: Description of the task to process
        
    Returns:
        The final state with all agent outputs
    """
    # Initialize state
    initial_state = TaskState(
        task_description=task_description,
        status="initialized",
        current_agent=WorkflowStage.ORCHESTRATION.value,
        history=[],
        research_findings=None,
        analysis_result=None,
        decision=None,
        implementation_plan=[],
        critique=None,
        final_output=None
    ).dict()
    
    # Execute the graph
    result = graph.invoke(initial_state)
    
    return result

# Command-line interface
if __name__ == "__main__":
    task_description = input("Enter a complex task to process through the multi-agent workflow: ")
    
    print("\n==== PROCESSING TASK THROUGH MULTI-AGENT WORKFLOW ====\n")
    print(f"Task: {task_description}")
    print("\nPlease wait while the agents work on this task...\n")
    
    result = process_task(task_description)
    
    print("\n==== WORKFLOW COMPLETE ====\n")
    print("FINAL OUTPUT:")
    print("-" * 80)
    print(result["final_output"])
    print("-" * 80)
    
    # Offer to show detailed outputs from each agent
    show_details = input("\nWould you like to see detailed outputs from each agent? (y/n): ").lower()
    
    if show_details == 'y':
        if result["research_findings"]:
            print("\n==== RESEARCH FINDINGS ====")
            for fact in result["research_findings"]["key_facts"]:
                print(f"- {fact}")
        
        if result["analysis_result"]:
            print("\n==== ANALYSIS (SWOT) ====")
            print("Strengths:")
            for strength in result["analysis_result"]["strengths"]:
                print(f"- {strength}")
            print("\nWeaknesses:")
            for weakness in result["analysis_result"]["weaknesses"]:
                print(f"- {weakness}")
        
        if result["decision"]:
            print("\n==== DECISION ====")
            print(f"Recommendation: {result['decision']['recommended_action']}")
            print(f"Rationale: {result['decision']['rationale']}")
        
        if result["implementation_plan"]:
            print("\n==== IMPLEMENTATION PLAN ====")
            for step in result["implementation_plan"]:
                print(f"{step['step_number']}. {step['description']}")
        
        if result["critique"]:
            print("\n==== CRITIQUE ====")
            print(result["critique"])
```

## Practical Exercise: Building a Decision-Making Assistant with LangGraph

Let's build a practical assistant that helps with complex decision-making processes by guiding users through structured steps:

```python
import os
import streamlit as st
from typing import Dict, List, Tuple, Any, TypedDict, Literal, Optional, Union
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import json
from langgraph.graph import StateGraph, END
from langgraph.checkpoint import MemorySaver

# Load environment variables
load_dotenv()

# Initialize Streamlit interface
st.set_page_config(
    page_title="Decision-Making Assistant",
    page_icon="ðŸ¤”",
    layout="wide"
)

# State definitions
class Decision(TypedDict):
    messages: List[Dict[str, str]]
    criteria: Optional[List[Dict[str, Union[str, int]]]]
    options: Optional[List[Dict[str, Any]]]
    analysis: Optional[Dict[str, Any]]
    recommendation: Optional[str]
    current_stage: str
    user_input: Optional[str]
    awaiting_user_input: bool

# Decision stages
STAGES = {
    "DEFINE_PROBLEM": "define_problem",
    "COLLECT_CRITERIA": "collect_criteria",
    "GENERATE_OPTIONS": "generate_options",
    "ANALYZE_OPTIONS": "analyze_options",
    "MAKE_RECOMMENDATION": "make_recommendation",
    "REFLECT": "reflect"
}

# Agent definitions
def get_llm():
    """Initialize the LLM with appropriate settings"""
    return ChatOpenAI(
        model="gpt-4o",
        temperature=0.7,
        api_key=os.getenv("OPENAI_API_KEY")
    )

# Define agent nodes for each decision stage
def create_define_problem_node():
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a Decision-Making Assistant. Your first task is to help the user clearly define the decision they need to make.
Ask questions to understand:
1. What is the specific decision that needs to be made?
2. Why is this decision important?
3. What is the timeline for making this decision?
4. Who will be affected by this decision?
5. What are the constraints or limitations?

Guide the user to articulate a clear, specific decision statement that can be analyzed."""),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    def define_problem_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        if state["user_input"]:
            # Add user input to messages
            messages.append({"role": "user", "content": state["user_input"]})
            
            # Reset user input
            new_state["user_input"] = None
            
            # Determine if we have a well-defined problem
            last_messages = messages[-4:] if len(messages) >= 4 else messages
            user_messages = [msg for msg in last_messages if msg["role"] == "user"]
            
            # If user has provided enough context (at least 2 responses)
            if len(user_messages) >= 2:
                # Check if ready to move to next stage
                final_prompt = prompt.format(messages=messages) 
                response = llm.invoke(final_prompt)
                
                # Add response to messages
                messages.append({"role": "assistant", "content": response.content})
                
                # If the problem seems well defined, ask if ready to move to criteria
                if "Is this decision statement clear?" in response.content or "Would you like to move on" in response.content:
                    new_state["awaiting_user_input"] = True
                    new_state["current_stage"] = STAGES["COLLECT_CRITERIA"]
                    return new_state
            
            # Otherwise continue with problem definition
            chain = prompt | llm
            response = chain.invoke({"messages": messages})
            
            # Add response to messages
            messages.append({"role": "assistant", "content": response.content})
            new_state["messages"] = messages
            new_state["awaiting_user_input"] = True
        
        return new_state
    
    return define_problem_agent

def create_collect_criteria_node():
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a Decision-Making Assistant. Now that the decision is defined, help the user identify key criteria for evaluating options.
For each criterion, determine:
1. Name of the criterion
2. Description of what it means
3. Weight/importance (1-10 scale)

Aim to gather 3-6 criteria that will be used to evaluate options. Suggest common criteria for this type of decision, but encourage the user to customize them.
When finished collecting criteria, ask if they're ready to move on to generating options."""),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    def collect_criteria_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        if state["user_input"]:
            # Add user input to messages
            messages.append({"role": "user", "content": state["user_input"]})
            
            # Reset user input
            new_state["user_input"] = None
            
            # Check if the user wants to move to the next stage
            if "next" in state["user_input"].lower() or "done" in state["user_input"].lower() or "continue" in state["user_input"].lower():
                # Extract criteria from conversation
                criteria_prompt = ChatPromptTemplate.from_messages([
                    ("system", """Extract the decision criteria from this conversation. Format as a JSON array of objects with:
- name: The name of the criterion
- description: Description of what it measures
- weight: Importance on a scale of 1-10

Return ONLY the JSON array with no other text."""),
                    MessagesPlaceholder(variable_name="messages")
                ])
                
                criteria_chain = criteria_prompt | llm
                criteria_response = criteria_chain.invoke({"messages": messages})
                
                try:
                    # Try to extract JSON
                    import re
                    json_match = re.search(r'```json\n(.*?)\n```', criteria_response.content, re.DOTALL)
                    if json_match:
                        criteria_json = json.loads(json_match.group(1))
                    else:
                        criteria_json = json.loads(criteria_response.content)
                    
                    new_state["criteria"] = criteria_json
                except:
                    # Fallback if JSON extraction fails
                    new_state["criteria"] = [
                        {"name": "Extracted criteria", "description": "See conversation for details", "weight": 5}
                    ]
                
                # Move to next stage
                new_state["current_stage"] = STAGES["GENERATE_OPTIONS"]
                messages.append({"role": "assistant", "content": "Great! Now let's identify possible options for this decision."})
                new_state["messages"] = messages
                new_state["awaiting_user_input"] = True
                return new_state
            
            # Continue collecting criteria
            chain = prompt | llm
            response = chain.invoke({"messages": messages})
            
            # Add response to messages
            messages.append({"role": "assistant", "content": response.content})
            new_state["messages"] = messages
            new_state["awaiting_user_input"] = True
        
        return new_state
    
    return collect_criteria_agent

def create_generate_options_node():
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a Decision-Making Assistant. Now help the user generate potential options for the decision.
For each option:
1. Name the option clearly
2. Describe it briefly
3. Identify initial pros and cons

Aim to generate 3-5 distinct options. Encourage creative thinking and suggest options the user might not have considered.
When the user is satisfied with the options, ask if they want to move to analyzing these options against their criteria."""),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    def generate_options_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        if state["user_input"]:
            # Add user input to messages
            messages.append({"role": "user", "content": state["user_input"]})
            
            # Reset user input
            new_state["user_input"] = None
            
            # Check if the user wants to move to the next stage
            if "next" in state["user_input"].lower() or "done" in state["user_input"].lower() or "analyze" in state["user_input"].lower():
                # Extract options from conversation
                options_prompt = ChatPromptTemplate.from_messages([
                    ("system", """Extract the decision options from this conversation. Format as a JSON array of objects with:
- name: The name of the option
- description: Brief description
- pros: Array of pros
- cons: Array of cons

Return ONLY the JSON array with no other text."""),
                    MessagesPlaceholder(variable_name="messages")
                ])
                
                options_chain = options_prompt | llm
                options_response = options_chain.invoke({"messages": messages})
                
                try:
                    # Try to extract JSON
                    import re
                    json_match = re.search(r'```json\n(.*?)\n```', options_response.content, re.DOTALL)
                    if json_match:
                        options_json = json.loads(json_match.group(1))
                    else:
                        options_json = json.loads(options_response.content)
                    
                    new_state["options"] = options_json
                except:
                    # Fallback if JSON extraction fails
                    new_state["options"] = [
                        {"name": "Extracted options", "description": "See conversation for details", 
                         "pros": ["See discussion"], "cons": ["See discussion"]}
                    ]
                
                # Move to next stage
                new_state["current_stage"] = STAGES["ANALYZE_OPTIONS"]
                messages.append({"role": "assistant", "content": "Now I'll analyze each option against your criteria to help with your decision."})
                new_state["messages"] = messages
                new_state["awaiting_user_input"] = False  # No user input needed for analysis
                return new_state
            
            # Continue generating options
            chain = prompt | llm
            response = chain.invoke({"messages": messages})
            
            # Add response to messages
            messages.append({"role": "assistant", "content": response.content})
            new_state["messages"] = messages
            new_state["awaiting_user_input"] = True
        
        return new_state
    
    return generate_options_agent

def create_analyze_options_node():
    llm = get_llm()
    
    def analyze_options_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        # Create analysis prompt with options and criteria
        criteria = state.get("criteria", [])
        options = state.get("options", [])
        
        analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", f"""You are a Decision-Making Assistant. Analyze each option against each criterion.
            
Decision Options:
{json.dumps(options, indent=2)}

Decision Criteria:
{json.dumps(criteria, indent=2)}

For each option, score how well it meets each criterion on a scale of 1-10.
Also calculate a weighted score based on the criterion weights.
Provide a summary of the strengths and weaknesses of each option.

Format your analysis as JSON with:
1. scores: A matrix of scores for each option against each criterion
2. weighted_totals: Total weighted score for each option
3. rankings: Options ranked from best to worst
4. summary: Brief explanation of the results

Return ONLY the JSON with no other text."""),
        ])
        
        # Get analysis from LLM
        analysis_chain = analysis_prompt | llm
        analysis_response = analysis_chain.invoke({})
        
        try:
            # Try to extract JSON
            import re
            json_match = re.search(r'```json\n(.*?)\n```', analysis_response.content, re.DOTALL)
            if json_match:
                analysis_json = json.loads(json_match.group(1))
            else:
                analysis_json = json.loads(analysis_response.content)
            
            new_state["analysis"] = analysis_json
        except:
            # Fallback if JSON extraction fails
            new_state["analysis"] = {
                "summary": analysis_response.content,
                "scores": "See summary",
                "weighted_totals": "See summary"
            }
        
        # Create a message explaining the analysis
        explanation_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a Decision-Making Assistant. Explain the analysis results in a clear, concise way.
Highlight the top-performing options and explain why they scored well.
Mention any notable strengths or weaknesses.
Keep your explanation friendly and helpful."""),
            ("user", f"Explain this analysis in plain language: {json.dumps(new_state['analysis'])}")
        ])
        
        explanation_chain = explanation_prompt | llm
        explanation = explanation_chain.invoke({})
        
        # Add explanation to messages
        messages.append({"role": "assistant", "content": explanation.content})
        new_state["messages"] = messages
        
        # Move to next stage
        new_state["current_stage"] = STAGES["MAKE_RECOMMENDATION"]
        new_state["awaiting_user_input"] = False  # No user input needed for recommendation
        
        return new_state
    
    return analyze_options_agent

def create_make_recommendation_node():
    llm = get_llm()
    
    def make_recommendation_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        # Get analysis and create recommendation
        analysis = state.get("analysis", {})
        options = state.get("options", [])
        criteria = state.get("criteria", [])
        
        recommendation_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a Decision-Making Assistant. Based on the analysis, make a thoughtful recommendation.

Provide:
1. The recommended option and why it's the best choice
2. Any caveats or conditions to consider
3. Potential next steps for implementing this decision
4. Alternative options if the recommended one isn't feasible

Be decisive but acknowledge uncertainty where appropriate."""),
            ("user", f"""
Decision Options: {json.dumps(options)}
Decision Criteria: {json.dumps(criteria)}
Analysis Results: {json.dumps(analysis)}

What is your recommendation based on this analysis?
""")
        ])
        
        # Get recommendation from LLM
        recommendation_chain = recommendation_prompt | llm
        recommendation = recommendation_chain.invoke({})
        
        # Store recommendation
        new_state["recommendation"] = recommendation.content
        
        # Add recommendation to messages
        messages.append({"role": "assistant", "content": recommendation.content})
        messages.append({"role": "assistant", "content": "Would you like to reflect on this recommendation or revisit any part of the decision process?"})
        new_state["messages"] = messages
        
        # Move to next stage
        new_state["current_stage"] = STAGES["REFLECT"]
        new_state["awaiting_user_input"] = True
        
        return new_state
    
    return make_recommendation_agent

def create_reflect_node():
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a Decision-Making Assistant helping the user reflect on the decision process.
Ask questions like:
- How do you feel about the recommended option?
- Are there any aspects we didn't consider?
- What concerns do you still have?
- What are your next steps for implementing this decision?

Help the user gain clarity and confidence in their decision. If they want to revisit any part of the process, guide them accordingly."""),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    def reflect_agent(state: Decision) -> Decision:
        new_state = state.copy()
        messages = state["messages"]
        
        if state["user_input"]:
            # Add user input to messages
            messages.append({"role": "user", "content": state["user_input"]})
            
            # Reset user input
            new_state["user_input"] = None
            
            # Check if user wants to end the session
            if "end" in state["user_input"].lower() or "finish" in state["user_input"].lower() or "thank" in state["user_input"].lower():
                # Add final message
                final_message = "Thank you for using the Decision-Making Assistant. I hope this process has been helpful in making your decision. Feel free to revisit this decision or start a new one whenever you need assistance!"
                messages.append({"role": "assistant", "content": final_message})
                new_state["messages"] = messages
                new_state["awaiting_user_input"] = False
                return new_state
            
            # Generate reflection response
            chain = prompt | llm
            response = chain.invoke({"messages": messages})
            
            # Add response to messages
            messages.append({"role": "assistant", "content": response.content})
            new_state["messages"] = messages
            new_state["awaiting_user_input"] = True
        
        return new_state
    
    return reflect_agent

# Create conditional edge function to determine next step
def router(state: Decision) -> str:
    # If awaiting user input, stay in current stage
    if state["awaiting_user_input"] and not state["user_input"]:
        return state["current_stage"]
    
    # Otherwise, follow the current stage setting
    return state["current_stage"]

# Build the workflow graph
def build_decision_graph():
    workflow = StateGraph(Decision)
    
    # Add nodes
    workflow.add_node(STAGES["DEFINE_PROBLEM"], create_define_problem_node())
    workflow.add_node(STAGES["COLLECT_CRITERIA"], create_collect_criteria_node())
    workflow.add_node(STAGES["GENERATE_OPTIONS"], create_generate_options_node())
    workflow.add_node(STAGES["ANALYZE_OPTIONS"], create_analyze_options_node())
    workflow.add_node(STAGES["MAKE_RECOMMENDATION"], create_make_recommendation_node())
    workflow.add_node(STAGES["REFLECT"], create_reflect_node())
    
    # Add conditional edges
    workflow.add_conditional_edges("", router)
    
    # Set entry point
    workflow.set_entry_point(STAGES["DEFINE_PROBLEM"])
    
    return workflow.compile()

# Streamlit app logic
def main():
    st.title("ðŸ¤” Decision-Making Assistant")
    st.subheader("A step-by-step guide to making better decisions")
    
    # Initialize session state
    if "graph" not in st.session_state:
        st.session_state.graph = build_decision_graph()
    
    if "state" not in st.session_state:
        st.session_state.state = {
            "messages": [],
            "criteria": None,
            "options": None,
            "analysis": None,
            "recommendation": None,
            "current_stage": STAGES["DEFINE_PROBLEM"],
            "user_input": "I need help making a decision.",
            "awaiting_user_input": False
        }
    
    if "conversation_started" not in st.session_state:
        st.session_state.conversation_started = False
    
    # Button to start new decision
    if not st.session_state.conversation_started:
        st.write("This assistant will guide you through a structured decision-making process:")
        st.markdown("""
        1. **Define the problem** - What decision are you trying to make?
        2. **Establish criteria** - What factors are important in this decision?
        3. **Generate options** - What are your possible choices?
        4. **Analyze options** - How does each option perform on your criteria?
        5. **Make a recommendation** - What's the best choice based on the analysis?
        6. **Reflect** - Are you satisfied with the recommendation?
        """)
        
        if st.button("Start New Decision"):
            st.session_state.conversation_started = True
            st.session_state.state = {
                "messages": [],
                "criteria": None,
                "options": None,
                "analysis": None,
                "recommendation": None,
                "current_stage": STAGES["DEFINE_PROBLEM"],
                "user_input": "I need help making a decision.",
                "awaiting_user_input": False
            }
            st.experimental_rerun()
    
    # Display status
    if st.session_state.conversation_started:
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            stage_index = list(STAGES.values()).index(st.session_state.state["current_stage"])
            current_stage_name = list(STAGES.keys())[stage_index]
            st.info(f"Current stage: {current_stage_name}")
        
        # Conversation area
        st.subheader("Conversation")
        
        # Run the graph if needed
        if not st.session_state.state["awaiting_user_input"]:
            # Execute the graph with current state
            st.session_state.state = st.session_state.graph.invoke(st.session_state.state)
        
        # Display conversation history
        messages = st.session_state.state["messages"]
        for msg in messages:
            if msg["role"] == "assistant":
                with st.chat_message("assistant"):
                    st.write(msg["content"])
            elif msg["role"] == "user":
                with st.chat_message("user"):
                    st.write(msg["content"])
        
        # User input
        if st.session_state.state["awaiting_user_input"]:
            user_input = st.chat_input("Your response")
            if user_input:
                with st.chat_message("user"):
                    st.write(user_input)
                
                # Update state with user input
                st.session_state.state["user_input"] = user_input
                st.session_state.state["awaiting_user_input"] = False
                
                # Run the graph with updated state
                st.session_state.state = st.session_state.graph.invoke(st.session_state.state)
                
                # Force a rerun to update the UI
                st.experimental_rerun()
        
        # Display results if available
        if st.session_state.state["current_stage"] in [STAGES["ANALYZE_OPTIONS"], STAGES["MAKE_RECOMMENDATION"], STAGES["REFLECT"]]:
            st.subheader("Decision Analysis")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.session_state.state["criteria"]:
                    st.write("**Decision Criteria**")
                    for criterion in st.session_state.state["criteria"]:
                        st.write(f"- **{criterion['name']}** (Weight: {criterion['weight']})")
            
            with col2:
                if st.session_state.state["options"]:
                    st.write("**Options Considered**")
                    for option in st.session_state.state["options"]:
                        st.write(f"- **{option['name']}**")
            
            # Show analysis if available
            if st.session_state.state["analysis"]:
                with st.expander("View Detailed Analysis", expanded=False):
                    analysis = st.session_state.state["analysis"]
                    
                    if "weighted_totals" in analysis and isinstance(analysis["weighted_totals"], dict):
                        st.write("**Option Scores**")
                        scores = {k: v for k, v in analysis["weighted_totals"].items()}
                        st.bar_chart(scores)
                    
                    if "summary" in analysis:
                        st.write("**Analysis Summary**")
                        st.write(analysis["summary"])
        
        # Option to restart
        if st.button("Start New Decision"):
            st.session_state.state = {
                "messages": [],
                "criteria": None,
                "options": None,
                "analysis": None,
                "recommendation": None,
                "current_stage": STAGES["DEFINE_PROBLEM"],
                "user_input": "I need help making a decision.",
                "awaiting_user_input": False
            }
            st.experimental_rerun()

if __name__ == "__main__":
    main()
```

To run this application:
1. Create a `.env` file with your API key:
```
OPENAI_API_KEY=your_openai_api_key
```

2. Install dependencies:
```
pip install streamlit langchain langchain-openai langgraph python-dotenv
```

3. Run the app:
```
streamlit run decision_assistant.py
```

## Conclusion

Orchestrating multiple agents through LangGraph represents a significant advancement in building sophisticated AI applications. By structuring workflows as directed graphs with specialized agent nodes, we can create systems that combine the strengths of different reasoning approaches and domain expertise.

Key insights from this module include:

1. **Advanced Workflow Design**: LangGraph enables the creation of state machines with complex control flows, allowing for dynamic, adaptive agent interactions that traditional sequential chains cannot achieve.

2. **Role Specialization**: By assigning distinct roles and responsibilities to different agents, we can develop systems that leverage specialized capabilities for different aspects of a task.

3. **State Management**: Maintaining a persistent state across multiple interactions enables long-running, multi-turn conversations with memory and context awareness.

4. **Decision Logic**: Implementing conditional branching and routing provides sophisticated decision-making capabilities that respond appropriately to evolving scenarios.

5. **Scalability**: The modular nature of LangGraph allows for incremental expansion of agent capabilities and workflow complexity while maintaining maintainable code.

The practical applications for these multi-agent systems are extensive, from complex decision support tools to creative collaborations between specialized agents. As LLM technology continues to evolve, the orchestration of multiple agents with complementary skills will likely become a standard architectural pattern for advanced AI applications.

In building these systems, considering how agents communicate, maintaining shared context, and designing appropriate fallback mechanisms are crucial for creating robust, reliable multi-agent applications. The examples provided demonstrate effective patterns for implementing these principles in production-ready applications.