<small>Claude Sonnet 4</small>
# 07. Semantic Kernel and Autogen

## Key Terms

**Semantic Kernel**: Microsoft's open-source SDK for building AI applications that combines traditional programming languages with the latest AI models. It provides a middleware layer between AI models and application code, enabling seamless integration of AI capabilities into existing applications.

**Planner**: A component in Semantic Kernel that automatically generates and executes multi-step plans to achieve complex goals by decomposing tasks into smaller, manageable steps and selecting appropriate skills/functions.

**Memory**: Persistent storage system for AI agents that maintains context, learned information, and conversation history across sessions, enabling agents to build upon previous interactions and maintain long-term understanding.

**Multi-Agent System**: A distributed system of multiple autonomous AI agents that interact, collaborate, and coordinate to solve complex problems that are beyond the capability of individual agents.

**Autogen**: Microsoft's framework for creating multi-agent conversational AI systems where different agents with specialized roles can collaborate through structured conversations to solve complex tasks.

**Agent Interaction Protocol**: The communication framework that defines how agents exchange information, coordinate actions, and resolve conflicts in multi-agent environments.

**Group Chat**: A coordination mechanism in Autogen where multiple agents participate in structured conversations with defined roles, turn-taking protocols, and termination conditions.

## Planning, Memory, and Agent Interactions

Semantic Kernel provides a sophisticated architecture for building AI applications with advanced planning capabilities and persistent memory management. The framework's strength lies in its ability to orchestrate complex workflows while maintaining context across extended interactions.

### Advanced Semantic Kernel Implementation

````python
import asyncio
import os
import json
from typing import Dict, List, Any, Optional, Callable, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import semantic_kernel as sk
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding
from semantic_kernel.connectors.memory.chroma import ChromaMemoryStore
from semantic_kernel.core_plugins import (
    TextMemoryPlugin,
    TimePlugin,
    MathPlugin,
    FileIOPlugin
)
from semantic_kernel.planning import BasicPlanner, ActionPlanner, SequentialPlanner
from semantic_kernel.planning.plan import Plan
from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter
from semantic_kernel.orchestration.sk_context import SKContext
import sqlite3
import redis
from dotenv import load_dotenv

load_dotenv()

class TaskPriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class AgentTask:
    id: str
    description: str
    priority: TaskPriority
    assigned_agent: Optional[str] = None
    dependencies: List[str] = field(default_factory=list)
    status: str = "pending"
    created_at: datetime = field(default_factory=datetime.now)
    deadline: Optional[datetime] = None
    context: Dict[str, Any] = field(default_factory=dict)

class AdvancedSemanticKernelAgent:
    """Advanced Semantic Kernel agent with planning and memory capabilities"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        
        # Initialize Semantic Kernel
        self.kernel = sk.Kernel()
        
        # Setup AI connectors
        self._setup_ai_connectors()
        
        # Setup memory systems
        self._setup_memory_systems()
        
        # Register plugins and skills
        self._register_plugins()
        
        # Initialize planners
        self._setup_planners()
        
        # Task management
        self.active_tasks: Dict[str, AgentTask] = {}
        self.completed_tasks: List[AgentTask] = []
        
        # Agent state
        self.current_plan: Optional[Plan] = None
        self.execution_context: Dict[str, Any] = {}
        
    def _setup_ai_connectors(self):
        """Setup AI service connectors"""
        
        # OpenAI Chat Completion
        chat_service = OpenAIChatCompletion(
            service_id="openai_chat",
            ai_model_id="gpt-4-turbo-preview",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        self.kernel.add_chat_service("openai_chat", chat_service)
        
        # OpenAI Embeddings
        embedding_service = OpenAITextEmbedding(
            service_id="openai_embedding",
            ai_model_id="text-embedding-3-large",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        self.kernel.add_text_embedding_generation_service("openai_embedding", embedding_service)
    
    def _setup_memory_systems(self):
        """Setup multiple memory systems for different purposes"""
        
        # Vector memory for semantic search
        memory_store = ChromaMemoryStore(persist_directory="./chroma_memory")
        self.kernel.register_memory_store(memory_store)
        
        # Import TextMemoryPlugin
        memory_plugin = self.kernel.import_plugin(TextMemoryPlugin(), "memory")
        
        # Setup Redis for session memory
        self.redis_client = redis.Redis(
            host=self.config.get('redis_host', 'localhost'),
            port=self.config.get('redis_port', 6379),
            password=self.config.get('redis_password'),
            decode_responses=True
        )
        
        # Setup SQLite for persistent task storage
        self.db_path = f"agent_data_{self.agent_id}.db"
        self._init_database()
    
    def _init_database(self):
        """Initialize SQLite database for persistent storage"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS agent_tasks (
                id TEXT PRIMARY KEY,
                description TEXT NOT NULL,
                priority INTEGER NOT NULL,
                assigned_agent TEXT,
                dependencies TEXT,
                status TEXT NOT NULL,
                created_at TIMESTAMP,
                deadline TIMESTAMP,
                context TEXT,
                completed_at TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS agent_memories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                agent_id TEXT NOT NULL,
                memory_type TEXT NOT NULL,
                key_path TEXT NOT NULL,
                content TEXT NOT NULL,
                embedding_vector BLOB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                accessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                access_count INTEGER DEFAULT 1
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS agent_interactions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_agent TEXT NOT NULL,
                target_agent TEXT NOT NULL,
                interaction_type TEXT NOT NULL,
                message_content TEXT NOT NULL,
                response_content TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                success BOOLEAN DEFAULT TRUE
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def _register_plugins(self):
        """Register built-in and custom plugins"""
        
        # Import built-in plugins
        self.kernel.import_plugin(TimePlugin(), "time")
        self.kernel.import_plugin(MathPlugin(), "math")
        self.kernel.import_plugin(FileIOPlugin(), "file")
        
        # Register custom skills
        self._register_database_skills()
        self._register_analysis_skills()
        self._register_communication_skills()
    
    def _register_database_skills(self):
        """Register database-related skills"""
        
        @sk_function(
            description="Execute SQL query on the database",
            name="execute_query"
        )
        @sk_function_context_parameter(
            name="query",
            description="SQL query to execute"
        )
        @sk_function_context_parameter(
            name="database",
            description="Target database name",
            default_value="main"
        )
        async def execute_sql_query(context: SKContext) -> str:
            """Execute SQL query with safety checks"""
            query = context["query"]
            database = context.get("database", "main")
            
            try:
                # Basic SQL injection protection
                forbidden_keywords = ["DROP", "DELETE", "TRUNCATE", "ALTER", "CREATE"]
                if any(keyword in query.upper() for keyword in forbidden_keywords):
                    return "Error: Query contains forbidden operations"
                
                # Simulate database execution
                mock_results = [
                    {"id": 1, "name": "Sample Data 1", "value": 100},
                    {"id": 2, "name": "Sample Data 2", "value": 200}
                ]
                
                return json.dumps({
                    "query": query,
                    "database": database,
                    "results": mock_results,
                    "row_count": len(mock_results)
                })
                
            except Exception as e:
                return f"Database error: {str(e)}"
        
        # Register the skill
        database_skill = self.kernel.import_skill({
            "execute_query": execute_sql_query
        }, "database")
    
    def _register_analysis_skills(self):
        """Register data analysis skills"""
        
        @sk_function(
            description="Perform statistical analysis on numerical data",
            name="analyze_data"
        )
        @sk_function_context_parameter(
            name="data",
            description="Numerical data as JSON array"
        )
        @sk_function_context_parameter(
            name="analysis_type",
            description="Type of analysis: basic, trend, correlation",
            default_value="basic"
        )
        async def analyze_numerical_data(context: SKContext) -> str:
            """Perform statistical analysis"""
            try:
                data = json.loads(context["data"])
                analysis_type = context.get("analysis_type", "basic")
                
                if not isinstance(data, list) or not all(isinstance(x, (int, float)) for x in data):
                    return "Error: Data must be a list of numbers"
                
                import statistics
                
                basic_stats = {
                    "count": len(data),
                    "mean": statistics.mean(data),
                    "median": statistics.median(data),
                    "std_dev": statistics.stdev(data) if len(data) > 1 else 0,
                    "min": min(data),
                    "max": max(data)
                }
                
                if analysis_type == "trend":
                    # Simple trend analysis
                    if len(data) >= 2:
                        trend = "increasing" if data[-1] > data[0] else "decreasing"
                        basic_stats["trend"] = trend
                        basic_stats["change_percent"] = ((data[-1] - data[0]) / data[0]) * 100
                
                return json.dumps(basic_stats, indent=2)
                
            except Exception as e:
                return f"Analysis error: {str(e)}"
        
        analysis_skill = self.kernel.import_skill({
            "analyze_data": analyze_numerical_data
        }, "analysis")
    
    def _register_communication_skills(self):
        """Register inter-agent communication skills"""
        
        @sk_function(
            description="Send message to another agent",
            name="send_message"
        )
        @sk_function_context_parameter(
            name="target_agent",
            description="Target agent identifier"
        )
        @sk_function_context_parameter(
            name="message",
            description="Message content"
        )
        @sk_function_context_parameter(
            name="message_type",
            description="Type of message: request, response, notification",
            default_value="request"
        )
        async def send_agent_message(context: SKContext) -> str:
            """Send message to another agent"""
            target_agent = context["target_agent"]
            message = context["message"]
            message_type = context.get("message_type", "request")
            
            # Log interaction
            await self._log_interaction(
                source_agent=self.agent_id,
                target_agent=target_agent,
                interaction_type=message_type,
                message_content=message
            )
            
            return f"Message sent to {target_agent}: {message}"
        
        communication_skill = self.kernel.import_skill({
            "send_message": send_agent_message
        }, "communication")
    
    def _setup_planners(self):
        """Setup different types of planners"""
        
        # Basic planner for simple tasks
        self.basic_planner = BasicPlanner()
        
        # Sequential planner for multi-step tasks
        self.sequential_planner = SequentialPlanner(self.kernel)
        
        # Action planner for complex goal-oriented tasks
        self.action_planner = ActionPlanner(self.kernel)
    
    async def create_and_execute_plan(self, goal: str, planner_type: str = "sequential") -> Dict[str, Any]:
        """Create and execute a plan to achieve the given goal"""
        
        planners = {
            "basic": self.basic_planner,
            "sequential": self.sequential_planner,
            "action": self.action_planner
        }
        
        if planner_type not in planners:
            planner_type = "sequential"
        
        planner = planners[planner_type]
        
        try:
            # Create plan
            if planner_type == "basic":
                plan = await planner.create_plan_async(goal, self.kernel)
            else:
                plan = await planner.create_plan_async(goal)
            
            self.current_plan = plan
            
            # Execute plan
            execution_start = datetime.now()
            context = self.kernel.create_new_context()
            context.variables["goal"] = goal
            
            result = await plan.invoke_async(context)
            
            execution_time = (datetime.now() - execution_start).total_seconds()
            
            # Store execution results
            execution_result = {
                "goal": goal,
                "planner_type": planner_type,
                "plan_steps": len(plan._steps) if hasattr(plan, '_steps') else 1,
                "execution_time": execution_time,
                "result": str(result),
                "success": True,
                "timestamp": datetime.now().isoformat()
            }
            
            # Save to memory
            await self._store_execution_memory(execution_result)
            
            return execution_result
            
        except Exception as e:
            error_result = {
                "goal": goal,
                "planner_type": planner_type,
                "error": str(e),
                "success": False,
                "timestamp": datetime.now().isoformat()
            }
            
            return error_result
    
    async def manage_task(self, task: AgentTask) -> Dict[str, Any]:
        """Manage and execute individual tasks"""
        
        self.active_tasks[task.id] = task
        
        try:
            # Check dependencies
            if not await self._check_task_dependencies(task):
                return {
                    "task_id": task.id,
                    "status": "waiting_dependencies",
                    "message": "Task dependencies not satisfied"
                }
            
            # Create execution plan for the task
            plan_result = await self.create_and_execute_plan(
                goal=task.description,
                planner_type="sequential"
            )
            
            # Update task status
            if plan_result["success"]:
                task.status = "completed"
                self.completed_tasks.append(task)
                del self.active_tasks[task.id]
            else:
                task.status = "failed"
            
            # Store task result
            await self._store_task_result(task, plan_result)
            
            return {
                "task_id": task.id,
                "status": task.status,
                "execution_result": plan_result
            }
            
        except Exception as e:
            task.status = "error"
            return {
                "task_id": task.id,
                "status": "error",
                "error": str(e)
            }
    
    async def _check_task_dependencies(self, task: AgentTask) -> bool:
        """Check if task dependencies are satisfied"""
        
        if not task.dependencies:
            return True
        
        for dep_id in task.dependencies:
            # Check if dependency task is completed
            completed_ids = [t.id for t in self.completed_tasks]
            if dep_id not in completed_ids:
                return False
        
        return True
    
    async def _store_execution_memory(self, execution_result: Dict[str, Any]):
        """Store execution results in memory"""
        
        memory_key = f"execution_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        await self.kernel.memory.save_information_async(
            collection="executions",
            text=json.dumps(execution_result),
            id=memory_key,
            description=f"Execution of goal: {execution_result['goal']}"
        )
    
    async def _store_task_result(self, task: AgentTask, result: Dict[str, Any]):
        """Store task execution result in database"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO agent_tasks 
            (id, description, priority, assigned_agent, dependencies, status, 
             created_at, deadline, context, completed_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            task.id,
            task.description,
            task.priority.value,
            task.assigned_agent,
            json.dumps(task.dependencies),
            task.status,
            task.created_at.isoformat(),
            task.deadline.isoformat() if task.deadline else None,
            json.dumps(task.context),
            datetime.now().isoformat() if task.status == "completed" else None
        ))
        
        conn.commit()
        conn.close()
    
    async def _log_interaction(self, source_agent: str, target_agent: str, 
                             interaction_type: str, message_content: str, 
                             response_content: str = None, success: bool = True):
        """Log agent interactions"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO agent_interactions 
            (source_agent, target_agent, interaction_type, message_content, 
             response_content, success)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            source_agent,
            target_agent,
            interaction_type,
            message_content,
            response_content,
            success
        ))
        
        conn.commit()
        conn.close()

class MultiAgentOrchestrator:
    """Orchestrator for managing multiple Semantic Kernel agents"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.agents: Dict[str, AdvancedSemanticKernelAgent] = {}
        self.task_queue: List[AgentTask] = []
        self.coordination_protocols = {
            "round_robin": self._round_robin_assignment,
            "priority_based": self._priority_based_assignment,
            "capability_based": self._capability_based_assignment
        }
        
    async def register_agent(self, agent_id: str, agent_config: Dict[str, Any]) -> str:
        """Register a new agent with the orchestrator"""
        
        agent = AdvancedSemanticKernelAgent(agent_id, agent_config)
        self.agents[agent_id] = agent
        
        return f"Agent {agent_id} registered successfully"
    
    async def submit_task(self, task: AgentTask) -> Dict[str, Any]:
        """Submit task for execution by appropriate agent"""
        
        # Assign agent based on coordination protocol
        assignment_protocol = self.config.get("assignment_protocol", "priority_based")
        assigned_agent = await self.coordination_protocols[assignment_protocol](task)
        
        if not assigned_agent:
            return {
                "status": "failed",
                "message": "No suitable agent available for task"
            }
        
        task.assigned_agent = assigned_agent
        
        # Execute task
        result = await self.agents[assigned_agent].manage_task(task)
        
        return result
    
    async def _round_robin_assignment(self, task: AgentTask) -> Optional[str]:
        """Assign task using round-robin strategy"""
        
        if not self.agents:
            return None
        
        # Simple round-robin based on task ID hash
        agent_ids = list(self.agents.keys())
        index = hash(task.id) % len(agent_ids)
        
        return agent_ids[index]
    
    async def _priority_based_assignment(self, task: AgentTask) -> Optional[str]:
        """Assign task based on priority and agent availability"""
        
        # Find agents with lowest current workload
        agent_workloads = {}
        
        for agent_id, agent in self.agents.items():
            workload = len(agent.active_tasks)
            agent_workloads[agent_id] = workload
        
        # Sort by workload and select least busy agent
        sorted_agents = sorted(agent_workloads.items(), key=lambda x: x[1])
        
        return sorted_agents[0][0] if sorted_agents else None
    
    async def _capability_based_assignment(self, task: AgentTask) -> Optional[str]:
        """Assign task based on agent capabilities"""
        
        # Analyze task requirements
        task_keywords = task.description.lower().split()
        
        best_agent = None
        best_score = 0
        
        for agent_id, agent in self.agents.items():
            # Score based on available skills
            score = 0
            
            # Check if agent has database skills
            if any(keyword in task_keywords for keyword in ["database", "sql", "query", "data"]):
                if "database" in [skill.name for skill in agent.kernel.skills.values()]:
                    score += 3
            
            # Check if agent has analysis skills
            if any(keyword in task_keywords for keyword in ["analyze", "analysis", "calculate", "statistics"]):
                if "analysis" in [skill.name for skill in agent.kernel.skills.values()]:
                    score += 3
            
            # Check current workload (lower is better)
            workload_penalty = len(agent.active_tasks)
            score -= workload_penalty
            
            if score > best_score:
                best_score = score
                best_agent = agent_id
        
        return best_agent
````

## Building Multi-Agent Systems

Multi-agent systems represent the next evolution in AI applications, where specialized agents collaborate to solve complex problems that exceed individual agent capabilities.

### Advanced Autogen Implementation

````python
import asyncio
import os
import json
from typing import Dict, List, Any, Optional, Callable, Union
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum
import autogen
from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
import chromadb
from dotenv import load_dotenv

load_dotenv()

class AgentRole(Enum):
    COORDINATOR = "coordinator"
    ANALYST = "analyst"
    DEVELOPER = "developer"
    TESTER = "tester"
    REVIEWER = "reviewer"
    SPECIALIST = "specialist"

@dataclass
class ConversationContext:
    topic: str
    participants: List[str]
    objectives: List[str]
    constraints: List[str] = field(default_factory=list)
    resources: Dict[str, Any] = field(default_factory=dict)
    timeline: Optional[datetime] = None

class AdvancedAutogenSystem:
    """Advanced multi-agent system using Autogen framework"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.agents: Dict[str, autogen.Agent] = {}
        self.group_chats: Dict[str, GroupChat] = {}
        self.conversation_histories: Dict[str, List[Dict[str, Any]]] = {}
        
        # LLM configuration
        self.llm_config = {
            "request_timeout": 600,
            "seed": 42,
            "config_list": [
                {
                    "model": "gpt-4-turbo-preview",
                    "api_key": os.getenv("OPENAI_API_KEY"),
                    "temperature": 0.3,
                    "max_tokens": 2000
                }
            ]
        }
        
        # Initialize retrieval system
        self._setup_retrieval_system()
        
    def _setup_retrieval_system(self):
        """Setup retrieval system for knowledge-augmented agents"""
        
        self.chroma_client = chromadb.Client()
        
        # Create collection for knowledge base
        try:
            self.knowledge_collection = self.chroma_client.create_collection(
                name="agent_knowledge",
                metadata={"description": "Shared knowledge base for agents"}
            )
        except:
            self.knowledge_collection = self.chroma_client.get_collection("agent_knowledge")
    
    def create_specialized_agent(self, 
                               agent_id: str, 
                               role: AgentRole, 
                               system_message: str,
                               capabilities: List[str] = None) -> autogen.Agent:
        """Create specialized agent with specific role and capabilities"""
        
        capabilities = capabilities or []
        
        # Enhanced system message with role-specific instructions
        enhanced_system_message = f"""
        {system_message}
        
        AGENT ROLE: {role.value.upper()}
        AGENT ID: {agent_id}
        
        CAPABILITIES: {', '.join(capabilities) if capabilities else 'General assistance'}
        
        BEHAVIORAL GUIDELINES:
        1. Stay in character for your assigned role
        2. Collaborate effectively with other agents
        3. Provide clear, actionable responses
        4. Ask for clarification when needed
        5. Share relevant information with the team
        6. Respect other agents' expertise areas
        
        COMMUNICATION PROTOCOL:
        - Begin responses with your role identifier
        - Be concise but thorough
        - Use structured formatting when presenting complex information
        - Tag other agents when their input is needed (@AgentName)
        """
        
        if role == AgentRole.COORDINATOR:
            agent = AssistantAgent(
                name=agent_id,
                system_message=enhanced_system_message + """
                
                COORDINATOR SPECIFIC INSTRUCTIONS:
                - Manage conversation flow and ensure all voices are heard
                - Synthesize inputs from multiple agents
                - Make final decisions when consensus is needed
                - Track progress toward objectives
                - Identify when additional expertise is required
                """,
                llm_config=self.llm_config,
                human_input_mode="NEVER"
            )
            
        elif role == AgentRole.ANALYST:
            agent = RetrieveAssistantAgent(
                name=agent_id,
                system_message=enhanced_system_message + """
                
                ANALYST SPECIFIC INSTRUCTIONS:
                - Perform deep analysis of data and requirements
                - Identify patterns, trends, and insights
                - Provide evidence-based recommendations
                - Challenge assumptions with data
                - Create structured analytical reports
                """,
                llm_config=self.llm_config,
                retrieve_config={
                    "task": "qa",
                    "docs_path": "./knowledge_base",
                    "chunk_token_size": 1000,
                    "model": self.llm_config["config_list"][0]["model"],
                    "client": self.chroma_client,
                    "collection_name": "agent_knowledge",
                    "get_or_create": True
                }
            )
            
        elif role == AgentRole.DEVELOPER:
            agent = AssistantAgent(
                name=agent_id,
                system_message=enhanced_system_message + """
                
                DEVELOPER SPECIFIC INSTRUCTIONS:
                - Focus on technical implementation details
                - Provide code examples and architectural guidance
                - Consider scalability, maintainability, and performance
                - Identify technical risks and mitigation strategies
                - Suggest best practices and design patterns
                """,
                llm_config=self.llm_config,
                human_input_mode="NEVER"
            )
            
        elif role == AgentRole.TESTER:
            agent = AssistantAgent(
                name=agent_id,
                system_message=enhanced_system_message + """
                
                TESTER SPECIFIC INSTRUCTIONS:
                - Design comprehensive test strategies
                - Identify edge cases and failure scenarios
                - Validate requirements and acceptance criteria
                - Suggest quality assurance processes
                - Focus on reliability and robustness
                """,
                llm_config=self.llm_config,
                human_input_mode="NEVER"
            )
            
        else:  # SPECIALIST or default
            agent = AssistantAgent(
                name=agent_id,
                system_message=enhanced_system_message,
                llm_config=self.llm_config,
                human_input_mode="NEVER"
            )
        
        self.agents[agent_id] = agent
        return agent
    
    def create_user_proxy(self, 
                         proxy_id: str, 
                         human_input_mode: str = "ALWAYS",
                         code_execution_config: Dict[str, Any] = None) -> UserProxyAgent:
        """Create user proxy agent for human interaction"""
        
        if code_execution_config is None:
            code_execution_config = {
                "work_dir": "./code_execution",
                "use_docker": False,  # Set to True in production
                "timeout": 60,
                "last_n_messages": "auto"
            }
        
        proxy = UserProxyAgent(
            name=proxy_id,
            human_input_mode=human_input_mode,
            max_consecutive_auto_reply=10,
            is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
            code_execution_config=code_execution_config,
            system_message="""
            You are a user proxy facilitating communication between humans and AI agents.
            
            RESPONSIBILITIES:
            - Relay human instructions to agents
            - Execute code when requested
            - Provide feedback on agent responses
            - Ensure human oversight in critical decisions
            
            TERMINATION: Reply 'TERMINATE' when the task is complete or no further action is needed.
            """
        )
        
        self.agents[proxy_id] = proxy
        return proxy
    
    def create_group_chat(self, 
                         chat_id: str,
                         participants: List[str],
                         context: ConversationContext,
                         custom_speaker_selection: Optional[Callable] = None) -> GroupChat:
        """Create structured group chat with conversation management"""
        
        # Validate all participants exist
        chat_agents = []
        for participant_id in participants:
            if participant_id not in self.agents:
                raise ValueError(f"Agent {participant_id} not found")
            chat_agents.append(self.agents[participant_id])
        
        # Custom speaker selection function
        def intelligent_speaker_selection(last_speaker, group_chat):
            """Intelligent speaker selection based on context and expertise"""
            
            if custom_speaker_selection:
                return custom_speaker_selection(last_speaker, group_chat)
            
            messages = group_chat.messages
            if not messages:
                # Start with coordinator if available
                for agent in chat_agents:
                    if "coordinator" in agent.name.lower():
                        return agent
                return chat_agents[0]
            
            last_message = messages[-1]["content"].lower()
            
            # Determine next speaker based on content
            if any(keyword in last_message for keyword in ["analyze", "data", "metrics", "statistics"]):
                for agent in chat_agents:
                    if "analyst" in agent.name.lower():
                        return agent
            
            if any(keyword in last_message for keyword in ["code", "implement", "develop", "technical"]):
                for agent in chat_agents:
                    if "developer" in agent.name.lower():
                        return agent
            
            if any(keyword in last_message for keyword in ["test", "verify", "validate", "quality"]):
                for agent in chat_agents:
                    if "tester" in agent.name.lower():
                        return agent
            
            # Default to next agent in round-robin
            current_index = chat_agents.index(last_speaker)
            next_index = (current_index + 1) % len(chat_agents)
            return chat_agents[next_index]
        
        group_chat = GroupChat(
            agents=chat_agents,
            messages=[],
            max_round=context.timeline.minute if context.timeline else 20,
            speaker_selection_method=intelligent_speaker_selection,
            allow_repeat_speaker=False
        )
        
        self.group_chats[chat_id] = group_chat
        self.conversation_histories[chat_id] = []
        
        return group_chat
    
    async def initiate_group_conversation(self, 
                                        chat_id: str,
                                        initial_message: str,
                                        max_turns: int = 20) -> Dict[str, Any]:
        """Initiate and manage group conversation"""
        
        if chat_id not in self.group_chats:
            raise ValueError(f"Group chat {chat_id} not found")
        
        group_chat = self.group_chats[chat_id]
        
        # Create group chat manager
        manager = GroupChatManager(
            groupchat=group_chat,
            llm_config=self.llm_config,
            system_message=f"""
            You are the group chat manager for conversation: {chat_id}
            
            RESPONSIBILITIES:
            - Facilitate smooth conversation flow
            - Ensure all relevant agents contribute
            - Synthesize final conclusions
            - Maintain focus on objectives
            - Manage turn-taking and prevent loops
            
            CONVERSATION OBJECTIVES:
            {initial_message}
            
            MANAGEMENT GUIDELINES:
            - Allow each agent to express their perspective
            - Redirect if conversation goes off-topic
            - Summarize key points periodically
            - Signal completion when objectives are met
            """
        )
        
        # Start conversation
        conversation_start = datetime.now()
        
        try:
            # Initiate chat with the first agent (usually coordinator or user proxy)
            first_agent = group_chat.agents[0]
            
            # Run the conversation
            chat_result = await asyncio.to_thread(
                first_agent.initiate_chat,
                manager,
                message=initial_message,
                max_turns=max_turns
            )
            
            conversation_duration = (datetime.now() - conversation_start).total_seconds()
            
            # Process and store conversation results
            conversation_summary = {
                "chat_id": chat_id,
                "initial_message": initial_message,
                "participants": [agent.name for agent in group_chat.agents],
                "total_messages": len(group_chat.messages),
                "duration_seconds": conversation_duration,
                "final_result": chat_result,
                "conversation_flow": self._analyze_conversation_flow(group_chat.messages),
                "timestamp": conversation_start.isoformat()
            }
            
            # Store in conversation history
            self.conversation_histories[chat_id].append(conversation_summary)
            
            return conversation_summary
            
        except Exception as e:
            return {
                "chat_id": chat_id,
                "error": str(e),
                "status": "failed",
                "timestamp": conversation_start.isoformat()
            }
    
    def _analyze_conversation_flow(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze conversation flow and patterns"""
        
        if not messages:
            return {"analysis": "No messages to analyze"}
        
        # Count contributions by agent
        agent_contributions = {}
        for message in messages:
            agent_name = message.get("name", "unknown")
            agent_contributions[agent_name] = agent_contributions.get(agent_name, 0) + 1
        
        # Analyze turn-taking patterns
        speakers = [msg.get("name", "unknown") for msg in messages]
        consecutive_speakers = []
        current_speaker = speakers[0]
        consecutive_count = 1
        
        for speaker in speakers[1:]:
            if speaker == current_speaker:
                consecutive_count += 1
            else:
                consecutive_speakers.append({
                    "agent": current_speaker,
                    "consecutive_turns": consecutive_count
                })
                current_speaker = speaker
                consecutive_count = 1
        
        # Add final speaker
        consecutive_speakers.append({
            "agent": current_speaker,
            "consecutive_turns": consecutive_count
        })
        
        return {
            "total_messages": len(messages),
            "unique_speakers": len(agent_contributions),
            "agent_contributions": agent_contributions,
            "average_message_length": sum(len(msg.get("content", "")) for msg in messages) / len(messages),
            "conversation_balance": max(agent_contributions.values()) / min(agent_contributions.values()) if agent_contributions.values() else 1,
            "turn_taking_analysis": consecutive_speakers
        }
    
    async def create_task_solving_team(self, 
                                     task_description: str,
                                     required_roles: List[AgentRole],
                                     team_id: str) -> Dict[str, Any]:
        """Create specialized team for solving specific task"""
        
        team_agents = []
        
        # Create agents for required roles
        for role in required_roles:
            agent_id = f"{team_id}_{role.value}"
            
            role_prompts = {
                AgentRole.COORDINATOR: "You are a project coordinator responsible for managing the team and ensuring task completion.",
                AgentRole.ANALYST: "You are a data analyst who provides insights and recommendations based on thorough analysis.",
                AgentRole.DEVELOPER: "You are a software developer who focuses on technical implementation and architecture.",
                AgentRole.TESTER: "You are a quality assurance specialist who ensures reliability and identifies potential issues.",
                AgentRole.REVIEWER: "You are a reviewer who evaluates work quality and provides constructive feedback.",
                AgentRole.SPECIALIST: "You are a domain specialist with deep expertise in specific areas."
            }
            
            agent = self.create_specialized_agent(
                agent_id=agent_id,
                role=role,
                system_message=role_prompts[role],
                capabilities=[f"{role.value}_expertise"]
            )
            
            team_agents.append(agent_id)
        
        # Create user proxy for human oversight
        proxy_id = f"{team_id}_proxy"
        self.create_user_proxy(proxy_id, human_input_mode="TERMINATE")
        team_agents.append(proxy_id)
        
        # Create group chat context
        context = ConversationContext(
            topic=task_description,
            participants=team_agents,
            objectives=[
                "Understand the task requirements",
                "Develop comprehensive solution approach",
                "Identify potential challenges and risks",
                "Create actionable implementation plan",
                "Ensure quality and completeness"
            ]
        )
        
        # Create group chat
        chat_id = f"{team_id}_chat"
        group_chat = self.create_group_chat(chat_id, team_agents, context)
        
        return {
            "team_id": team_id,
            "chat_id": chat_id,
            "agents": team_agents,
            "roles": [role.value for role in required_roles],
            "context": context,
            "status": "ready"
        }
    
    def get_conversation_insights(self, chat_id: str) -> Dict[str, Any]:
        """Get comprehensive insights from conversation history"""
        
        if chat_id not in self.conversation_histories:
            return {"error": "Conversation not found"}
        
        conversations = self.conversation_histories[chat_id]
        
        if not conversations:
            return {"error": "No conversation data available"}
        
        # Aggregate insights
        total_conversations = len(conversations)
        total_messages = sum(conv.get("total_messages", 0) for conv in conversations)
        total_duration = sum(conv.get("duration_seconds", 0) for conv in conversations)
        
        # Agent participation analysis
        all_participants = set()
        for conv in conversations:
            all_participants.update(conv.get("participants", []))
        
        return {
            "chat_id": chat_id,
            "total_conversations": total_conversations,
            "total_messages": total_messages,
            "total_duration_seconds": total_duration,
            "average_messages_per_conversation": total_messages / total_conversations if total_conversations > 0 else 0,
            "unique_participants": list(all_participants),
            "conversation_efficiency": total_messages / total_duration if total_duration > 0 else 0,
            "recent_conversations": conversations[-5:],  # Last 5 conversations
            "insights_generated_at": datetime.now().isoformat()
        }

# Practical exercise: Database-integrated agent
class DatabaseIntegratedAgent:
    """Agent with advanced database integration capabilities"""
    
    def __init__(self, agent_id: str, db_config: Dict[str, Any]):
        self.agent_id = agent_id
        self.db_config = db_config
        
        # Initialize Autogen agent
        self.agent = AssistantAgent(
            name=agent_id,
            system_message="""
            You are a database-integrated AI agent with the following capabilities:
            
            DATABASE OPERATIONS:
            - Execute SQL queries safely
            - Analyze data patterns and trends
            - Generate reports and insights
            - Perform data validation and cleaning
            
            TOOL INTEGRATION:
            - Use built-in database tools
            - Perform calculations and analysis
            - Generate visualizations descriptions
            - Export results in various formats
            
            SAFETY PROTOCOLS:
            - Never execute destructive operations
            - Validate all queries before execution
            - Protect sensitive information
            - Follow data governance policies
            """,
            llm_config={
                "config_list": [
                    {
                        "model": "gpt-4-turbo-preview",
                        "api_key": os.getenv("OPENAI_API_KEY")
                    }
                ]
            }
        )
        
        # Register database tools
        self._register_database_tools()
    
    def _register_database_tools(self):
        """Register database-specific tools"""
        
        @autogen.register_function
        def execute_safe_query(query: str, limit: int = 100) -> str:
            """Execute a read-only database query with safety checks"""
            
            # Basic safety validation
            query_upper = query.upper().strip()
            
            # Check for destructive operations
            dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
            if any(keyword in query_upper for keyword in dangerous_keywords):
                return "Error: Destructive operations are not allowed"
            
            # Ensure LIMIT clause for large result sets
            if 'LIMIT' not in query_upper and limit:
                query += f" LIMIT {limit}"
            
            try:
                # Simulate database execution
                mock_results = [
                    {"id": 1, "name": "Product A", "price": 29.99, "category": "Electronics"},
                    {"id": 2, "name": "Product B", "price": 49.99, "category": "Books"},
                    {"id": 3, "name": "Product C", "price": 19.99, "category": "Electronics"}
                ]
                
                return json.dumps({
                    "query": query,
                    "results": mock_results[:limit],
                    "row_count": len(mock_results),
                    "execution_time_ms": 45
                }, indent=2)
                
            except Exception as e:
                return f"Database error: {str(e)}"
        
        @autogen.register_function
        def analyze_data_trends(data_json: str, analysis_type: str = "basic") -> str:
            """Analyze trends in the provided data"""
            
            try:
                data = json.loads(data_json)
                
                if not isinstance(data, list):
                    return "Error: Data must be a list of records"
                
                analysis_result = {
                    "total_records": len(data),
                    "analysis_type": analysis_type,
                    "insights": []
                }
                
                # Basic statistical analysis
                if data and isinstance(data[0], dict):
                    numeric_fields = []
                    for key, value in data[0].items():
                        if isinstance(value, (int, float)):
                            numeric_fields.append(key)
                    
                    for field in numeric_fields:
                        values = [record.get(field, 0) for record in data if isinstance(record.get(field), (int, float))]
                        if values:
                            analysis_result["insights"].append({
                                "field": field,
                                "min": min(values),
                                "max": max(values),
                                "average": sum(values) / len(values),
                                "total": sum(values)
                            })
                
                return json.dumps(analysis_result, indent=2)
                
            except Exception as e:
                return f"Analysis error: {str(e)}"
    
    async def solve_database_task(self, task_description: str) -> Dict[str, Any]:
        """Solve database-related task using integrated tools"""
        
        # Create user proxy for task execution
        user_proxy = UserProxyAgent(
            name="task_executor",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=5,
            is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
            code_execution_config=False
        )
        
        # Execute task
        result = await asyncio.to_thread(
            user_proxy.initiate_chat,
            self.agent,
            message=f"""
            Please help me with the following database task:
            
            {task_description}
            
            Use the available database tools to:
            1. Understand the requirements
            2. Execute appropriate queries
            3. Analyze the results
            4. Provide insights and recommendations
            
            When complete, respond with 'TERMINATE'.
            """,
            max_turns=10
        )
        
        return {
            "task": task_description,
            "agent_id": self.agent_id,
            "result": result,
            "timestamp": datetime.now().isoformat()
        }
````

## Autogen Studio and Differences from LangChain

Autogen Studio provides a visual interface for building multi-agent systems, while LangChain focuses on chain-based workflows. The key differences lie in their architectural approaches and use case optimization.

## Conclusion

Semantic Kernel and Autogen represent sophisticated approaches to building AI applications with fundamentally different philosophies. **Semantic Kernel** excels in enterprise integration scenarios where AI capabilities need to be seamlessly embedded into existing applications. Its planning system and memory management provide robust foundations for building intelligent applications that can maintain context and execute complex multi-step workflows.

**Autogen's multi-agent architecture** offers unique advantages for collaborative problem-solving scenarios. The framework's strength lies in its ability to simulate human team dynamics through structured conversations between specialized agents. This approach is particularly valuable for complex tasks that benefit from multiple perspectives and expertise areas.

**Key architectural differences** include Semantic Kernel's function-centric approach versus Autogen's conversation-centric model. Semantic Kernel treats AI as a service layer that enhances traditional programming, while Autogen creates autonomous agents that collaborate through natural language interactions.

**Memory and state management** in Semantic Kernel provides more granular control over data persistence and retrieval, making it suitable for applications requiring sophisticated knowledge management. Autogen's memory is primarily conversation-based, focusing on maintaining dialogue context rather than persistent knowledge storage.

**Planning capabilities** differ significantly - Semantic Kernel offers multiple planner types for different scenarios, while Autogen relies on emergent planning through agent collaboration. This makes Semantic Kernel more predictable and Autogen more creative in problem-solving approaches.

**Integration considerations** favor Semantic Kernel for traditional software development workflows, while Autogen excels in research, creative problem-solving, and scenarios requiring diverse expertise. The choice between frameworks depends on whether the application needs structured, predictable AI enhancement or flexible, collaborative intelligence.

Both frameworks represent the cutting edge of AI application development, offering complementary approaches to building sophisticated AI systems that can handle complex, real-world challenges.