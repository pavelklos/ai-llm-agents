<small>Claude 3.7 Sonnet Thinking</small>
# 11. AI Agent Development Workshop

## Key Terms

- **AI Agent**: An autonomous software entity that can perceive its environment, make decisions, and take actions to achieve goals.
- **LangGraph**: A framework for building stateful, multi-agent applications with language models using a graph-based architecture.
- **Agent State Management**: The process of tracking and persisting information across agent interactions and steps.
- **Agent Testing**: Methods and frameworks for evaluating agent behavior and performance.
- **Deployment Pipeline**: Structured workflow for bringing AI agents from development to production.
- **Agent Orchestration**: Coordinating multiple agents to work together on complex tasks.
- **Agent Memory**: Storage mechanisms allowing agents to recall past interactions and knowledge.
- **Function Calling**: The ability for agents to invoke specific functions for external tool usage.
- **Evaluation Harness**: Framework for systematically testing agent capabilities.
- **Multi-agent Environment**: A system where multiple agents can interact with each other.

## Designing AI Agents with LangGraph and OpenAI

Let's build a comprehensive AI agent system that combines LangGraph's state management capabilities with OpenAI's powerful models:

```python
import os
import json
import uuid
import datetime
from typing import Dict, List, Any, Optional, Union, TypedDict, Annotated
from enum import Enum
from pathlib import Path
from dotenv import load_dotenv

import openai
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, FunctionMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda
from langchain_core.tools import tool
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

from langgraph.graph import StateGraph, END
from langgraph.checkpoint import MemorySaver, FileSystemCheckpointer
from langgraph.prebuilt import ToolNode

# Load environment variables
load_dotenv()

# Configure API keys
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY environment variable not set")

# Set up the OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)


class AgentState(TypedDict):
    """State maintained throughout the agent workflow."""
    messages: List[Dict[str, Any]]
    task: str
    context: Dict[str, Any]
    tools_output: Optional[Dict[str, Any]]
    current_step: str
    history: List[Dict[str, Any]]
    status: str
    

class AgentWorkflowBuilder:
    """Builder for creating sophisticated AI agent workflows."""
    
    def __init__(
        self,
        model_name: str = "gpt-4o",
        temperature: float = 0.2,
        workspace_dir: str = "./agent_workspace",
        verbose: bool = False
    ):
        """
        Initialize the agent workflow builder.
        
        Args:
            model_name: OpenAI model to use
            temperature: Temperature for generation
            workspace_dir: Directory for checkpointing and artifacts
            verbose: Whether to enable verbose output
        """
        self.model_name = model_name
        self.temperature = temperature
        self.workspace_dir = Path(workspace_dir)
        self.verbose = verbose
        
        # Create workspace directory if it doesn't exist
        self.workspace_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize the LLM
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            api_key=OPENAI_API_KEY
        )
        
        # Initialize tools registry
        self.tools = []
        
        # Define default system prompt
        self.default_system_prompt = """
        You are an advanced AI assistant designed to solve complex problems.
        You have access to tools that can help you accomplish tasks.
        Always think step-by-step before providing your answer.
        """
        
        if self.verbose:
            print(f"Initialized agent workflow builder with model: {model_name}")
    
    def add_tool(self, tool_function):
        """Add a tool to the agent's toolkit."""
        self.tools.append(tool_function)
        if self.verbose:
            print(f"Added tool: {tool_function.name}")
        return self
    
    def build_workflow(self) -> StateGraph:
        """
        Build the agent workflow graph.
        
        Returns:
            Constructed workflow graph
        """
        # Create a state graph with the agent state
        graph = StateGraph(AgentState)
        
        # Create a prompt that includes the system message and tools
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.default_system_prompt),
            MessagesPlaceholder(variable_name="messages"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # Create the agent that uses tools
        agent = prompt | self.llm.bind_tools(self.tools) | RunnableLambda(self._process_llm_response)
        
        # Define the agent node
        def agent_node(state: AgentState) -> Dict[str, Any]:
            messages = state["messages"]
            
            # Format agent scratchpad with tool outputs
            if state.get("tools_output"):
                observation = state["tools_output"].get("output", "")
                tool_name = state["tools_output"].get("tool_name", "")
                
                if tool_name and observation:
                    agent_scratchpad = [
                        AIMessage(content=f"I'll use the {tool_name} tool."),
                        FunctionMessage(name=tool_name, content=observation)
                    ]
                else:
                    agent_scratchpad = []
            else:
                agent_scratchpad = []
            
            # Get the agent's response
            output = agent.invoke({
                "messages": messages,
                "agent_scratchpad": agent_scratchpad
            })
            
            # Add to messages
            messages.append(AIMessage(content=output["content"]))
            
            # Record in history
            state["history"].append({
                "role": "assistant",
                "content": output["content"],
                "timestamp": datetime.datetime.now().isoformat()
            })
            
            # Update state and determine next step
            if output.get("tool_calls"):
                # Tool was called, go to tools node
                state["current_step"] = "tools"
                return {
                    "type": "tool_calls",
                    "tool_calls": output["tool_calls"]
                }
            else:
                # No tool called, we're done
                state["status"] = "completed"
                state["current_step"] = "end"
                return {"type": "end"}
        
        # Add the agent node
        graph.add_node("agent", agent_node)
        
        # Add a tools node
        tools_node = ToolNode(self.tools)
        graph.add_node("tools", tools_node)
        
        # Set up conditional edges based on agent output
        def route_agent_output(output):
            if output["type"] == "tool_calls":
                return "tools"
            else:
                return END
        
        # Configure the edges
        graph.add_conditional_edges(
            "agent",
            route_agent_output
        )
        
        # Tools node always goes back to agent
        graph.add_edge("tools", "agent")
        
        # Set the entry point
        graph.set_entry_point("agent")
        
        return graph
    
    def _process_llm_response(self, response):
        """Process the LLM response to extract tool calls."""
        # Initialize the result
        result = {
            "content": response.content
        }
        
        # Extract tool calls if present
        tool_calls = response.tool_calls
        if tool_calls:
            result["tool_calls"] = []
            for call in tool_calls:
                result["tool_calls"].append({
                    "name": call.name,
                    "arguments": json.loads(call.arguments)
                })
        
        return result
    
    def compile_workflow(self, checkpoint_dir: Optional[str] = None) -> Any:
        """
        Compile the workflow into an executable form.
        
        Args:
            checkpoint_dir: Directory for checkpointing
            
        Returns:
            Compiled workflow
        """
        # Build the workflow graph
        graph = self.build_workflow()
        
        # Set up the checkpointer
        if checkpoint_dir:
            checkpointer = FileSystemCheckpointer(
                Path(checkpoint_dir)
            )
        else:
            checkpointer = MemorySaver()
        
        # Compile the graph
        return graph.compile(checkpointer=checkpointer)


class AgentDeploymentManager:
    """Manager for deploying and monitoring AI agents."""
    
    def __init__(
        self,
        workflow,
        deployment_dir: str = "./agent_deployments",
        verbose: bool = False
    ):
        """
        Initialize the deployment manager.
        
        Args:
            workflow: Compiled agent workflow
            deployment_dir: Directory for deployment artifacts
            verbose: Whether to enable verbose output
        """
        self.workflow = workflow
        self.deployment_dir = Path(deployment_dir)
        self.verbose = verbose
        
        # Create deployment directory if it doesn't exist
        self.deployment_dir.mkdir(parents=True, exist_ok=True)
        
        # Deployment metadata
        self.deployment_id = str(uuid.uuid4())
        self.deployment_time = datetime.datetime.now().isoformat()
        self.active_sessions = {}
        
        if self.verbose:
            print(f"Initialized deployment manager with ID: {self.deployment_id}")
    
    def create_session(self, task: str, initial_context: Optional[Dict[str, Any]] = None) -> str:
        """
        Create a new agent session.
        
        Args:
            task: The task description
            initial_context: Optional initial context
            
        Returns:
            Session ID
        """
        # Generate a unique session ID
        session_id = str(uuid.uuid4())
        
        # Initialize context if none provided
        if initial_context is None:
            initial_context = {}
        
        # Prepare initial state
        initial_state = {
            "messages": [
                {"role": "user", "content": task}
            ],
            "task": task,
            "context": initial_context,
            "tools_output": None,
            "current_step": "agent",
            "history": [
                {"role": "user", "content": task, "timestamp": datetime.datetime.now().isoformat()}
            ],
            "status": "in_progress"
        }
        
        # Create thread config
        thread_config = {"configurable": {"thread_id": session_id}}
        
        # Store session info
        self.active_sessions[session_id] = {
            "created_at": datetime.datetime.now().isoformat(),
            "task": task,
            "state": initial_state,
            "thread_config": thread_config,
            "events": [{
                "type": "session_created",
                "timestamp": datetime.datetime.now().isoformat()
            }]
        }
        
        if self.verbose:
            print(f"Created session {session_id} for task: {task}")
        
        return session_id
    
    def run_session(self, session_id: str, max_steps: int = 10) -> Dict[str, Any]:
        """
        Run an agent session until completion or max steps.
        
        Args:
            session_id: ID of the session to run
            max_steps: Maximum number of steps to run
            
        Returns:
            Session results
        """
        if session_id not in self.active_sessions:
            raise ValueError(f"Session {session_id} not found")
        
        session = self.active_sessions[session_id]
        initial_state = session["state"]
        thread_config = session["thread_config"]
        
        steps_taken = 0
        current_state = initial_state
        
        # Run the workflow until completion or max steps
        while steps_taken < max_steps and current_state["status"] != "completed":
            steps_taken += 1
            
            if self.verbose:
                print(f"Running step {steps_taken} for session {session_id}")
            
            # Invoke the workflow
            result = self.workflow.invoke({
                "state": current_state,
                **thread_config
            })
            
            # Update the current state
            current_state = result["state"]
            
            # Record event
            session["events"].append({
                "type": "step_completed",
                "step_number": steps_taken,
                "current_step": current_state["current_step"],
                "timestamp": datetime.datetime.now().isoformat()
            })
        
        # Update the session state
        session["state"] = current_state
        session["last_updated"] = datetime.datetime.now().isoformat()
        
        if current_state["status"] == "completed":
            session["events"].append({
                "type": "session_completed",
                "timestamp": datetime.datetime.now().isoformat()
            })
        
        # Prepare the result
        result = {
            "session_id": session_id,
            "task": session["task"],
            "steps_taken": steps_taken,
            "status": current_state["status"],
            "messages": current_state["messages"],
            "history": current_state["history"]
        }
        
        return result
    
    def get_session_state(self, session_id: str) -> Dict[str, Any]:
        """Get the current state of a session."""
        if session_id not in self.active_sessions:
            raise ValueError(f"Session {session_id} not found")
        
        return self.active_sessions[session_id]["state"]
    
    def save_deployment_metrics(self) -> str:
        """
        Save deployment metrics to a file.
        
        Returns:
            Path to the metrics file
        """
        metrics = {
            "deployment_id": self.deployment_id,
            "deployment_time": self.deployment_time,
            "session_count": len(self.active_sessions),
            "sessions": {
                session_id: {
                    "created_at": session["created_at"],
                    "task": session["task"],
                    "event_count": len(session["events"]),
                    "status": session["state"]["status"]
                }
                for session_id, session in self.active_sessions.items()
            }
        }
        
        # Save metrics to file
        metrics_file = self.deployment_dir / f"metrics_{self.deployment_id}.json"
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        if self.verbose:
            print(f"Saved deployment metrics to {metrics_file}")
        
        return str(metrics_file)
```

## Implementing a Multi-agent Task System

Now let's implement a practical system with specialized agents that can work together on complex tasks:

```python
# Define tools for our agents

@tool
def web_search(query: str) -> str:
    """
    Search the web for information about a query.
    
    Args:
        query: The search query
        
    Returns:
        Search results
    """
    # This would typically call a search API, but for demo purposes we'll simulate
    return f"Results for '{query}':\n" + \
           f"1. Latest information about {query} from Wikipedia\n" + \
           f"2. Recent news articles about {query}\n" + \
           f"3. Academic papers related to {query}"

@tool
def analyze_data(data: str, analysis_type: str = "summary") -> str:
    """
    Analyze data and provide insights.
    
    Args:
        data: Data to analyze in text or JSON format
        analysis_type: Type of analysis to perform (summary, statistics, etc.)
        
    Returns:
        Analysis results
    """
    if analysis_type == "summary":
        return f"Summary of provided data:\n" + \
               f"- Contains approximately {len(data.split())} words\n" + \
               f"- Main topics appear to be: AI, data, analysis"
    else:
        return f"Performed {analysis_type} analysis on the data."

@tool
def generate_code(task_description: str, language: str = "python") -> str:
    """
    Generate code based on a task description.
    
    Args:
        task_description: Description of the coding task
        language: Programming language to use
        
    Returns:
        Generated code
    """
    if language.lower() == "python":
        return f"# Generated Python code for: {task_description}\n\n" + \
               f"def main():\n" + \
               f"    print('Implementing: {task_description}')\n" + \
               f"    # TODO: Implement the actual logic\n" + \
               f"    return 'Task completed'\n\n" + \
               f"if __name__ == '__main__':\n" + \
               f"    main()"
    else:
        return f"// Generated {language} code for: {task_description}\n" + \
               f"// Implementation would go here"

class MultiAgentTaskSystem:
    """System for orchestrating multiple specialized agents on complex tasks."""
    
    def __init__(self, verbose: bool = False):
        """Initialize the multi-agent task system."""
        self.verbose = verbose
        self.agents = {}
        self.deployment_managers = {}
    
    def create_research_agent(self) -> str:
        """
        Create a specialized research agent.
        
        Returns:
            Agent ID
        """
        # Create a builder for the research agent
        builder = AgentWorkflowBuilder(
            model_name="gpt-4o",
            temperature=0.2,
            workspace_dir="./agent_workspace/research",
            verbose=self.verbose
        )
        
        # Add research-focused tools
        builder.add_tool(web_search)
        builder.add_tool(analyze_data)
        
        # Customize the system prompt
        builder.default_system_prompt = """
        You are a specialized research agent designed to find and analyze information.
        Your strengths include thorough information gathering, critical evaluation of sources,
        and synthesizing complex data into clear insights.
        
        When asked a question:
        1. First determine what information you need
        2. Use the web_search tool to find relevant information
        3. Use the analyze_data tool to process and understand complex information
        4. Synthesize your findings into a comprehensive answer
        
        Always cite your sources and explain your reasoning process.
        """
        
        # Build and compile the workflow
        workflow = builder.compile_workflow("./agent_checkpoints/research")
        
        # Create a deployment manager
        agent_id = f"research_{uuid.uuid4().hex[:8]}"
        deployment_manager = AgentDeploymentManager(
            workflow=workflow,
            deployment_dir="./agent_deployments/research",
            verbose=self.verbose
        )
        
        # Store the agent
        self.agents[agent_id] = {
            "type": "research",
            "builder": builder,
            "workflow": workflow
        }
        
        # Store the deployment manager
        self.deployment_managers[agent_id] = deployment_manager
        
        if self.verbose:
            print(f"Created research agent with ID: {agent_id}")
        
        return agent_id
    
    def create_coding_agent(self) -> str:
        """
        Create a specialized coding agent.
        
        Returns:
            Agent ID
        """
        # Create a builder for the coding agent
        builder = AgentWorkflowBuilder(
            model_name="gpt-4o",
            temperature=0.1,  # Lower temperature for more deterministic code
            workspace_dir="./agent_workspace/coding",
            verbose=self.verbose
        )
        
        # Add coding-focused tools
        builder.add_tool(generate_code)
        builder.add_tool(web_search)  # For looking up documentation
        
        # Customize the system prompt
        builder.default_system_prompt = """
        You are a specialized coding agent designed to write, explain, and debug code.
        Your strengths include translating requirements into working code, following best practices,
        and explaining technical concepts clearly.
        
        When asked to create code:
        1. First clarify the requirements if needed
        2. Use the generate_code tool to create well-structured code
        3. Use the web_search tool if you need to reference documentation
        4. Provide explanations of how the code works
        
        Always write clean, well-documented code following best practices for the language.
        """
        
        # Build and compile the workflow
        workflow = builder.compile_workflow("./agent_checkpoints/coding")
        
        # Create a deployment manager
        agent_id = f"coding_{uuid.uuid4().hex[:8]}"
        deployment_manager = AgentDeploymentManager(
            workflow=workflow,
            deployment_dir="./agent_deployments/coding",
            verbose=self.verbose
        )
        
        # Store the agent
        self.agents[agent_id] = {
            "type": "coding",
            "builder": builder,
            "workflow": workflow
        }
        
        # Store the deployment manager
        self.deployment_managers[agent_id] = deployment_manager
        
        if self.verbose:
            print(f"Created coding agent with ID: {agent_id}")
        
        return agent_id
    
    def execute_task(
        self,
        task: str,
        agent_id: str,
        max_steps: int = 10
    ) -> Dict[str, Any]:
        """
        Execute a task using the specified agent.
        
        Args:
            task: Task description
            agent_id: ID of the agent to use
            max_steps: Maximum number of steps to run
            
        Returns:
            Task execution results
        """
        if agent_id not in self.deployment_managers:
            raise ValueError(f"Agent {agent_id} not found")
        
        deployment_manager = self.deployment_managers[agent_id]
        
        # Create a session
        session_id = deployment_manager.create_session(task)
        
        # Run the session
        result = deployment_manager.run_session(session_id, max_steps=max_steps)
        
        return result
    
    def execute_complex_task(self, task: str, max_steps: int = 15) -> Dict[str, Any]:
        """
        Execute a complex task by coordinating multiple agents.
        
        Args:
            task: Complex task description
            max_steps: Maximum steps per agent
            
        Returns:
            Task execution results
        """
        # Create agents if they don't exist
        if not any(agent["type"] == "research" for agent in self.agents.values()):
            research_agent_id = self.create_research_agent()
        else:
            research_agent_id = next(aid for aid, agent in self.agents.items() 
                                     if agent["type"] == "research")
        
        if not any(agent["type"] == "coding" for agent in self.agents.values()):
            coding_agent_id = self.create_coding_agent()
        else:
            coding_agent_id = next(aid for aid, agent in self.agents.items() 
                                   if agent["type"] == "coding")
        
        # First, use the research agent to gather information
        research_task = f"Research the following task and gather all necessary information: {task}"
        research_result = self.execute_task(research_task, research_agent_id, max_steps)
        
        if self.verbose:
            print("Research phase completed")
        
        # Extract the research findings
        research_findings = ""
        for message in research_result["history"]:
            if message["role"] == "assistant":
                research_findings += message["content"] + "\n\n"
        
        # Use the coding agent to implement a solution based on research
        coding_task = f"""
        Based on the following research, implement a solution for the task: {task}
        
        Research findings:
        {research_findings}
        """
        
        coding_result = self.execute_task(coding_task, coding_agent_id, max_steps)
        
        if self.verbose:
            print("Coding phase completed")
        
        # Combine the results
        combined_result = {
            "task": task,
            "research_phase": {
                "agent_id": research_agent_id,
                "session_id": research_result["session_id"],
                "history": research_result["history"]
            },
            "coding_phase": {
                "agent_id": coding_agent_id,
                "session_id": coding_result["session_id"],
                "history": coding_result["history"]
            },
            "combined_output": {
                "research": research_result["history"][-1]["content"] if research_result["history"] else "",
                "implementation": coding_result["history"][-1]["content"] if coding_result["history"] else ""
            }
        }
        
        return combined_result


# Function to demonstrate the multi-agent task system
def run_agent_workshop_demo():
    """Run a demonstration of the multi-agent task system."""
    print("Initializing Multi-Agent Task System...")
    system = MultiAgentTaskSystem(verbose=True)
    
    print("\nCreating specialized agents...")
    research_agent_id = system.create_research_agent()
    coding_agent_id = system.create_coding_agent()
    
    print(f"\nCreated Research Agent: {research_agent_id}")
    print(f"Created Coding Agent: {coding_agent_id}")
    
    # Example 1: Simple research task
    print("\n--- Example 1: Research Task ---")
    research_task = "Explain the key differences between LangGraph and LangChain for AI agent development"
    print(f"Task: {research_task}")
    
    result = system.execute_task(research_task, research_agent_id)
    
    print("\nResearch Results:")
    for message in result["history"]:
        if message["role"] == "assistant":
            print(f"\nAgent: {message['content'][:300]}...")
    
    # Example 2: Coding task
    print("\n--- Example 2: Coding Task ---")
    coding_task = "Create a Python function that analyzes sentiment in text using a pre-trained model"
    print(f"Task: {coding_task}")
    
    result = system.execute_task(coding_task, coding_agent_id)
    
    print("\nCoding Results:")
    for message in result["history"]:
        if message["role"] == "assistant":
            print(f"\nAgent: {message['content'][:300]}...")
    
    # Example 3: Complex task with multiple agents
    print("\n--- Example 3: Complex Multi-Agent Task ---")
    complex_task = "Research the best approach for implementing a RAG system with citation support, then create a Python implementation"
    print(f"Task: {complex_task}")
    
    result = system.execute_complex_task(complex_task)
    
    print("\nComplex Task Results:")
    print("\nResearch Phase:")
    print(result["combined_output"]["research"][:300] + "...")
    
    print("\nImplementation Phase:")
    print(result["combined_output"]["implementation"][:300] + "...")
    
    print("\nDemo completed!")
    
    return system

if __name__ == "__main__":
    load_dotenv()
    run_agent_workshop_demo()
```

## Automating Interactions Between AI Models

Now, let's build a system to automate interactions between different AI models:

```python
from typing import Dict, List, Any, Optional, Union, Callable, TypedDict
import json
import time
import asyncio
from enum import Enum
from pydantic import BaseModel, Field

class ModelType(str, Enum):
    """Types of AI models."""
    CHAT = "chat"
    EMBEDDING = "embedding"
    IMAGE = "image"
    TEXT = "text"

class ModelProvider(str, Enum):
    """AI model providers."""
    OPENAI = "openai"
    ANTHROPIC = "anthropic" 
    COHERE = "cohere"
    HUGGINGFACE = "huggingface"
    AZURE = "azure"

class ModelConfig(BaseModel):
    """Configuration for an AI model."""
    name: str
    provider: ModelProvider
    type: ModelType
    api_key_env: str = "OPENAI_API_KEY"
    base_url: Optional[str] = None
    parameters: Dict[str, Any] = Field(default_factory=dict)

class ModelInteractionSystem:
    """System for automating interactions between AI models."""
    
    def __init__(self, verbose: bool = False):
        """Initialize the model interaction system."""
        self.verbose = verbose
        self.models = {}
        self.interaction_flows = {}
        self.active_flows = {}
    
    def register_model(self, model_config: ModelConfig) -> str:
        """
        Register an AI model with the system.
        
        Args:
            model_config: Model configuration
            
        Returns:
            Model ID
        """
        model_id = f"{model_config.provider.value}_{model_config.name}_{uuid.uuid4().hex[:6]}"
        
        self.models[model_id] = {
            "config": model_config,
            "client": self._create_model_client(model_config)
        }
        
        if self.verbose:
            print(f"Registered model: {model_id}")
        
        return model_id
    
    def _create_model_client(self, config: ModelConfig) -> Any:
        """Create a client for the specified model."""
        if config.provider == ModelProvider.OPENAI:
            api_key = os.getenv(config.api_key_env)
            if not api_key:
                raise ValueError(f"API key not found in environment variable: {config.api_key_env}")
            
            return OpenAI(
                api_key=api_key,
                base_url=config.base_url
            )
        
        elif config.provider == ModelProvider.ANTHROPIC:
            # This would be implemented for Anthropic
            raise NotImplementedError("Anthropic integration not implemented")
        
        elif config.provider == ModelProvider.COHERE:
            # This would be implemented for Cohere
            raise NotImplementedError("Cohere integration not implemented")
        
        elif config.provider == ModelProvider.HUGGINGFACE:
            # This would be implemented for HuggingFace
            raise NotImplementedError("HuggingFace integration not implemented")
        
        elif config.provider == ModelProvider.AZURE:
            # This would be implemented for Azure
            raise NotImplementedError("Azure integration not implemented")
        
        else:
            raise ValueError(f"Unsupported provider: {config.provider}")
    
    def define_interaction_flow(
        self,
        flow_name: str,
        steps: List[Dict[str, Any]]
    ) -> str:
        """
        Define a flow for model interactions.
        
        Args:
            flow_name: Name of the interaction flow
            steps: List of interaction steps
            
        Returns:
            Flow ID
        """
        flow_id = f"flow_{flow_name}_{uuid.uuid4().hex[:6]}"
        
        # Validate the steps
        for i, step in enumerate(steps):
            if "model_id" not in step:
                raise ValueError(f"Step {i} missing model_id")
            if step["model_id"] not in self.models:
                raise ValueError(f"Model {step['model_id']} not found")
            if "operation" not in step:
                raise ValueError(f"Step {i} missing operation")
        
        self.interaction_flows[flow_id] = {
            "name": flow_name,
            "steps": steps,
            "created_at": datetime.datetime.now().isoformat()
        }
        
        if self.verbose:
            print(f"Defined interaction flow: {flow_id} with {len(steps)} steps")
        
        return flow_id
    
    async def execute_flow(
        self,
        flow_id: str,
        initial_input: Any,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute an interaction flow.
        
        Args:
            flow_id: ID of the flow to execute
            initial_input: Initial input for the flow
            context: Optional additional context
            
        Returns:
            Flow execution results
        """
        if flow_id not in self.interaction_flows:
            raise ValueError(f"Flow {flow_id} not found")
        
        flow = self.interaction_flows[flow_id]
        steps = flow["steps"]
        
        # Create execution context
        exec_context = {
            "flow_id": flow_id,
            "execution_id": str(uuid.uuid4()),
            "start_time": datetime.datetime.now().isoformat(),
            "current_input": initial_input,
            "context": context or {},
            "step_results": [],
            "errors": []
        }
        
        # Store as active flow
        self.active_flows[exec_context["execution_id"]] = exec_context
        
        if self.verbose:
            print(f"Starting flow execution: {flow_id} ({exec_context['execution_id']})")
        
        # Execute each step
        current_input = initial_input
        
        for i, step in enumerate(steps):
            try:
                if self.verbose:
                    print(f"Executing step {i+1}/{len(steps)}: {step.get('name', 'Unnamed step')}")
                
                # Get the model
                model_info = self.models[step["model_id"]]
                model_config = model_info["config"]
                client = model_info["client"]
                
                # Execute the operation
                operation = step["operation"]
                step_result = await self._execute_operation(
                    client=client,
                    config=model_config,
                    operation=operation,
                    input_data=current_input,
                    context=exec_context["context"]
                )
                
                # Store the result
                step_execution = {
                    "step_index": i,
                    "model_id": step["model_id"],
                    "operation": operation,
                    "input": current_input,
                    "output": step_result,
                    "execution_time": datetime.datetime.now().isoformat()
                }
                
                exec_context["step_results"].append(step_execution)
                
                # Update current input for next step
                current_input = step_result
                
                # Apply any transformations for the next step
                if "transform" in step and callable(step["transform"]):
                    current_input = step["transform"](current_input)
                
            except Exception as e:
                error = {
                    "step_index": i,
                    "error": str(e),
                    "time": datetime.datetime.now().isoformat()
                }
                exec_context["errors"].append(error)
                
                if self.verbose:
                    print(f"Error in step {i+1}: {str(e)}")
                
                if step.get("continue_on_error", False):
                    # Continue with next step despite error
                    continue
                else:
                    # Stop flow execution on error
                    break
        
        # Update execution context
        exec_context["end_time"] = datetime.datetime.now().isoformat()
        exec_context["final_output"] = current_input
        exec_context["success"] = len(exec_context["errors"]) == 0
        
        if self.verbose:
            status = "completed successfully" if exec_context["success"] else "completed with errors"
            print(f"Flow execution {exec_context['execution_id']} {status}")
        
        return exec_context
    
    async def _execute_operation(
        self,
        client: Any,
        config: ModelConfig,
        operation: str,
        input_data: Any,
        context: Dict[str, Any]
    ) -> Any:
        """Execute a specific operation with a model client."""
        if config.provider == ModelProvider.OPENAI:
            if config.type == ModelType.CHAT:
                if operation == "chat_completion":
                    # Prepare messages
                    if isinstance(input_data, list):
                        messages = input_data
                    elif isinstance(input_data, str):
                        messages = [{"role": "user", "content": input_data}]
                    else:
                        messages = [{"role": "user", "content": str(input_data)}]
                    
                    # Get parameters with defaults
                    params = {
                        "model": config.name,
                        "temperature": 0.7,
                        "max_tokens": 1000,
                        **config.parameters  # Override with configured parameters
                    }
                    
                    # Call the API
                    response = await asyncio.to_thread(
                        client.chat.completions.create,
                        messages=messages,
                        **params
                    )
                    
                    # Return the response
                    return {
                        "content": response.choices[0].message.content,
                        "finish_reason": response.choices[0].finish_reason,
                        "model": response.model
                    }
                
                elif operation == "function_calling":
                    # Prepare messages and functions
                    if isinstance(input_data, dict) and "messages" in input_data and "functions" in input_data:
                        messages = input_data["messages"]
                        functions = input_data["functions"]
                    else:
                        raise ValueError("Input must contain 'messages' and 'functions' for function_calling")
                    
                    # Get parameters with defaults
                    params = {
                        "model": config.name,
                        "temperature": 0.2,
                        **config.parameters
                    }
                    
                    # Call the API
                    response = await asyncio.to_thread(
                        client.chat.completions.create,
                        messages=messages,
                        tools=functions,
                        **params
                    )
                    
                    # Return the response
                    return {
                        "content": response.choices[0].message.content,
                        "tool_calls": response.choices[0].message.tool_calls,
                        "finish_reason": response.choices[0].finish_reason,
                        "model": response.model
                    }
            
            elif config.type == ModelType.EMBEDDING:
                if operation == "create_embedding":
                    # Get parameters with defaults
                    params = {
                        "model": config.name,
                        **config.parameters
                    }
                    
                    # Call the API
                    response = await asyncio.to_thread(
                        client.embeddings.create,
                        input=input_data,
                        **params
                    )
                    
                    # Return the embeddings
                    return {
                        "embeddings": [data.embedding for data in response.data],
                        "model": response.model
                    }
        
        # Handle other providers and operations
        raise ValueError(f"Unsupported operation '{operation}' for provider '{config.provider}' and type '{config.type}'")


async def demonstrate_model_interaction():
    """Demonstrate the model interaction system."""
    
    # Create the system
    system = ModelInteractionSystem(verbose=True)
    
    # Register models
    chat_model_config = ModelConfig(
        name="gpt-4o",
        provider=ModelProvider.OPENAI,
        type=ModelType.CHAT,
        parameters={"temperature": 0.7, "max_tokens": 500}
    )
    
    embedding_model_config = ModelConfig(
        name="text-embedding-3-small",
        provider=ModelProvider.OPENAI,
        type=ModelType.EMBEDDING
    )
    
    chat_model_id = system.register_model(chat_model_config)
    embedding_model_id = system.register_model(embedding_model_config)
    
    # Define a transformation function
    def extract_key_points(chat_response):
        """Extract key points from a chat response."""
        content = chat_response["content"]
        return f"Key points from analysis: {content}"
    
    # Define an interaction flow
    flow_id = system.define_interaction_flow(
        flow_name="question_answering_with_embeddings",
        steps=[
            {
                "name": "Generate detailed answer",
                "model_id": chat_model_id,
                "operation": "chat_completion",
                "transform": extract_key_points
            },
            {
                "name": "Create embeddings",
                "model_id": embedding_model_id,
                "operation": "create_embedding",
                "continue_on_error": True
            }
        ]
    )
    
    # Execute the flow
    result = await system.execute_flow(
        flow_id=flow_id,
        initial_input="Explain the concept of large language models and how they work"
    )
    
    # Print the results
    print("\nFlow Execution Results:")
    print(f"Flow ID: {result['flow_id']}")
    print(f"Execution ID: {result['execution_id']}")
    print(f"Success: {result['success']}")
    
    print("\nStep Results:")
    for i, step in enumerate(result['step_results']):
        print(f"\nStep {i+1}: {step['operation']} with {step['model_id']}")
        
        if i == 0:  # Chat completion
            print(f"Output content: {step['output']['content'][:200]}...")
        elif i == 1:  # Embedding
            print(f"Generated {len(step['output']['embeddings'])} embeddings")
            print(f"First embedding vector (first 5 values): {step['output']['embeddings'][0][:5]}")
    
    print("\nFinal Output:")
    if isinstance(result['final_output'], dict) and 'embeddings' in result['final_output']:
        print(f"Generated {len(result['final_output']['embeddings'])} embeddings for the response")
    
    return system, result
```

## End-to-End Practical Workshop Example

Let's tie everything together in a comprehensive workshop example that demonstrates a complete AI agent workflow:

```python
async def run_complete_workshop():
    """Run a complete end-to-end workshop example."""
    print("Starting AI Agent Development Workshop\n")
    print("This workshop demonstrates the complete lifecycle of AI agent development,")
    print("including design, implementation, testing, and deployment.\n")
    
    # Step 1: Set up the environment
    print("Step 1: Setting up the environment...")
    load_dotenv()
    
    # Verify API keys
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY not found in .env file")
    
    # Create necessary directories
    os.makedirs("./agent_workspace", exist_ok=True)
    os.makedirs("./agent_checkpoints", exist_ok=True)
    os.makedirs("./agent_deployments", exist_ok=True)
    
    print("Environment setup complete.\n")
    
    # Step 2: Define tools for our agent
    print("Step 2: Defining agent tools...")
    
    @tool
    def search_documentation(query: str) -> str:
        """
        Search documentation for a query.
        
        Args:
            query: Search query
            
        Returns:
            Documentation search results
        """
        # Simulate documentation search
        return f"Documentation results for '{query}':\n" + \
               f"1. API Reference for {query}\n" + \
               f"2. Tutorial on using {query}\n" + \
               f"3. Best practices for {query}"
    
    @tool
    def execute_code(code: str, language: str = "python") -> str:
        """
        Execute code in a sandbox environment.
        
        Args:
            code: Code to execute
            language: Programming language
            
        Returns:
            Execution results
        """
        # In a real implementation, this would use a secure sandbox
        if language.lower() != "python":
            return f"Execution of {language} code is not supported."
        
        return f"Executed Python code:\n{code}\n\nResult: Code executed successfully (simulated)"
    
    @tool
    def query_database(query: str) -> str:
        """
        Query a database.
        
        Args:
            query: SQL query
            
        Returns:
            Query results
        """
        # Simulate database query
        return f"Database query results for '{query}':\n" + \
               f"| id | name | value |\n" + \
               f"|----+------+-------|\n" + \
               f"| 1  | Item1 | 100   |\n" + \
               f"| 2  | Item2 | 200   |"
    
    print("Tools defined successfully.\n")
    
    # Step 3: Create a multi-agent system
    print("Step 3: Building a multi-agent system...")
    system = MultiAgentTaskSystem(verbose=True)
    
    # Create different types of agents
    research_agent_id = system.create_research_agent()
    coding_agent_id = system.create_coding_agent()
    
    print(f"Created research agent: {research_agent_id}")
    print(f"Created coding agent: {coding_agent_id}")
    print("Multi-agent system built successfully.\n")
    
    # Step 4: Execute some tasks to demonstrate the system
    print("Step 4: Executing tasks with the multi-agent system...")
    
    # Task 1: Research task
    print("\nExecuting Task 1: Research on RAG systems...")
    task1 = "Research the latest developments in Retrieval-Augmented Generation (RAG) systems"
    result1 = system.execute_task(task1, research_agent_id)
    
    print("\nTask 1 Results:")
    for message in result1["history"][-1:]:
        if message["role"] == "assistant":
            print(f"Agent Response: {message['content'][:300]}...")
    
    # Task 2: Coding task
    print("\nExecuting Task 2: Generate code for a simple RAG system...")
    task2 = "Write Python code for a basic RAG system using LangChain"
    result2 = system.execute_task(task2, coding_agent_id)
    
    print("\nTask 2 Results:")
    for message in result2["history"][-1:]:
        if message["role"] == "assistant":
            print(f"Agent Response: {message['content'][:300]}...")
    
    # Task 3: Complex multi-agent task
    print("\nExecuting Task 3: Complex multi-agent task...")
    task3 = "Research best practices for evaluating RAG systems, then create a Python evaluation framework"
    result3 = system.execute_complex_task(task3)
    
    print("\nTask 3 Results (Multi-agent collaboration):")
    print("\nResearch Agent Output:")
    print(f"{result3['combined_output']['research'][:300]}...")
    
    print("\nCoding Agent Output:")
    print(f"{result3['combined_output']['implementation'][:300]}...")
    
    print("\nTasks executed successfully.\n")
    
    # Step 5: Demonstrate model interaction system
    print("Step 5: Setting up model interaction system...")
    interaction_system, interaction_result = await demonstrate_model_interaction()
    
    print("\nModel interaction system demonstrated successfully.\n")
    
    # Step 6: Workshop summary
    print("Workshop Summary:")
    print("1. Created a flexible AI agent framework with LangGraph and OpenAI")
    print("2. Implemented specialized agents for research and coding tasks")
    print("3. Built a multi-agent system for complex task collaboration")
    print("4. Created a model interaction system for automating AI workflows")
    print("5. Executed various tasks to demonstrate the system capabilities")
    
    print("\nWorkshop completed successfully!")
    
    return {
        "agent_system": system,
        "interaction_system": interaction_system,
        "results": {
            "task1": result1,
            "task2": result2,
            "task3": result3,
            "interaction": interaction_result
        }
    }

if __name__ == "__main__":
    load_dotenv()
    asyncio.run(run_complete_workshop())
```

## Conclusion

The development of AI agents represents a significant advancement in applying language models to complex real-world tasks. Through this practical workshop, we've explored the complete lifecycle of AI agent development using modern frameworks like LangGraph and OpenAI.

Key takeaways from this workshop include:

1. **Sophisticated Agent Design**: The modular architecture we implemented allows for specialized agents with different capabilities and personas, enabling them to tackle diverse tasks from research to code generation.

2. **State Management**: LangGraph's state management capabilities enable the creation of agents that can maintain context across multiple interactions, making them more coherent and useful for complex tasks.

3. **Multi-agent Orchestration**: The multi-agent system demonstrates how specialized agents can collaborate to solve complex problems more effectively than a single general-purpose agent.

4. **Testing and Deployment**: We've established a framework for systematically testing and deploying agents, ensuring they perform reliably and can be maintained in production environments.

5. **Model Interaction Automation**: The model interaction system showcases how different AI models can be orchestrated into workflows, enabling more sophisticated applications than what any single model could achieve.

As AI agent technology continues to evolve, these patterns and techniques will become increasingly important. The future of AI development is moving toward more composable, specialized systems that can be orchestrated to achieve complex goals. By understanding how to design, implement, and deploy such systems, developers can create powerful AI applications that go beyond simple Q&A to autonomous problem-solving.

For further exploration, consider extending these systems with:
- More sophisticated planning capabilities
- Enhanced memory mechanisms
- Integration with domain-specific knowledge bases
- Improved evaluation and monitoring frameworks
- Advanced security and safety constraints

This workshop provides a foundation for building modern AI agent systems that can tackle real-world problems through intelligent collaboration and orchestration.