<small>Claude Sonnet 4</small>
# 04. Automation and Workflow with n8n

## Key Terms

**n8n**: An open-source workflow automation platform that allows you to connect different services and automate complex processes through a visual interface. It supports over 400 integrations and can be self-hosted or used as a cloud service.

**Workflow**: A sequence of automated tasks that are executed in a specific order, often triggered by events or schedules. In n8n, workflows are represented as visual graphs with nodes and connections.

**Node**: A fundamental building block in n8n that represents a single operation or service integration. Each node can perform actions like API calls, data transformation, or conditional logic.

**Webhook**: An HTTP endpoint that receives data from external services when specific events occur, enabling real-time automation triggers.

**Expression**: Dynamic data manipulation using JavaScript-like syntax in n8n to transform and process data between nodes.

## Process Visualization and Agent Creation with n8n

n8n provides a powerful visual interface for creating complex automation workflows that can serve as AI agents. The platform excels at orchestrating multiple services, APIs, and data sources through an intuitive drag-and-drop interface.

### Core Architecture Components

n8n workflows consist of interconnected nodes that process data sequentially or in parallel. Each node receives input data, performs operations, and passes output to subsequent nodes. This architecture is particularly suitable for AI agent development because it allows for:

- **Event-driven triggers**: Webhooks, schedules, or manual executions
- **Data processing pipelines**: Transform and enrich data between services
- **Conditional logic**: Branch workflows based on data or external conditions
- **Error handling**: Robust error management and retry mechanisms

### Advanced Node Configuration

````python
import requests
import json
import os
from dotenv import load_dotenv

load_dotenv()

class N8nWorkflowManager:
    def __init__(self):
        self.base_url = os.getenv('N8N_BASE_URL', 'http://localhost:5678')
        self.webhook_url = f"{self.base_url}/webhook"
        self.api_key = os.getenv('N8N_API_KEY')
        
    def create_ai_agent_workflow(self):
        """Create a comprehensive AI agent workflow"""
        workflow_definition = {
            "name": "Advanced AI Agent Workflow",
            "nodes": [
                {
                    "parameters": {
                        "path": "ai-agent",
                        "httpMethod": "POST",
                        "responseMode": "responseNode"
                    },
                    "name": "Webhook Trigger",
                    "type": "n8n-nodes-base.webhook",
                    "typeVersion": 1,
                    "position": [240, 300]
                },
                {
                    "parameters": {
                        "jsCode": """
// Data preprocessing and validation
const inputData = $input.first().json;

// Validate required fields
const requiredFields = ['query', 'context', 'user_id'];
for (const field of requiredFields) {
    if (!inputData[field]) {
        throw new Error(`Missing required field: ${field}`);
    }
}

// Clean and normalize input
const processedData = {
    query: inputData.query.trim().toLowerCase(),
    context: inputData.context,
    user_id: inputData.user_id,
    timestamp: new Date().toISOString(),
    session_id: inputData.session_id || `session_${Date.now()}`,
    metadata: {
        source: inputData.source || 'api',
        priority: inputData.priority || 'normal'
    }
};

return [{ json: processedData }];
"""
                    },
                    "name": "Data Preprocessing",
                    "type": "n8n-nodes-base.code",
                    "typeVersion": 1,
                    "position": [440, 300]
                },
                {
                    "parameters": {
                        "method": "POST",
                        "url": "https://api.openai.com/v1/chat/completions",
                        "authentication": "headerAuth",
                        "sendHeaders": True,
                        "headerParameters": {
                            "parameters": [
                                {
                                    "name": "Authorization",
                                    "value": f"Bearer {os.getenv('OPENAI_API_KEY')}"
                                },
                                {
                                    "name": "Content-Type",
                                    "value": "application/json"
                                }
                            ]
                        },
                        "sendBody": True,
                        "bodyParameters": {
                            "parameters": [
                                {
                                    "name": "model",
                                    "value": "gpt-4-turbo-preview"
                                },
                                {
                                    "name": "messages",
                                    "value": "={{JSON.stringify([{role: 'system', content: 'You are an advanced AI agent with access to tools and databases. Analyze the user query and determine the appropriate action.'}, {role: 'user', content: $json.query}])}}"
                                },
                                {
                                    "name": "tools",
                                    "value": """[
                                        {
                                            "type": "function",
                                            "function": {
                                                "name": "search_database",
                                                "description": "Search the knowledge database",
                                                "parameters": {
                                                    "type": "object",
                                                    "properties": {
                                                        "query": {"type": "string"},
                                                        "limit": {"type": "integer", "default": 5}
                                                    }
                                                }
                                            }
                                        },
                                        {
                                            "type": "function",
                                            "function": {
                                                "name": "execute_action",
                                                "description": "Execute a specific action",
                                                "parameters": {
                                                    "type": "object",
                                                    "properties": {
                                                        "action": {"type": "string"},
                                                        "parameters": {"type": "object"}
                                                    }
                                                }
                                            }
                                        }
                                    ]"""
                                },
                                {
                                    "name": "tool_choice",
                                    "value": "auto"
                                }
                            ]
                        }
                    },
                    "name": "OpenAI LLM Call",
                    "type": "n8n-nodes-base.httpRequest",
                    "typeVersion": 3,
                    "position": [640, 300]
                }
            ],
            "connections": {
                "Webhook Trigger": {
                    "main": [
                        [
                            {
                                "node": "Data Preprocessing",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Data Preprocessing": {
                    "main": [
                        [
                            {
                                "node": "OpenAI LLM Call",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                }
            }
        }
        
        return workflow_definition

    def deploy_workflow(self, workflow_definition):
        """Deploy workflow to n8n instance"""
        headers = {
            'Content-Type': 'application/json',
            'X-N8N-API-KEY': self.api_key
        }
        
        response = requests.post(
            f"{self.base_url}/api/v1/workflows",
            headers=headers,
            json=workflow_definition
        )
        
        if response.status_code == 201:
            return response.json()
        else:
            raise Exception(f"Failed to deploy workflow: {response.text}")
````

## Working with Nodes, Variables, Databases, and APIs

### Advanced Node Interactions

n8n supports sophisticated data flow patterns through various node types. The platform's strength lies in its ability to seamlessly integrate different services while maintaining data consistency and error handling.

````python
import asyncio
import aiohttp
import motor.motor_asyncio
from sqlalchemy import create_engine, text
import chromadb
from elasticsearch import AsyncElasticsearch

class DatabaseIntegrationManager:
    def __init__(self):
        self.mongo_client = motor.motor_asyncio.AsyncIOMotorClient(
            os.getenv('MONGODB_URL')
        )
        self.postgres_engine = create_engine(os.getenv('POSTGRES_URL'))
        self.chroma_client = chromadb.PersistentClient(
            path=os.getenv('CHROMA_PATH', './chroma_db')
        )
        self.elasticsearch_client = AsyncElasticsearch([
            {'host': os.getenv('ELASTICSEARCH_HOST', 'localhost'), 
             'port': int(os.getenv('ELASTICSEARCH_PORT', 9200))}
        ])

    async def execute_multi_database_query(self, query_context):
        """Execute queries across multiple database types"""
        results = {}
        
        # Vector similarity search in ChromaDB
        collection = self.chroma_client.get_or_create_collection("knowledge_base")
        vector_results = collection.query(
            query_texts=[query_context['semantic_query']],
            n_results=5,
            include=['documents', 'metadatas', 'distances']
        )
        results['vector_search'] = vector_results
        
        # Full-text search in Elasticsearch
        search_body = {
            "query": {
                "multi_match": {
                    "query": query_context['text_query'],
                    "fields": ["title", "content", "tags"],
                    "fuzziness": "AUTO"
                }
            },
            "highlight": {
                "fields": {
                    "content": {}
                }
            },
            "size": 10
        }
        
        es_results = await self.elasticsearch_client.search(
            index="documents",
            body=search_body
        )
        results['fulltext_search'] = es_results['hits']
        
        # Structured data query in PostgreSQL
        with self.postgres_engine.connect() as conn:
            sql_query = text("""
                SELECT id, title, category, created_at, metadata
                FROM documents 
                WHERE category = :category 
                AND created_at >= :date_filter
                ORDER BY created_at DESC
                LIMIT 20
            """)
            
            sql_results = conn.execute(sql_query, {
                'category': query_context.get('category', 'general'),
                'date_filter': query_context.get('date_filter', '2023-01-01')
            }).fetchall()
            
            results['structured_data'] = [dict(row._mapping) for row in sql_results]
        
        # Document metadata in MongoDB
        db = self.mongo_client.knowledge_db
        mongo_results = await db.document_metadata.find({
            "tags": {"$in": query_context.get('tags', [])},
            "status": "active"
        }).limit(15).to_list(length=15)
        
        results['document_metadata'] = mongo_results
        
        return results

    def create_n8n_database_nodes(self):
        """Generate n8n node configurations for database operations"""
        return {
            "mongodb_node": {
                "parameters": {
                    "operation": "find",
                    "collection": "={{$json.collection_name}}",
                    "query": "={{JSON.stringify($json.query_filter)}}",
                    "limit": 50,
                    "sort": "={{JSON.stringify({created_at: -1})}}"
                },
                "name": "MongoDB Query",
                "type": "n8n-nodes-base.mongoDb",
                "typeVersion": 1
            },
            "postgres_node": {
                "parameters": {
                    "query": """
                        SELECT d.*, u.username, u.department
                        FROM documents d
                        LEFT JOIN users u ON d.created_by = u.id
                        WHERE d.content_vector <-> $1::vector < 0.5
                        ORDER BY d.content_vector <-> $1::vector
                        LIMIT $2
                    """,
                    "additionalFields": {
                        "mode": "executeQuery"
                    }
                },
                "name": "PostgreSQL Vector Search",
                "type": "n8n-nodes-base.postgres",
                "typeVersion": 2
            },
            "elasticsearch_node": {
                "parameters": {
                    "operation": "search",
                    "indexId": "={{$json.index_name}}",
                    "body": {
                        "query": {
                            "bool": {
                                "must": [
                                    {
                                        "multi_match": {
                                            "query": "={{$json.search_query}}",
                                            "fields": ["title^2", "content", "tags"]
                                        }
                                    }
                                ],
                                "filter": [
                                    {
                                        "range": {
                                            "created_at": {
                                                "gte": "={{$json.date_filter}}"
                                            }
                                        }
                                    }
                                ]
                            }
                        },
                        "aggs": {
                            "categories": {
                                "terms": {
                                    "field": "category.keyword",
                                    "size": 10
                                }
                            }
                        }
                    }
                },
                "name": "Elasticsearch Advanced Search",
                "type": "n8n-nodes-base.elasticsearch",
                "typeVersion": 1
            }
        }
````

### Variable Management and State Persistence

````python
import redis
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

class WorkflowStateManager:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            password=os.getenv('REDIS_PASSWORD'),
            decode_responses=True
        )
        
    def create_stateful_workflow_nodes(self):
        """Create n8n nodes with advanced state management"""
        return {
            "state_initialization": {
                "parameters": {
                    "jsCode": """
// Initialize workflow state
const workflowId = $('Webhook Trigger').first().json.headers['x-workflow-id'] || 
                   `wf_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

const initialState = {
    workflow_id: workflowId,
    session_id: $json.session_id,
    user_id: $json.user_id,
    start_time: new Date().toISOString(),
    step_count: 0,
    context: {
        conversation_history: [],
        user_preferences: {},
        active_tools: [],
        data_cache: {}
    },
    metadata: {
        source: $json.source || 'api',
        version: '1.0',
        environment: process.env.NODE_ENV || 'development'
    }
};

// Store in Redis through HTTP request node
return [{
    json: {
        state: initialState,
        redis_key: `workflow_state:${workflowId}`,
        operation: 'set'
    }
}];
"""
                },
                "name": "Initialize Workflow State",
                "type": "n8n-nodes-base.code",
                "typeVersion": 2
            },
            
            "state_update": {
                "parameters": {
                    "jsCode": """
// Update workflow state with new information
const currentState = JSON.parse($('Get Current State').first().json.state || '{}');
const newData = $json;

// Increment step counter
currentState.step_count = (currentState.step_count || 0) + 1;

// Update conversation history
if (newData.message) {
    currentState.context.conversation_history.push({
        timestamp: new Date().toISOString(),
        type: newData.message_type || 'user_input',
        content: newData.message,
        metadata: newData.message_metadata || {}
    });
    
    // Keep only last 50 messages to prevent memory issues
    if (currentState.context.conversation_history.length > 50) {
        currentState.context.conversation_history = 
            currentState.context.conversation_history.slice(-50);
    }
}

// Update user preferences
if (newData.preferences) {
    currentState.context.user_preferences = {
        ...currentState.context.user_preferences,
        ...newData.preferences
    };
}

// Update data cache
if (newData.cache_data) {
    const cacheKey = newData.cache_key || 'default';
    currentState.context.data_cache[cacheKey] = {
        data: newData.cache_data,
        timestamp: new Date().toISOString(),
        ttl: newData.cache_ttl || 3600 // 1 hour default
    };
}

// Update active tools
if (newData.active_tools) {
    currentState.context.active_tools = [
        ...new Set([...currentState.context.active_tools, ...newData.active_tools])
    ];
}

return [{
    json: {
        updated_state: currentState,
        redis_key: `workflow_state:${currentState.workflow_id}`,
        operation: 'update'
    }
}];
"""
                },
                "name": "Update Workflow State",
                "type": "n8n-nodes-base.code",
                "typeVersion": 2
            },
            
            "conditional_logic": {
                "parameters": {
                    "conditions": {
                        "options": {
                            "caseSensitive": True,
                            "leftValue": "",
                            "typeValidation": "strict"
                        },
                        "conditions": [
                            {
                                "leftValue": "={{$json.state.step_count}}",
                                "rightValue": 10,
                                "operator": {
                                    "type": "number",
                                    "operation": "gt"
                                }
                            },
                            {
                                "leftValue": "={{$json.user_intent}}",
                                "rightValue": "terminate",
                                "operator": {
                                    "type": "string",
                                    "operation": "equals"
                                }
                            }
                        ],
                        "combineOperation": "any"
                    }
                },
                "name": "Check Termination Conditions",
                "type": "n8n-nodes-base.if",
                "typeVersion": 1
            }
        }

    async def manage_workflow_state(self, workflow_id: str, operation: str, data: Optional[Dict[str, Any]] = None):
        """Manage workflow state in Redis"""
        key = f"workflow_state:{workflow_id}"
        
        if operation == "get":
            state_json = self.redis_client.get(key)
            return json.loads(state_json) if state_json else None
            
        elif operation == "set":
            if data:
                self.redis_client.setex(
                    key, 
                    timedelta(hours=24),  # 24-hour TTL
                    json.dumps(data, default=str)
                )
                return True
            return False
            
        elif operation == "update":
            current_state = await self.manage_workflow_state(workflow_id, "get")
            if current_state and data:
                updated_state = {**current_state, **data}
                return await self.manage_workflow_state(workflow_id, "set", updated_state)
            return False
            
        elif operation == "delete":
            return bool(self.redis_client.delete(key))
            
        return False
````

## LLM Integration and Agent Creation in Workflow

### Advanced AI Agent Workflow Implementation

````python
import asyncio
import json
from typing import List, Dict, Any
import openai
from anthropic import Anthropic

class AdvancedAIAgentWorkflow:
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        
    def create_multi_llm_workflow(self):
        """Create sophisticated workflow with multiple LLM providers"""
        return {
            "name": "Multi-LLM AI Agent Workflow",
            "nodes": [
                {
                    "parameters": {
                        "jsCode": """
// LLM Router - determines which model to use based on query type
const query = $json.query;
const queryType = $json.query_type || 'general';
const complexity = $json.complexity || 'medium';

let selectedProvider = 'openai';
let selectedModel = 'gpt-4-turbo-preview';

// Route based on query characteristics
if (queryType === 'creative' || queryType === 'writing') {
    selectedProvider = 'anthropic';
    selectedModel = 'claude-3-sonnet-20240229';
} else if (queryType === 'analytical' || queryType === 'code') {
    selectedProvider = 'openai';
    selectedModel = complexity === 'high' ? 'gpt-4-turbo-preview' : 'gpt-3.5-turbo';
} else if (queryType === 'reasoning' || queryType === 'math') {
    selectedProvider = 'openai';
    selectedModel = 'gpt-4-turbo-preview';
}

// Determine if function calling is needed
const needsFunctionCalling = query.toLowerCase().includes('search') || 
                              query.toLowerCase().includes('database') ||
                              query.toLowerCase().includes('calculate') ||
                              query.toLowerCase().includes('execute');

return [{
    json: {
        original_query: query,
        provider: selectedProvider,
        model: selectedModel,
        needs_function_calling: needsFunctionCalling,
        routing_metadata: {
            query_type: queryType,
            complexity: complexity,
            timestamp: new Date().toISOString()
        }
    }
}];
"""
                    },
                    "name": "LLM Router",
                    "type": "n8n-nodes-base.code",
                    "typeVersion": 2,
                    "position": [440, 300]
                },
                
                {
                    "parameters": {
                        "method": "POST",
                        "url": "={{$json.provider === 'openai' ? 'https://api.openai.com/v1/chat/completions' : 'https://api.anthropic.com/v1/messages'}}",
                        "authentication": "headerAuth",
                        "sendHeaders": True,
                        "headerParameters": {
                            "parameters": [
                                {
                                    "name": "Authorization",
                                    "value": "={{$json.provider === 'openai' ? 'Bearer ' + $env.OPENAI_API_KEY : 'Bearer ' + $env.ANTHROPIC_API_KEY}}"
                                },
                                {
                                    "name": "Content-Type",
                                    "value": "application/json"
                                },
                                {
                                    "name": "anthropic-version",
                                    "value": "={{$json.provider === 'anthropic' ? '2023-06-01' : ''}}"
                                }
                            ]
                        },
                        "sendBody": True,
                        "bodyParameters": {
                            "parameters": [
                                {
                                    "name": "model",
                                    "value": "={{$json.model}}"
                                },
                                {
                                    "name": "messages",
                                    "value": "={{$json.provider === 'openai' ? JSON.stringify([{role: 'system', content: 'You are an advanced AI agent with access to tools and databases. Analyze user queries and provide comprehensive responses.'}, {role: 'user', content: $json.original_query}]) : JSON.stringify([{role: 'user', content: $json.original_query}])}}"
                                },
                                {
                                    "name": "max_tokens",
                                    "value": "={{$json.provider === 'anthropic' ? 4000 : undefined}}"
                                },
                                {
                                    "name": "tools",
                                    "value": "={{$json.needs_function_calling ? JSON.stringify([\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"search_knowledge_base\",\n      \"description\": \"Search the knowledge base for relevant information\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n          \"filters\": {\"type\": \"object\", \"description\": \"Optional filters\"},\n          \"limit\": {\"type\": \"integer\", \"default\": 10}\n        },\n        \"required\": [\"query\"]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"execute_database_query\",\n      \"description\": \"Execute a database query\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"query_type\": {\"type\": \"string\", \"enum\": [\"sql\", \"nosql\", \"vector\"]},\n          \"query\": {\"type\": \"string\"},\n          \"database\": {\"type\": \"string\"}\n        },\n        \"required\": [\"query_type\", \"query\"]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"generate_report\",\n      \"description\": \"Generate a structured report\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"report_type\": {\"type\": \"string\"},\n          \"data_sources\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n          \"format\": {\"type\": \"string\", \"enum\": [\"json\", \"markdown\", \"html\"]}\n        },\n        \"required\": [\"report_type\"]\n      }\n    }\n  }\n]) : undefined}}"
                                },
                                {
                                    "name": "tool_choice",
                                    "value": "={{$json.needs_function_calling ? 'auto' : undefined}}"
                                },
                                {
                                    "name": "temperature",
                                    "value": 0.7
                                }
                            ]
                        }
                    },
                    "name": "Multi-Provider LLM Call",
                    "type": "n8n-nodes-base.httpRequest",
                    "typeVersion": 3,
                    "position": [640, 300]
                },
                
                {
                    "parameters": {
                        "jsCode": """
// Process LLM response and handle function calls
const response = $json;
const provider = $('LLM Router').first().json.provider;

let processedResponse = {
    provider: provider,
    model: $('LLM Router').first().json.model,
    timestamp: new Date().toISOString()
};

if (provider === 'openai') {
    const choice = response.choices[0];
    processedResponse.content = choice.message.content;
    processedResponse.finish_reason = choice.finish_reason;
    
    // Handle function calls
    if (choice.message.tool_calls) {
        processedResponse.tool_calls = choice.message.tool_calls.map(call => ({
            id: call.id,
            function: call.function.name,
            arguments: JSON.parse(call.function.arguments)
        }));
        processedResponse.needs_tool_execution = true;
    }
    
    processedResponse.usage = response.usage;
    
} else if (provider === 'anthropic') {
    processedResponse.content = response.content[0].text;
    processedResponse.stop_reason = response.stop_reason;
    processedResponse.usage = response.usage;
    
    // Handle tool use for Anthropic
    const toolUseBlocks = response.content.filter(block => block.type === 'tool_use');
    if (toolUseBlocks.length > 0) {
        processedResponse.tool_calls = toolUseBlocks.map(block => ({
            id: block.id,
            function: block.name,
            arguments: block.input
        }));
        processedResponse.needs_tool_execution = true;
    }
}

// Analyze response sentiment and confidence
const content = processedResponse.content || '';
const confidenceIndicators = [
    'certainly', 'definitely', 'clearly', 'obviously',
    'might', 'possibly', 'perhaps', 'maybe', 'uncertain'
];

let confidence = 'medium';
if (confidenceIndicators.slice(0, 4).some(word => content.toLowerCase().includes(word))) {
    confidence = 'high';
} else if (confidenceIndicators.slice(4).some(word => content.toLowerCase().includes(word))) {
    confidence = 'low';
}

processedResponse.analysis = {
    confidence: confidence,
    word_count: content.split(' ').length,
    has_questions: content.includes('?'),
    requires_followup: content.toLowerCase().includes('more information') || 
                      content.toLowerCase().includes('clarify')
};

return [{ json: processedResponse }];
"""
                    },
                    "name": "Process LLM Response",
                    "type": "n8n-nodes-base.code",
                    "typeVersion": 2,
                    "position": [840, 300]
                }
            ],
            "connections": {
                "LLM Router": {
                    "main": [
                        [
                            {
                                "node": "Multi-Provider LLM Call",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Multi-Provider LLM Call": {
                    "main": [
                        [
                            {
                                "node": "Process LLM Response",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                }
            }
        }

    async def execute_function_call(self, function_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Execute function calls from LLM responses"""
        function_registry = {
            'search_knowledge_base': self._search_knowledge_base,
            'execute_database_query': self._execute_database_query,
            'generate_report': self._generate_report,
            'send_email': self._send_email,
            'create_calendar_event': self._create_calendar_event,
            'analyze_sentiment': self._analyze_sentiment
        }
        
        if function_name in function_registry:
            try:
                result = await function_registry[function_name](**arguments)
                return {
                    'success': True,
                    'function': function_name,
                    'result': result,
                    'timestamp': datetime.now().isoformat()
                }
            except Exception as e:
                return {
                    'success': False,
                    'function': function_name,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        else:
            return {
                'success': False,
                'function': function_name,
                'error': f'Function {function_name} not found',
                'timestamp': datetime.now().isoformat()
            }

    async def _search_knowledge_base(self, query: str, filters: Dict = None, limit: int = 10):
        """Search knowledge base implementation"""
        # Integration with vector database and search engines
        return {
            'query': query,
            'results': [],
            'total_found': 0,
            'search_time_ms': 0
        }

    async def _execute_database_query(self, query_type: str, query: str, database: str = None):
        """Execute database query implementation"""
        # Database query execution logic
        return {
            'query_type': query_type,
            'query': query,
            'results': [],
            'execution_time_ms': 0
        }

    async def _generate_report(self, report_type: str, data_sources: List[str] = None, format: str = 'json'):
        """Generate report implementation"""
        # Report generation logic
        return {
            'report_type': report_type,
            'format': format,
            'generated_at': datetime.now().isoformat(),
            'content': {}
        }
````

## Practical Exercise: Custom AI Agent in n8n Environment

### Complete Agent Implementation

````python
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

class CustomAIAgentExercise:
    """Complete implementation of a custom AI agent in n8n environment"""
    
    def __init__(self):
        self.agent_config = self._load_agent_configuration()
        
    def _load_agent_configuration(self):
        """Load agent configuration from environment"""
        return {
            'name': 'Advanced Customer Service Agent',
            'capabilities': [
                'customer_inquiry_handling',
                'knowledge_base_search',
                'order_management',
                'escalation_management',
                'sentiment_analysis',
                'multi_language_support'
            ],
            'databases': {
                'customer_db': os.getenv('CUSTOMER_DB_URL'),
                'product_db': os.getenv('PRODUCT_DB_URL'),
                'knowledge_base': os.getenv('KNOWLEDGE_BASE_URL')
            },
            'integrations': {
                'email': os.getenv('EMAIL_SERVICE_URL'),
                'slack': os.getenv('SLACK_WEBHOOK_URL'),
                'crm': os.getenv('CRM_API_URL')
            }
        }

    def create_complete_agent_workflow(self):
        """Create a comprehensive AI agent workflow with all components"""
        return {
            "name": "Advanced Customer Service AI Agent",
            "active": True,
            "nodes": [
                # Input Processing
                {
                    "parameters": {
                        "path": "customer-service-agent",
                        "httpMethod": "POST",
                        "responseMode": "responseNode"
                    },
                    "name": "Customer Input Webhook",
                    "type": "n8n-nodes-base.webhook",
                    "typeVersion": 1,
                    "position": [240, 300]
                },
                
                # Input Validation and Classification
                {
                    "parameters": {
                        "jsCode": """
// Advanced input processing and classification
const input = $input.first().json;

// Validate input structure
const requiredFields = ['customer_id', 'message', 'channel'];
const missingFields = requiredFields.filter(field => !input[field]);

if (missingFields.length > 0) {
    throw new Error(`Missing required fields: ${missingFields.join(', ')}`);
}

// Extract and clean message
const message = input.message.trim();
const customerId = input.customer_id;
const channel = input.channel;

// Intent classification using keyword analysis
const intentPatterns = {
    'order_inquiry': ['order', 'purchase', 'delivery', 'shipping', 'tracking'],
    'technical_support': ['bug', 'error', 'not working', 'issue', 'problem', 'help'],
    'billing': ['payment', 'bill', 'charge', 'refund', 'invoice', 'cost'],
    'product_info': ['product', 'feature', 'specification', 'compatibility'],
    'complaint': ['complaint', 'dissatisfied', 'angry', 'terrible', 'awful'],
    'compliment': ['great', 'excellent', 'awesome', 'love', 'perfect'],
    'cancellation': ['cancel', 'unsubscribe', 'stop', 'terminate']
};

let detectedIntent = 'general_inquiry';
let confidence = 0;

for (const [intent, keywords] of Object.entries(intentPatterns)) {
    const matches = keywords.filter(keyword => 
        message.toLowerCase().includes(keyword.toLowerCase())
    ).length;
    
    const currentConfidence = matches / keywords.length;
    if (currentConfidence > confidence) {
        confidence = currentConfidence;
        detectedIntent = intent;
    }
}

// Urgency detection
const urgencyKeywords = ['urgent', 'asap', 'immediately', 'emergency', 'critical'];
const isUrgent = urgencyKeywords.some(keyword => 
    message.toLowerCase().includes(keyword.toLowerCase())
);

// Language detection (simple implementation)
const languagePatterns = {
    'spanish': ['hola', 'gracias', 'por favor', 'ayuda'],
    'french': ['bonjour', 'merci', 'aide', 's\'il vous plaît'],
    'german': ['hallo', 'danke', 'bitte', 'hilfe']
};

let detectedLanguage = 'english';
for (const [lang, patterns] of Object.entries(languagePatterns)) {
    if (patterns.some(pattern => message.toLowerCase().includes(pattern))) {
        detectedLanguage = lang;
        break;
    }
}

const processedInput = {
    customer_id: customerId,
    original_message: message,
    channel: channel,
    timestamp: new Date().toISOString(),
    classification: {
        intent: detectedIntent,
        confidence: confidence,
        is_urgent: isUrgent,
        language: detectedLanguage
    },
    metadata: {
        message_length: message.length,
        word_count: message.split(' ').length,
        contains_email: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/.test(message),
        contains_phone: /(\+\d{1,3}[- ]?)?\d{10}/.test(message)
    },
    processing_id: `proc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
};

return [{ json: processedInput }];
"""
                    },
                    "name": "Input Classification",
                    "type": "n8n-nodes-base.code",
                    "typeVersion": 2,
                    "position": [440, 300]
                },
                
                # Customer Data Retrieval
                {
                    "parameters": {
                        "query": """
                            SELECT 
                                c.customer_id,
                                c.first_name,
                                c.last_name,
                                c.email,
                                c.phone,
                                c.tier,
                                c.created_at,
                                c.last_contact_date,
                                COUNT(o.order_id) as total_orders,
                                SUM(o.total_amount) as total_spent,
                                AVG(s.satisfaction_score) as avg_satisfaction
                            FROM customers c
                            LEFT JOIN orders o ON c.customer_id = o.customer_id
                            LEFT JOIN support_tickets s ON c.customer_id = s.customer_id
                            WHERE c.customer_id = $1
                            GROUP BY c.customer_id, c.first_name, c.last_name, c.email, c.phone, c.tier, c.created_at, c.last_contact_date
                        """,
                        "additionalFields": {
                            "mode": "executeQuery"
                        }
                    },
                    "name": "Get Customer Data",
                    "type": "n8n-nodes-base.postgres",
                    "typeVersion": 2,
                    "position": [640, 200]
                },
                
                # Knowledge Base Search
                {
                    "parameters": {
                        "operation": "search",
                        "indexId": "knowledge_base",
                        "body": {
                            "query": {
                                "bool": {
                                    "should": [
                                        {
                                            "multi_match": {
                                                "query": "={{$json.original_message}}",
                                                "fields": ["title^3", "content^2", "tags", "category"],
                                                "type": "best_fields",
                                                "fuzziness": "AUTO"
                                            }
                                        },
                                        {
                                            "match": {
                                                "intent": "={{$json.classification.intent}}"
                                            }
                                        }
                                    ],
                                    "filter": [
                                        {
                                            "term": {
                                                "status": "published"
                                            }
                                        },
                                        {
                                            "term": {
                                                "language": "={{$json.classification.language}}"
                                            }
                                        }
                                    ]
                                }
                            },
                            "highlight": {
                                "fields": {
                                    "content": {
                                        "fragment_size": 150,
                                        "number_of_fragments": 3
                                    }
                                }
                            },
                            "size": 5,
                            "_source": ["title", "content", "category", "confidence_score", "last_updated"]
                        }
                    },
                    "name": "Search Knowledge Base",
                    "type": "n8n-nodes-base.elasticsearch",
                    "typeVersion": 1,
                    "position": [640, 400]
                },
                
                # AI Response Generation
                {
                    "parameters": {
                        "method": "POST",
                        "url": "https://api.openai.com/v1/chat/completions",
                        "authentication": "headerAuth",
                        "sendHeaders": True,
                        "headerParameters": {
                            "parameters": [
                                {
                                    "name": "Authorization",
                                    "value": "Bearer {{$env.OPENAI_API_KEY}}"
                                },
                                {
                                    "name": "Content-Type",
                                    "value": "application/json"
                                }
                            ]
                        },
                        "sendBody": True,
                        "bodyParameters": {
                            "parameters": [
                                {
                                    "name": "model",
                                    "value": "gpt-4-turbo-preview"
                                },
                                {
                                    "name": "messages",
                                    "value": """[
  {
    "role": "system",
    "content": "You are an advanced customer service AI agent. Use the provided customer data and knowledge base information to generate helpful, personalized responses. Always maintain a professional and empathetic tone. If you need to escalate or cannot resolve the issue, indicate this clearly."
  },
  {
    "role": "user",
    "content": "Customer Message: {{$('Input Classification').first().json.original_message}}\n\nCustomer Data: {{JSON.stringify($('Get Customer Data').first().json)}}\n\nKnowledge Base Results: {{JSON.stringify($('Search Knowledge Base').first().json.hits)}}\n\nClassification: {{JSON.stringify($('Input Classification').first().json.classification)}}\n\nPlease provide a comprehensive response to the customer."
  }
]"""
                                },
                                {
                                    "name": "tools",
                                    "value": """[
  {
    "type": "function",
    "function": {
      "name": "escalate_to_human",
      "description": "Escalate the conversation to a human agent",
      "parameters": {
        "type": "object",
        "properties": {
          "reason": {"type": "string", "description": "Reason for escalation"},
          "priority": {"type": "string", "enum": ["low", "medium", "high", "critical"]},
          "department": {"type": "string", "enum": ["general", "technical", "billing", "sales"]}
        },
        "required": ["reason", "priority"]
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "create_support_ticket",
      "description": "Create a support ticket for tracking",
      "parameters": {
        "type": "object",
        "properties": {
          "title": {"type": "string"},
          "description": {"type": "string"},
          "category": {"type": "string"},
          "priority": {"type": "string", "enum": ["low", "medium", "high", "critical"]}
        },
        "required": ["title", "description", "category"]
      }
    }
  },
  {
    "type": "function",
    "function": {
      "name": "send_follow_up_email",
      "description": "Schedule a follow-up email",
      "parameters": {
        "type": "object",
        "properties": {
          "subject": {"type": "string"},
          "template": {"type": "string"},
          "delay_hours": {"type": "integer", "default": 24}
        },
        "required": ["subject", "template"]
      }
    }
  }
]"""
                                },
                                {
                                    "name": "tool_choice",
                                    "value": "auto"
                                },
                                {
                                    "name": "temperature",
                                    "value": 0.7
                                },
                                {
                                    "name": "max_tokens",
                                    "value": 1500
                                }
                            ]
                        }
                    },
                    "name": "Generate AI Response",
                    "type": "n8n-nodes-base.httpRequest",
                    "typeVersion": 3,
                    "position": [840, 300]
                },
                
                # Response Processing and Actions
                {
                    "parameters": {
                        "jsCode": """
// Process AI response and execute any required actions
const aiResponse = $json;
const originalInput = $('Input Classification').first().json;
const customerData = $('Get Customer Data').first().json;

const choice = aiResponse.choices[0];
const responseMessage = choice.message.content;
const toolCalls = choice.message.tool_calls || [];

// Build comprehensive response object
const processedResponse = {
    response_id: `resp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
    customer_id: originalInput.customer_id,
    processing_id: originalInput.processing_id,
    timestamp: new Date().toISOString(),
    
    // Response content
    message: responseMessage,
    language: originalInput.classification.language,
    channel: originalInput.channel,
    
    // AI metadata
    model_used: 'gpt-4-turbo-preview',
    confidence: choice.finish_reason === 'stop' ? 'high' : 'medium',
    requires_human_review: choice.finish_reason === 'length' || toolCalls.some(call => call.function.name === 'escalate_to_human'),
    
    // Actions to execute
    actions: toolCalls.map(call => ({
        action_id: call.id,
        type: call.function.name,
        parameters: JSON.parse(call.function.arguments),
        status: 'pending'
    })),
    
    // Customer context
    customer_context: {
        tier: customerData.tier,
        total_orders: customerData.total_orders,
        is_urgent: originalInput.classification.is_urgent,
        intent: originalInput.classification.intent
    },
    
    // Quality metrics
    metrics: {
        response_time_ms: Date.now() - new Date(originalInput.timestamp).getTime(),
        knowledge_base_results_used: $('Search Knowledge Base').first().json.hits.hits.length,
        customer_data_enriched: !!customerData.customer_id
    }
};

// Determine response priority and routing
if (processedResponse.requires_human_review || originalInput.classification.is_urgent) {
    processedResponse.routing = {
        destination: 'human_agent_queue',
        priority: originalInput.classification.is_urgent ? 'high' : 'medium',
        estimated_wait_time: originalInput.classification.is_urgent ? 5 : 15
    };
} else {
    processedResponse.routing = {
        destination: 'automated_response',
        priority: 'low',
        estimated_wait_time: 0
    };
}

return [{ json: processedResponse }];
"""
                    },
                    "name": "Process Response and Actions",
                    "type": "n8n-nodes-base.code",
                    "typeVersion": 2,
                    "position": [1040, 300]
                },
                
                // Response Output
                {
                    "parameters": {
                        "respondWith": "json",
                        "responseBody": "={{JSON.stringify($json, null, 2)}}"
                    },
                    "name": "Send Response",
                    "type": "n8n-nodes-base.respondToWebhook",
                    "typeVersion": 1,
                    "position": [1240, 300]
                }
            ],
            
            "connections": {
                "Customer Input Webhook": {
                    "main": [
                        [
                            {
                                "node": "Input Classification",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Input Classification": {
                    "main": [
                        [
                            {
                                "node": "Get Customer Data",
                                "type": "main",
                                "index": 0
                            },
                            {
                                "node": "Search Knowledge Base",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Get Customer Data": {
                    "main": [
                        [
                            {
                                "node": "Generate AI Response",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Search Knowledge Base": {
                    "main": [
                        [
                            {
                                "node": "Generate AI Response",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Generate AI Response": {
                    "main": [
                        [
                            {
                                "node": "Process Response and Actions",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                },
                "Process Response and Actions": {
                    "main": [
                        [
                            {
                                "node": "Send Response",
                                "type": "main",
                                "index": 0
                            }
                        ]
                    ]
                }
            }
        }

    def create_monitoring_and_analytics_workflow(self):
        """Create workflow for monitoring agent performance"""
        return {
            "name": "Agent Performance Monitoring",
            "active": True,
            "nodes": [
                {
                    "parameters": {
                        "rule": {
                            "interval": [{"field": "minutes", "value": 5}]
                        }
                    },
                    "name": "Performance Check Schedule",
                    "type": "n8n-nodes-base.scheduleTrigger",
                    "typeVersion": 1,
                    "position": [240, 300]
                },
                {
                    "parameters": {
                        "query": """
                            SELECT 
                                DATE_TRUNC('hour', timestamp) as hour,
                                COUNT(*) as total_interactions,
                                AVG(metrics->>'response_time_ms')::float as avg_response_time,
                                COUNT(*) FILTER (WHERE requires_human_review = true) as escalations,
                                COUNT(*) FILTER (WHERE customer_context->>'is_urgent' = 'true') as urgent_requests,
                                COUNT(*) FILTER (WHERE routing->>'destination' = 'automated_response') as automated_resolutions
                            FROM agent_interactions 
                            WHERE timestamp >= NOW() - INTERVAL '24 hours'
                            GROUP BY DATE_TRUNC('hour', timestamp)
                            ORDER BY hour DESC
                        """
                    },
                    "name": "Get Performance Metrics",
                    "type": "n8n-nodes-base.postgres",
                    "typeVersion": 2,
                    "position": [440, 300]
                }
            ]
        }
````

## Conclusion

n8n provides a powerful platform for creating sophisticated AI agents through visual workflow design. The platform's strength lies in its ability to seamlessly integrate multiple services, databases, and AI providers while maintaining clear data flow and error handling. Key advantages include:

**Rapid Prototyping**: Visual interface allows for quick iteration and testing of agent workflows without extensive coding.

**Scalable Architecture**: Node-based design supports complex multi-step processes with parallel execution and conditional logic.

**Integration Ecosystem**: Extensive library of pre-built nodes for popular services reduces development time.

**State Management**: Built-in support for workflow state persistence enables sophisticated conversational agents.

**Multi-Modal Support**: Handles various input types (webhooks, schedules, manual triggers) and output formats (HTTP responses, emails, database updates).

The practical implementation demonstrates how n8n can orchestrate complex AI agent workflows involving multiple LLM providers, database queries, knowledge base searches, and automated actions. This approach is particularly valuable for businesses requiring rapid deployment of AI capabilities without extensive infrastructure development.

However, considerations include performance limitations for high-throughput scenarios and the need for careful error handling in complex workflows. For production deployments, proper monitoring, logging, and backup strategies are essential to ensure reliable agent operation.