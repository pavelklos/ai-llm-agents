<small>Claude Sonnet 4</small>
# 01. Introduction to AI Assistants and Creating Your First GPT Assistant

## Key Terms

**AI Assistant**: An intelligent software agent that uses natural language processing and machine learning to understand user queries and provide contextual responses, capable of performing tasks, answering questions, and engaging in conversational interactions with human-like understanding and reasoning capabilities.

**GPT (Generative Pre-trained Transformer)**: A state-of-the-art language model architecture based on transformer neural networks that has been pre-trained on vast amounts of text data, enabling it to generate human-like text, understand context, and perform various language tasks through few-shot or zero-shot learning.

**Conversational AI**: Advanced artificial intelligence systems designed to engage in natural, contextual dialogue with users, incorporating memory, personality traits, and domain-specific knowledge to provide personalized and relevant interactions across multiple turns of conversation.

**Large Language Model (LLM)**: Massive neural networks with billions of parameters trained on diverse text corpora that can understand and generate human language, perform reasoning tasks, and exhibit emergent capabilities in various domains without task-specific training.

**Prompt Engineering**: The systematic practice of designing, optimizing, and structuring input prompts to elicit desired responses from language models, involving techniques such as few-shot examples, chain-of-thought reasoning, and contextual framing to maximize model performance.

**System Prompt**: A foundational instruction set that defines the AI assistant's behavior, personality, capabilities, and constraints, serving as the primary configuration mechanism for establishing consistent character and operational parameters throughout conversations.

**Token Management**: The process of efficiently handling input and output tokens within the context window limitations of language models, including strategies for context compression, conversation summarization, and optimal prompt structuring to maintain coherent long-form interactions.

**Assistant Persona**: A carefully crafted identity and personality profile for an AI assistant that includes communication style, expertise areas, behavioral patterns, and response characteristics designed to create consistent and engaging user experiences.

## Comprehensive AI Assistant Development Framework

Modern AI assistants represent the convergence of advanced natural language processing, conversational AI, and sophisticated prompt engineering techniques to create intelligent systems capable of understanding context, maintaining conversation state, and providing valuable assistance across diverse domains and use cases.

### Advanced GPT Assistant Implementation

````python
import asyncio
import json
import logging
import os
import time
import warnings
from typing import Dict, List, Any, Optional, Union, Callable, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
import uuid
import re
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor

# OpenAI and AI model libraries
import openai
from openai import OpenAI, AsyncOpenAI
import tiktoken

# LangChain components for assistant development
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.output_parsers import PydanticOutputParser, JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

# Advanced conversation management
from langchain.memory.chat_message_histories import ChatMessageHistory
from langchain.schema.chat_history import BaseChatMessageHistory
from langchain.memory.summary import ConversationSummaryBufferMemory

# Data processing and analysis
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Web framework for API deployment
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel as PydanticBaseModel, Field as PydanticField, validator
import uvicorn

# Session and state management
import redis
import sqlite3
from sqlalchemy import create_engine, Column, String, DateTime, Text, Integer
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session

# Monitoring and observability
import structlog
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import wandb

# Utility libraries
from dotenv import load_dotenv
import hashlib
import secrets
from datetime import timedelta
import pytz

load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)

# Setup structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Prometheus metrics
assistant_requests = Counter('assistant_requests_total', 'Total assistant requests', ['assistant_type', 'status'])
response_time = Histogram('assistant_response_time_seconds', 'Assistant response time')
active_conversations = Gauge('assistant_active_conversations', 'Number of active conversations')

class AssistantType(Enum):
    """Types of AI assistants"""
    GENERAL_PURPOSE = "general_purpose"
    CUSTOMER_SUPPORT = "customer_support"
    TECHNICAL_ADVISOR = "technical_advisor"
    CREATIVE_WRITER = "creative_writer"
    RESEARCH_ASSISTANT = "research_assistant"
    EDUCATIONAL_TUTOR = "educational_tutor"
    PERSONAL_COACH = "personal_coach"

class ConversationState(Enum):
    """Conversation states"""
    INITIATED = "initiated"
    ACTIVE = "active"
    WAITING = "waiting"
    COMPLETED = "completed"
    ERROR = "error"

@dataclass
class AssistantConfig:
    """Configuration for AI assistant behavior and capabilities"""
    name: str
    assistant_type: AssistantType
    system_prompt: str
    personality_traits: Dict[str, float]  # traits like friendliness, formality, expertise
    temperature: float = 0.7
    max_tokens: int = 1000
    model_name: str = "gpt-4"
    memory_type: str = "buffer"  # buffer, summary, buffer_summary
    max_memory_tokens: int = 4000
    conversation_timeout: int = 3600  # seconds
    capabilities: List[str] = field(default_factory=list)
    constraints: List[str] = field(default_factory=list)
    fallback_responses: List[str] = field(default_factory=list)

@dataclass
class ConversationContext:
    """Context information for ongoing conversations"""
    conversation_id: str
    user_id: str
    assistant_config: AssistantConfig
    state: ConversationState
    created_at: datetime
    last_activity: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)
    session_data: Dict[str, Any] = field(default_factory=dict)

class ConversationMessage(PydanticBaseModel):
    """Message structure for conversation handling"""
    content: str
    role: str = "user"  # user, assistant, system
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    metadata: Dict[str, Any] = {}

class AssistantResponse(PydanticBaseModel):
    """Response structure from AI assistant"""
    message: str
    confidence: float = 0.8
    conversation_id: str
    response_time: float
    token_usage: Dict[str, int] = {}
    suggested_actions: List[str] = []
    context_used: List[str] = []

class AdvancedAssistantMemory:
    """Advanced memory management for AI assistants"""
    
    def __init__(self, memory_type: str = "buffer", max_tokens: int = 4000):
        self.memory_type = memory_type
        self.max_tokens = max_tokens
        self.conversation_history = []
        self.summary = ""
        self.key_facts = {}
        self.user_preferences = {}
        self.tokenizer = tiktoken.encoding_for_model("gpt-4")
    
    def add_message(self, message: ConversationMessage):
        """Add message to conversation memory"""
        self.conversation_history.append(message)
        self._manage_memory_size()
        self._extract_key_information(message)
    
    def _manage_memory_size(self):
        """Manage memory size to stay within token limits"""
        total_tokens = self._calculate_total_tokens()
        
        if total_tokens > self.max_tokens:
            if self.memory_type == "summary":
                self._create_summary()
                self.conversation_history = self.conversation_history[-5:]  # Keep recent messages
            elif self.memory_type == "buffer":
                # Remove oldest messages
                while total_tokens > self.max_tokens and len(self.conversation_history) > 1:
                    self.conversation_history.pop(0)
                    total_tokens = self._calculate_total_tokens()
            elif self.memory_type == "buffer_summary":
                if len(self.conversation_history) > 10:
                    self._create_summary()
                    self.conversation_history = self.conversation_history[-8:]
    
    def _calculate_total_tokens(self) -> int:
        """Calculate total tokens in conversation history"""
        total = len(self.tokenizer.encode(self.summary)) if self.summary else 0
        for msg in self.conversation_history:
            total += len(self.tokenizer.encode(msg.content))
        return total
    
    def _create_summary(self):
        """Create summary of conversation history"""
        if len(self.conversation_history) < 3:
            return
        
        # Create simple summary (in production, use LLM for better summarization)
        messages_text = "\n".join([f"{msg.role}: {msg.content}" for msg in self.conversation_history[:-3]])
        
        # Simple keyword extraction for summary
        words = re.findall(r'\w+', messages_text.lower())
        word_freq = {}
        for word in words:
            if len(word) > 3:  # Skip short words
                word_freq[word] = word_freq.get(word, 0) + 1
        
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        self.summary = f"Previous conversation topics: {', '.join([word for word, _ in top_words])}"
    
    def _extract_key_information(self, message: ConversationMessage):
        """Extract key information from messages"""
        content = message.content.lower()
        
        # Extract user preferences
        if "i like" in content or "i prefer" in content:
            preference_match = re.search(r"i (?:like|prefer) ([^.!?]+)", content)
            if preference_match:
                preference = preference_match.group(1).strip()
                self.user_preferences[f"preference_{len(self.user_preferences)}"] = preference
        
        # Extract key facts
        if "my name is" in content:
            name_match = re.search(r"my name is (\w+)", content)
            if name_match:
                self.key_facts["user_name"] = name_match.group(1)
    
    def get_context_for_prompt(self) -> str:
        """Get formatted context for prompt"""
        context_parts = []
        
        if self.summary:
            context_parts.append(f"Conversation Summary: {self.summary}")
        
        if self.key_facts:
            facts_str = ", ".join([f"{k}: {v}" for k, v in self.key_facts.items()])
            context_parts.append(f"Key Facts: {facts_str}")
        
        if self.user_preferences:
            prefs_str = ", ".join([f"{k}: {v}" for k, v in self.user_preferences.items()])
            context_parts.append(f"User Preferences: {prefs_str}")
        
        # Add recent conversation history
        if self.conversation_history:
            recent_messages = self.conversation_history[-5:]  # Last 5 messages
            history_str = "\n".join([f"{msg.role}: {msg.content}" for msg in recent_messages])
            context_parts.append(f"Recent Conversation:\n{history_str}")
        
        return "\n\n".join(context_parts)

class AdvancedGPTAssistant:
    """Advanced GPT-based AI assistant with sophisticated capabilities"""
    
    def __init__(self, config: AssistantConfig):
        self.config = config
        self.client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.sync_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.memory = AdvancedAssistantMemory(
            memory_type=config.memory_type,
            max_tokens=config.max_memory_tokens
        )
        self.conversation_contexts = {}
        self.performance_metrics = {
            "total_conversations": 0,
            "successful_responses": 0,
            "average_response_time": 0.0,
            "user_satisfaction": 0.0
        }
        self._initialize_assistant()
    
    def _initialize_assistant(self):
        """Initialize assistant with configuration"""
        logger.info(f"Initializing {self.config.name} assistant of type {self.config.assistant_type.value}")
        
        # Validate configuration
        if not self.config.system_prompt:
            raise ValueError("System prompt is required for assistant configuration")
        
        # Initialize performance tracking
        self.performance_metrics["initialized_at"] = datetime.now(timezone.utc).isoformat()
    
    async def start_conversation(self, user_id: str, initial_message: str = None) -> str:
        """Start a new conversation with the assistant"""
        conversation_id = str(uuid.uuid4())
        
        # Create conversation context
        context = ConversationContext(
            conversation_id=conversation_id,
            user_id=user_id,
            assistant_config=self.config,
            state=ConversationState.INITIATED,
            created_at=datetime.now(timezone.utc),
            last_activity=datetime.now(timezone.utc)
        )
        
        self.conversation_contexts[conversation_id] = context
        
        # Track metrics
        self.performance_metrics["total_conversations"] += 1
        active_conversations.inc()
        
        # Send welcome message if no initial message
        if not initial_message:
            welcome_response = await self._generate_welcome_message(context)
            return welcome_response
        else:
            # Process initial message
            response = await self.process_message(conversation_id, initial_message)
            return response.message
    
    async def process_message(self, conversation_id: str, message: str) -> AssistantResponse:
        """Process a user message and generate response"""
        start_time = time.time()
        
        try:
            # Get conversation context
            if conversation_id not in self.conversation_contexts:
                raise ValueError(f"Conversation {conversation_id} not found")
            
            context = self.conversation_contexts[conversation_id]
            context.last_activity = datetime.now(timezone.utc)
            context.state = ConversationState.ACTIVE
            
            # Add user message to memory
            user_message = ConversationMessage(content=message, role="user")
            self.memory.add_message(user_message)
            
            # Generate response
            response_content = await self._generate_response(context, message)
            
            # Add assistant response to memory
            assistant_message = ConversationMessage(content=response_content, role="assistant")
            self.memory.add_message(assistant_message)
            
            # Calculate metrics
            response_time_value = time.time() - start_time
            
            # Create response object
            response = AssistantResponse(
                message=response_content,
                conversation_id=conversation_id,
                response_time=response_time_value,
                confidence=self._calculate_confidence(message, response_content),
                suggested_actions=self._generate_suggested_actions(message, response_content),
                context_used=self._get_context_sources()
            )
            
            # Update metrics
            self.performance_metrics["successful_responses"] += 1
            self._update_performance_metrics(response_time_value)
            
            # Track Prometheus metrics
            assistant_requests.labels(
                assistant_type=self.config.assistant_type.value,
                status="success"
            ).inc()
            response_time.observe(response_time_value)
            
            logger.info(f"Processed message for conversation {conversation_id} in {response_time_value:.2f}s")
            
            return response
            
        except Exception as e:
            # Track error metrics
            assistant_requests.labels(
                assistant_type=self.config.assistant_type.value,
                status="error"
            ).inc()
            
            logger.error(f"Error processing message: {e}")
            
            # Return fallback response
            fallback_message = self._get_fallback_response()
            return AssistantResponse(
                message=fallback_message,
                conversation_id=conversation_id,
                response_time=time.time() - start_time,
                confidence=0.1
            )
    
    async def _generate_response(self, context: ConversationContext, message: str) -> str:
        """Generate AI response using OpenAI GPT"""
        
        # Build system prompt with personality and context
        system_prompt = self._build_comprehensive_system_prompt(context)
        
        # Get conversation context
        conversation_context = self.memory.get_context_for_prompt()
        
        # Prepare messages for API call
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        if conversation_context:
            messages.append({"role": "system", "content": f"Context:\n{conversation_context}"})
        
        messages.append({"role": "user", "content": message})
        
        # Generate response
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=messages,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
            presence_penalty=0.1,
            frequency_penalty=0.1
        )
        
        return response.choices[0].message.content
    
    def _build_comprehensive_system_prompt(self, context: ConversationContext) -> str:
        """Build comprehensive system prompt with personality and constraints"""
        
        prompt_parts = [
            f"You are {self.config.name}, a {self.config.assistant_type.value.replace('_', ' ')} AI assistant.",
            f"Base Instructions: {self.config.system_prompt}"
        ]
        
        # Add personality traits
        if self.config.personality_traits:
            traits_description = self._build_personality_description()
            prompt_parts.append(f"Personality: {traits_description}")
        
        # Add capabilities
        if self.config.capabilities:
            capabilities_str = ", ".join(self.config.capabilities)
            prompt_parts.append(f"Capabilities: {capabilities_str}")
        
        # Add constraints
        if self.config.constraints:
            constraints_str = ". ".join(self.config.constraints)
            prompt_parts.append(f"Constraints: {constraints_str}")
        
        # Add conversation guidelines
        guidelines = [
            "Maintain consistency with your personality throughout the conversation",
            "Be helpful, accurate, and engaging",
            "Ask clarifying questions when needed",
            "Acknowledge when you don't know something",
            "Keep responses concise but informative"
        ]
        prompt_parts.append(f"Guidelines: {'. '.join(guidelines)}")
        
        return "\n\n".join(prompt_parts)
    
    def _build_personality_description(self) -> str:
        """Build personality description from traits"""
        trait_descriptions = {
            "friendliness": {0.2: "formal", 0.5: "professional", 0.8: "friendly", 1.0: "very warm"},
            "expertise": {0.2: "basic knowledge", 0.5: "good knowledge", 0.8: "expert level", 1.0: "world-class expert"},
            "creativity": {0.2: "conservative", 0.5: "balanced", 0.8: "creative", 1.0: "highly innovative"},
            "formality": {0.2: "casual", 0.5: "semi-formal", 0.8: "formal", 1.0: "very formal"},
            "empathy": {0.2: "analytical", 0.5: "understanding", 0.8: "empathetic", 1.0: "highly compassionate"}
        }
        
        personality_parts = []
        for trait, value in self.config.personality_traits.items():
            if trait in trait_descriptions:
                levels = trait_descriptions[trait]
                # Find the appropriate level
                for threshold in sorted(levels.keys()):
                    if value <= threshold:
                        personality_parts.append(f"{trait}: {levels[threshold]}")
                        break
        
        return ", ".join(personality_parts)
    
    async def _generate_welcome_message(self, context: ConversationContext) -> str:
        """Generate personalized welcome message"""
        
        welcome_prompts = {
            AssistantType.GENERAL_PURPOSE: "Hello! I'm here to help with any questions or tasks you might have. What can I assist you with today?",
            AssistantType.CUSTOMER_SUPPORT: "Welcome! I'm here to help resolve any issues or answer questions about our services. How can I assist you?",
            AssistantType.TECHNICAL_ADVISOR: "Greetings! I'm your technical advisor, ready to help with technical questions and solutions. What technical challenge can I help you with?",
            AssistantType.CREATIVE_WRITER: "Hello there! I'm excited to help with your creative projects. Whether it's writing, brainstorming, or storytelling, I'm here to inspire. What are we creating today?",
            AssistantType.RESEARCH_ASSISTANT: "Hi! I'm your research assistant, ready to help you find information, analyze data, and explore topics in depth. What would you like to research?",
            AssistantType.EDUCATIONAL_TUTOR: "Welcome to our learning session! I'm here to help you understand concepts, work through problems, and achieve your learning goals. What subject shall we explore?",
            AssistantType.PERSONAL_COACH: "Hello! I'm here to support your personal development and help you achieve your goals. What area of your life would you like to work on today?"
        }
        
        base_welcome = welcome_prompts.get(
            self.config.assistant_type,
            "Hello! I'm your AI assistant. How can I help you today?"
        )
        
        # Personalize based on time of day and personality
        current_hour = datetime.now().hour
        time_greeting = ""
        
        if 5 <= current_hour < 12:
            time_greeting = "Good morning! "
        elif 12 <= current_hour < 17:
            time_greeting = "Good afternoon! "
        elif 17 <= current_hour < 22:
            time_greeting = "Good evening! "
        else:
            time_greeting = "Hello! "
        
        # Adjust for personality
        friendliness = self.config.personality_traits.get("friendliness", 0.5)
        if friendliness > 0.7:
            base_welcome = base_welcome.replace("Hello!", time_greeting + "It's wonderful to meet you!")
        else:
            base_welcome = base_welcome.replace("Hello!", time_greeting)
        
        return base_welcome
    
    def _calculate_confidence(self, user_message: str, response: str) -> float:
        """Calculate confidence score for the response"""
        
        # Simple confidence calculation based on response characteristics
        confidence = 0.5  # Base confidence
        
        # Higher confidence for longer, more detailed responses
        if len(response) > 100:
            confidence += 0.2
        
        # Lower confidence for very short responses
        if len(response) < 20:
            confidence -= 0.2
        
        # Higher confidence if response includes specific information
        if any(word in response.lower() for word in ["specifically", "exactly", "precisely", "according to"]):
            confidence += 0.1
        
        # Lower confidence if response includes uncertainty indicators
        if any(phrase in response.lower() for phrase in ["i'm not sure", "might be", "possibly", "i think"]):
            confidence -= 0.2
        
        # Ensure confidence is within valid range
        return max(0.0, min(1.0, confidence))
    
    def _generate_suggested_actions(self, user_message: str, response: str) -> List[str]:
        """Generate suggested follow-up actions"""
        
        suggestions = []
        
        # Analyze user message intent
        message_lower = user_message.lower()
        
        if "how" in message_lower:
            suggestions.append("Ask for more specific details")
            suggestions.append("Request step-by-step instructions")
        
        if "what" in message_lower:
            suggestions.append("Explore related topics")
            suggestions.append("Ask for examples")
        
        if "why" in message_lower:
            suggestions.append("Request deeper explanation")
            suggestions.append("Ask about alternatives")
        
        # Add general suggestions based on assistant type
        type_suggestions = {
            AssistantType.CUSTOMER_SUPPORT: ["Check account status", "Contact human agent", "View documentation"],
            AssistantType.TECHNICAL_ADVISOR: ["Review technical specs", "Test the solution", "Explore alternatives"],
            AssistantType.CREATIVE_WRITER: ["Brainstorm more ideas", "Develop the concept", "Review and revise"],
            AssistantType.RESEARCH_ASSISTANT: ["Find more sources", "Analyze data", "Create summary"],
            AssistantType.EDUCATIONAL_TUTOR: ["Practice problems", "Review concepts", "Take assessment"],
            AssistantType.PERSONAL_COACH: ["Set action plan", "Track progress", "Schedule follow-up"]
        }
        
        assistant_suggestions = type_suggestions.get(self.config.assistant_type, [])
        suggestions.extend(assistant_suggestions[:2])  # Add up to 2 type-specific suggestions
        
        return suggestions[:4]  # Return maximum 4 suggestions
    
    def _get_context_sources(self) -> List[str]:
        """Get list of context sources used in response generation"""
        sources = ["conversation_history"]
        
        if self.memory.summary:
            sources.append("conversation_summary")
        
        if self.memory.key_facts:
            sources.append("user_facts")
        
        if self.memory.user_preferences:
            sources.append("user_preferences")
        
        return sources
    
    def _get_fallback_response(self) -> str:
        """Get fallback response for error cases"""
        if self.config.fallback_responses:
            return np.random.choice(self.config.fallback_responses)
        
        return "I apologize, but I'm having trouble processing your request right now. Could you please try rephrasing your question?"
    
    def _update_performance_metrics(self, response_time: float):
        """Update performance metrics"""
        current_avg = self.performance_metrics["average_response_time"]
        total_responses = self.performance_metrics["successful_responses"]
        
        # Update rolling average
        new_avg = ((current_avg * (total_responses - 1)) + response_time) / total_responses
        self.performance_metrics["average_response_time"] = new_avg
    
    async def end_conversation(self, conversation_id: str) -> Dict[str, Any]:
        """End conversation and cleanup resources"""
        if conversation_id in self.conversation_contexts:
            context = self.conversation_contexts[conversation_id]
            context.state = ConversationState.COMPLETED
            
            # Calculate conversation metrics
            duration = (context.last_activity - context.created_at).total_seconds()
            message_count = len(self.memory.conversation_history)
            
            # Cleanup
            del self.conversation_contexts[conversation_id]
            active_conversations.dec()
            
            logger.info(f"Ended conversation {conversation_id}, duration: {duration:.1f}s, messages: {message_count}")
            
            return {
                "conversation_id": conversation_id,
                "duration_seconds": duration,
                "message_count": message_count,
                "status": "completed"
            }
        
        return {"status": "conversation_not_found"}
    
    def get_assistant_info(self) -> Dict[str, Any]:
        """Get comprehensive assistant information"""
        return {
            "name": self.config.name,
            "type": self.config.assistant_type.value,
            "capabilities": self.config.capabilities,
            "personality_traits": self.config.personality_traits,
            "performance_metrics": self.performance_metrics,
            "active_conversations": len(self.conversation_contexts),
            "memory_type": self.config.memory_type,
            "model": self.config.model_name
        }

class AssistantFactory:
    """Factory for creating different types of AI assistants"""
    
    @staticmethod
    def create_general_purpose_assistant(name: str = "Alex") -> AdvancedGPTAssistant:
        """Create a general-purpose AI assistant"""
        config = AssistantConfig(
            name=name,
            assistant_type=AssistantType.GENERAL_PURPOSE,
            system_prompt="""You are a helpful, knowledgeable, and friendly AI assistant designed to assist users with a wide variety of tasks and questions. You excel at providing accurate information, helping with problem-solving, offering creative solutions, and engaging in meaningful conversations.

Your core strengths include:
- Comprehensive knowledge across multiple domains
- Ability to break down complex topics into understandable explanations
- Creative problem-solving and brainstorming
- Adaptability to different conversation styles and user needs
- Maintaining helpful and positive interactions

Always strive to be helpful, accurate, and engaging while being honest about limitations.""",
            personality_traits={
                "friendliness": 0.8,
                "expertise": 0.7,
                "creativity": 0.6,
                "formality": 0.4,
                "empathy": 0.7
            },
            temperature=0.7,
            capabilities=[
                "General knowledge questions",
                "Problem-solving assistance",
                "Creative brainstorming",
                "Text analysis and writing help",
                "Educational explanations",
                "Task planning and organization"
            ],
            constraints=[
                "Cannot access real-time information",
                "Cannot perform actions outside the conversation",
                "Cannot provide medical, legal, or financial advice",
                "Must maintain user privacy and data protection"
            ],
            fallback_responses=[
                "I'd be happy to help! Could you provide a bit more detail about what you're looking for?",
                "That's an interesting question. Let me think about the best way to assist you with that.",
                "I want to make sure I give you the most helpful response. Could you clarify what specific aspect you're most interested in?"
            ]
        )
        
        return AdvancedGPTAssistant(config)
    
    @staticmethod
    def create_customer_support_assistant(name: str = "Sarah", company_name: str = "AcmeCorp") -> AdvancedGPTAssistant:
        """Create a customer support AI assistant"""
        config = AssistantConfig(
            name=name,
            assistant_type=AssistantType.CUSTOMER_SUPPORT,
            system_prompt=f"""You are {name}, a professional customer support representative for {company_name}. Your primary goal is to help customers resolve their issues, answer questions about products and services, and ensure they have a positive experience.

Your approach should be:
- Professional yet warm and empathetic
- Solution-oriented and proactive
- Patient and understanding, especially with frustrated customers
- Knowledgeable about company policies and procedures
- Efficient in resolving issues while maintaining quality service

Key responsibilities:
- Troubleshoot customer problems step-by-step
- Provide clear explanations of products, services, and policies
- Escalate complex issues to human agents when necessary
- Collect feedback to improve service quality
- Maintain accurate records of customer interactions

Always aim to resolve issues on the first contact when possible, and ensure customers feel heard and valued.""",
            personality_traits={
                "friendliness": 0.9,
                "expertise": 0.8,
                "creativity": 0.4,
                "formality": 0.7,
                "empathy": 0.9
            },
            temperature=0.5,
            capabilities=[
                "Product and service information",
                "Troubleshooting assistance",
                "Policy explanations",
                "Order status inquiries",
                "Account management help",
                "Feedback collection",
                "Issue escalation"
            ],
            constraints=[
                "Cannot access customer personal data without verification",
                "Cannot make unauthorized policy exceptions",
                "Must escalate complex technical issues to specialists",
                "Cannot process payments or refunds directly",
                "Must follow company guidelines and compliance requirements"
            ],
            fallback_responses=[
                "I understand your concern and want to help resolve this for you. Let me connect you with a specialist who can assist further.",
                "Thank you for your patience. I'm gathering the information needed to help you with this issue.",
                "I apologize for any inconvenience. Let me find the best way to address your situation."
            ]
        )
        
        return AdvancedGPTAssistant(config)
    
    @staticmethod
    def create_technical_advisor_assistant(name: str = "Dr. Tech", specialization: str = "Software Development") -> AdvancedGPTAssistant:
        """Create a technical advisor AI assistant"""
        config = AssistantConfig(
            name=name,
            assistant_type=AssistantType.TECHNICAL_ADVISOR,
            system_prompt=f"""You are {name}, a highly skilled technical advisor specializing in {specialization}. You provide expert technical guidance, solve complex problems, and help users understand and implement technical solutions.

Your expertise includes:
- Deep technical knowledge and problem-solving skills
- Ability to explain complex concepts clearly
- Best practices and industry standards
- Architecture and design principles
- Performance optimization and troubleshooting
- Security considerations and compliance requirements

Your approach:
- Provide accurate, well-researched technical advice
- Break down complex solutions into manageable steps
- Consider multiple approaches and trade-offs
- Emphasize best practices and quality standards
- Ask clarifying questions to understand requirements fully
- Provide code examples and practical implementations when appropriate

Always ensure solutions are robust, scalable, and maintainable while considering security and performance implications.""",
            personality_traits={
                "friendliness": 0.6,
                "expertise": 0.95,
                "creativity": 0.7,
                "formality": 0.8,
                "empathy": 0.5
            },
            temperature=0.3,
            capabilities=[
                "Technical problem analysis and solution design",
                "Code review and optimization recommendations",
                "Architecture and system design guidance",
                "Best practices and standards consultation",
                "Performance troubleshooting",
                "Security assessment and recommendations",
                "Technology selection and evaluation",
                "Documentation and knowledge transfer"
            ],
            constraints=[
                "Cannot access or modify external systems",
                "Cannot guarantee solution performance without proper testing",
                "Must recommend following proper development and deployment procedures",
                "Cannot provide solutions that violate security or compliance requirements",
                "Must emphasize the importance of testing and validation"
            ],
            fallback_responses=[
                "This is a complex technical challenge. Let me analyze the requirements and provide a comprehensive solution approach.",
                "I want to ensure I provide the most accurate technical guidance. Could you share more details about your specific environment and constraints?",
                "That's an excellent technical question. Let me break down the solution into clear, implementable steps."
            ]
        )
        
        return AdvancedGPTAssistant(config)

# FastAPI application for serving assistants
app = FastAPI(title="Advanced AI Assistant API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global assistant instances
assistants = {}

class ChatRequest(PydanticBaseModel):
    message: str
    conversation_id: Optional[str] = None
    user_id: str
    assistant_type: str = "general_purpose"

class ChatResponse(PydanticBaseModel):
    message: str
    conversation_id: str
    response_time: float
    confidence: float
    suggested_actions: List[str] = []

@app.on_event("startup")
async def startup_event():
    """Initialize assistants on startup"""
    global assistants
    
    # Create default assistants
    assistants["general"] = AssistantFactory.create_general_purpose_assistant("Alex")
    assistants["support"] = AssistantFactory.create_customer_support_assistant("Sarah", "TechCorp")
    assistants["technical"] = AssistantFactory.create_technical_advisor_assistant("Dr. Tech", "AI/ML Development")
    
    # Start Prometheus metrics server
    start_http_server(8001)
    
    logger.info("AI Assistant API started with assistants: " + ", ".join(assistants.keys()))

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """Chat with AI assistant"""
    try:
        # Get or create assistant
        assistant_key = request.assistant_type
        if assistant_key not in assistants:
            assistant_key = "general"  # Fallback to general assistant
        
        assistant = assistants[assistant_key]
        
        # Start conversation if needed
        if not request.conversation_id:
            conversation_id = await assistant.start_conversation(request.user_id, request.message)
            # For new conversations, return the welcome message or initial response
            return ChatResponse(
                message=conversation_id,  # This contains the response message
                conversation_id=assistant.conversation_contexts[list(assistant.conversation_contexts.keys())[-1]].conversation_id,
                response_time=0.1,
                confidence=0.9,
                suggested_actions=["Ask a question", "Get help", "Explore topics"]
            )
        else:
            # Process message in existing conversation
            response = await assistant.process_message(request.conversation_id, request.message)
            
            return ChatResponse(
                message=response.message,
                conversation_id=response.conversation_id,
                response_time=response.response_time,
                confidence=response.confidence,
                suggested_actions=response.suggested_actions
            )
            
    except Exception as e:
        logger.error(f"Chat endpoint error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/assistants")
async def list_assistants():
    """List available assistants"""
    assistant_info = {}
    for key, assistant in assistants.items():
        assistant_info[key] = assistant.get_assistant_info()
    
    return assistant_info

@app.delete("/conversation/{conversation_id}")
async def end_conversation(conversation_id: str):
    """End a conversation"""
    for assistant in assistants.values():
        if conversation_id in assistant.conversation_contexts:
            result = await assistant.end_conversation(conversation_id)
            return result
    
    raise HTTPException(status_code=404, detail="Conversation not found")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "assistants_available": len(assistants),
        "total_active_conversations": sum(len(a.conversation_contexts) for a in assistants.values()),
        "timestamp": datetime.now(timezone.utc).isoformat()
    }

# Demonstration functions
async def demonstrate_assistant_capabilities():
    """Demonstrate various assistant capabilities"""
    logger.info("=== AI Assistant Capabilities Demonstration ===")
    
    # Create different types of assistants
    general_assistant = AssistantFactory.create_general_purpose_assistant("Alex")
    support_assistant = AssistantFactory.create_customer_support_assistant("Sarah", "DemoTech")
    technical_assistant = AssistantFactory.create_technical_advisor_assistant("Dr. Tech", "AI Development")
    
    assistants_demo = [
        ("General Purpose", general_assistant),
        ("Customer Support", support_assistant),
        ("Technical Advisor", technical_assistant)
    ]
    
    # Test scenarios for each assistant
    test_scenarios = {
        "General Purpose": [
            "Hello! I'm looking for help with planning a project.",
            "Can you explain how machine learning works?",
            "I need creative ideas for a marketing campaign."
        ],
        "Customer Support": [
            "I'm having trouble with my account login.",
            "What's your return policy?",
            "I'm not satisfied with the service I received."
        ],
        "Technical Advisor": [
            "How should I architect a scalable web application?",
            "What's the best approach for implementing real-time data processing?",
            "Can you review this Python code for optimization opportunities?"
        ]
    }
    
    demo_results = {}
    
    for assistant_name, assistant in assistants_demo:
        logger.info(f"\n--- Testing {assistant_name} Assistant ---")
        
        scenarios = test_scenarios[assistant_name]
        assistant_results = []
        
        for i, scenario in enumerate(scenarios):
            try:
                # Start conversation
                conversation_id = await assistant.start_conversation(f"demo_user_{i}", scenario)
                
                # Get the actual conversation ID from the assistant's contexts
                actual_conversation_id = list(assistant.conversation_contexts.keys())[-1]
                
                # Process the scenario message
                response = await assistant.process_message(actual_conversation_id, scenario)
                
                assistant_results.append({
                    "scenario": scenario,
                    "response": response.message[:200] + "..." if len(response.message) > 200 else response.message,
                    "confidence": response.confidence,
                    "response_time": response.response_time,
                    "suggested_actions": response.suggested_actions
                })
                
                # End conversation
                await assistant.end_conversation(actual_conversation_id)
                
                logger.info(f"Scenario {i+1}: {response.confidence:.2f} confidence, {response.response_time:.2f}s")
                
            except Exception as e:
                logger.error(f"Error in scenario {i+1}: {e}")
        
        demo_results[assistant_name] = assistant_results
    
    # Generate summary report
    summary_report = {
        "demonstration_completed": datetime.now(timezone.utc).isoformat(),
        "assistants_tested": len(assistants_demo),
        "total_scenarios": sum(len(scenarios) for scenarios in test_scenarios.values()),
        "results": demo_results,
        "performance_summary": {
            assistant_name: {
                "average_confidence": np.mean([r["confidence"] for r in results]),
                "average_response_time": np.mean([r["response_time"] for r in results]),
                "total_suggested_actions": sum(len(r["suggested_actions"]) for r in results)
            }
            for assistant_name, results in demo_results.items()
        }
    }
    
    # Save results
    with open("assistant_demonstration_results.json", "w") as f:
        json.dump(summary_report, f, indent=2, default=str)
    
    logger.info("Assistant demonstration completed! Check 'assistant_demonstration_results.json' for detailed results.")
    
    return summary_report

# Main execution for development
if __name__ == "__main__":
    # Run demonstration
    asyncio.run(demonstrate_assistant_capabilities())
    
    # Start API server (uncomment for production deployment)
    # uvicorn.run(app, host="0.0.0.0", port=8000)
````

## Conclusion

This comprehensive AI Assistant development framework establishes the fundamental architecture for creating sophisticated, production-ready chatbots that combine advanced natural language processing with intelligent conversation management, memory systems, and personality-driven interactions to deliver exceptional user experiences across diverse application domains.

**Advanced Assistant Architecture** through modular design patterns enables the creation of specialized AI assistants with distinct personalities, capabilities, and behavioral patterns, providing the flexibility to develop domain-specific solutions while maintaining consistent quality and performance standards across different use cases.

**Sophisticated Memory Management** via multi-modal memory systems including conversation buffering, summarization, and key information extraction ensures that assistants maintain contextual awareness throughout extended interactions, enabling personalized responses and continuity that enhances user engagement and satisfaction.

**Comprehensive Conversation State Management** through structured context tracking, session persistence, and intelligent routing mechanisms provides the foundation for building scalable assistant systems that can handle multiple concurrent conversations while maintaining individual conversation quality and context integrity.

**Production-Ready Deployment Infrastructure** including FastAPI integration, Prometheus monitoring, error handling, and performance optimization ensures that AI assistants can be deployed in enterprise environments with appropriate scalability, observability, and reliability characteristics required for business-critical applications.

**Flexible Assistant Factory Patterns** enable rapid prototyping and deployment of specialized assistants for different roles including general-purpose assistance, customer support, technical advisory, and creative collaboration, demonstrating the versatility and adaptability of modern AI assistant architectures.

**Advanced Personality and Behavioral Modeling** through configurable trait systems, dynamic response generation, and context-aware personality adaptation creates engaging and consistent assistant experiences that align with specific use cases and user preferences while maintaining authentic and helpful interactions.

This foundational framework provides developers with the essential tools and patterns necessary to build intelligent AI assistants that not only understand and respond to user queries effectively but also maintain engaging personalities, remember important context, and deliver value-driven interactions that enhance productivity and user satisfaction in real-world applications.