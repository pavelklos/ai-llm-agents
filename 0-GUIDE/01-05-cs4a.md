<small>Claude Sonnet 4</small>
# 05. Custom Agent Framework

## Key Terms

**Autonomous Agent**: A self-directed AI system that can independently perceive its environment, make decisions, and take actions to achieve goals without continuous human intervention. These agents operate based on their internal logic and learned behaviors.

**Workflow Agent**: A structured AI system that follows predefined sequences of operations and decision trees. These agents execute tasks in a predetermined manner, often with specific checkpoints and validation steps.

**ReAct (Reasoning and Acting)**: A paradigm that combines reasoning traces and task-specific actions in an interleaved manner, allowing language models to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting.

**Agent State**: The internal representation of an agent's current situation, including memory, context, goals, and environmental awareness that persists across interactions and influences decision-making.

**Decision Cycle**: The iterative process where an agent perceives its environment, processes information, makes decisions, executes actions, and evaluates outcomes to inform future decisions.

## Agent Types: Autonomous vs. Workflow

### Autonomous Agent Architecture

Autonomous agents represent the most sophisticated form of AI systems, capable of independent operation with minimal human oversight. These agents possess self-directed behavior patterns and can adapt their strategies based on environmental feedback and learned experiences.

````python
import asyncio
import json
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Any, Optional, Callable, Union
import openai
from pydantic import BaseModel, Field
import redis
import numpy as np
from collections import deque
import os
from dotenv import load_dotenv

load_dotenv()

class AgentState(Enum):
    INITIALIZING = "initializing"
    IDLE = "idle"
    THINKING = "thinking"
    ACTING = "acting"
    LEARNING = "learning"
    ERROR = "error"
    TERMINATED = "terminated"

class GoalStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"

@dataclass
class Goal:
    id: str
    description: str
    priority: int
    status: GoalStatus = GoalStatus.PENDING
    created_at: datetime = field(default_factory=datetime.now)
    deadline: Optional[datetime] = None
    success_criteria: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)
    
class PerceptionModule:
    """Handles environmental perception and data gathering"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.sensors = {}
        self.perception_history = deque(maxlen=1000)
        
    async def perceive_environment(self) -> Dict[str, Any]:
        """Gather information from various sources"""
        perception_data = {
            'timestamp': datetime.now().isoformat(),
            'agent_id': self.agent_id,
            'environment': await self._scan_environment(),
            'internal_state': await self._monitor_internal_state(),
            'external_signals': await self._collect_external_signals()
        }
        
        self.perception_history.append(perception_data)
        return perception_data
    
    async def _scan_environment(self) -> Dict[str, Any]:
        """Scan immediate environment for relevant information"""
        return {
            'available_tools': self._discover_available_tools(),
            'data_sources': self._identify_data_sources(),
            'constraints': self._detect_constraints(),
            'opportunities': self._identify_opportunities()
        }
    
    async def _monitor_internal_state(self) -> Dict[str, Any]:
        """Monitor agent's internal state and resources"""
        return {
            'memory_usage': self._calculate_memory_usage(),
            'processing_load': self._measure_processing_load(),
            'error_rate': self._calculate_error_rate(),
            'goal_progress': self._assess_goal_progress()
        }
    
    async def _collect_external_signals(self) -> Dict[str, Any]:
        """Collect signals from external systems and users"""
        return {
            'user_feedback': await self._gather_user_feedback(),
            'system_alerts': await self._check_system_alerts(),
            'market_conditions': await self._analyze_market_conditions(),
            'performance_metrics': await self._collect_performance_metrics()
        }
    
    def _discover_available_tools(self) -> List[Dict[str, Any]]:
        """Dynamically discover available tools and capabilities"""
        return [
            {
                'name': 'web_search',
                'description': 'Search the web for information',
                'availability': 'high',
                'cost': 'low'
            },
            {
                'name': 'database_query',
                'description': 'Query structured databases',
                'availability': 'high',
                'cost': 'medium'
            },
            {
                'name': 'code_execution',
                'description': 'Execute code in sandboxed environment',
                'availability': 'medium',
                'cost': 'high'
            }
        ]

class ReasoningEngine:
    """Advanced reasoning and decision-making engine"""
    
    def __init__(self, model_config: Dict[str, Any]):
        self.model_config = model_config
        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.reasoning_history = deque(maxlen=500)
        self.decision_patterns = {}
        
    async def reason_about_situation(self, perception: Dict[str, Any], goals: List[Goal]) -> Dict[str, Any]:
        """Perform complex reasoning about current situation"""
        reasoning_context = {
            'current_perception': perception,
            'active_goals': [g for g in goals if g.status == GoalStatus.IN_PROGRESS],
            'pending_goals': [g for g in goals if g.status == GoalStatus.PENDING],
            'past_experiences': list(self.reasoning_history)[-10:],  # Last 10 experiences
            'decision_patterns': self.decision_patterns
        }
        
        # Multi-step reasoning process
        situation_analysis = await self._analyze_current_situation(reasoning_context)
        goal_prioritization = await self._prioritize_goals(reasoning_context)
        strategy_formulation = await self._formulate_strategy(situation_analysis, goal_prioritization)
        risk_assessment = await self._assess_risks(strategy_formulation)
        
        reasoning_result = {
            'situation_analysis': situation_analysis,
            'goal_prioritization': goal_prioritization,
            'strategy': strategy_formulation,
            'risk_assessment': risk_assessment,
            'confidence_score': self._calculate_confidence(situation_analysis, strategy_formulation),
            'reasoning_timestamp': datetime.now().isoformat()
        }
        
        self.reasoning_history.append(reasoning_result)
        return reasoning_result
    
    async def _analyze_current_situation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Deep analysis of current situation using LLM"""
        analysis_prompt = f"""
        Analyze the current situation for an autonomous AI agent:
        
        Current Perception: {json.dumps(context['current_perception'], indent=2)}
        Active Goals: {[g.description for g in context['active_goals']]}
        Available Resources: {context['current_perception'].get('environment', {}).get('available_tools', [])}
        
        Provide a comprehensive analysis including:
        1. Situation summary
        2. Critical factors and constraints
        3. Opportunities and threats
        4. Resource availability assessment
        5. Urgency indicators
        
        Format as JSON with clear categories.
        """
        
        response = await self.openai_client.chat.completions.create(
            model=self.model_config.get('model', 'gpt-4-turbo-preview'),
            messages=[
                {
                    "role": "system",
                    "content": "You are an advanced reasoning engine for an autonomous AI agent. Provide detailed, structured analysis in JSON format."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        try:
            return json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            return {
                'summary': response.choices[0].message.content,
                'confidence': 'low',
                'parsing_error': True
            }
    
    async def _prioritize_goals(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Intelligent goal prioritization based on current context"""
        all_goals = context['active_goals'] + context['pending_goals']
        
        prioritization_factors = {
            'urgency': self._calculate_urgency_scores(all_goals),
            'importance': self._calculate_importance_scores(all_goals, context),
            'feasibility': self._calculate_feasibility_scores(all_goals, context),
            'resource_requirements': self._calculate_resource_requirements(all_goals),
            'interdependencies': self._analyze_goal_dependencies(all_goals)
        }
        
        prioritized_goals = []
        for goal in all_goals:
            priority_score = (
                prioritization_factors['urgency'].get(goal.id, 0) * 0.3 +
                prioritization_factors['importance'].get(goal.id, 0) * 0.3 +
                prioritization_factors['feasibility'].get(goal.id, 0) * 0.25 +
                (1 - prioritization_factors['resource_requirements'].get(goal.id, 0.5)) * 0.15
            )
            
            prioritized_goals.append({
                'goal': goal,
                'priority_score': priority_score,
                'factors': {k: v.get(goal.id, 0) for k, v in prioritization_factors.items()}
            })
        
        return sorted(prioritized_goals, key=lambda x: x['priority_score'], reverse=True)

class AutonomousAgent:
    """Complete autonomous agent implementation"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        self.state = AgentState.INITIALIZING
        self.goals: List[Goal] = []
        self.memory = AgentMemory(agent_id)
        self.perception = PerceptionModule(agent_id)
        self.reasoning = ReasoningEngine(config.get('model_config', {}))
        self.action_executor = ActionExecutor(agent_id)
        self.learning_module = LearningModule(agent_id)
        self.decision_cycle_count = 0
        self.performance_metrics = {
            'goals_completed': 0,
            'goals_failed': 0,
            'average_decision_time': 0,
            'success_rate': 0,
            'uptime': datetime.now()
        }
        
    async def run_autonomously(self, duration_hours: Optional[float] = None):
        """Run agent autonomously for specified duration or indefinitely"""
        self.state = AgentState.IDLE
        start_time = datetime.now()
        end_time = start_time + timedelta(hours=duration_hours) if duration_hours else None
        
        logging.info(f"Agent {self.agent_id} starting autonomous operation")
        
        try:
            while self.state != AgentState.TERMINATED:
                if end_time and datetime.now() >= end_time:
                    break
                
                cycle_start = datetime.now()
                
                # Execute decision cycle
                await self._execute_decision_cycle()
                
                # Update performance metrics
                cycle_duration = (datetime.now() - cycle_start).total_seconds()
                self._update_performance_metrics(cycle_duration)
                
                # Brief pause to prevent overwhelming system
                await asyncio.sleep(self.config.get('cycle_delay', 1.0))
                
        except Exception as e:
            logging.error(f"Agent {self.agent_id} encountered error: {e}")
            self.state = AgentState.ERROR
            await self._handle_error(e)
        
        finally:
            await self._shutdown_gracefully()
    
    async def _execute_decision_cycle(self):
        """Execute complete decision-making cycle"""
        self.decision_cycle_count += 1
        logging.debug(f"Agent {self.agent_id} executing decision cycle #{self.decision_cycle_count}")
        
        # 1. Perception Phase
        self.state = AgentState.THINKING
        perception_data = await self.perception.perceive_environment()
        
        # 2. Reasoning Phase
        reasoning_result = await self.reasoning.reason_about_situation(perception_data, self.goals)
        
        # 3. Decision Phase
        decisions = await self._make_decisions(reasoning_result)
        
        # 4. Action Phase
        self.state = AgentState.ACTING
        action_results = await self.action_executor.execute_actions(decisions.get('actions', []))
        
        # 5. Learning Phase
        self.state = AgentState.LEARNING
        await self.learning_module.learn_from_experience({
            'perception': perception_data,
            'reasoning': reasoning_result,
            'decisions': decisions,
            'actions': action_results,
            'cycle_id': self.decision_cycle_count
        })
        
        # 6. Goal Management
        await self._update_goal_status(action_results)
        
        self.state = AgentState.IDLE
    
    async def _make_decisions(self, reasoning_result: Dict[str, Any]) -> Dict[str, Any]:
        """Make decisions based on reasoning results"""
        strategy = reasoning_result.get('strategy', {})
        risk_assessment = reasoning_result.get('risk_assessment', {})
        
        # Determine actions to take
        proposed_actions = strategy.get('recommended_actions', [])
        filtered_actions = self._filter_actions_by_risk(proposed_actions, risk_assessment)
        
        # Goal management decisions
        goal_decisions = self._make_goal_decisions(reasoning_result.get('goal_prioritization', []))
        
        return {
            'actions': filtered_actions,
            'goal_decisions': goal_decisions,
            'reasoning_confidence': reasoning_result.get('confidence_score', 0),
            'decision_timestamp': datetime.now().isoformat()
        }

class WorkflowAgent:
    """Structured workflow-based agent implementation"""
    
    def __init__(self, agent_id: str, workflow_definition: Dict[str, Any]):
        self.agent_id = agent_id
        self.workflow = workflow_definition
        self.current_step = 0
        self.workflow_state = {}
        self.step_results = []
        self.error_handlers = {}
        
    async def execute_workflow(self, initial_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute predefined workflow with structured steps"""
        self.workflow_state = {
            'initial_data': initial_data,
            'current_step': 0,
            'start_time': datetime.now().isoformat(),
            'status': 'running'
        }
        
        steps = self.workflow.get('steps', [])
        
        for step_index, step in enumerate(steps):
            self.current_step = step_index
            self.workflow_state['current_step'] = step_index
            
            try:
                step_result = await self._execute_step(step, self.workflow_state)
                self.step_results.append(step_result)
                
                # Update workflow state with step result
                self.workflow_state.update(step_result.get('state_updates', {}))
                
                # Check for early termination conditions
                if step_result.get('terminate_workflow', False):
                    break
                    
                # Handle conditional branching
                if step.get('type') == 'conditional':
                    next_step = self._evaluate_condition(step, step_result)
                    if next_step is not None:
                        # Jump to specified step
                        continue
                        
            except Exception as e:
                error_result = await self._handle_step_error(step, e)
                if error_result.get('terminate_workflow', False):
                    self.workflow_state['status'] = 'failed'
                    break
        
        self.workflow_state['status'] = 'completed'
        self.workflow_state['end_time'] = datetime.now().isoformat()
        
        return {
            'workflow_state': self.workflow_state,
            'step_results': self.step_results,
            'success': self.workflow_state['status'] == 'completed'
        }
````

## ReAct Agent and Building from Scratch

### ReAct Pattern Implementation

The ReAct (Reasoning and Acting) pattern represents a sophisticated approach to agent design that interleaves thought processes with actionable steps, creating a more transparent and debuggable agent behavior.

````python
import asyncio
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import openai
import os

@dataclass
class ReActStep:
    step_type: str  # 'thought', 'action', 'observation'
    content: str
    timestamp: datetime
    metadata: Dict[str, Any] = None

class ToolRegistry:
    """Registry for available tools that the agent can use"""
    
    def __init__(self):
        self.tools = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        """Register default tools available to the agent"""
        self.register_tool(
            name="web_search",
            description="Search the web for current information",
            function=self._web_search,
            parameters={
                "query": {"type": "string", "description": "Search query"},
                "max_results": {"type": "integer", "default": 5}
            }
        )
        
        self.register_tool(
            name="calculator",
            description="Perform mathematical calculations",
            function=self._calculator,
            parameters={
                "expression": {"type": "string", "description": "Mathematical expression to evaluate"}
            }
        )
        
        self.register_tool(
            name="database_query",
            description="Query structured database",
            function=self._database_query,
            parameters={
                "query": {"type": "string", "description": "SQL query to execute"},
                "database": {"type": "string", "description": "Target database name"}
            }
        )
        
        self.register_tool(
            name="code_executor",
            description="Execute Python code in sandbox environment",
            function=self._code_executor,
            parameters={
                "code": {"type": "string", "description": "Python code to execute"},
                "timeout": {"type": "integer", "default": 30}
            }
        )
    
    def register_tool(self, name: str, description: str, function: callable, parameters: Dict[str, Any]):
        """Register a new tool for agent use"""
        self.tools[name] = {
            'description': description,
            'function': function,
            'parameters': parameters
        }
    
    async def execute_tool(self, tool_name: str, **kwargs) -> Dict[str, Any]:
        """Execute specified tool with given parameters"""
        if tool_name not in self.tools:
            return {
                'success': False,
                'error': f'Tool {tool_name} not found',
                'available_tools': list(self.tools.keys())
            }
        
        try:
            result = await self.tools[tool_name]['function'](**kwargs)
            return {
                'success': True,
                'result': result,
                'tool_used': tool_name,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'tool_used': tool_name,
                'timestamp': datetime.now().isoformat()
            }
    
    async def _web_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """Simulate web search functionality"""
        # In production, integrate with actual search API
        return {
            'query': query,
            'results': [
                {
                    'title': f'Result {i+1} for {query}',
                    'url': f'https://example.com/result{i+1}',
                    'snippet': f'This is a simulated search result snippet for {query}'
                }
                for i in range(min(max_results, 3))
            ],
            'total_results': max_results
        }
    
    async def _calculator(self, expression: str) -> Dict[str, Any]:
        """Safe mathematical expression evaluator"""
        try:
            # Sanitize expression to prevent code injection
            allowed_chars = set('0123456789+-*/()., ')
            if not all(c in allowed_chars for c in expression):
                raise ValueError("Invalid characters in expression")
            
            result = eval(expression)
            return {
                'expression': expression,
                'result': result,
                'type': type(result).__name__
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e)
            }
    
    async def _database_query(self, query: str, database: str = 'default') -> Dict[str, Any]:
        """Simulate database query execution"""
        # In production, implement actual database connectivity
        return {
            'query': query,
            'database': database,
            'results': [
                {'id': 1, 'name': 'Sample Record 1', 'value': 100},
                {'id': 2, 'name': 'Sample Record 2', 'value': 200}
            ],
            'row_count': 2
        }
    
    async def _code_executor(self, code: str, timeout: int = 30) -> Dict[str, Any]:
        """Execute Python code in sandbox environment"""
        # In production, implement proper sandboxing
        try:
            # Simple simulation - in practice use containerized execution
            local_vars = {}
            exec(code, {"__builtins__": {}}, local_vars)
            return {
                'code': code,
                'output': str(local_vars),
                'success': True
            }
        except Exception as e:
            return {
                'code': code,
                'error': str(e),
                'success': False
            }

class ReActAgent:
    """Complete ReAct (Reasoning and Acting) agent implementation"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.tool_registry = ToolRegistry()
        self.step_history: List[ReActStep] = []
        self.max_iterations = config.get('max_iterations', 10)
        self.current_task = None
        
    async def solve_task(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Solve a task using ReAct pattern"""
        self.current_task = task
        self.step_history = []
        
        task_context = context or {}
        task_context['available_tools'] = list(self.tool_registry.tools.keys())
        
        iteration = 0
        solution_found = False
        
        # Initial thought about the task
        await self._add_step('thought', f"I need to solve the task: {task}")
        
        while iteration < self.max_iterations and not solution_found:
            iteration += 1
            
            # Generate next thought and action
            next_step = await self._generate_next_step(task_context)
            
            if next_step['type'] == 'thought':
                await self._add_step('thought', next_step['content'])
                
            elif next_step['type'] == 'action':
                # Execute action
                action_result = await self._execute_action(next_step)
                await self._add_step('action', next_step['content'])
                await self._add_step('observation', self._format_observation(action_result))
                
                # Update context with action result
                task_context['last_action_result'] = action_result
                
            elif next_step['type'] == 'final_answer':
                await self._add_step('thought', "I have found the solution.")
                solution_found = True
                break
                
            # Check if we should continue
            if await self._should_terminate(task_context):
                break
        
        return {
            'task': task,
            'solution_found': solution_found,
            'iterations': iteration,
            'steps': [
                {
                    'type': step.step_type,
                    'content': step.content,
                    'timestamp': step.timestamp.isoformat(),
                    'metadata': step.metadata
                }
                for step in self.step_history
            ],
            'final_answer': self._extract_final_answer(),
            'performance_metrics': self._calculate_performance_metrics()
        }
    
    async def _generate_next_step(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate the next step in the ReAct sequence"""
        
        # Format conversation history for the LLM
        conversation_history = self._format_conversation_history()
        
        available_tools_desc = "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.tool_registry.tools.items()
        ])
        
        prompt = f"""
You are a ReAct agent solving the following task: {self.current_task}

Available tools:
{available_tools_desc}

Conversation history:
{conversation_history}

You should follow the ReAct pattern:
1. Thought: Think about what you need to do next
2. Action: Use a tool if needed (format: Action: tool_name(param1=value1, param2=value2))
3. Observation: The result will be provided
4. Repeat until you can provide a final answer

Current context: {json.dumps(context, indent=2)}

What is your next step? Respond with either:
- Thought: [your reasoning]
- Action: [tool_name(parameters)]
- Final Answer: [your solution]
"""

        response = await self.openai_client.chat.completions.create(
            model=self.config.get('model', 'gpt-4-turbo-preview'),
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful ReAct agent. Follow the ReAct pattern precisely."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        response_text = response.choices[0].message.content.strip()
        
        # Parse the response to determine step type and content
        if response_text.startswith('Thought:'):
            return {
                'type': 'thought',
                'content': response_text[8:].strip()
            }
        elif response_text.startswith('Action:'):
            return {
                'type': 'action',
                'content': response_text[7:].strip()
            }
        elif response_text.startswith('Final Answer:'):
            return {
                'type': 'final_answer',
                'content': response_text[13:].strip()
            }
        else:
            # Default to thought if format is unclear
            return {
                'type': 'thought',
                'content': response_text
            }
    
    async def _execute_action(self, action_step: Dict[str, Any]) -> Dict[str, Any]:
        """Parse and execute an action"""
        action_text = action_step['content']
        
        # Parse action format: tool_name(param1=value1, param2=value2)
        match = re.match(r'(\w+)\((.*)\)', action_text)
        if not match:
            return {
                'success': False,
                'error': f'Invalid action format: {action_text}',
                'expected_format': 'tool_name(param1=value1, param2=value2)'
            }
        
        tool_name = match.group(1)
        params_str = match.group(2)
        
        # Parse parameters
        params = {}
        if params_str.strip():
            try:
                # Simple parameter parsing (in production, use more robust parsing)
                for param_pair in params_str.split(','):
                    if '=' in param_pair:
                        key, value = param_pair.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"\'')
                        params[key] = value
            except Exception as e:
                return {
                    'success': False,
                    'error': f'Failed to parse parameters: {e}',
                    'raw_params': params_str
                }
        
        # Execute tool
        return await self.tool_registry.execute_tool(tool_name, **params)
    
    async def _add_step(self, step_type: str, content: str, metadata: Dict[str, Any] = None):
        """Add a step to the ReAct sequence"""
        step = ReActStep(
            step_type=step_type,
            content=content,
            timestamp=datetime.now(),
            metadata=metadata or {}
        )
        self.step_history.append(step)
    
    def _format_conversation_history(self) -> str:
        """Format conversation history for LLM prompt"""
        formatted_steps = []
        for step in self.step_history:
            if step.step_type == 'thought':
                formatted_steps.append(f"Thought: {step.content}")
            elif step.step_type == 'action':
                formatted_steps.append(f"Action: {step.content}")
            elif step.step_type == 'observation':
                formatted_steps.append(f"Observation: {step.content}")
        
        return "\n".join(formatted_steps)
    
    def _format_observation(self, action_result: Dict[str, Any]) -> str:
        """Format action result as observation"""
        if action_result.get('success', False):
            result = action_result.get('result', {})
            if isinstance(result, dict):
                return f"Tool executed successfully. Result: {json.dumps(result, indent=2)}"
            else:
                return f"Tool executed successfully. Result: {result}"
        else:
            error = action_result.get('error', 'Unknown error')
            return f"Tool execution failed. Error: {error}"
    
    async def _should_terminate(self, context: Dict[str, Any]) -> bool:
        """Determine if the agent should terminate the current task"""
        # Check for obvious termination conditions
        if len(self.step_history) > self.max_iterations * 3:  # Too many steps
            return True
        
        # Check for repeated actions (possible infinite loop)
        recent_actions = [
            step.content for step in self.step_history[-6:]
            if step.step_type == 'action'
        ]
        if len(recent_actions) >= 3 and len(set(recent_actions)) == 1:
            return True
        
        return False
    
    def _extract_final_answer(self) -> Optional[str]:
        """Extract final answer from step history"""
        for step in reversed(self.step_history):
            if step.step_type == 'thought' and 'solution' in step.content.lower():
                return step.content
        
        # Return last thought if no explicit solution found
        thoughts = [step for step in self.step_history if step.step_type == 'thought']
        return thoughts[-1].content if thoughts else None
    
    def _calculate_performance_metrics(self) -> Dict[str, Any]:
        """Calculate performance metrics for the task solution"""
        total_steps = len(self.step_history)
        thoughts = len([s for s in self.step_history if s.step_type == 'thought'])
        actions = len([s for s in self.step_history if s.step_type == 'action'])
        observations = len([s for s in self.step_history if s.step_type == 'observation'])
        
        if self.step_history:
            duration = (self.step_history[-1].timestamp - self.step_history[0].timestamp).total_seconds()
        else:
            duration = 0
        
        return {
            'total_steps': total_steps,
            'thoughts': thoughts,
            'actions': actions,
            'observations': observations,
            'duration_seconds': duration,
            'steps_per_second': total_steps / max(duration, 1),
            'action_success_rate': self._calculate_action_success_rate()
        }
    
    def _calculate_action_success_rate(self) -> float:
        """Calculate the success rate of executed actions"""
        action_results = []
        for i, step in enumerate(self.step_history):
            if step.step_type == 'observation':
                success = 'successfully' in step.content.lower()
                action_results.append(success)
        
        if not action_results:
            return 0.0
        
        return sum(action_results) / len(action_results)
````

## Working with State, Decision-Making, and Cycles

### Advanced State Management and Decision Cycles

````python
import asyncio
import json
import pickle
import hashlib
from typing import Dict, List, Any, Optional, Set, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import redis
import sqlite3
from collections import defaultdict, deque
import numpy as np

class StateType(Enum):
    PERSISTENT = "persistent"  # Survives agent restarts
    SESSION = "session"        # Survives during session only
    TEMPORARY = "temporary"    # Short-lived working memory
    SHARED = "shared"          # Shared across agent instances

@dataclass
class StateSnapshot:
    timestamp: datetime
    state_data: Dict[str, Any]
    state_hash: str
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'timestamp': self.timestamp.isoformat(),
            'state_data': self.state_data,
            'state_hash': self.state_hash,
            'metadata': self.metadata
        }

class AdvancedStateManager:
    """Sophisticated state management system for AI agents"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        self.redis_client = redis.Redis(
            host=config.get('redis_host', 'localhost'),
            port=config.get('redis_port', 6379),
            password=config.get('redis_password'),
            decode_responses=True
        )
        
        # Initialize local database for persistent state
        self.db_path = f"agent_state_{agent_id}.db"
        self._init_local_database()
        
        # State containers
        self.persistent_state = {}
        self.session_state = {}
        self.temporary_state = {}
        self.shared_state = {}
        
        # State history and versioning
        self.state_history = deque(maxlen=config.get('max_history', 1000))
        self.state_version = 0
        
        # Change tracking
        self.state_change_listeners = defaultdict(list)
        self.dirty_flags = {state_type: False for state_type in StateType}
        
        # Load existing state
        asyncio.create_task(self._load_existing_state())
    
    def _init_local_database(self):
        """Initialize SQLite database for persistent state storage"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS agent_state (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                agent_id TEXT NOT NULL,
                state_type TEXT NOT NULL,
                key_path TEXT NOT NULL,
                value_data BLOB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT,
                UNIQUE(agent_id, state_type, key_path)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS state_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                agent_id TEXT NOT NULL,
                snapshot_hash TEXT NOT NULL,
                snapshot_data BLOB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    async def set_state(self, key_path: str, value: Any, state_type: StateType = StateType.SESSION, metadata: Dict[str, Any] = None):
        """Set state value with hierarchical key support"""
        
        # Determine target state container
        state_container = self._get_state_container(state_type)
        
        # Set nested value using key path
        self._set_nested_value(state_container, key_path, value)
        
        # Mark as dirty for persistence
        self.dirty_flags[state_type] = True
        
        # Trigger change listeners
        await self._notify_state_change(key_path, value, state_type, metadata)
        
        # Persist if required
        if state_type in [StateType.PERSISTENT, StateType.SHARED]:
            await self._persist_state_change(key_path, value, state_type, metadata)
        
        # Create state snapshot if significant change
        if await self._is_significant_change(key_path, value, state_type):
            await self._create_state_snapshot()
    
    async def get_state(self, key_path: str, state_type: StateType = StateType.SESSION, default: Any = None) -> Any:
        """Get state value with hierarchical key support"""
        state_container = self._get_state_container(state_type)
        return self._get_nested_value(state_container, key_path, default)
    
    async def delete_state(self, key_path: str, state_type: StateType = StateType.SESSION):
        """Delete state value"""
        state_container = self._get_state_container(state_type)
        self._delete_nested_value(state_container, key_path)
        self.dirty_flags[state_type] = True
        
        if state_type in [StateType.PERSISTENT, StateType.SHARED]:
            await self._persist_state_deletion(key_path, state_type)
    
    def _get_state_container(self, state_type: StateType) -> Dict[str, Any]:
        """Get appropriate state container"""
        containers = {
            StateType.PERSISTENT: self.persistent_state,
            StateType.SESSION: self.session_state,
            StateType.TEMPORARY: self.temporary_state,
            StateType.SHARED: self.shared_state
        }
        return containers[state_type]
    
    def _set_nested_value(self, container: Dict[str, Any], key_path: str, value: Any):
        """Set value in nested dictionary structure"""
        keys = key_path.split('.')
        current = container
        
        for key in keys[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
    
    def _get_nested_value(self, container: Dict[str, Any], key_path: str, default: Any) -> Any:
        """Get value from nested dictionary structure"""
        keys = key_path.split('.')
        current = container
        
        try:
            for key in keys:
                current = current[key]
            return current
        except (KeyError, TypeError):
            return default
    
    async def _create_state_snapshot(self):
        """Create snapshot of current state"""
        current_state = {
            'persistent': self.persistent_state,
            'session': self.session_state,
            'temporary': self.temporary_state,
            'shared': self.shared_state
        }
        
        state_json = json.dumps(current_state, sort_keys=True)
        state_hash = hashlib.sha256(state_json.encode()).hexdigest()
        
        snapshot = StateSnapshot(
            timestamp=datetime.now(),
            state_data=current_state,
            state_hash=state_hash,
            metadata={'version': self.state_version}
        )
        
        self.state_history.append(snapshot)
        self.state_version += 1
        
        # Persist snapshot to database
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO state_snapshots (agent_id, snapshot_hash, snapshot_data, metadata)
            VALUES (?, ?, ?, ?)
        ''', (
            self.agent_id,
            state_hash,
            pickle.dumps(snapshot.to_dict()),
            json.dumps({'version': self.state_version})
        ))
        
        conn.commit()
        conn.close()

class DecisionEngine:
    """Advanced decision-making engine with multiple strategies"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        self.decision_history = deque(maxlen=1000)
        self.decision_patterns = defaultdict(list)
        self.success_metrics = defaultdict(float)
        
    async def make_decision(self, context: Dict[str, Any], options: List[Dict[str, Any]], strategy: str = 'weighted_scoring') -> Dict[str, Any]:
        """Make decision using specified strategy"""
        
        decision_strategies = {
            'weighted_scoring': self._weighted_scoring_decision,
            'utility_maximization': self._utility_maximization_decision,
            'monte_carlo': self._monte_carlo_decision,
            'multi_criteria': self._multi_criteria_decision,
            'reinforcement_learning': self._rl_based_decision
        }
        
        if strategy not in decision_strategies:
            strategy = 'weighted_scoring'
        
        decision_result = await decision_strategies[strategy](context, options)
        
        # Record decision for learning
        decision_record = {
            'timestamp': datetime.now().isoformat(),
            'context': context,
            'options': options,
            'strategy': strategy,
            'decision': decision_result,
            'confidence': decision_result.get('confidence', 0.5)
        }
        
        self.decision_history.append(decision_record)
        
        return decision_result
    
    async def _weighted_scoring_decision(self, context: Dict[str, Any], options: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Make decision using weighted scoring"""
        
        # Define scoring criteria and weights
        criteria_weights = context.get('criteria_weights', {
            'feasibility': 0.3,
            'impact': 0.25,
            'urgency': 0.2,
            'resources': 0.15,
            'risk': 0.1
        })
        
        scored_options = []
        
        for option in options:
            total_score = 0
            criterion_scores = {}
            
            for criterion, weight in criteria_weights.items():
                score = await self._evaluate_criterion(option, criterion, context)
                criterion_scores[criterion] = score
                total_score += score * weight
            
            scored_options.append({
                'option': option,
                'total_score': total_score,
                'criterion_scores': criterion_scores
            })
        
        # Sort by score and select best option
        scored_options.sort(key=lambda x: x['total_score'], reverse=True)
        best_option = scored_options[0]
        
        return {
            'selected_option': best_option['option'],
            'score': best_option['total_score'],
            'criterion_scores': best_option['criterion_scores'],
            'all_scores': scored_options,
            'confidence': min(best_option['total_score'], 1.0),
            'decision_method': 'weighted_scoring'
        }
    
    async def _evaluate_criterion(self, option: Dict[str, Any], criterion: str, context: Dict[str, Any]) -> float:
        """Evaluate single criterion for an option"""
        
        # Criterion evaluation logic
        evaluators = {
            'feasibility': self._evaluate_feasibility,
            'impact': self._evaluate_impact,
            'urgency': self._evaluate_urgency,
            'resources': self._evaluate_resources,
            'risk': self._evaluate_risk
        }
        
        if criterion in evaluators:
            return await evaluators[criterion](option, context)
        else:
            return 0.5  # Default neutral score
    
    async def _evaluate_feasibility(self, option: Dict[str, Any], context: Dict[str, Any]) -> float:
        """Evaluate feasibility of an option"""
        required_resources = option.get('required_resources', [])
        available_resources = context.get('available_resources', [])
        
        if not required_resources:
            return 1.0
        
        availability_ratio = len(set(required_resources) & set(available_resources)) / len(required_resources)
        return availability_ratio
    
    async def _monte_carlo_decision(self, context: Dict[str, Any], options: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Make decision using Monte Carlo simulation"""
        
        num_simulations = context.get('num_simulations', 1000)
        simulation_results = defaultdict(list)
        
        for _ in range(num_simulations):
            # Simulate random scenario
            scenario = self._generate_random_scenario(context)
            
            # Evaluate each option in this scenario
            for i, option in enumerate(options):
                outcome = await self._simulate_option_outcome(option, scenario, context)
                simulation_results[i].append(outcome)
        
        # Analyze simulation results
        option_statistics = {}
        for i, outcomes in simulation_results.items():
            option_statistics[i] = {
                'mean_outcome': np.mean(outcomes),
                'std_outcome': np.std(outcomes),
                'success_rate': len([o for o in outcomes if o > 0.5]) / len(outcomes),
                'worst_case': min(outcomes),
                'best_case': max(outcomes)
            }
        
        # Select option with best expected outcome
        best_option_idx = max(option_statistics.keys(), 
                            key=lambda x: option_statistics[x]['mean_outcome'])
        
        return {
            'selected_option': options[best_option_idx],
            'statistics': option_statistics[best_option_idx],
            'all_statistics': option_statistics,
            'confidence': option_statistics[best_option_idx]['success_rate'],
            'decision_method': 'monte_carlo'
        }

class CycleManager:
    """Manages agent decision and action cycles"""
    
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.config = config
        self.cycle_count = 0
        self.cycle_history = deque(maxlen=500)
        self.cycle_metrics = defaultdict(list)
        self.is_running = False
        
    async def start_continuous_cycle(self, cycle_handler: callable, cycle_interval: float = 1.0):
        """Start continuous decision-action cycle"""
        self.is_running = True
        
        while self.is_running:
            cycle_start = datetime.now()
            
            try:
                # Execute cycle
                cycle_result = await self._execute_cycle(cycle_handler)
                
                # Record cycle metrics
                cycle_duration = (datetime.now() - cycle_start).total_seconds()
                self._record_cycle_metrics(cycle_result, cycle_duration)
                
                # Adaptive cycle timing
                adjusted_interval = await self._calculate_adaptive_interval(cycle_duration, cycle_interval)
                
                await asyncio.sleep(adjusted_interval)
                
            except Exception as e:
                await self._handle_cycle_error(e)
                await asyncio.sleep(cycle_interval * 2)  # Slower retry on error
    
    async def _execute_cycle(self, cycle_handler: callable) -> Dict[str, Any]:
        """Execute single decision-action cycle"""
        self.cycle_count += 1
        
        cycle_context = {
            'cycle_id': self.cycle_count,
            'timestamp': datetime.now().isoformat(),
            'agent_id': self.agent_id
        }
        
        # Execute custom cycle logic
        cycle_result = await cycle_handler(cycle_context)
        
        # Record cycle
        cycle_record = {
            'cycle_id': self.cycle_count,
            'timestamp': datetime.now().isoformat(),
            'duration': cycle_result.get('duration', 0),
            'success': cycle_result.get('success', False),
            'actions_taken': cycle_result.get('actions_taken', 0),
            'decisions_made': cycle_result.get('decisions_made', 0),
            'errors': cycle_result.get('errors', [])
        }
        
        self.cycle_history.append(cycle_record)
        
        return cycle_result
    
    async def _calculate_adaptive_interval(self, last_duration: float, base_interval: float) -> float:
        """Calculate adaptive cycle interval based on performance"""
        
        # Get recent cycle durations
        recent_durations = [
            cycle['duration'] for cycle in list(self.cycle_history)[-10:]
            if 'duration' in cycle
        ]
        
        if not recent_durations:
            return base_interval
        
        avg_duration = np.mean(recent_durations)
        duration_std = np.std(recent_durations)
        
        # Adaptive logic
        if avg_duration > base_interval * 0.8:  # Cycles taking too long
            return base_interval * 1.2
        elif avg_duration < base_interval * 0.3:  # Cycles too fast, might be inefficient
            return max(base_interval * 0.8, 0.1)
        else:
            return base_interval
    
    def _record_cycle_metrics(self, cycle_result: Dict[str, Any], duration: float):
        """Record cycle performance metrics"""
        metrics = {
            'duration': duration,
            'success': cycle_result.get('success', False),
            'efficiency': cycle_result.get('actions_taken', 0) / max(duration, 0.001),
            'error_rate': len(cycle_result.get('errors', [])),
            'timestamp': datetime.now().isoformat()
        }
        
        for key, value in metrics.items():
            self.cycle_metrics[key].append(value)
        
        # Keep only recent metrics
        max_metrics = 1000
        for key in self.cycle_metrics:
            if len(self.cycle_metrics[key]) > max_metrics:
                self.cycle_metrics[key] = self.cycle_metrics[key][-max_metrics:]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get comprehensive performance summary"""
        if not self.cycle_history:
            return {'message': 'No cycle data available'}
        
        recent_cycles = list(self.cycle_history)[-100:]  # Last 100 cycles
        
        return {
            'total_cycles': self.cycle_count,
            'recent_success_rate': np.mean([c.get('success', False) for c in recent_cycles]),
            'average_duration': np.mean([c.get('duration', 0) for c in recent_cycles]),
            'total_actions': sum([c.get('actions_taken', 0) for c in recent_cycles]),
            'error_rate': np.mean([len(c.get('errors', [])) for c in recent_cycles]),
            'uptime': (datetime.now() - datetime.fromisoformat(self.cycle_history[0]['timestamp'])).total_seconds() if self.cycle_history else 0,
            'cycles_per_minute': len(recent_cycles) / max((datetime.now() - datetime.fromisoformat(recent_cycles[0]['timestamp'])).total_seconds() / 60, 1) if recent_cycles else 0
        }
````

## Conclusion

Custom agent frameworks provide the ultimate flexibility for creating sophisticated AI systems tailored to specific requirements. The distinction between autonomous and workflow agents represents fundamentally different approaches to AI system design, each with unique advantages and use cases.

**Autonomous agents** excel in dynamic, unpredictable environments where adaptability and self-direction are paramount. Their ability to learn from experience, maintain complex state representations, and make independent decisions makes them ideal for scenarios requiring creativity and problem-solving capabilities. However, they require more computational resources and can be less predictable in their behavior.

**Workflow agents** provide reliability and transparency in structured environments where consistency and auditability are critical. Their predefined decision trees and validation checkpoints make them suitable for business processes, compliance-heavy operations, and scenarios where human oversight is essential.

The **ReAct pattern** bridges these approaches by providing structured reasoning while maintaining flexibility. This pattern's strength lies in its transparency - each reasoning step and action is explicitly documented, making agent behavior interpretable and debuggable. The interleaved thinking and acting approach closely mimics human problem-solving processes.

**Advanced state management** enables agents to maintain context across extended interactions, learn from experience, and coordinate with other systems. The implementation of persistent, session, temporary, and shared state types provides granular control over information lifecycle and accessibility.

**Decision cycles** with adaptive timing and performance monitoring ensure agents can operate efficiently in production environments. The combination of multiple decision strategies (weighted scoring, Monte Carlo simulation, utility maximization) allows agents to adapt their decision-making approach based on context and requirements.

Building custom frameworks requires significant development effort but provides unmatched control over agent behavior, performance characteristics, and integration capabilities. This approach is most valuable for organizations with specific requirements that cannot be adequately addressed by existing frameworks or when competitive advantage depends on unique AI capabilities.