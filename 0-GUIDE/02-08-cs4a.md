<small>Claude Sonnet 4</small>
# 08. LangGraph (AI Agents)

## Key Terms

**LangGraph Framework**: A sophisticated graph-based orchestration framework built on top of LangChain that enables the creation, coordination, and supervision of multiple AI agents through directed graph structures, providing advanced control flow, state management, and agent interaction patterns.

**Multi-Agent Orchestration**: The systematic coordination and management of multiple AI agents working together to solve complex problems, involving task delegation, communication protocols, resource sharing, and collaborative decision-making across distributed agent networks.

**Agent Supervision**: Advanced monitoring, control, and governance mechanisms for AI agents including performance tracking, error handling, decision auditing, safety constraints, and human-in-the-loop interventions to ensure reliable and predictable agent behavior.

**Graph-Based Workflow**: A computational model that represents AI agent interactions and task flows as directed graphs where nodes represent agents, tools, or decision points, and edges define the flow of information, control, and dependencies between components.

**State Management**: The systematic handling of persistent information across agent interactions, including conversation context, task progress, shared memory, and coordination state that enables agents to maintain coherence and collaborate effectively over extended workflows.

**Conditional Routing**: Dynamic decision-making mechanisms that determine the flow of execution between agents based on runtime conditions, agent outputs, performance metrics, or external factors, enabling adaptive and intelligent workflow orchestration.

**Agent Communication Protocols**: Standardized methods for information exchange between agents including message passing, shared state updates, event notifications, and coordination signals that ensure reliable and efficient inter-agent collaboration.

**Pipeline Architecture**: Structured design patterns for organizing AI agent workflows into reusable, scalable, and maintainable pipeline components with clear input/output interfaces, error handling, and monitoring capabilities.

## Comprehensive LangGraph Multi-Agent Framework

LangGraph represents the next evolution in AI agent orchestration, providing sophisticated graph-based workflows that enable complex multi-agent systems with advanced supervision, coordination, and control mechanisms. This framework demonstrates production-ready patterns for building scalable agent networks.

### Advanced LangGraph Implementation

````python
import asyncio
import json
import logging
import os
import time
import warnings
from typing import Dict, List, Any, Optional, Union, Tuple, Callable, TypedDict, Annotated
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
import uuid
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import inspect

# Core LangGraph imports
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langgraph.checkpoint.sqlite import SqliteSaver

# LangChain components
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import BaseTool, tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

# RAG components
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.document_loaders import TextLoader, PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.retrievers import BaseRetriever

# Monitoring and observability
from langsmith import Client as LangSmithClient
from langfuse import Langfuse
import wandb

# Data structures and utilities
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pydantic import BaseModel, Field, validator
import sqlite3
import pickle
import psutil
import threading
from collections import defaultdict, deque

from dotenv import load_dotenv

load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AgentRole(Enum):
    """Predefined agent roles for multi-agent systems"""
    SUPERVISOR = "supervisor"
    RESEARCHER = "researcher"
    ANALYST = "analyst"
    WRITER = "writer"
    CRITIC = "critic"
    COORDINATOR = "coordinator"
    SPECIALIST = "specialist"
    VALIDATOR = "validator"

class TaskStatus(Enum):
    """Task execution status tracking"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    REVIEWING = "reviewing"

class AgentState(TypedDict):
    """State structure for LangGraph agents"""
    messages: Annotated[List[BaseMessage], add_messages]
    current_agent: str
    task_id: str
    task_status: str
    task_progress: Dict[str, Any]
    shared_context: Dict[str, Any]
    agent_outputs: Dict[str, Any]
    error_log: List[Dict[str, Any]]
    iteration_count: int
    max_iterations: int
    human_feedback: Optional[str]
    final_output: Optional[str]

@dataclass
class AgentConfig:
    """Configuration for individual agents"""
    name: str
    role: AgentRole
    system_prompt: str
    model_name: str = "gpt-4"
    temperature: float = 0.7
    max_tokens: int = 1000
    tools: List[str] = field(default_factory=list)
    rag_enabled: bool = False
    rag_config: Optional[Dict[str, Any]] = None
    supervision_level: str = "medium"  # low, medium, high
    retry_attempts: int = 3
    timeout: int = 300

@dataclass
class WorkflowConfig:
    """Configuration for multi-agent workflows"""
    workflow_id: str
    description: str
    agents: List[AgentConfig]
    max_iterations: int = 10
    require_human_approval: bool = False
    enable_monitoring: bool = True
    checkpoint_enabled: bool = True
    parallel_execution: bool = False

class AdvancedToolkit:
    """Comprehensive toolkit for AI agents"""
    
    def __init__(self):
        self.tools = {}
        self._setup_default_tools()
    
    def _setup_default_tools(self):
        """Setup default tools for agents"""
        
        @tool
        def web_search(query: str) -> str:
            """Search the web for current information"""
            try:
                search = DuckDuckGoSearchRun()
                results = search.run(query)
                return f"Search results for '{query}': {results[:1000]}"
            except Exception as e:
                return f"Search failed: {str(e)}"
        
        @tool
        def wikipedia_lookup(topic: str) -> str:
            """Look up information on Wikipedia"""
            try:
                wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())
                result = wikipedia.run(topic)
                return f"Wikipedia information about '{topic}': {result[:1000]}"
            except Exception as e:
                return f"Wikipedia lookup failed: {str(e)}"
        
        @tool
        def calculator(expression: str) -> str:
            """Perform mathematical calculations"""
            try:
                # Safe evaluation of mathematical expressions
                allowed_names = {
                    k: v for k, v in __builtins__.items() 
                    if k in ['abs', 'round', 'min', 'max', 'sum', 'len']
                }
                allowed_names.update({"__builtins__": {}})
                
                result = eval(expression, allowed_names)
                return f"Calculation result: {result}"
            except Exception as e:
                return f"Calculation error: {str(e)}"
        
        @tool
        def text_analyzer(text: str) -> str:
            """Analyze text for various metrics"""
            words = text.split()
            sentences = text.split('.')
            paragraphs = text.split('\n\n')
            
            analysis = {
                "word_count": len(words),
                "sentence_count": len([s for s in sentences if s.strip()]),
                "paragraph_count": len([p for p in paragraphs if p.strip()]),
                "avg_words_per_sentence": len(words) / max(len(sentences), 1),
                "readability_score": min(100, max(0, 206.835 - 1.015 * (len(words) / max(len(sentences), 1)) - 84.6 * (len([w for w in words if len(w) > 6]) / max(len(words), 1))))
            }
            
            return json.dumps(analysis, indent=2)
        
        @tool
        def data_processor(data_json: str) -> str:
            """Process structured data and return insights"""
            try:
                data = json.loads(data_json)
                
                if isinstance(data, list) and all(isinstance(x, (int, float)) for x in data):
                    # Numeric data processing
                    result = {
                        "count": len(data),
                        "sum": sum(data),
                        "mean": np.mean(data),
                        "median": np.median(data),
                        "std": np.std(data),
                        "min": min(data),
                        "max": max(data)
                    }
                    return json.dumps(result, indent=2)
                elif isinstance(data, dict):
                    # Dictionary analysis
                    result = {
                        "keys": list(data.keys()),
                        "key_count": len(data),
                        "value_types": {k: type(v).__name__ for k, v in data.items()}
                    }
                    return json.dumps(result, indent=2)
                else:
                    return f"Data type not supported: {type(data)}"
                    
            except Exception as e:
                return f"Data processing error: {str(e)}"
        
        # Register tools
        self.tools = {
            "web_search": web_search,
            "wikipedia_lookup": wikipedia_lookup,
            "calculator": calculator,
            "text_analyzer": text_analyzer,
            "data_processor": data_processor
        }
    
    def get_tools(self, tool_names: List[str]) -> List[BaseTool]:
        """Get tools by names"""
        return [self.tools[name] for name in tool_names if name in self.tools]
    
    def add_custom_tool(self, name: str, tool_func: Callable) -> None:
        """Add custom tool to toolkit"""
        self.tools[name] = tool(tool_func)

class RAGIntegration:
    """RAG integration for AI agents"""
    
    def __init__(self, openai_api_key: str):
        self.openai_api_key = openai_api_key
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.vector_stores = {}
        self.retrievers = {}
    
    def create_rag_system(self, documents: List[str], 
                         collection_name: str = "default") -> BaseRetriever:
        """Create RAG system from documents"""
        
        try:
            # Process documents
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            
            # Split documents
            doc_objects = []
            for i, doc in enumerate(documents):
                chunks = text_splitter.split_text(doc)
                for j, chunk in enumerate(chunks):
                    doc_objects.append({
                        "page_content": chunk,
                        "metadata": {"source": f"doc_{i}", "chunk": j}
                    })
            
            # Create vector store
            vector_store = FAISS.from_texts(
                texts=[doc["page_content"] for doc in doc_objects],
                embedding=self.embeddings,
                metadatas=[doc["metadata"] for doc in doc_objects]
            )
            
            # Create retriever
            retriever = vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            )
            
            self.vector_stores[collection_name] = vector_store
            self.retrievers[collection_name] = retriever
            
            logger.info(f"RAG system created for collection '{collection_name}' with {len(doc_objects)} chunks")
            return retriever
            
        except Exception as e:
            logger.error(f"Error creating RAG system: {e}")
            raise
    
    def retrieve_context(self, query: str, collection_name: str = "default") -> str:
        """Retrieve relevant context for a query"""
        
        if collection_name not in self.retrievers:
            return "No RAG system available for this collection"
        
        try:
            retriever = self.retrievers[collection_name]
            docs = retriever.get_relevant_documents(query)
            
            context = "\n\n".join([doc.page_content for doc in docs])
            return f"Retrieved context:\n{context}"
            
        except Exception as e:
            logger.error(f"Error retrieving context: {e}")
            return f"Context retrieval failed: {str(e)}"

class AgentSupervisor:
    """Advanced agent supervision and monitoring"""
    
    def __init__(self):
        self.agent_metrics = defaultdict(lambda: {
            "task_count": 0,
            "success_count": 0,
            "failure_count": 0,
            "avg_response_time": 0.0,
            "total_tokens": 0,
            "last_activity": None
        })
        
        self.system_metrics = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "avg_workflow_time": 0.0,
            "active_agents": set(),
            "error_log": deque(maxlen=1000)
        }
        
        self.alerts = deque(maxlen=100)
        self.monitoring_active = True
        self.monitoring_thread = None
    
    def start_monitoring(self):
        """Start continuous monitoring"""
        if not self.monitoring_thread or not self.monitoring_thread.is_alive():
            self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
            self.monitoring_thread.start()
            logger.info("Agent monitoring started")
    
    def _monitoring_loop(self):
        """Continuous monitoring loop"""
        while self.monitoring_active:
            try:
                self._check_system_health()
                self._check_agent_performance()
                time.sleep(10)  # Check every 10 seconds
            except Exception as e:
                logger.error(f"Monitoring error: {e}")
    
    def _check_system_health(self):
        """Check overall system health"""
        # CPU and memory usage
        cpu_percent = psutil.cpu_percent()
        memory_percent = psutil.virtual_memory().percent
        
        if cpu_percent > 90:
            self._create_alert("high_cpu", f"High CPU usage: {cpu_percent}%")
        
        if memory_percent > 90:
            self._create_alert("high_memory", f"High memory usage: {memory_percent}%")
    
    def _check_agent_performance(self):
        """Check individual agent performance"""
        for agent_name, metrics in self.agent_metrics.items():
            # Check failure rate
            total_tasks = metrics["task_count"]
            if total_tasks > 0:
                failure_rate = metrics["failure_count"] / total_tasks
                if failure_rate > 0.3:  # 30% failure rate threshold
                    self._create_alert(
                        "high_failure_rate", 
                        f"Agent {agent_name} has high failure rate: {failure_rate:.2%}"
                    )
    
    def _create_alert(self, alert_type: str, message: str):
        """Create system alert"""
        alert = {
            "type": alert_type,
            "message": message,
            "timestamp": datetime.now(timezone.utc),
            "severity": "warning"
        }
        self.alerts.append(alert)
        logger.warning(f"ALERT: {message}")
    
    def log_agent_activity(self, agent_name: str, task_type: str, 
                          success: bool, response_time: float, tokens_used: int):
        """Log agent activity for monitoring"""
        metrics = self.agent_metrics[agent_name]
        metrics["task_count"] += 1
        
        if success:
            metrics["success_count"] += 1
        else:
            metrics["failure_count"] += 1
        
        # Update average response time
        old_avg = metrics["avg_response_time"]
        metrics["avg_response_time"] = (old_avg * (metrics["task_count"] - 1) + response_time) / metrics["task_count"]
        
        metrics["total_tokens"] += tokens_used
        metrics["last_activity"] = datetime.now(timezone.utc)
        
        self.system_metrics["active_agents"].add(agent_name)
    
    def get_supervision_report(self) -> Dict[str, Any]:
        """Generate comprehensive supervision report"""
        return {
            "system_metrics": dict(self.system_metrics),
            "agent_metrics": dict(self.agent_metrics),
            "recent_alerts": list(self.alerts)[-10:],  # Last 10 alerts
            "system_health": {
                "cpu_usage": psutil.cpu_percent(),
                "memory_usage": psutil.virtual_memory().percent,
                "active_threads": threading.active_count()
            }
        }

class MultiAgentOrchestrator:
    """Advanced multi-agent orchestration with LangGraph"""
    
    def __init__(self, openai_api_key: str):
        self.openai_api_key = openai_api_key
        self.toolkit = AdvancedToolkit()
        self.rag_integration = RAGIntegration(openai_api_key)
        self.supervisor = AgentSupervisor()
        self.workflows = {}
        self.active_sessions = {}
        
        # Setup checkpointing
        self.checkpointer = MemorySaver()
        
        # Start monitoring
        self.supervisor.start_monitoring()
    
    def create_agent(self, config: AgentConfig) -> Callable:
        """Create individual agent with specified configuration"""
        
        # Setup LLM
        llm = ChatOpenAI(
            openai_api_key=self.openai_api_key,
            model=config.model_name,
            temperature=config.temperature,
            max_tokens=config.max_tokens
        )
        
        # Setup tools
        tools = self.toolkit.get_tools(config.tools) if config.tools else []
        
        # Create agent prompt
        agent_prompt = ChatPromptTemplate.from_messages([
            ("system", config.system_prompt),
            MessagesPlaceholder(variable_name="messages"),
        ])
        
        def agent_node(state: AgentState) -> AgentState:
            """Agent execution node"""
            start_time = time.time()
            
            try:
                # Prepare messages
                messages = state["messages"]
                
                # Add RAG context if enabled
                if config.rag_enabled and config.rag_config:
                    last_human_message = None
                    for msg in reversed(messages):
                        if isinstance(msg, HumanMessage):
                            last_human_message = msg.content
                            break
                    
                    if last_human_message:
                        rag_context = self.rag_integration.retrieve_context(
                            last_human_message, 
                            config.rag_config.get("collection_name", "default")
                        )
                        
                        # Add context to system message
                        context_message = SystemMessage(content=f"Additional context: {rag_context}")
                        messages = [context_message] + messages
                
                # Execute agent
                if tools:
                    # Agent with tools
                    llm_with_tools = llm.bind_tools(tools)
                    chain = agent_prompt | llm_with_tools
                    response = chain.invoke({"messages": messages})
                    
                    # Handle tool calls
                    if response.tool_calls:
                        tool_messages = []
                        for tool_call in response.tool_calls:
                            tool_name = tool_call["name"]
                            tool_args = tool_call["args"]
                            
                            # Execute tool
                            for tool in tools:
                                if tool.name == tool_name:
                                    try:
                                        tool_result = tool.invoke(tool_args)
                                        tool_messages.append(ToolMessage(
                                            content=str(tool_result),
                                            tool_call_id=tool_call["id"]
                                        ))
                                    except Exception as e:
                                        tool_messages.append(ToolMessage(
                                            content=f"Tool execution failed: {str(e)}",
                                            tool_call_id=tool_call["id"]
                                        ))
                                    break
                        
                        # Get final response with tool results
                        all_messages = messages + [response] + tool_messages
                        final_response = (agent_prompt | llm).invoke({"messages": all_messages})
                        
                        # Update state
                        state["messages"].extend([response] + tool_messages + [final_response])
                    else:
                        state["messages"].append(response)
                else:
                    # Simple agent without tools
                    chain = agent_prompt | llm
                    response = chain.invoke({"messages": messages})
                    state["messages"].append(response)
                
                # Update agent state
                state["current_agent"] = config.name
                state["agent_outputs"][config.name] = response.content if hasattr(response, 'content') else str(response)
                
                # Log successful execution
                response_time = time.time() - start_time
                self.supervisor.log_agent_activity(
                    config.name, "task_execution", True, response_time, 
                    getattr(response, 'usage', {}).get('total_tokens', 0)
                )
                
                return state
                
            except Exception as e:
                # Log error
                error_info = {
                    "agent": config.name,
                    "error": str(e),
                    "timestamp": datetime.now(timezone.utc)
                }
                state["error_log"].append(error_info)
                
                # Log failed execution
                response_time = time.time() - start_time
                self.supervisor.log_agent_activity(
                    config.name, "task_execution", False, response_time, 0
                )
                
                # Add error message
                error_message = AIMessage(content=f"Agent {config.name} encountered an error: {str(e)}")
                state["messages"].append(error_message)
                
                return state
        
        return agent_node
    
    def create_supervisor_node(self, workflow_config: WorkflowConfig) -> Callable:
        """Create supervisor node for orchestrating agents"""
        
        agent_names = [agent.name for agent in workflow_config.agents]
        
        supervisor_prompt = ChatPromptTemplate.from_messages([
            ("system", f"""
            You are a supervisor managing a team of AI agents: {', '.join(agent_names)}.
            
            Based on the conversation and task requirements, decide which agent should act next.
            Consider the expertise of each agent and the current progress.
            
            Available agents and their roles:
            {chr(10).join([f"- {agent.name}: {agent.role.value}" for agent in workflow_config.agents])}
            
            Respond with just the name of the agent who should act next, or "FINISH" if the task is complete.
            Consider the conversation history and choose the most appropriate agent for the next step.
            """),
            MessagesPlaceholder(variable_name="messages"),
        ])
        
        llm = ChatOpenAI(
            openai_api_key=self.openai_api_key,
            model="gpt-4",
            temperature=0.1
        )
        
        chain = supervisor_prompt | llm | StrOutputParser()
        
        def supervisor_node(state: AgentState) -> AgentState:
            """Supervisor decision node"""
            try:
                # Check iteration limit
                if state["iteration_count"] >= state["max_iterations"]:
                    state["current_agent"] = "FINISH"
                    return state
                
                # Get supervisor decision
                decision = chain.invoke({"messages": state["messages"]})
                
                # Clean up decision
                decision = decision.strip().upper()
                if decision not in agent_names + ["FINISH"]:
                    # Default to first agent if decision is unclear
                    decision = agent_names[0]
                
                state["current_agent"] = decision
                state["iteration_count"] += 1
                
                return state
                
            except Exception as e:
                logger.error(f"Supervisor error: {e}")
                state["current_agent"] = "FINISH"
                return state
        
        return supervisor_node
    
    def create_workflow(self, config: WorkflowConfig) -> StateGraph:
        """Create complete multi-agent workflow"""
        
        # Initialize state graph
        workflow = StateGraph(AgentState)
        
        # Create agents
        agent_nodes = {}
        for agent_config in config.agents:
            agent_node = self.create_agent(agent_config)
            agent_nodes[agent_config.name] = agent_node
            workflow.add_node(agent_config.name, agent_node)
        
        # Create supervisor
        supervisor_node = self.create_supervisor_node(config)
        workflow.add_node("supervisor", supervisor_node)
        
        # Add conditional routing
        def route_to_agent(state: AgentState) -> str:
            """Route to next agent based on supervisor decision"""
            next_agent = state["current_agent"]
            if next_agent == "FINISH":
                return END
            return next_agent
        
        # Define workflow edges
        workflow.add_edge(START, "supervisor")
        
        for agent_name in agent_nodes.keys():
            workflow.add_edge(agent_name, "supervisor")
        
        workflow.add_conditional_edges(
            "supervisor",
            route_to_agent,
            {agent_name: agent_name for agent_name in agent_nodes.keys()} | {END: END}
        )
        
        # Compile workflow
        compiled_workflow = workflow.compile(checkpointer=self.checkpointer)
        
        # Store workflow
        self.workflows[config.workflow_id] = {
            "config": config,
            "workflow": compiled_workflow,
            "created_at": datetime.now(timezone.utc)
        }
        
        logger.info(f"Workflow '{config.workflow_id}' created with {len(config.agents)} agents")
        return compiled_workflow
    
    async def execute_workflow(self, workflow_id: str, initial_message: str,
                             session_id: Optional[str] = None) -> Dict[str, Any]:
        """Execute multi-agent workflow"""
        
        if workflow_id not in self.workflows:
            raise ValueError(f"Workflow '{workflow_id}' not found")
        
        workflow_info = self.workflows[workflow_id]
        workflow = workflow_info["workflow"]
        config = workflow_info["config"]
        
        # Generate session ID if not provided
        if session_id is None:
            session_id = str(uuid.uuid4())
        
        try:
            # Initialize state
            initial_state = {
                "messages": [HumanMessage(content=initial_message)],
                "current_agent": "supervisor",
                "task_id": str(uuid.uuid4()),
                "task_status": TaskStatus.IN_PROGRESS.value,
                "task_progress": {},
                "shared_context": {},
                "agent_outputs": {},
                "error_log": [],
                "iteration_count": 0,
                "max_iterations": config.max_iterations,
                "human_feedback": None,
                "final_output": None
            }
            
            # Execute workflow
            start_time = time.time()
            
            final_state = None
            async for state in workflow.astream(
                initial_state,
                config={"configurable": {"thread_id": session_id}}
            ):
                final_state = state
                
                # Log progress
                current_agent = state.get("current_agent", "unknown")
                iteration = state.get("iteration_count", 0)
                logger.info(f"Workflow step {iteration}: {current_agent}")
            
            execution_time = time.time() - start_time
            
            # Extract final output
            if final_state and final_state["messages"]:
                last_message = final_state["messages"][-1]
                if isinstance(last_message, AIMessage):
                    final_output = last_message.content
                else:
                    final_output = str(last_message)
            else:
                final_output = "No output generated"
            
            # Update metrics
            self.supervisor.system_metrics["total_tasks"] += 1
            self.supervisor.system_metrics["completed_tasks"] += 1
            
            # Prepare result
            result = {
                "workflow_id": workflow_id,
                "session_id": session_id,
                "task_id": final_state["task_id"],
                "status": TaskStatus.COMPLETED.value,
                "final_output": final_output,
                "agent_outputs": final_state["agent_outputs"],
                "execution_time": execution_time,
                "iteration_count": final_state["iteration_count"],
                "messages": [
                    {
                        "type": type(msg).__name__,
                        "content": msg.content if hasattr(msg, 'content') else str(msg)
                    } 
                    for msg in final_state["messages"]
                ],
                "error_log": final_state["error_log"],
                "timestamp": datetime.now(timezone.utc)
            }
            
            return result
            
        except Exception as e:
            # Update error metrics
            self.supervisor.system_metrics["failed_tasks"] += 1
            
            error_result = {
                "workflow_id": workflow_id,
                "session_id": session_id,
                "status": TaskStatus.FAILED.value,
                "error": str(e),
                "timestamp": datetime.now(timezone.utc)
            }
            
            logger.error(f"Workflow execution failed: {e}")
            return error_result
    
    def get_workflow_info(self, workflow_id: str) -> Dict[str, Any]:
        """Get workflow information"""
        if workflow_id not in self.workflows:
            return {"error": "Workflow not found"}
        
        workflow_info = self.workflows[workflow_id]
        config = workflow_info["config"]
        
        return {
            "workflow_id": config.workflow_id,
            "description": config.description,
            "agents": [
                {
                    "name": agent.name,
                    "role": agent.role.value,
                    "tools": agent.tools,
                    "rag_enabled": agent.rag_enabled
                }
                for agent in config.agents
            ],
            "max_iterations": config.max_iterations,
            "created_at": workflow_info["created_at"],
            "checkpoint_enabled": config.checkpoint_enabled
        }
    
    def list_workflows(self) -> List[Dict[str, Any]]:
        """List all available workflows"""
        return [
            {
                "workflow_id": workflow_id,
                "description": info["config"].description,
                "agent_count": len(info["config"].agents),
                "created_at": info["created_at"]
            }
            for workflow_id, info in self.workflows.items()
        ]

# Demonstration and practical implementation
async def demonstrate_langgraph_multi_agent():
    """Comprehensive demonstration of LangGraph multi-agent systems"""
    
    logger.info("=== LangGraph Multi-Agent Systems Demonstration ===")
    
    # Check for OpenAI API key
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        logger.error("OpenAI API key not found. Please set OPENAI_API_KEY environment variable.")
        return
    
    # Initialize orchestrator
    orchestrator = MultiAgentOrchestrator(openai_api_key)
    
    # 1. Create Sample Documents for RAG
    logger.info("\n1. Setting up RAG Knowledge Base")
    
    sample_documents = [
        """
        LangGraph is a framework for building stateful, multi-actor applications with LLMs. 
        It provides a graph-based approach to orchestrating multiple AI agents, enabling 
        complex workflows with conditional logic, loops, and state management.
        
        Key features include:
        - Graph-based workflow definition
        - State management across agent interactions
        - Conditional routing and decision making
        - Built-in checkpointing and persistence
        - Integration with LangChain tools and components
        """,
        
        """
        Multi-agent systems enable multiple AI agents to work together on complex tasks.
        Each agent can have specialized capabilities and knowledge domains. Benefits include:
        
        - Task specialization and expertise
        - Parallel processing capabilities
        - Fault tolerance and redundancy
        - Scalable architecture for complex problems
        - Human-like collaborative problem solving
        
        Common patterns include supervisor-worker, peer-to-peer, and hierarchical structures.
        """,
        
        """
        Retrieval-Augmented Generation (RAG) enhances AI agents by providing access to 
        external knowledge sources. This enables agents to:
        
        - Access up-to-date information
        - Reduce hallucinations
        - Provide factual, grounded responses
        - Work with domain-specific knowledge
        - Maintain consistency across interactions
        
        RAG can be integrated into individual agents or shared across multiple agents
        in a multi-agent system for collaborative knowledge access.
        """
    ]
    
    # Create RAG system
    rag_retriever = orchestrator.rag_integration.create_rag_system(
        sample_documents, 
        "knowledge_base"
    )
    
    # 2. Define Agent Configurations
    logger.info("\n2. Creating Agent Configurations")
    
    # Research Agent
    researcher_config = AgentConfig(
        name="researcher",
        role=AgentRole.RESEARCHER,
        system_prompt="""
        You are a research specialist responsible for gathering and analyzing information.
        Your role is to:
        - Search for relevant information from various sources
        - Analyze and synthesize research findings
        - Provide comprehensive background information
        - Identify key facts and data points
        
        Use available tools to gather information and provide thorough research summaries.
        Be accurate, thorough, and cite your sources when possible.
        """,
        tools=["web_search", "wikipedia_lookup"],
        temperature=0.3
    )
    
    # Analyst Agent
    analyst_config = AgentConfig(
        name="analyst",
        role=AgentRole.ANALYST,
        system_prompt="""
        You are an analytical specialist responsible for processing and interpreting data.
        Your role is to:
        - Analyze information provided by other agents
        - Identify patterns, trends, and insights
        - Perform calculations and data processing
        - Generate analytical reports and summaries
        
        Focus on providing clear, logical analysis with supporting evidence.
        Use tools when needed for calculations or data processing.
        """,
        tools=["calculator", "data_processor", "text_analyzer"],
        temperature=0.2
    )
    
    # Writer Agent with RAG
    writer_config = AgentConfig(
        name="writer",
        role=AgentRole.WRITER,
        system_prompt="""
        You are a writing specialist responsible for creating clear, engaging content.
        Your role is to:
        - Transform research and analysis into well-written content
        - Ensure proper structure and flow
        - Adapt tone and style to the target audience
        - Create comprehensive, coherent documents
        
        Use the knowledge base and information from other agents to create high-quality content.
        Focus on clarity, accuracy, and engagement.
        """,
        rag_enabled=True,
        rag_config={"collection_name": "knowledge_base"},
        temperature=0.7
    )
    
    # Critic Agent
    critic_config = AgentConfig(
        name="critic",
        role=AgentRole.CRITIC,
        system_prompt="""
        You are a quality assurance specialist responsible for reviewing and improving work.
        Your role is to:
        - Review content for accuracy, clarity, and completeness
        - Identify areas for improvement
        - Suggest specific enhancements
        - Ensure high-quality standards are met
        
        Provide constructive feedback and specific recommendations.
        Focus on both content quality and presentation.
        """,
        tools=["text_analyzer"],
        temperature=0.4
    )
    
    # 3. Create Multi-Agent Workflow
    logger.info("\n3. Creating Multi-Agent Workflow")
    
    workflow_config = WorkflowConfig(
        workflow_id="research_analysis_workflow",
        description="Comprehensive research, analysis, and content creation workflow",
        agents=[researcher_config, analyst_config, writer_config, critic_config],
        max_iterations=15,
        require_human_approval=False,
        enable_monitoring=True,
        checkpoint_enabled=True
    )
    
    # Create workflow
    workflow = orchestrator.create_workflow(workflow_config)
    
    # 4. Execute Research Workflow
    logger.info("\n4. Executing Research Workflow")
    
    research_task = """
    Please conduct a comprehensive analysis of the impact of artificial intelligence on modern software development.
    
    The analysis should include:
    1. Current trends in AI-assisted development
    2. Benefits and challenges for developers
    3. Statistical analysis of adoption rates
    4. Future predictions and recommendations
    5. A well-structured report with key insights
    
    Please work collaboratively to produce a thorough, accurate, and well-written analysis.
    """
    
    result = await orchestrator.execute_workflow(
        workflow_id="research_analysis_workflow",
        initial_message=research_task
    )
    
    logger.info(f"Workflow Status: {result['status']}")
    logger.info(f"Execution Time: {result.get('execution_time', 0):.2f} seconds")
    logger.info(f"Iterations: {result.get('iteration_count', 0)}")
    
    if result['status'] == TaskStatus.COMPLETED.value:
        logger.info("\nFinal Output:")
        logger.info(result['final_output'][:500] + "..." if len(result['final_output']) > 500 else result['final_output'])
        
        logger.info("\nAgent Contributions:")
        for agent_name, output in result['agent_outputs'].items():
            logger.info(f"{agent_name}: {output[:200]}..." if len(output) > 200 else f"{agent_name}: {output}")
    
    # 5. Create Specialized Technical Workflow
    logger.info("\n5. Creating Specialized Technical Workflow")
    
    # Technical Specialist Agent
    tech_specialist_config = AgentConfig(
        name="tech_specialist",
        role=AgentRole.SPECIALIST,
        system_prompt="""
        You are a technical specialist with expertise in software architecture and AI systems.
        Your role is to:
        - Provide technical insights and recommendations
        - Analyze system architectures and implementations
        - Suggest best practices and optimization strategies
        - Address technical challenges and solutions
        
        Focus on practical, implementable technical guidance.
        """,
        tools=["calculator", "data_processor"],
        rag_enabled=True,
        rag_config={"collection_name": "knowledge_base"},
        temperature=0.3
    )
    
    # Coordinator Agent
    coordinator_config = AgentConfig(
        name="coordinator",
        role=AgentRole.COORDINATOR,
        system_prompt="""
        You are a project coordinator responsible for managing technical workflows.
        Your role is to:
        - Coordinate between different specialists
        - Ensure project requirements are met
        - Manage timeline and deliverables
        - Facilitate communication and collaboration
        
        Focus on efficient project management and clear communication.
        """,
        temperature=0.5
    )
    
    technical_workflow_config = WorkflowConfig(
        workflow_id="technical_consultation_workflow",
        description="Technical consultation and problem-solving workflow",
        agents=[tech_specialist_config, coordinator_config, analyst_config],
        max_iterations=10,
        enable_monitoring=True
    )
    
    # Create technical workflow
    tech_workflow = orchestrator.create_workflow(technical_workflow_config)
    
    # Execute technical consultation
    technical_task = """
    We need to design a scalable multi-agent system for processing customer support requests.
    
    Requirements:
    - Handle 10,000+ requests per day
    - Automatic categorization and routing
    - Integration with existing CRM systems
    - Real-time response capabilities
    - Quality monitoring and analytics
    
    Please provide a detailed technical architecture and implementation plan.
    """
    
    tech_result = await orchestrator.execute_workflow(
        workflow_id="technical_consultation_workflow",
        initial_message=technical_task
    )
    
    logger.info(f"\nTechnical Workflow Status: {tech_result['status']}")
    logger.info(f"Technical Analysis Output: {tech_result['final_output'][:300]}...")
    
    # 6. Monitoring and Supervision Analysis
    logger.info("\n6. Agent Supervision and Monitoring")
    
    # Get supervision report
    supervision_report = orchestrator.supervisor.get_supervision_report()
    
    logger.info("System Metrics:")
    for metric, value in supervision_report["system_metrics"].items():
        if metric != "active_agents":
            logger.info(f"  {metric}: {value}")
    
    logger.info("\nAgent Performance:")
    for agent_name, metrics in supervision_report["agent_metrics"].items():
        success_rate = metrics["success_count"] / max(metrics["task_count"], 1)
        logger.info(f"  {agent_name}: {metrics['task_count']} tasks, {success_rate:.2%} success rate")
    
    # 7. Performance Analysis and Visualization
    logger.info("\n7. Performance Analysis")
    
    try:
        # Create performance visualization
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Workflow execution times
        workflow_times = [result.get('execution_time', 0), tech_result.get('execution_time', 0)]
        workflow_names = ['Research Workflow', 'Technical Workflow']
        
        axes[0, 0].bar(workflow_names, workflow_times)
        axes[0, 0].set_title('Workflow Execution Times')
        axes[0, 0].set_ylabel('Time (seconds)')
        
        # Agent task distribution
        agent_tasks = {}
        for agent_name, metrics in supervision_report["agent_metrics"].items():
            agent_tasks[agent_name] = metrics["task_count"]
        
        if agent_tasks:
            axes[0, 1].pie(agent_tasks.values(), labels=agent_tasks.keys(), autopct='%1.1f%%')
            axes[0, 1].set_title('Agent Task Distribution')
        
        # Success rates
        agent_success_rates = {}
        for agent_name, metrics in supervision_report["agent_metrics"].items():
            if metrics["task_count"] > 0:
                agent_success_rates[agent_name] = metrics["success_count"] / metrics["task_count"]
        
        if agent_success_rates:
            axes[1, 0].bar(agent_success_rates.keys(), agent_success_rates.values())
            axes[1, 0].set_title('Agent Success Rates')
            axes[1, 0].set_ylabel('Success Rate')
            axes[1, 0].set_ylim(0, 1)
        
        # System health metrics
        health_metrics = supervision_report["system_health"]
        health_names = list(health_metrics.keys())
        health_values = list(health_metrics.values())
        
        colors = ['red' if v > 80 else 'orange' if v > 60 else 'green' for v in health_values]
        axes[1, 1].bar(health_names, health_values, color=colors)
        axes[1, 1].set_title('System Health Metrics')
        axes[1, 1].set_ylabel('Percentage / Count')
        
        plt.tight_layout()
        plt.savefig('langgraph_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info("Performance visualization saved")
        
    except Exception as e:
        logger.warning(f"Error creating visualizations: {e}")
    
    # 8. Generate Comprehensive Report
    workflow_info = [orchestrator.get_workflow_info(wf_id) for wf_id in orchestrator.workflows.keys()]
    
    comprehensive_report = {
        "demonstration_summary": {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "workflows_created": len(orchestrator.workflows),
            "total_executions": len([result, tech_result]),
            "successful_executions": sum(1 for r in [result, tech_result] if r['status'] == TaskStatus.COMPLETED.value),
            "total_agents": len(set().union(*[wf["agents"] for wf in workflow_info])),
        },
        
        "workflow_results": {
            "research_workflow": {
                "status": result['status'],
                "execution_time": result.get('execution_time', 0),
                "iterations": result.get('iteration_count', 0),
                "agents_involved": len(result.get('agent_outputs', {})),
                "output_length": len(result.get('final_output', ''))
            },
            "technical_workflow": {
                "status": tech_result['status'],
                "execution_time": tech_result.get('execution_time', 0),
                "iterations": tech_result.get('iteration_count', 0),
                "agents_involved": len(tech_result.get('agent_outputs', {})),
                "output_length": len(tech_result.get('final_output', ''))
            }
        },
        
        "supervision_metrics": supervision_report,
        
        "agent_configurations": [
            {
                "name": agent.name,
                "role": agent.role.value,
                "tools": agent.tools,
                "rag_enabled": agent.rag_enabled,
                "temperature": agent.temperature
            }
            for workflow_config in [workflow_config, technical_workflow_config]
            for agent in workflow_config.agents
        ],
        
        "features_demonstrated": [
            "Multi-agent workflow orchestration",
            "Graph-based agent coordination",
            "RAG integration with agents",
            "Tool usage and specialization",
            "Agent supervision and monitoring",
            "Conditional routing and decision making",
            "State management across interactions",
            "Performance tracking and analytics",
            "Error handling and recovery",
            "Checkpointing and persistence"
        ],
        
        "best_practices": [
            "Design agents with clear, specialized roles",
            "Use appropriate tools for each agent's expertise",
            "Implement comprehensive monitoring and supervision",
            "Enable checkpointing for long-running workflows",
            "Design workflows with clear termination conditions",
            "Use RAG for knowledge-intensive tasks",
            "Implement proper error handling and recovery",
            "Monitor performance and resource usage",
            "Use conditional routing for efficient workflows",
            "Maintain conversation state across agent interactions"
        ],
        
        "recommendations": [
            "Start with simple workflows before complex orchestration",
            "Use supervision and monitoring in production systems",
            "Implement proper authentication and authorization",
            "Consider human-in-the-loop for critical decisions",
            "Use appropriate LLM models for each agent's needs",
            "Implement cost monitoring for production deployments",
            "Design workflows with fault tolerance",
            "Use caching for repeated operations",
            "Implement proper logging and observability",
            "Consider scaling strategies for high-volume use cases"
        ]
    }
    
    # Save comprehensive report
    with open("langgraph_multi_agent_report.json", "w") as f:
        json.dump(comprehensive_report, f, indent=2, default=str)
    
    logger.info("LangGraph multi-agent demonstration completed!")
    logger.info("Check 'langgraph_multi_agent_report.json' for detailed results")
    
    return comprehensive_report

# Main execution
async def main():
    """Main execution for LangGraph multi-agent demonstration"""
    try:
        report = await demonstrate_langgraph_multi_agent()
        
        # Display key results
        logger.info("\n=== LangGraph Multi-Agent Summary ===")
        logger.info(f"Workflows created: {report['demonstration_summary']['workflows_created']}")
        logger.info(f"Successful executions: {report['demonstration_summary']['successful_executions']}")
        logger.info(f"Total agents: {report['demonstration_summary']['total_agents']}")
        
        # Display workflow performance
        for workflow_name, workflow_data in report["workflow_results"].items():
            logger.info(f"{workflow_name}: {workflow_data['status']} in {workflow_data['execution_time']:.2f}s")
        
    except Exception as e:
        logger.error(f"LangGraph demonstration failed: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    asyncio.run(main())
````

## Conclusion

The comprehensive LangGraph multi-agent framework demonstrates the revolutionary capabilities of graph-based agent orchestration, providing sophisticated patterns for building, coordinating, and supervising intelligent agent networks. This implementation establishes production-ready foundations for complex AI systems that require collaborative problem-solving and specialized expertise.

**Graph-Based Orchestration Excellence** enables the creation of complex workflows through intuitive node-and-edge patterns, providing clear visualization and management of agent interactions while supporting conditional routing, parallel execution, and dynamic decision-making based on runtime conditions.

**Advanced Agent Supervision** through comprehensive monitoring, performance tracking, and health assessment ensures reliable operation in production environments, with real-time alerting, error recovery, and detailed analytics that support continuous optimization and maintenance.

**Intelligent State Management** across multi-agent interactions maintains conversation context, shared knowledge, and coordination state, enabling agents to work collaboratively on complex tasks while preserving coherence and building upon previous interactions.

**RAG Integration Architecture** demonstrates how external knowledge sources can be seamlessly integrated into individual agents or shared across agent networks, providing grounded, factual responses while reducing hallucinations and improving overall system reliability.

**Tool Specialization Framework** showcases how different agents can be equipped with specialized tools and capabilities, enabling task-specific expertise while maintaining system modularity and allowing for flexible composition of agent networks.

**Production-Ready Infrastructure** including checkpointing, persistence, error handling, and performance optimization ensures that multi-agent systems can be deployed reliably in enterprise environments with appropriate scalability and maintainability.

**Conditional Workflow Logic** through sophisticated routing mechanisms enables dynamic adaptation of agent workflows based on task requirements, intermediate results, and system conditions, providing intelligent automation that can handle complex, non-linear problem-solving scenarios.

**Comprehensive Analytics Platform** provides detailed insights into agent performance, workflow efficiency, resource utilization, and system health, enabling data-driven optimization and continuous improvement of multi-agent systems.

This advanced LangGraph framework establishes the foundation for building intelligent, collaborative AI systems that can tackle complex real-world problems through coordinated agent networks, providing the scalability, reliability, and sophistication required for enterprise-grade AI applications.