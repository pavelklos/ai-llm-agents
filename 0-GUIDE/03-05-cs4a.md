<small>Claude Sonnet 4</small>
# 05. Advanced API Integration for Dynamic Responses

## Key Terms

**API Integration Framework**: A comprehensive architectural pattern that enables AI assistants to seamlessly connect with external application programming interfaces, allowing real-time data retrieval, service interaction, and dynamic response generation based on current information from diverse data sources and third-party services.

**Dynamic Response Generation**: An advanced computational approach where AI assistants generate contextually relevant responses by combining large language model capabilities with real-time data from external APIs, creating adaptive and current information delivery that reflects the latest available data rather than static knowledge cutoffs.

**API Security Management**: A sophisticated security framework encompassing authentication protocols, credential encryption, rate limiting, input validation, and secure communication channels to protect sensitive API keys, user data, and system integrity while maintaining seamless integration capabilities.

**Rate Limiting and Throttling**: Advanced traffic management mechanisms that control the frequency and volume of API requests to prevent service overload, ensure fair usage distribution, handle quota limitations, and maintain optimal performance across multiple concurrent user interactions.

**Error Handling and Resilience**: Comprehensive fault-tolerance strategies including circuit breaker patterns, retry mechanisms, graceful degradation, and fallback responses that ensure assistant reliability even when external APIs are unavailable, slow, or returning unexpected responses.

**Real-Time Data Fusion**: The process of combining multiple API responses, processing heterogeneous data formats, normalizing information structures, and synthesizing coherent responses that leverage insights from various external sources while maintaining consistency and accuracy.

**Secure Credential Management**: Advanced practices for storing, accessing, and rotating sensitive authentication information including environment variables, secret management systems, encrypted storage, and principle of least privilege access controls to protect API credentials and sensitive configuration data.

**Asynchronous Request Processing**: Modern programming paradigms that enable concurrent API calls, non-blocking operations, and efficient resource utilization through asyncio patterns, allowing assistants to handle multiple requests simultaneously while maintaining responsive user interactions.

## Comprehensive Advanced API Integration System

Advanced API integration transforms static AI assistants into dynamic, information-rich systems that can access real-time data from weather services, financial markets, news sources, and countless other external platforms, enabling contextually aware responses that reflect current conditions and up-to-date information.

### Enterprise-Grade API Integration Framework

````python
import asyncio
import json
import logging
import os
import time
import warnings
from typing import Dict, List, Any, Optional, Union, Callable, Tuple, TypedDict
from dataclasses import dataclass, field
from datetime import datetime, timezone, timedelta
from pathlib import Path
import uuid
import re
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor
import hashlib
import hmac
import base64
from urllib.parse import urlencode, quote

# HTTP and API client libraries
import aiohttp
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import httpx

# OpenAI and LangChain
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import BaseTool, tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field, validator
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory
from langchain.callbacks import get_openai_callback

# Data processing and validation
import pandas as pd
import numpy as np
from pydantic import BaseSettings, SecretStr
import yaml
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup

# Security and encryption
import cryptography
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import jwt
from passlib.context import CryptContext

# Rate limiting and caching
import asyncio_throttle
from cachetools import TTLCache, LRUCache
import redis
from functools import wraps, lru_cache
import time

# Performance monitoring
import structlog
from prometheus_client import Counter, Histogram, Gauge
import psutil
import memory_profiler

# Circuit breaker and resilience
import pybreaker
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Utilities
from dotenv import load_dotenv
from collections import defaultdict, deque
import validators
from contextlib import asynccontextmanager

load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)

# Setup structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Metrics
api_requests = Counter('api_requests_total', 'Total API requests', ['service', 'method', 'status'])
api_response_time = Histogram('api_response_time_seconds', 'API response time', ['service'])
active_connections = Gauge('active_api_connections', 'Active API connections')
rate_limit_hits = Counter('rate_limit_hits_total', 'Rate limit hits', ['service'])
cache_hits = Counter('cache_hits_total', 'Cache hits', ['cache_type'])

class APIServiceType(Enum):
    """Types of API services"""
    WEATHER = "weather"
    FINANCIAL = "financial"
    NEWS = "news"
    SOCIAL_MEDIA = "social_media"
    GEOCODING = "geocoding"
    TRANSLATION = "translation"
    CRYPTOCURRENCY = "cryptocurrency"
    STOCK_MARKET = "stock_market"
    CUSTOM = "custom"

class AuthenticationType(Enum):
    """API authentication types"""
    API_KEY = "api_key"
    BEARER_TOKEN = "bearer_token"
    OAUTH2 = "oauth2"
    BASIC_AUTH = "basic_auth"
    HMAC_SIGNATURE = "hmac_signature"
    JWT_TOKEN = "jwt_token"
    NO_AUTH = "no_auth"

class ResponseFormat(Enum):
    """API response formats"""
    JSON = "json"
    XML = "xml"
    CSV = "csv"
    TEXT = "text"
    HTML = "html"

@dataclass
class APIEndpointConfig:
    """Configuration for API endpoints"""
    service_name: str
    service_type: APIServiceType
    base_url: str
    endpoints: Dict[str, str]
    authentication: AuthenticationType
    auth_config: Dict[str, Any]
    rate_limits: Dict[str, int]  # requests per time period
    timeout: int = 30
    max_retries: int = 3
    response_format: ResponseFormat = ResponseFormat.JSON
    headers: Dict[str, str] = field(default_factory=dict)
    query_params: Dict[str, str] = field(default_factory=dict)

class SecureCredentialManager:
    """Secure credential management system"""
    
    def __init__(self, encryption_key: Optional[bytes] = None):
        if encryption_key:
            self.cipher_suite = Fernet(encryption_key)
        else:
            # Generate key from environment variable or create new one
            password = os.getenv('ENCRYPTION_PASSWORD', 'default_password').encode()
            salt = os.getenv('ENCRYPTION_SALT', 'default_salt').encode()
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            key = base64.urlsafe_b64encode(kdf.derive(password))
            self.cipher_suite = Fernet(key)
        
        self.credentials_cache = {}
        self.last_rotation = datetime.now(timezone.utc)
        
    def encrypt_credential(self, credential: str) -> str:
        """Encrypt a credential"""
        return self.cipher_suite.encrypt(credential.encode()).decode()
    
    def decrypt_credential(self, encrypted_credential: str) -> str:
        """Decrypt a credential"""
        return self.cipher_suite.decrypt(encrypted_credential.encode()).decode()
    
    def store_credential(self, service: str, credential_type: str, value: str):
        """Store encrypted credential"""
        key = f"{service}_{credential_type}"
        encrypted_value = self.encrypt_credential(value)
        self.credentials_cache[key] = {
            "value": encrypted_value,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    
    def get_credential(self, service: str, credential_type: str) -> Optional[str]:
        """Retrieve and decrypt credential"""
        key = f"{service}_{credential_type}"
        
        # First try environment variables
        env_key = f"{service.upper()}_{credential_type.upper()}"
        if env_value := os.getenv(env_key):
            return env_value
        
        # Then try cached credentials
        if key in self.credentials_cache:
            encrypted_value = self.credentials_cache[key]["value"]
            return self.decrypt_credential(encrypted_value)
        
        return None
    
    def rotate_credentials(self, service: str):
        """Rotate credentials for a service"""
        # Implementation for credential rotation
        logger.info(f"Rotating credentials for service: {service}")
        self.last_rotation = datetime.now(timezone.utc)

class RateLimiter:
    """Advanced rate limiting with multiple strategies"""
    
    def __init__(self):
        self.limiters = {}
        self.request_history = defaultdict(deque)
        
    def create_limiter(self, service: str, requests_per_minute: int, 
                      requests_per_hour: int = None, burst_limit: int = None):
        """Create rate limiter for a service"""
        
        limiters = {}
        
        # Per minute limiter
        limiters['minute'] = asyncio_throttle.Throttler(rate_limit=requests_per_minute, period=60)
        
        # Per hour limiter if specified
        if requests_per_hour:
            limiters['hour'] = asyncio_throttle.Throttler(rate_limit=requests_per_hour, period=3600)
        
        # Burst limiter if specified
        if burst_limit:
            limiters['burst'] = asyncio_throttle.Throttler(rate_limit=burst_limit, period=1)
        
        self.limiters[service] = limiters
    
    async def acquire(self, service: str):
        """Acquire rate limit permission"""
        if service not in self.limiters:
            return  # No rate limiting configured
        
        service_limiters = self.limiters[service]
        
        # Apply all configured limiters
        for limiter_name, limiter in service_limiters.items():
            await limiter.acquire()
        
        # Track request
        now = time.time()
        self.request_history[service].append(now)
        
        # Clean old history (keep last hour)
        cutoff = now - 3600
        while (self.request_history[service] and 
               self.request_history[service][0] < cutoff):
            self.request_history[service].popleft()

class APIClient:
    """Advanced API client with security, resilience, and performance features"""
    
    def __init__(self, config: APIEndpointConfig, 
                 credential_manager: SecureCredentialManager,
                 rate_limiter: RateLimiter):
        
        self.config = config
        self.credential_manager = credential_manager
        self.rate_limiter = rate_limiter
        
        # Setup rate limiting
        self.rate_limiter.create_limiter(
            service=config.service_name,
            requests_per_minute=config.rate_limits.get('requests_per_minute', 60),
            requests_per_hour=config.rate_limits.get('requests_per_hour', 1000),
            burst_limit=config.rate_limits.get('burst_limit', 10)
        )
        
        # Setup caching
        self.cache = TTLCache(maxsize=1000, ttl=300)  # 5 minute TTL
        
        # Setup circuit breaker
        self.circuit_breaker = pybreaker.CircuitBreaker(
            fail_max=5,
            reset_timeout=30,
            exclude=[aiohttp.ClientError]
        )
        
        # Setup HTTP session with retry strategy
        self.session = None
        
        logger.info(f"Initialized API client for {config.service_name}")
    
    async def __aenter__(self):
        """Async context manager entry"""
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=30)
        timeout = aiohttp.ClientTimeout(total=self.config.timeout)
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers=self._get_headers()
        )
        
        active_connections.inc()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()
        active_connections.dec()
    
    def _get_headers(self) -> Dict[str, str]:
        """Get headers with authentication"""
        headers = self.config.headers.copy()
        
        if self.config.authentication == AuthenticationType.API_KEY:
            api_key = self.credential_manager.get_credential(
                self.config.service_name, "api_key"
            )
            if api_key:
                key_param = self.config.auth_config.get('key_param', 'X-API-Key')
                headers[key_param] = api_key
        
        elif self.config.authentication == AuthenticationType.BEARER_TOKEN:
            token = self.credential_manager.get_credential(
                self.config.service_name, "bearer_token"
            )
            if token:
                headers['Authorization'] = f'Bearer {token}'
        
        elif self.config.authentication == AuthenticationType.JWT_TOKEN:
            jwt_token = self._generate_jwt_token()
            if jwt_token:
                headers['Authorization'] = f'Bearer {jwt_token}'
        
        return headers
    
    def _generate_jwt_token(self) -> Optional[str]:
        """Generate JWT token for authentication"""
        try:
            secret = self.credential_manager.get_credential(
                self.config.service_name, "jwt_secret"
            )
            if not secret:
                return None
            
            payload = {
                'iss': self.config.service_name,
                'exp': datetime.now(timezone.utc) + timedelta(hours=1),
                'iat': datetime.now(timezone.utc)
            }
            
            return jwt.encode(payload, secret, algorithm='HS256')
        except Exception as e:
            logger.error(f"Error generating JWT token: {e}")
            return None
    
    def _create_cache_key(self, endpoint: str, params: Dict[str, Any]) -> str:
        """Create cache key for request"""
        param_str = urlencode(sorted(params.items()))
        key_data = f"{self.config.service_name}:{endpoint}:{param_str}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError))
    )
    async def make_request(self, endpoint: str, method: str = "GET", 
                          params: Dict[str, Any] = None, 
                          data: Dict[str, Any] = None,
                          use_cache: bool = True) -> Dict[str, Any]:
        """Make authenticated API request with resilience features"""
        
        start_time = time.time()
        params = params or {}
        
        try:
            # Apply rate limiting
            await self.rate_limiter.acquire(self.config.service_name)
            
            # Check cache first
            cache_key = self._create_cache_key(endpoint, params)
            if use_cache and cache_key in self.cache:
                cache_hits.labels(cache_type='api_response').inc()
                return self.cache[cache_key]
            
            # Prepare URL and parameters
            if endpoint not in self.config.endpoints:
                raise ValueError(f"Endpoint '{endpoint}' not configured")
            
            url = f"{self.config.base_url.rstrip('/')}/{self.config.endpoints[endpoint].lstrip('/')}"
            
            # Add default query parameters
            final_params = {**self.config.query_params, **params}
            
            # Make request through circuit breaker
            response_data = await self.circuit_breaker.call_async(
                self._execute_request, url, method, final_params, data
            )
            
            # Cache successful response
            if use_cache and response_data:
                self.cache[cache_key] = response_data
            
            # Record metrics
            api_requests.labels(
                service=self.config.service_name,
                method=method,
                status='success'
            ).inc()
            
            api_response_time.labels(service=self.config.service_name).observe(
                time.time() - start_time
            )
            
            return response_data
            
        except pybreaker.CircuitBreakerOpenException:
            logger.warning(f"Circuit breaker open for {self.config.service_name}")
            api_requests.labels(
                service=self.config.service_name,
                method=method,
                status='circuit_breaker_open'
            ).inc()
            raise
            
        except Exception as e:
            api_requests.labels(
                service=self.config.service_name,
                method=method,
                status='error'
            ).inc()
            
            logger.error(f"API request failed for {self.config.service_name}: {e}")
            raise
    
    async def _execute_request(self, url: str, method: str, 
                              params: Dict[str, Any], 
                              data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the actual HTTP request"""
        
        if not self.session:
            raise RuntimeError("Session not initialized. Use async context manager.")
        
        request_kwargs = {
            'params': params if method.upper() == 'GET' else None,
            'json': data if method.upper() in ['POST', 'PUT', 'PATCH'] else None
        }
        
        async with self.session.request(method, url, **request_kwargs) as response:
            # Handle rate limiting
            if response.status == 429:
                rate_limit_hits.labels(service=self.config.service_name).inc()
                retry_after = int(response.headers.get('Retry-After', 60))
                logger.warning(f"Rate limited by {self.config.service_name}, waiting {retry_after}s")
                await asyncio.sleep(retry_after)
                raise aiohttp.ClientError("Rate limited")
            
            # Raise for HTTP errors
            response.raise_for_status()
            
            # Parse response based on format
            if self.config.response_format == ResponseFormat.JSON:
                return await response.json()
            elif self.config.response_format == ResponseFormat.XML:
                text = await response.text()
                return self._parse_xml_response(text)
            elif self.config.response_format == ResponseFormat.CSV:
                text = await response.text()
                return self._parse_csv_response(text)
            else:
                return {"content": await response.text()}
    
    def _parse_xml_response(self, xml_text: str) -> Dict[str, Any]:
        """Parse XML response to dictionary"""
        try:
            root = ET.fromstring(xml_text)
            return self._xml_to_dict(root)
        except Exception as e:
            logger.error(f"Error parsing XML response: {e}")
            return {"content": xml_text}
    
    def _xml_to_dict(self, element) -> Dict[str, Any]:
        """Convert XML element to dictionary"""
        result = {}
        
        # Add attributes
        if element.attrib:
            result.update(element.attrib)
        
        # Add text content
        if element.text and element.text.strip():
            if len(element) == 0:  # No children
                return element.text.strip()
            result['text'] = element.text.strip()
        
        # Add children
        for child in element:
            child_data = self._xml_to_dict(child)
            if child.tag in result:
                if not isinstance(result[child.tag], list):
                    result[child.tag] = [result[child.tag]]
                result[child.tag].append(child_data)
            else:
                result[child.tag] = child_data
        
        return result
    
    def _parse_csv_response(self, csv_text: str) -> Dict[str, Any]:
        """Parse CSV response to dictionary"""
        try:
            lines = csv_text.strip().split('\n')
            if not lines:
                return {"data": []}
            
            headers = [h.strip() for h in lines[0].split(',')]
            data = []
            
            for line in lines[1:]:
                values = [v.strip() for v in line.split(',')]
                if len(values) == len(headers):
                    data.append(dict(zip(headers, values)))
            
            return {"data": data}
        except Exception as e:
            logger.error(f"Error parsing CSV response: {e}")
            return {"content": csv_text}

class APIIntegratedAssistant:
    """AI Assistant with advanced API integration capabilities"""
    
    def __init__(self, model_name: str = "gpt-4"):
        self.llm = ChatOpenAI(
            model_name=model_name,
            temperature=0.1,
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )
        
        self.credential_manager = SecureCredentialManager()
        self.rate_limiter = RateLimiter()
        
        # Initialize API clients
        self.api_clients = {}
        self._initialize_api_services()
        
        # Create tools
        self.tools = self._create_api_tools()
        
        # Performance tracking
        self.request_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_response_time": 0.0
        }
        
        logger.info("Initialized API-integrated assistant")
    
    def _initialize_api_services(self):
        """Initialize predefined API services"""
        
        # Weather API (OpenWeatherMap)
        weather_config = APIEndpointConfig(
            service_name="openweathermap",
            service_type=APIServiceType.WEATHER,
            base_url="https://api.openweathermap.org/data/2.5",
            endpoints={
                "current": "weather",
                "forecast": "forecast",
                "onecall": "onecall"
            },
            authentication=AuthenticationType.API_KEY,
            auth_config={"key_param": "appid"},
            rate_limits={"requests_per_minute": 60, "requests_per_hour": 1000},
            query_params={"units": "metric"}
        )
        
        # Financial API (Alpha Vantage)
        financial_config = APIEndpointConfig(
            service_name="alphavantage",
            service_type=APIServiceType.FINANCIAL,
            base_url="https://www.alphavantage.co/query",
            endpoints={
                "quote": "",
                "intraday": "",
                "daily": ""
            },
            authentication=AuthenticationType.API_KEY,
            auth_config={"key_param": "apikey"},
            rate_limits={"requests_per_minute": 5, "requests_per_hour": 500}
        )
        
        # News API
        news_config = APIEndpointConfig(
            service_name="newsapi",
            service_type=APIServiceType.NEWS,
            base_url="https://newsapi.org/v2",
            endpoints={
                "headlines": "top-headlines",
                "everything": "everything",
                "sources": "sources"
            },
            authentication=AuthenticationType.API_KEY,
            auth_config={"key_param": "apiKey"},
            rate_limits={"requests_per_minute": 100, "requests_per_hour": 1000}
        )
        
        # Cryptocurrency API (CoinGecko)
        crypto_config = APIEndpointConfig(
            service_name="coingecko",
            service_type=APIServiceType.CRYPTOCURRENCY,
            base_url="https://api.coingecko.com/api/v3",
            endpoints={
                "price": "simple/price",
                "coins": "coins/markets",
                "trending": "search/trending"
            },
            authentication=AuthenticationType.NO_AUTH,
            auth_config={},
            rate_limits={"requests_per_minute": 50, "requests_per_hour": 1000}
        )
        
        # Store configurations
        self.api_configs = {
            "weather": weather_config,
            "financial": financial_config,
            "news": news_config,
            "crypto": crypto_config
        }
    
    def _create_api_tools(self) -> List[BaseTool]:
        """Create LangChain tools for API integration"""
        
        tools = []
        
        # Weather tool
        @tool
        async def get_weather(location: str, forecast_type: str = "current") -> str:
            """Get weather information for a location.
            
            Args:
                location: City name or coordinates
                forecast_type: 'current', 'forecast', or 'detailed'
            """
            try:
                config = self.api_configs["weather"]
                async with APIClient(config, self.credential_manager, self.rate_limiter) as client:
                    if forecast_type == "current":
                        params = {"q": location}
                        data = await client.make_request("current", params=params)
                        
                        return f"Weather in {location}: {data['weather'][0]['description']}, "
                        f"Temperature: {data['main']['temp']}°C, "
                        f"Feels like: {data['main']['feels_like']}°C, "
                        f"Humidity: {data['main']['humidity']}%"
                    
                    elif forecast_type == "forecast":
                        params = {"q": location, "cnt": 5}
                        data = await client.make_request("forecast", params=params)
                        
                        forecast_text = f"5-day forecast for {location}:\n"
                        for item in data['list'][:5]:
                            date = datetime.fromtimestamp(item['dt']).strftime('%Y-%m-%d %H:%M')
                            forecast_text += f"{date}: {item['weather'][0]['description']}, {item['main']['temp']}°C\n"
                        
                        return forecast_text
                    
            except Exception as e:
                return f"Error getting weather data: {str(e)}"
        
        # Financial tool
        @tool
        async def get_stock_quote(symbol: str) -> str:
            """Get current stock quote for a symbol.
            
            Args:
                symbol: Stock symbol (e.g., AAPL, GOOGL)
            """
            try:
                config = self.api_configs["financial"]
                async with APIClient(config, self.credential_manager, self.rate_limiter) as client:
                    params = {
                        "function": "GLOBAL_QUOTE",
                        "symbol": symbol.upper()
                    }
                    data = await client.make_request("quote", params=params)
                    
                    quote = data['Global Quote']
                    return f"Stock quote for {symbol.upper()}: "
                    f"Price: ${quote['05. price']}, "
                    f"Change: {quote['09. change']} ({quote['10. change percent']}), "
                    f"Volume: {quote['06. volume']}"
                    
            except Exception as e:
                return f"Error getting stock quote: {str(e)}"
        
        # News tool
        @tool
        async def get_news(query: str, category: str = "general") -> str:
            """Get latest news articles.
            
            Args:
                query: Search query for news
                category: News category (business, technology, sports, etc.)
            """
            try:
                config = self.api_configs["news"]
                async with APIClient(config, self.credential_manager, self.rate_limiter) as client:
                    params = {
                        "q": query,
                        "category": category,
                        "pageSize": 5,
                        "sortBy": "publishedAt"
                    }
                    data = await client.make_request("everything", params=params)
                    
                    news_text = f"Latest news for '{query}':\n"
                    for article in data['articles'][:3]:
                        news_text += f"- {article['title']}\n"
                        news_text += f"  Source: {article['source']['name']}\n"
                        news_text += f"  Published: {article['publishedAt']}\n\n"
                    
                    return news_text
                    
            except Exception as e:
                return f"Error getting news: {str(e)}"
        
        # Cryptocurrency tool
        @tool
        async def get_crypto_price(cryptocurrency: str, currency: str = "usd") -> str:
            """Get current cryptocurrency price.
            
            Args:
                cryptocurrency: Cryptocurrency name or symbol
                currency: Target currency (usd, eur, etc.)
            """
            try:
                config = self.api_configs["crypto"]
                async with APIClient(config, self.credential_manager, self.rate_limiter) as client:
                    params = {
                        "ids": cryptocurrency.lower(),
                        "vs_currencies": currency.lower(),
                        "include_24hr_change": "true"
                    }
                    data = await client.make_request("price", params=params)
                    
                    crypto_id = cryptocurrency.lower()
                    if crypto_id in data:
                        price_data = data[crypto_id]
                        price = price_data[currency.lower()]
                        change_key = f"{currency.lower()}_24h_change"
                        change = price_data.get(change_key, 0)
                        
                        return f"{cryptocurrency.upper()} price: {price:.2f} {currency.upper()} "
                        f"(24h change: {change:.2f}%)"
                    else:
                        return f"Cryptocurrency '{cryptocurrency}' not found"
                        
            except Exception as e:
                return f"Error getting crypto price: {str(e)}"
        
        # Custom API tool
        @tool
        async def call_custom_api(service_name: str, endpoint: str, 
                                 params: str = "{}") -> str:
            """Call a custom API endpoint.
            
            Args:
                service_name: Name of the configured API service
                endpoint: Endpoint to call
                params: JSON string of parameters
            """
            try:
                if service_name not in self.api_configs:
                    return f"API service '{service_name}' not configured"
                
                import json
                parsed_params = json.loads(params) if params != "{}" else {}
                
                config = self.api_configs[service_name]
                async with APIClient(config, self.credential_manager, self.rate_limiter) as client:
                    data = await client.make_request(endpoint, params=parsed_params)
                    return json.dumps(data, indent=2)[:1000]  # Limit response size
                    
            except Exception as e:
                return f"Error calling custom API: {str(e)}"
        
        tools.extend([get_weather, get_stock_quote, get_news, get_crypto_price, call_custom_api])
        return tools
    
    async def process_query_with_apis(self, query: str, 
                                    context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Process query with API integration"""
        
        start_time = time.time()
        self.request_stats["total_requests"] += 1
        
        try:
            # Analyze query to determine which APIs might be needed
            api_suggestions = self._analyze_query_for_apis(query)
            
            # Create prompt with API context
            system_prompt = f"""You are an AI assistant with access to real-time data through various APIs. 
You can access:
- Weather information (current conditions and forecasts)
- Stock market data and financial information
- Latest news articles
- Cryptocurrency prices
- Custom API endpoints

Available tools: {[tool.name for tool in self.tools]}

Suggested APIs for this query: {api_suggestions}

Use the appropriate tools to get current, accurate information to answer the user's question.
"""
            
            # Create agent with tools
            agent = initialize_agent(
                tools=self.tools,
                llm=self.llm,
                agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                verbose=False,
                handle_parsing_errors=True,
                max_iterations=3
            )
            
            # Process query
            with get_openai_callback() as cb:
                response = await agent.arun(query)
            
            # Calculate metrics
            response_time = time.time() - start_time
            self.request_stats["successful_requests"] += 1
            self._update_average_response_time(response_time)
            
            result = {
                "query": query,
                "response": response,
                "api_suggestions": api_suggestions,
                "response_time": response_time,
                "token_usage": {
                    "prompt_tokens": cb.prompt_tokens,
                    "completion_tokens": cb.completion_tokens,
                    "total_cost": cb.total_cost
                },
                "context": context or {},
                "success": True
            }
            
            logger.info(f"Processed API-integrated query in {response_time:.2f}s")
            return result
            
        except Exception as e:
            self.request_stats["failed_requests"] += 1
            logger.error(f"Error processing API-integrated query: {e}")
            
            return {
                "query": query,
                "error": str(e),
                "response_time": time.time() - start_time,
                "success": False
            }
    
    def _analyze_query_for_apis(self, query: str) -> List[str]:
        """Analyze query to suggest relevant APIs"""
        
        query_lower = query.lower()
        suggestions = []
        
        # Weather keywords
        weather_keywords = ["weather", "temperature", "forecast", "rain", "snow", "climate"]
        if any(keyword in query_lower for keyword in weather_keywords):
            suggestions.append("weather")
        
        # Financial keywords
        financial_keywords = ["stock", "price", "market", "shares", "investment", "trading"]
        if any(keyword in query_lower for keyword in financial_keywords):
            suggestions.append("financial")
        
        # News keywords
        news_keywords = ["news", "article", "headline", "breaking", "latest", "update"]
        if any(keyword in query_lower for keyword in news_keywords):
            suggestions.append("news")
        
        # Crypto keywords
        crypto_keywords = ["bitcoin", "ethereum", "cryptocurrency", "crypto", "btc", "eth"]
        if any(keyword in query_lower for keyword in crypto_keywords):
            suggestions.append("crypto")
        
        return suggestions
    
    def _update_average_response_time(self, response_time: float):
        """Update average response time"""
        
        total_requests = self.request_stats["total_requests"]
        current_avg = self.request_stats["average_response_time"]
        
        new_avg = ((current_avg * (total_requests - 1)) + response_time) / total_requests
        self.request_stats["average_response_time"] = new_avg
    
    def add_custom_api_service(self, config: APIEndpointConfig):
        """Add custom API service configuration"""
        
        self.api_configs[config.service_name] = config
        logger.info(f"Added custom API service: {config.service_name}")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get comprehensive performance statistics"""
        
        return {
            "request_statistics": self.request_stats,
            "api_services": list(self.api_configs.keys()),
            "available_tools": [tool.name for tool in self.tools],
            "rate_limiter_status": {
                service: len(history) 
                for service, history in self.rate_limiter.request_history.items()
            }
        }

# Demonstration and testing functions
async def comprehensive_api_integration_demonstration():
    """Comprehensive demonstration of API integration capabilities"""
    
    logger.info("=== Comprehensive API Integration Demonstration ===")
    
    # Initialize API-integrated assistant
    logger.info("1. Initializing API-Integrated Assistant")
    assistant = APIIntegratedAssistant()
    
    # Test queries with different API integrations
    logger.info("2. Testing API Integration with Various Queries")
    
    test_queries = [
        {
            "query": "What's the current weather in New York and how does it compare to the 5-day forecast?",
            "expected_apis": ["weather"],
            "description": "Weather API integration test"
        },
        {
            "query": "What's the current price of Apple stock and how has it performed today?",
            "expected_apis": ["financial"],
            "description": "Financial API integration test"
        },
        {
            "query": "Give me the latest news about artificial intelligence and technology trends",
            "expected_apis": ["news"],
            "description": "News API integration test"
        },
        {
            "query": "What's the current price of Bitcoin and Ethereum in USD?",
            "expected_apis": ["crypto"],
            "description": "Cryptocurrency API integration test"
        },
        {
            "query": "I'm planning a trip to London tomorrow. What's the weather forecast and any travel-related news?",
            "expected_apis": ["weather", "news"],
            "description": "Multi-API integration test"
        },
        {
            "query": "Compare the performance of tech stocks with Bitcoin prices today",
            "expected_apis": ["financial", "crypto"],
            "description": "Financial data comparison test"
        }
    ]
    
    query_results = []
    
    for i, test_case in enumerate(test_queries):
        logger.info(f"Processing query {i+1}: {test_case['description']}")
        
        try:
            result = await assistant.process_query_with_apis(
                query=test_case["query"],
                context={"test_case": test_case["description"]}
            )
            
            query_results.append({
                "test_case": test_case,
                "result": result
            })
            
            logger.info(f"Query {i+1} completed: {result['success']}")
            if result['success']:
                logger.info(f"Response time: {result['response_time']:.2f}s")
                logger.info(f"APIs suggested: {result['api_suggestions']}")
            
        except Exception as e:
            logger.error(f"Error processing query {i+1}: {e}")
            query_results.append({
                "test_case": test_case,
                "result": {"error": str(e), "success": False}
            })
        
        # Add delay between requests to respect rate limits
        await asyncio.sleep(2)
    
    # Performance analysis
    logger.info("3. Analyzing API Integration Performance")
    
    performance_stats = assistant.get_performance_stats()
    
    # Create comprehensive analysis report
    analysis_report = {
        "demonstration_timestamp": datetime.now(timezone.utc).isoformat(),
        "system_configuration": {
            "api_services_configured": len(assistant.api_configs),
            "available_tools": len(assistant.tools),
            "security_features": [
                "credential_encryption",
                "rate_limiting",
                "circuit_breaker",
                "request_retry",
                "response_caching"
            ]
        },
        "query_executions": len(query_results),
        "performance_statistics": performance_stats,
        "query_results": query_results,
        "api_utilization_analysis": {},
        "security_analysis": {},
        "insights_and_recommendations": []
    }
    
    # Analyze query performance
    successful_queries = [r for r in query_results if r["result"].get("success", False)]
    
    if successful_queries:
        response_times = [r["result"]["response_time"] for r in successful_queries]
        api_suggestions_count = {}
        
        for result in successful_queries:
            for api in result["result"]["api_suggestions"]:
                api_suggestions_count[api] = api_suggestions_count.get(api, 0) + 1
        
        analysis_report["api_utilization_analysis"] = {
            "success_rate": len(successful_queries) / len(query_results),
            "average_response_time": np.mean(response_times),
            "median_response_time": np.median(response_times),
            "api_usage_frequency": api_suggestions_count,
            "min_response_time": min(response_times),
            "max_response_time": max(response_times)
        }
    
    # Security analysis
    analysis_report["security_analysis"] = {
        "credential_management": "encrypted_storage",
        "rate_limiting_active": True,
        "circuit_breaker_configured": True,
        "authentication_methods": [
            config.authentication.value 
            for config in assistant.api_configs.values()
        ],
        "security_recommendations": [
            "Regular credential rotation",
            "Monitor rate limit usage",
            "Implement request logging",
            "Use HTTPS for all API calls"
        ]
    }
    
    # Generate insights
    insights = [
        f"Successfully processed {len(successful_queries)} out of {len(query_results)} API-integrated queries",
        f"Average response time: {analysis_report['api_utilization_analysis'].get('average_response_time', 0):.2f} seconds",
        f"Most requested API type: {max(api_suggestions_count, key=api_suggestions_count.get) if api_suggestions_count else 'None'}",
        f"Configured {len(assistant.api_configs)} different API services"
    ]
    
    # Add API-specific insights
    if "weather" in api_suggestions_count:
        insights.append(f"Weather API used in {api_suggestions_count['weather']} queries")
    
    if "financial" in api_suggestions_count:
        insights.append(f"Financial API used in {api_suggestions_count['financial']} queries")
    
    insights.extend([
        "All API credentials managed securely with encryption",
        "Rate limiting active to prevent service abuse",
        "Circuit breaker pattern implemented for resilience",
        "Response caching reduces API calls and improves performance"
    ])
    
    analysis_report["insights_and_recommendations"] = insights
    
    # Save results
    with open("api_integration_demonstration_results.json", "w") as f:
        json.dump(analysis_report, f, indent=2, default=str)
    
    # Create visualizations
    try:
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Query response times
        if successful_queries:
            response_times = [r["result"]["response_time"] for r in successful_queries]
            query_labels = [f"Query {i+1}" for i in range(len(response_times))]
            
            axes[0, 0].bar(query_labels, response_times, color='skyblue')
            axes[0, 0].set_title('API Query Response Times')
            axes[0, 0].set_ylabel('Time (seconds)')
            axes[0, 0].tick_params(axis='x', rotation=45)
        
        # API usage distribution
        if api_suggestions_count:
            apis = list(api_suggestions_count.keys())
            usage_counts = list(api_suggestions_count.values())
            
            axes[0, 1].pie(usage_counts, labels=apis, autopct='%1.1f%%')
            axes[0, 1].set_title('API Usage Distribution')
        
        # Success rate analysis
        success_data = [
            len(successful_queries),
            len(query_results) - len(successful_queries)
        ]
        labels = ['Successful', 'Failed']
        
        axes[1, 0].pie(success_data, labels=labels, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])
        axes[1, 0].set_title('Query Success Rate')
        
        # Response time distribution
        if successful_queries:
            response_times = [r["result"]["response_time"] for r in successful_queries]
            
            axes[1, 1].hist(response_times, bins=max(1, len(response_times)//2), color='purple', alpha=0.7)
            axes[1, 1].set_title('Response Time Distribution')
            axes[1, 1].set_xlabel('Response Time (seconds)')
            axes[1, 1].set_ylabel('Frequency')
        
        plt.tight_layout()
        plt.savefig('api_integration_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    except Exception as e:
        logger.warning(f"Error creating visualizations: {e}")
    
    logger.info("API Integration demonstration completed!")
    logger.info("Check 'api_integration_demonstration_results.json' for detailed results")
    
    return analysis_report

# Main execution
if __name__ == "__main__":
    asyncio.run(comprehensive_api_integration_demonstration())
````

## Conclusion

This comprehensive advanced API integration framework establishes a robust foundation for building AI assistants that can access and leverage real-time data from external services, transforming static chatbots into dynamic, information-rich systems capable of providing current, accurate, and contextually relevant responses across diverse domains.

**Enterprise-Grade Security Architecture** through encrypted credential management, secure authentication protocols, and comprehensive input validation ensures that sensitive API keys and user data remain protected while maintaining seamless integration capabilities, addressing critical security concerns in production deployments.

**Sophisticated Resilience and Performance Management** with circuit breaker patterns, retry mechanisms, rate limiting, and response caching creates fault-tolerant systems that gracefully handle service failures, respect API quotas, and optimize performance through intelligent request management and data caching strategies.

**Multi-Service Integration Capabilities** supporting diverse API types including weather, financial markets, news feeds, and cryptocurrency data demonstrates the framework's versatility in connecting AI assistants to virtually any RESTful service, enabling rich, multi-domain knowledge synthesis for comprehensive user assistance.

**Advanced Error Handling and Monitoring** with structured logging, performance metrics, and comprehensive analytics provides essential visibility into system behavior, enabling proactive maintenance, optimization opportunities, and reliable service level monitoring for production environments.

**Scalable Architecture Patterns** through asynchronous processing, connection pooling, and modular service configuration enable high-throughput API integration while maintaining responsive user interactions, supporting enterprise-scale deployments with multiple concurrent users and diverse service requirements.

**Intelligent Query Analysis and Tool Selection** automatically determines relevant APIs based on user intent, optimizing response generation by accessing only necessary external services while minimizing latency and API consumption costs through strategic tool utilization.

This framework empowers developers to create sophisticated AI assistants that bridge the gap between large language model capabilities and real-world data access, enabling applications that provide accurate, timely, and comprehensive responses by seamlessly integrating with the vast ecosystem of available web services and APIs.