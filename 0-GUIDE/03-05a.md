<small>Claude 3.7 Sonnet Thinking</small>
# 05. Advanced API Integration for Dynamic Responses

## Key Terms

- **API (Application Programming Interface)**: A set of rules that allows different software applications to communicate with each other
- **REST API**: An architectural style for APIs that uses HTTP requests to access and manipulate data
- **API Key**: A unique identifier used to authenticate requests to an API
- **Rate Limiting**: Restrictions on the number of API requests allowed within a time period
- **Webhook**: HTTP callbacks that deliver data to applications when triggered by events
- **JSON (JavaScript Object Notation)**: A lightweight data interchange format commonly used in API responses
- **Middleware**: Software that acts as a bridge between an operating system/database and applications
- **Tool Functions**: Functions exposed to LLMs that can call external services and process their responses
- **API Proxy**: An intermediary server that forwards API requests to protect credentials and manage access

## Connecting Assistants to External APIs

Integrating external APIs with AI assistants expands their capabilities beyond static knowledge, enabling them to access real-time information, perform transactions, and interact with external systems. Modern AI applications commonly leverage APIs to enhance their functionality and provide up-to-date responses.

Let's start by creating a flexible framework for integrating various APIs with an LLM-based assistant:

```python
import os
import json
import time
import requests
from typing import Dict, List, Any, Optional, Union, Callable
from enum import Enum
from functools import wraps
from dotenv import load_dotenv
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("APIManager")

# Load environment variables
load_dotenv()

class APIError(Exception):
    """Custom exception for API-related errors."""
    def __init__(self, message: str, status_code: Optional[int] = None, response_body: Optional[str] = None):
        self.message = message
        self.status_code = status_code
        self.response_body = response_body
        super().__init__(self.message)

class RateLimitStrategy(Enum):
    """Rate limit handling strategies."""
    FAIL = "fail"              # Immediately fail when rate limited
    WAIT = "wait"              # Wait and retry when rate limited
    FALLBACK = "fallback"      # Use fallback data when rate limited

def rate_limit_handler(max_retries: int = 3, retry_delay: int = 2, strategy: RateLimitStrategy = RateLimitStrategy.WAIT):
    """Decorator to handle rate limiting for API calls."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            while retries <= max_retries:
                try:
                    return func(*args, **kwargs)
                except APIError as e:
                    # Check if it's a rate limit error (typically 429)
                    if e.status_code == 429:
                        retries += 1
                        if strategy == RateLimitStrategy.FAIL or retries > max_retries:
                            raise
                        elif strategy == RateLimitStrategy.WAIT:
                            wait_time = retry_delay * retries
                            logger.warning(f"Rate limited. Waiting {wait_time}s before retry {retries}/{max_retries}")
                            time.sleep(wait_time)
                        elif strategy == RateLimitStrategy.FALLBACK:
                            # If fallback function is provided, use it
                            fallback = kwargs.get('fallback')
                            if callable(fallback):
                                return fallback(*args)
                            else:
                                raise
                    else:
                        # Not a rate limit error, propagate
                        raise
            raise APIError(f"Maximum retries ({max_retries}) exceeded for API call")
        return wrapper
    return decorator

class BaseAPIConnector:
    """Base class for API connectors."""
    
    def __init__(self, api_key: Optional[str] = None, base_url: str = "", timeout: int = 10):
        self.api_key = api_key
        self.base_url = base_url
        self.timeout = timeout
        self.session = requests.Session()
    
    def _get_headers(self) -> Dict[str, str]:
        """Get the headers for API requests."""
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}" if self.api_key else ""
        }
    
    def _handle_response(self, response: requests.Response) -> Dict[str, Any]:
        """Handle API response and extract data."""
        try:
            response.raise_for_status()
            return response.json()
        except requests.exceptions.HTTPError as e:
            raise APIError(
                message=f"HTTP error: {str(e)}",
                status_code=response.status_code,
                response_body=response.text
            )
        except json.JSONDecodeError:
            raise APIError(
                message="Invalid JSON response",
                status_code=response.status_code,
                response_body=response.text
            )
        except requests.exceptions.RequestException as e:
            raise APIError(f"Request error: {str(e)}")
    
    @rate_limit_handler(max_retries=3, retry_delay=2)
    def get(self, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Make a GET request to the API."""
        url = f"{self.base_url}{endpoint}"
        try:
            response = self.session.get(
                url,
                headers=self._get_headers(),
                params=params,
                timeout=self.timeout
            )
            return self._handle_response(response)
        except Exception as e:
            raise APIError(f"GET request failed: {str(e)}")
    
    @rate_limit_handler(max_retries=2, retry_delay=1)
    def post(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Make a POST request to the API."""
        url = f"{self.base_url}{endpoint}"
        try:
            response = self.session.post(
                url,
                headers=self._get_headers(),
                json=data,
                timeout=self.timeout
            )
            return self._handle_response(response)
        except Exception as e:
            raise APIError(f"POST request failed: {str(e)}")

class APIManager:
    """Manager for handling multiple API connections."""
    
    def __init__(self):
        self.connectors = {}
    
    def register_connector(self, name: str, connector: BaseAPIConnector) -> None:
        """Register an API connector."""
        self.connectors[name] = connector
    
    def get_connector(self, name: str) -> BaseAPIConnector:
        """Get an API connector by name."""
        connector = self.connectors.get(name)
        if not connector:
            raise ValueError(f"API connector '{name}' not registered")
        return connector
```

Now, let's implement specific API connectors for common use cases:

```python
from api_integration.api_manager import BaseAPIConnector, APIError, RateLimitStrategy
import os
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
import requests
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class WeatherAPIConnector(BaseAPIConnector):
    """Connector for weather API (OpenWeatherMap)."""
    
    def __init__(self, api_key: Optional[str] = None):
        # Use provided API key or get from environment
        api_key = api_key or os.getenv("OPENWEATHERMAP_API_KEY")
        base_url = "https://api.openweathermap.org/data/2.5"
        super().__init__(api_key=api_key, base_url=base_url)
    
    def get_current_weather(self, city: str, units: str = "metric") -> Dict[str, Any]:
        """Get current weather for a city."""
        params = {
            "q": city,
            "appid": self.api_key,
            "units": units
        }
        try:
            return self.get("/weather", params=params)
        except APIError as e:
            # Handle specific API errors
            if e.status_code == 404:
                raise APIError(f"City '{city}' not found")
            raise
    
    def get_forecast(self, city: str, days: int = 5, units: str = "metric") -> Dict[str, Any]:
        """Get weather forecast for a city."""
        params = {
            "q": city,
            "appid": self.api_key,
            "units": units,
            "cnt": min(days * 8, 40)  # OpenWeatherMap limit (5 days, 3-hour intervals)
        }
        return self.get("/forecast", params=params)
    
    def format_weather_response(self, weather_data: Dict[str, Any]) -> Dict[str, Any]:
        """Format raw weather data into a user-friendly structure."""
        try:
            main = weather_data.get("main", {})
            weather = weather_data.get("weather", [{}])[0]
            wind = weather_data.get("wind", {})
            
            return {
                "city": weather_data.get("name", "Unknown"),
                "country": weather_data.get("sys", {}).get("country", "Unknown"),
                "description": weather.get("description", "No description available"),
                "temperature": {
                    "current": main.get("temp", "N/A"),
                    "feels_like": main.get("feels_like", "N/A"),
                    "min": main.get("temp_min", "N/A"),
                    "max": main.get("temp_max", "N/A"),
                },
                "humidity": main.get("humidity", "N/A"),
                "pressure": main.get("pressure", "N/A"),
                "wind": {
                    "speed": wind.get("speed", "N/A"),
                    "direction": wind.get("deg", "N/A")
                },
                "clouds": weather_data.get("clouds", {}).get("all", "N/A"),
                "datetime": datetime.fromtimestamp(weather_data.get("dt", 0)).strftime("%Y-%m-%d %H:%M:%S"),
                "sunrise": datetime.fromtimestamp(weather_data.get("sys", {}).get("sunrise", 0)).strftime("%H:%M:%S"),
                "sunset": datetime.fromtimestamp(weather_data.get("sys", {}).get("sunset", 0)).strftime("%H:%M:%S")
            }
        except Exception as e:
            raise APIError(f"Error formatting weather data: {str(e)}")

class NewsAPIConnector(BaseAPIConnector):
    """Connector for news API (NewsAPI.org)."""
    
    def __init__(self, api_key: Optional[str] = None):
        api_key = api_key or os.getenv("NEWSAPI_KEY")
        base_url = "https://newsapi.org/v2"
        super().__init__(api_key=api_key, base_url=base_url)
    
    def get_top_headlines(self, country: str = "us", category: Optional[str] = None, 
                         page_size: int = 5, page: int = 1) -> Dict[str, Any]:
        """Get top news headlines."""
        params = {
            "country": country,
            "pageSize": page_size,
            "page": page,
        }
        
        if category:
            params["category"] = category
            
        response = self.get("/top-headlines", params=params)
        return response
    
    def search_news(self, query: str, from_date: Optional[str] = None, 
                  to_date: Optional[str] = None, language: str = "en",
                  sort_by: str = "publishedAt", page_size: int = 5, 
                  page: int = 1) -> Dict[str, Any]:
        """Search news articles."""
        params = {
            "q": query,
            "language": language,
            "sortBy": sort_by,
            "pageSize": page_size,
            "page": page
        }
        
        if from_date:
            params["from"] = from_date
        
        if to_date:
            params["to"] = to_date
        
        response = self.get("/everything", params=params)
        return response
    
    def format_news_response(self, news_data: Dict[str, Any], max_articles: int = 5) -> List[Dict[str, Any]]:
        """Format raw news data into a user-friendly structure."""
        try:
            articles = news_data.get("articles", [])[:max_articles]
            formatted_articles = []
            
            for article in articles:
                formatted_articles.append({
                    "title": article.get("title", "No title"),
                    "source": article.get("source", {}).get("name", "Unknown source"),
                    "author": article.get("author", "Unknown author"),
                    "description": article.get("description", "No description available"),
                    "url": article.get("url", ""),
                    "published_at": article.get("publishedAt", "Unknown date"),
                    "content": article.get("content", "No content available")
                })
            
            return formatted_articles
        except Exception as e:
            raise APIError(f"Error formatting news data: {str(e)}")

class CurrencyExchangeConnector(BaseAPIConnector):
    """Connector for currency exchange API (ExchangeRate-API)."""
    
    def __init__(self, api_key: Optional[str] = None):
        api_key = api_key or os.getenv("EXCHANGERATE_API_KEY")
        base_url = "https://v6.exchangerate-api.com/v6"
        super().__init__(api_key=api_key, base_url=base_url)
    
    def get_latest_rates(self, base_currency: str = "USD") -> Dict[str, Any]:
        """Get latest exchange rates."""
        endpoint = f"/{self.api_key}/latest/{base_currency}"
        return self.get(endpoint)
    
    def convert_currency(self, from_currency: str, to_currency: str, amount: float) -> Dict[str, Any]:
        """Convert an amount from one currency to another."""
        endpoint = f"/{self.api_key}/pair/{from_currency}/{to_currency}/{amount}"
        return self.get(endpoint)
    
    def format_exchange_response(self, from_currency: str, to_currency: str, 
                               amount: float, exchange_data: Dict[str, Any]) -> Dict[str, Any]:
        """Format raw exchange data into a user-friendly structure."""
        try:
            conversion_rate = exchange_data.get("conversion_rate", 0)
            converted_amount = exchange_data.get("conversion_result", 0)
            
            return {
                "from_currency": from_currency,
                "to_currency": to_currency,
                "amount": amount,
                "exchange_rate": conversion_rate,
                "converted_amount": converted_amount,
                "last_updated": exchange_data.get("time_last_update_utc", "Unknown")
            }
        except Exception as e:
            raise APIError(f"Error formatting exchange data: {str(e)}")
```

## Generating Responses from Current Data

To effectively integrate these APIs with an LLM-based assistant, we need to create tool functions that the LLM can use to fetch and incorporate real-time data into its responses:

```python
from typing import Dict, List, Any, Optional, Union, Callable, TypedDict
import json
from api_integration.api_manager import APIManager, APIError
from api_integration.api_connectors import WeatherAPIConnector, NewsAPIConnector, CurrencyExchangeConnector
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("AssistantTools")

class WeatherParams(TypedDict):
    city: str
    units: Optional[str]

class NewsSearchParams(TypedDict):
    query: str
    language: Optional[str]
    max_results: Optional[int]

class HeadlinesParams(TypedDict):
    country: Optional[str]
    category: Optional[str]
    max_results: Optional[int]

class CurrencyConversionParams(TypedDict):
    from_currency: str
    to_currency: str
    amount: float

class AssistantTools:
    """Tools for AI assistant to interact with external APIs."""
    
    def __init__(self):
        # Initialize API manager
        self.api_manager = APIManager()
        
        # Register API connectors
        self.api_manager.register_connector("weather", WeatherAPIConnector())
        self.api_manager.register_connector("news", NewsAPIConnector())
        self.api_manager.register_connector("currency", CurrencyExchangeConnector())
        
        # Register tool functions
        self.tools = {
            "get_weather": {
                "description": "Get current weather for a specific city",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {"type": "string", "description": "The name of the city"},
                        "units": {"type": "string", "enum": ["metric", "imperial"], "default": "metric"}
                    },
                    "required": ["city"]
                },
                "function": self.get_weather
            },
            "search_news": {
                "description": "Search for news articles by keyword",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "Search keywords or phrases"},
                        "language": {"type": "string", "default": "en"},
                        "max_results": {"type": "integer", "default": 3}
                    },
                    "required": ["query"]
                },
                "function": self.search_news
            },
            "get_top_headlines": {
                "description": "Get top news headlines by country and category",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "country": {"type": "string", "default": "us"},
                        "category": {"type": "string", "enum": ["business", "entertainment", "general", "health", "science", "sports", "technology"]},
                        "max_results": {"type": "integer", "default": 3}
                    }
                },
                "function": self.get_top_headlines
            },
            "convert_currency": {
                "description": "Convert an amount from one currency to another",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "from_currency": {"type": "string", "description": "Source currency code (e.g., USD)"},
                        "to_currency": {"type": "string", "description": "Target currency code (e.g., EUR)"},
                        "amount": {"type": "number", "description": "Amount to convert"}
                    },
                    "required": ["from_currency", "to_currency", "amount"]
                },
                "function": self.convert_currency
            }
        }
    
    def get_tool_definitions(self) -> List[Dict[str, Any]]:
        """Get the OpenAI-compatible tool definitions for the assistant."""
        tool_definitions = []
        
        for tool_name, tool_info in self.tools.items():
            tool_definitions.append({
                "type": "function",
                "function": {
                    "name": tool_name,
                    "description": tool_info["description"],
                    "parameters": tool_info["parameters"]
                }
            })
        
        return tool_definitions
    
    def execute_tool(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """Execute a tool function with the provided arguments."""
        if tool_name not in self.tools:
            return json.dumps({"error": f"Tool '{tool_name}' not found"})
        
        try:
            result = self.tools[tool_name]["function"](**tool_args)
            return json.dumps(result)
        except Exception as e:
            logger.error(f"Error executing tool {tool_name}: {str(e)}")
            return json.dumps({"error": str(e)})
    
    def get_weather(self, city: str, units: str = "metric") -> Dict[str, Any]:
        """Get current weather for a city."""
        try:
            connector = self.api_manager.get_connector("weather")
            weather_data = connector.get_current_weather(city, units)
            return connector.format_weather_response(weather_data)
        except APIError as e:
            return {"error": str(e)}
    
    def search_news(self, query: str, language: str = "en", max_results: int = 3) -> Dict[str, Any]:
        """Search for news articles."""
        try:
            connector = self.api_manager.get_connector("news")
            news_data = connector.search_news(query, language=language, page_size=max_results)
            articles = connector.format_news_response(news_data, max_articles=max_results)
            return {"query": query, "articles": articles, "total_results": news_data.get("totalResults", 0)}
        except APIError as e:
            return {"error": str(e)}
    
    def get_top_headlines(self, country: str = "us", category: Optional[str] = None, max_results: int = 3) -> Dict[str, Any]:
        """Get top news headlines."""
        try:
            connector = self.api_manager.get_connector("news")
            news_data = connector.get_top_headlines(country, category, page_size=max_results)
            articles = connector.format_news_response(news_data, max_articles=max_results)
            return {"country": country, "category": category or "all", "articles": articles}
        except APIError as e:
            return {"error": str(e)}
    
    def convert_currency(self, from_currency: str, to_currency: str, amount: float) -> Dict[str, Any]:
        """Convert currency."""
        try:
            connector = self.api_manager.get_connector("currency")
            exchange_data = connector.convert_currency(from_currency, to_currency, amount)
            return connector.format_exchange_response(from_currency, to_currency, amount, exchange_data)
        except APIError as e:
            return {"error": str(e)}
```

Now, let's integrate these tools with an LLM-based assistant:

```python
import os
import json
import time
from typing import Dict, List, Any, Optional, Union, Literal
from dotenv import load_dotenv
from openai import OpenAI
from api_integration.assistant_tools import AssistantTools
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("DynamicAssistant")

# Load environment variables
load_dotenv()

class DynamicAssistant:
    """An AI assistant that can access real-time data through APIs."""
    
    def __init__(self, model: str = "gpt-4o"):
        # Initialize OpenAI client
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model
        
        # Initialize assistant tools
        self.tools_manager = AssistantTools()
        self.tools = self.tools_manager.get_tool_definitions()
        
        # Session context
        self.messages = []
        
        # System prompt with capabilities description
        self.system_prompt = """
        You are a helpful assistant with access to real-time information through APIs.
        You can:
        - Check current weather conditions for any city
        - Search for news articles on specific topics
        - Get top news headlines by country and category
        - Convert between different currencies
        
        When information might be outdated or unavailable in your knowledge, use these tools to provide accurate and current data.
        Always cite the source and time when presenting API data.
        Format your responses in a clear, readable manner.
        """
    
    def reset_conversation(self) -> None:
        """Reset the conversation history."""
        self.messages = []
    
    def _prepare_messages(self, new_message: str) -> List[Dict[str, Any]]:
        """Prepare the messages for the API call."""
        if not self.messages:
            # Start with system message if it's a new conversation
            messages = [
                {"role": "system", "content": self.system_prompt}
            ]
        else:
            messages = self.messages.copy()
        
        # Add the new user message
        messages.append({"role": "user", "content": new_message})
        
        return messages
    
    def _process_tool_calls(self, tool_calls: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process tool calls and get their results."""
        tool_results = []
        
        for tool_call in tool_calls:
            function_name = tool_call["function"]["name"]
            function_args = json.loads(tool_call["function"]["arguments"])
            
            # Execute the tool and get the result
            result = self.tools_manager.execute_tool(function_name, function_args)
            
            # Format the tool result message
            tool_results.append({
                "tool_call_id": tool_call["id"],
                "role": "tool",
                "name": function_name,
                "content": result
            })
        
        return tool_results
    
    def ask(self, message: str, stream: bool = False) -> Dict[str, Any]:
        """Send a message to the assistant and get the response."""
        try:
            messages = self._prepare_messages(message)
            
            # Create the API request
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tools,
                tool_choice="auto",
                stream=stream
            )
            
            if stream:
                # Handle streaming response
                collected_chunks = []
                collected_messages = []
                tool_calls_builder = {}
                
                for chunk in response:
                    collected_chunks.append(chunk)
                    
                    # Extract content from the chunk
                    choice = chunk.choices[0] if chunk.choices else None
                    if not choice:
                        continue
                    
                    delta = choice.delta
                    
                    # Process regular content
                    if delta.content:
                        collected_messages.append(delta.content)
                    
                    # Process tool calls
                    if delta.tool_calls:
                        for tool_call in delta.tool_calls:
                            tool_id = tool_call.index
                            
                            # Initialize the tool call if it's new
                            if tool_id not in tool_calls_builder:
                                tool_calls_builder[tool_id] = {
                                    "id": tool_call.id or "",
                                    "function": {
                                        "name": "",
                                        "arguments": ""
                                    }
                                }
                            
                            # Update function name
                            if tool_call.function and tool_call.function.name:
                                tool_calls_builder[tool_id]["function"]["name"] = tool_call.function.name
                            
                            # Update function arguments
                            if tool_call.function and tool_call.function.arguments:
                                tool_calls_builder[tool_id]["function"]["arguments"] += tool_call.function.arguments
                
                # Combine the collected message content
                content = "".join(collected_messages)
                
                # Convert tool calls builder to list
                tool_calls = list(tool_calls_builder.values())
                
                # Add assistant's message to conversation history
                self.messages = messages + [{"role": "assistant", "content": content}]
                
                # Process tool calls if any
                if tool_calls:
                    tool_results = self._process_tool_calls(tool_calls)
                    
                    # Add tool results to messages
                    self.messages.extend(tool_results)
                    
                    # Get a follow-up response after tool calls
                    follow_up_response = self.client.chat.completions.create(
                        model=self.model,
                        messages=self.messages,
                        tools=self.tools,
                        tool_choice="auto"
                    )
                    
                    # Add follow-up response to messages
                    follow_up_message = follow_up_response.choices[0].message
                    self.messages.append({
                        "role": "assistant",
                        "content": follow_up_message.content or ""
                    })
                    
                    return {
                        "response": follow_up_message.content,
                        "has_tool_calls": True,
                        "tool_results": tool_results
                    }
                
                return {
                    "response": content,
                    "has_tool_calls": False,
                    "tool_results": []
                }
            else:
                # Handle regular response
                response_message = response.choices[0].message
                
                # Add assistant's message to conversation history
                self.messages = messages + [{"role": "assistant", "content": response_message.content or ""}]
                
                # Check if the model wants to use tools
                if response_message.tool_calls:
                    # Process tool calls
                    tool_results = self._process_tool_calls(response_message.tool_calls)
                    
                    # Add tool results to messages
                    self.messages.extend(tool_results)
                    
                    # Get a follow-up response after tool calls
                    follow_up_response = self.client.chat.completions.create(
                        model=self.model,
                        messages=self.messages,
                        tools=self.tools,
                        tool_choice="auto"
                    )
                    
                    # Add follow-up response to messages
                    follow_up_message = follow_up_response.choices[0].message
                    self.messages.append({
                        "role": "assistant", 
                        "content": follow_up_message.content or ""
                    })
                    
                    return {
                        "response": follow_up_message.content,
                        "has_tool_calls": True,
                        "tool_results": tool_results
                    }
                
                return {
                    "response": response_message.content,
                    "has_tool_calls": False,
                    "tool_results": []
                }
                
        except Exception as e:
            logger.error(f"Error in ask method: {str(e)}")
            return {"error": str(e), "response": "I'm having trouble accessing external data at the moment."}
```

## API Key Protection and Data Security

Securing API keys and sensitive data is a critical aspect of building robust AI assistants. Let's implement a secure key management system:

```python
import os
import json
import base64
from typing import Dict, Any, Optional
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from dotenv import load_dotenv
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("APIKeySecurity")

class APIKeySecurity:
    """Security utilities for API key management."""
    
    def __init__(self, encryption_key: Optional[str] = None):
        """
        Initialize security utilities.
        
        Args:
            encryption_key: Master encryption key (from .env if not provided)
        """
        load_dotenv()
        self.encryption_key = encryption_key or os.getenv("ENCRYPTION_KEY")
        
        if not self.encryption_key:
            # Generate a new key if not provided
            self.encryption_key = base64.urlsafe_b64encode(os.urandom(32)).decode()
            logger.warning("No encryption key found. Generated a new key. Save this to your .env file.")
            logger.warning(f"ENCRYPTION_KEY={self.encryption_key}")
        
        # Initialize Fernet cipher
        self._initialize_cipher()
    
    def _initialize_cipher(self) -> None:
        """Initialize the encryption cipher."""
        try:
            # Convert the key to the proper format
            key_bytes = self.encryption_key.encode()
            
            # If it's not already in the right format, derive a key
            if len(key_bytes) != 32 or not all(b in b'-_ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789' for b in key_bytes):
                salt = b'staticapisecurity'  # Use a static salt for reproducibility
                kdf = PBKDF2HMAC(
                    algorithm=hashes.SHA256(),
                    length=32,
                    salt=salt,
                    iterations=100000,
                )
                key = base64.urlsafe_b64encode(kdf.derive(key_bytes))
            else:
                # Ensure the key is base64 encoded
                key = base64.urlsafe_b64encode(key_bytes[:32])
            
            self.cipher = Fernet(key)
            
        except Exception as e:
            logger.error(f"Error initializing cipher: {str(e)}")
            raise ValueError("Could not initialize encryption cipher")
    
    def encrypt_api_key(self, api_key: str) -> str:
        """
        Encrypt an API key.
        
        Args:
            api_key: The API key to encrypt
            
        Returns:
            Encrypted API key as a base64 string
        """
        try:
            encrypted_key = self.cipher.encrypt(api_key.encode())
            return base64.urlsafe_b64encode(encrypted_key).decode()
        except Exception as e:
            logger.error(f"Error encrypting API key: {str(e)}")
            raise ValueError("Could not encrypt API key")
    
    def decrypt_api_key(self, encrypted_key: str) -> str:
        """
        Decrypt an encrypted API key.
        
        Args:
            encrypted_key: The encrypted API key as a base64 string
            
        Returns:
            Original API key
        """
        try:
            encrypted_bytes = base64.urlsafe_b64decode(encrypted_key)
            decrypted_key = self.cipher.decrypt(encrypted_bytes)
            return decrypted_key.decode()
        except Exception as e:
            logger.error(f"Error decrypting API key: {str(e)}")
            raise ValueError("Could not decrypt API key")
    
    def store_api_keys(self, keys: Dict[str, str], filepath: str = "api_keys.enc") -> None:
        """
        Encrypt and store multiple API keys to a file.
        
        Args:
            keys: Dictionary of API keys (service_name: api_key)
            filepath: Path to the encrypted file
        """
        try:
            # Encrypt each key
            encrypted_keys = {}
            for service, key in keys.items():
                encrypted_keys[service] = self.encrypt_api_key(key)
            
            # Write to file
            with open(filepath, 'w') as f:
                json.dump(encrypted_keys, f)
                
            logger.info(f"API keys stored to {filepath}")
            
        except Exception as e:
            logger.error(f"Error storing API keys: {str(e)}")
            raise ValueError("Could not store API keys")
    
    def load_api_keys(self, filepath: str = "api_keys.enc") -> Dict[str, str]:
        """
        Load and decrypt API keys from a file.
        
        Args:
            filepath: Path to the encrypted file
            
        Returns:
            Dictionary of decrypted API keys
        """
        try:
            # Read from file
            with open(filepath, 'r') as f:
                encrypted_keys = json.load(f)
            
            # Decrypt each key
            decrypted_keys = {}
            for service, encrypted_key in encrypted_keys.items():
                decrypted_keys[service] = self.decrypt_api_key(encrypted_key)
            
            return decrypted_keys
            
        except Exception as e:
            logger.error(f"Error loading API keys: {str(e)}")
            raise ValueError("Could not load API keys")

def initialize_api_keys():
    """Utility function to initialize API keys from .env file."""
    load_dotenv()
    
    # Get API keys from environment
    api_keys = {
        "openai": os.getenv("OPENAI_API_KEY", ""),
        "openweathermap": os.getenv("OPENWEATHERMAP_API_KEY", ""),
        "newsapi": os.getenv("NEWSAPI_KEY", ""),
        "exchangerate": os.getenv("EXCHANGERATE_API_KEY", "")
    }
    
    # Filter out empty keys
    api_keys = {k: v for k, v in api_keys.items() if v}
    
    if not api_keys:
        logger.warning("No API keys found in .env file")
        return
    
    # Initialize security and store keys
    security = APIKeySecurity()
    security.store_api_keys(api_keys)
    logger.info(f"Stored {len(api_keys)} API keys")

# Example usage
if __name__ == "__main__":
    initialize_api_keys()
```

## Practical Exercise: Integrating Weather, Currency, and News APIs 

Let's put everything together in a simple web application using Streamlit:

```python
import os
import streamlit as st
from typing import Dict, Any
from dotenv import load_dotenv
from api_integration.dynamic_assistant import DynamicAssistant
import json
import time

# Load environment variables
load_dotenv()

# Initialize the assistant
@st.cache_resource
def get_assistant():
    return DynamicAssistant(model="gpt-4o")

# Set page config
st.set_page_config(
    page_title="Dynamic AI Assistant",
    page_icon="🌐",
    layout="wide"
)

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "assistant" not in st.session_state:
    st.session_state.assistant = get_assistant()

if "tool_calls" not in st.session_state:
    st.session_state.tool_calls = []

# Header
st.title("🌐 Dynamic AI Assistant with Real-Time Data")
st.subheader("Ask questions that require current information")

# Sidebar with info about capabilities
with st.sidebar:
    st.header("Assistant Capabilities")
    st.markdown("""
    This assistant can access real-time data through these APIs:
    
    - **Weather**: Get current conditions for any city
    - **News**: Search for articles or get top headlines
    - **Currency**: Convert between currencies
    
    Example questions:
    - What's the weather like in Tokyo right now?
    - Show me the latest news about artificial intelligence
    - Convert 100 USD to EUR
    - What are the top headlines in technology today?
    """)
    
    st.divider()
    
    # API key status
    st.subheader("API Status")
    
    api_keys = {
        "OpenAI": os.getenv("OPENAI_API_KEY", ""),
        "OpenWeatherMap": os.getenv("OPENWEATHERMAP_API_KEY", ""),
        "NewsAPI": os.getenv("NEWSAPI_KEY", ""),
        "ExchangeRate-API": os.getenv("EXCHANGERATE_API_KEY", "")
    }
    
    for api, key in api_keys.items():
        if key:
            st.success(f"✅ {api}: Connected")
        else:
            st.error(f"❌ {api}: Missing API key")
    
    # Reset conversation button
    if st.button("Reset Conversation"):
        st.session_state.messages = []
        st.session_state.assistant.reset_conversation()
        st.session_state.tool_calls = []
        st.rerun()

# Display the conversation
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Tool calls display area
if st.session_state.tool_calls:
    with st.expander("API Data Used", expanded=False):
        for tool_call in st.session_state.tool_calls:
            st.subheader(f"🔍 {tool_call['name']}")
            try:
                data = json.loads(tool_call["content"])
                st.json(data)
            except:
                st.write(tool_call["content"])

# Chat input
if prompt := st.chat_input("Ask a question that requires current data..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.write(prompt)
    
    # Get response from assistant
    with st.spinner("Thinking and gathering information..."):
        response = st.session_state.assistant.ask(prompt)
    
    # Handle errors
    if "error" in response:
        with st.chat_message("assistant"):
            st.error(response["error"])
            st.write(response["response"])
        st.session_state.messages.append({"role": "assistant", "content": response["response"]})
    else:
        # Display assistant response
        with st.chat_message("assistant"):
            st.write(response["response"])
        
        # Add to messages history
        st.session_state.messages.append({"role": "assistant", "content": response["response"]})
        
        # Update tool calls display
        if response["has_tool_calls"]:
            st.session_state.tool_calls = response["tool_results"]
            st.rerun()  # Refresh to show tool calls in the expander
```

To use the application:

1. Create a `.env` file with your API keys:
```
OPENAI_API_KEY=your_openai_api_key
OPENWEATHERMAP_API_KEY=your_openweathermap_api_key
NEWSAPI_KEY=your_newsapi_key
EXCHANGERATE_API_KEY=your_exchangerate_api_key
ENCRYPTION_KEY=optional_custom_encryption_key
```

2. Install the required dependencies:
```
pip install openai python-dotenv requests streamlit cryptography
```

3. Run the Streamlit application:
```
streamlit run api_integration/app.py
```

## Conclusion

Integrating external APIs with AI assistants transforms them from static knowledge sources to dynamic, real-time information systems. This capability is essential for applications that require current data, such as weather updates, financial information, news, and more.

The architecture we've developed demonstrates several key principles:

1. **Modular API Connectors**: Creating reusable connectors that handle authentication, rate limiting, and data formatting simplifies integration and maintenance.

2. **Function Calling Integration**: Modern LLMs can determine when to call external functions and properly incorporate the results into their responses, creating a seamless experience.

3. **Security Best Practices**: Implementing encryption for API keys, using environment variables, and managing access control are essential for protecting sensitive credentials.

4. **Error Handling and Resilience**: Robust error handling ensures the assistant can gracefully respond even when APIs fail or rate limits are reached.

5. **User Experience**: Presenting API-sourced information with clear attribution and formatting enhances trust and readability.

This approach allows AI assistants to overcome the limitations of their training data cutoff and provide genuinely useful, current information. By combining LLM capabilities with real-time data sources, we create more powerful and practical AI applications that can solve real business problems and deliver ongoing value.

For future development, consider expanding the system with:
- Caching mechanisms to reduce API calls
- More sophisticated retry and fallback strategies
- Additional API integrations for specialized domains
- Proactive data fetching for common queries
- Fine-tuning models to better utilize tools based on specific application needs

With these techniques, you can build AI assistants that leverage the best of both worlds: the reasoning and language capabilities of LLMs combined with the accuracy and timeliness of external data sources.