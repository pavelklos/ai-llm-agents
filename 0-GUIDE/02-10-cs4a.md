<small>Claude Sonnet 4</small>
# 10. Autogen (Advanced AI Agent Framework)

## Key Terms

**Autogen Framework**: Microsoft's advanced multi-agent conversational AI framework that enables the creation, orchestration, and management of multiple AI agents working collaboratively to solve complex problems through structured conversations, role-based interactions, and automated workflows.

**Agent Orchestration**: The systematic coordination and management of multiple AI agents within Autogen, including conversation flow control, message routing, agent selection, and collaborative problem-solving patterns that enable emergent behaviors and complex task completion.

**AutogenStudio**: A visual, low-code interface for designing, managing, and monitoring multi-agent workflows in Autogen, providing drag-and-drop functionality for agent creation, conversation design, and workflow orchestration without extensive programming knowledge.

**Conversational Patterns**: Structured communication protocols between agents including human-in-the-loop interactions, sequential conversations, group chats, nested conversations, and hierarchical agent structures that enable sophisticated multi-agent collaboration.

**GroupChat Manager**: A specialized agent type in Autogen that facilitates multi-agent conversations by managing speaker selection, conversation flow, termination conditions, and ensuring productive collaboration between multiple agents with different roles and capabilities.

**Agent Roles and Personas**: Predefined or custom-defined behavioral patterns, expertise domains, and interaction styles that define how agents communicate, what tasks they perform, and how they contribute to collaborative problem-solving scenarios.

**Code Execution Environment**: Secure, sandboxed environments within Autogen that allow agents to execute code, run scripts, perform computations, and interact with external systems while maintaining security and isolation from the host system.

**Human Proxy Agent**: A special agent type that represents human users in multi-agent conversations, enabling human-in-the-loop interactions, manual approval workflows, and hybrid human-AI collaboration patterns.

**External Tool Integration**: The capability to connect Autogen agents with external APIs, services, databases, and tools, enabling agents to perform real-world actions, access external data sources, and integrate with existing enterprise systems.

## Comprehensive Autogen Multi-Agent Framework

Autogen represents the pinnacle of multi-agent AI systems, providing sophisticated conversational AI patterns that enable multiple agents to collaborate naturally through structured conversations. This implementation demonstrates advanced orchestration patterns and real-world integration capabilities.

### Advanced Autogen Implementation

````python
import asyncio
import json
import logging
import os
import time
import warnings
from typing import Dict, List, Any, Optional, Union, Tuple, Callable
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
import uuid
import inspect
from enum import Enum
import threading
import tempfile
import subprocess
import sys
import shutil

# Core Autogen imports
import autogen
from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager
from autogen import ConversableAgent, Agent
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
from autogen.retrieve_utils import TEXT_FORMATS

# Advanced Autogen features
from autogen.agentchat.contrib.math_user_proxy_agent import MathUserProxyAgent
from autogen.agentchat.contrib.web_surfer import WebSurferAgent
from autogen.code_utils import extract_code, execute_code
from autogen.oai import ChatCompletion

# External integrations
import docker
import requests
import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report
import yfinance as yf
from bs4 import BeautifulSoup
import aiohttp
import aiofiles

# Monitoring and observability
import wandb
from datadog import initialize, api
import structlog
import psutil

# Data handling and analysis
import pickle
import yaml
import xml.etree.ElementTree as ET
from pydantic import BaseModel, Field, validator
import schedule
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

# Vector databases and embeddings
import chromadb
from sentence_transformers import SentenceTransformer
import faiss

# API clients for external services
from slack_sdk import WebClient as SlackClient
from github import Github
import boto3
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient

from dotenv import load_dotenv

load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)

# Setup structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

class AgentRole(Enum):
    """Agent roles for Autogen agents"""
    MANAGER = "manager"
    RESEARCHER = "researcher"
    ANALYST = "analyst"
    DEVELOPER = "developer"
    REVIEWER = "reviewer"
    EXECUTOR = "executor"
    COORDINATOR = "coordinator"
    SPECIALIST = "specialist"
    CRITIC = "critic"
    VALIDATOR = "validator"

class ConversationPattern(Enum):
    """Conversation patterns for multi-agent interactions"""
    SEQUENTIAL = "sequential"
    ROUND_ROBIN = "round_robin"
    HIERARCHICAL = "hierarchical"
    DYNAMIC = "dynamic"
    BROADCAST = "broadcast"
    PEER_TO_PEER = "peer_to_peer"

class WorkflowStatus(Enum):
    """Workflow execution status"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"
    CANCELLED = "cancelled"

@dataclass
class AgentConfig:
    """Configuration for Autogen agents"""
    name: str
    role: AgentRole
    system_message: str
    model_config: Dict[str, Any]
    max_consecutive_auto_reply: int = 10
    human_input_mode: str = "NEVER"  # NEVER, TERMINATE, ALWAYS
    code_execution_config: Optional[Dict[str, Any]] = None
    retrieve_config: Optional[Dict[str, Any]] = None
    tools: List[str] = field(default_factory=list)
    temperature: float = 0.7
    timeout: int = 300

@dataclass
class WorkflowConfig:
    """Configuration for multi-agent workflows"""
    workflow_id: str
    name: str
    description: str
    agents: List[AgentConfig]
    conversation_pattern: ConversationPattern
    max_rounds: int = 20
    enable_code_execution: bool = True
    enable_retrieval: bool = False
    human_input_required: bool = False
    termination_keywords: List[str] = field(default_factory=lambda: ["TERMINATE", "COMPLETE"])

class ExternalToolIntegrator:
    """Integration with external tools and services"""
    
    def __init__(self):
        self.tools = {}
        self.clients = {}
        self._setup_tools()
    
    def _setup_tools(self):
        """Setup external tool integrations"""
        
        # Web scraping tool
        async def web_scraper(url: str, extract_text: bool = True) -> Dict[str, Any]:
            """Scrape web content"""
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=30) as response:
                        if response.status == 200:
                            content = await response.text()
                            
                            if extract_text:
                                soup = BeautifulSoup(content, 'html.parser')
                                text = soup.get_text()
                                return {
                                    "status": "success",
                                    "url": url,
                                    "text": text[:5000],  # Limit size
                                    "title": soup.title.string if soup.title else "No title"
                                }
                            else:
                                return {
                                    "status": "success",
                                    "url": url,
                                    "html": content[:5000]
                                }
                        else:
                            return {"status": "error", "message": f"HTTP {response.status}"}
            except Exception as e:
                return {"status": "error", "message": str(e)}
        
        # Stock data tool
        def get_stock_data(symbol: str, period: str = "1mo") -> Dict[str, Any]:
            """Get stock market data"""
            try:
                stock = yf.Ticker(symbol)
                hist = stock.history(period=period)
                
                if hist.empty:
                    return {"status": "error", "message": "No data found"}
                
                current_price = hist['Close'].iloc[-1]
                change = hist['Close'].iloc[-1] - hist['Close'].iloc[-2] if len(hist) > 1 else 0
                change_pct = (change / hist['Close'].iloc[-2]) * 100 if len(hist) > 1 else 0
                
                return {
                    "status": "success",
                    "symbol": symbol,
                    "current_price": float(current_price),
                    "change": float(change),
                    "change_percent": float(change_pct),
                    "volume": int(hist['Volume'].iloc[-1]),
                    "high": float(hist['High'].max()),
                    "low": float(hist['Low'].min())
                }
            except Exception as e:
                return {"status": "error", "message": str(e)}
        
        # Database tool
        def query_database(query: str, db_path: str = "temp_database.db") -> Dict[str, Any]:
            """Execute SQL query on SQLite database"""
            try:
                with sqlite3.connect(db_path) as conn:
                    df = pd.read_sql_query(query, conn)
                    return {
                        "status": "success",
                        "rows": len(df),
                        "columns": df.columns.tolist(),
                        "data": df.to_dict('records')[:100]  # Limit results
                    }
            except Exception as e:
                return {"status": "error", "message": str(e)}
        
        # File operations tool
        async def file_operations(operation: str, file_path: str, content: str = None) -> Dict[str, Any]:
            """Perform file operations"""
            try:
                if operation == "read":
                    async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                        content = await f.read()
                        return {
                            "status": "success",
                            "operation": operation,
                            "file_path": file_path,
                            "content": content[:5000]  # Limit size
                        }
                elif operation == "write" and content:
                    # Ensure directory exists
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
                        await f.write(content)
                        return {
                            "status": "success",
                            "operation": operation,
                            "file_path": file_path,
                            "bytes_written": len(content.encode('utf-8'))
                        }
                elif operation == "exists":
                    exists = os.path.exists(file_path)
                    return {
                        "status": "success",
                        "operation": operation,
                        "file_path": file_path,
                        "exists": exists
                    }
                else:
                    return {"status": "error", "message": "Invalid operation or missing content"}
            except Exception as e:
                return {"status": "error", "message": str(e)}
        
        # API request tool
        async def api_request(url: str, method: str = "GET", headers: Dict = None, data: Dict = None) -> Dict[str, Any]:
            """Make API requests"""
            try:
                async with aiohttp.ClientSession() as session:
                    if method.upper() == "GET":
                        async with session.get(url, headers=headers, timeout=30) as response:
                            result = await response.text()
                            return {
                                "status": "success",
                                "status_code": response.status,
                                "response": result[:2000]  # Limit size
                            }
                    elif method.upper() == "POST":
                        async with session.post(url, headers=headers, json=data, timeout=30) as response:
                            result = await response.text()
                            return {
                                "status": "success",
                                "status_code": response.status,
                                "response": result[:2000]
                            }
                    else:
                        return {"status": "error", "message": f"Method {method} not supported"}
            except Exception as e:
                return {"status": "error", "message": str(e)}
        
        # Register tools
        self.tools = {
            "web_scraper": web_scraper,
            "stock_data": get_stock_data,
            "database_query": query_database,
            "file_operations": file_operations,
            "api_request": api_request
        }
    
    def get_tool(self, tool_name: str) -> Optional[Callable]:
        """Get tool by name"""
        return self.tools.get(tool_name)
    
    def list_tools(self) -> List[str]:
        """List available tools"""
        return list(self.tools.keys())

class AdvancedGroupChatManager(GroupChatManager):
    """Advanced group chat manager with enhanced capabilities"""
    
    def __init__(self, groupchat, llm_config, workflow_config: WorkflowConfig):
        super().__init__(groupchat, llm_config)
        self.workflow_config = workflow_config
        self.conversation_history = []
        self.performance_metrics = {
            "total_messages": 0,
            "agent_participation": {},
            "conversation_duration": 0,
            "decisions_made": 0
        }
        self.start_time = time.time()
    
    def select_speaker(self, last_speaker: Agent, selector: Agent) -> Agent:
        """Enhanced speaker selection with workflow awareness"""
        try:
            # Track participation
            if last_speaker.name not in self.performance_metrics["agent_participation"]:
                self.performance_metrics["agent_participation"][last_speaker.name] = 0
            self.performance_metrics["agent_participation"][last_speaker.name] += 1
            
            # Use parent's selection logic
            next_speaker = super().select_speaker(last_speaker, selector)
            
            # Log decision
            self.performance_metrics["decisions_made"] += 1
            logger.info(f"Speaker selected: {next_speaker.name} (after {last_speaker.name})")
            
            return next_speaker
            
        except Exception as e:
            logger.error(f"Speaker selection error: {e}")
            # Fallback to round-robin
            agents = self.groupchat.agents
            current_index = agents.index(last_speaker)
            next_index = (current_index + 1) % len(agents)
            return agents[next_index]
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Get conversation performance metrics"""
        self.performance_metrics["conversation_duration"] = time.time() - self.start_time
        return self.performance_metrics.copy()

class AutogenWorkflowEngine:
    """Advanced workflow engine for Autogen"""
    
    def __init__(self):
        self.workflows = {}
        self.active_sessions = {}
        self.tool_integrator = ExternalToolIntegrator()
        self.execution_history = []
        
        # Setup default LLM configuration
        self.default_llm_config = {
            "timeout": 300,
            "cache_seed": 42,
            "config_list": [
                {
                    "model": "gpt-4",
                    "api_key": os.getenv('OPENAI_API_KEY'),
                }
            ],
            "temperature": 0.7,
        }
    
    def create_agent(self, config: AgentConfig) -> Union[AssistantAgent, UserProxyAgent, ConversableAgent]:
        """Create Autogen agent based on configuration"""
        
        try:
            # Prepare LLM config
            llm_config = {**self.default_llm_config, **config.model_config}
            llm_config["temperature"] = config.temperature
            
            # Create agent based on role and requirements
            if config.role == AgentRole.EXECUTOR or config.code_execution_config:
                # User proxy agent for code execution
                agent = UserProxyAgent(
                    name=config.name,
                    system_message=config.system_message,
                    human_input_mode=config.human_input_mode,
                    max_consecutive_auto_reply=config.max_consecutive_auto_reply,
                    code_execution_config=config.code_execution_config or {
                        "work_dir": "temp_code_execution",
                        "use_docker": False,
                        "timeout": 60,
                        "last_n_messages": 3
                    }
                )
            elif config.retrieve_config:
                # Retrieval-augmented agent
                agent = RetrieveAssistantAgent(
                    name=config.name,
                    system_message=config.system_message,
                    llm_config=llm_config,
                    retrieve_config=config.retrieve_config
                )
            else:
                # Standard assistant agent
                agent = AssistantAgent(
                    name=config.name,
                    system_message=config.system_message,
                    llm_config=llm_config,
                    max_consecutive_auto_reply=config.max_consecutive_auto_reply
                )
            
            # Add tool integration if specified
            if config.tools:
                self._integrate_tools(agent, config.tools)
            
            logger.info(f"Created agent '{config.name}' with role '{config.role.value}'")
            return agent
            
        except Exception as e:
            logger.error(f"Error creating agent '{config.name}': {e}")
            raise
    
    def _integrate_tools(self, agent: ConversableAgent, tool_names: List[str]):
        """Integrate external tools with agent"""
        
        for tool_name in tool_names:
            tool_func = self.tool_integrator.get_tool(tool_name)
            if tool_func:
                # Create a wrapper function for the tool
                def create_tool_wrapper(func, name):
                    async def wrapper(*args, **kwargs):
                        try:
                            if asyncio.iscoroutinefunction(func):
                                result = await func(*args, **kwargs)
                            else:
                                result = func(*args, **kwargs)
                            return f"Tool '{name}' result: {json.dumps(result, indent=2)}"
                        except Exception as e:
                            return f"Tool '{name}' error: {str(e)}"
                    return wrapper
                
                # Add tool as a method to the agent
                setattr(agent, f"tool_{tool_name}", create_tool_wrapper(tool_func, tool_name))
                
                logger.info(f"Integrated tool '{tool_name}' with agent '{agent.name}'")
    
    def create_workflow(self, config: WorkflowConfig) -> str:
        """Create multi-agent workflow"""
        
        try:
            # Create agents
            agents = []
            for agent_config in config.agents:
                agent = self.create_agent(agent_config)
                agents.append(agent)
            
            # Create group chat if multiple agents
            if len(agents) > 2:
                groupchat = GroupChat(
                    agents=agents,
                    messages=[],
                    max_round=config.max_rounds,
                    speaker_selection_method="round_robin" if config.conversation_pattern == ConversationPattern.ROUND_ROBIN else "auto"
                )
                
                # Create enhanced group chat manager
                manager = AdvancedGroupChatManager(
                    groupchat=groupchat,
                    llm_config=self.default_llm_config,
                    workflow_config=config
                )
                
                workflow_data = {
                    "config": config,
                    "agents": agents,
                    "groupchat": groupchat,
                    "manager": manager,
                    "created_at": datetime.now(timezone.utc)
                }
            else:
                # Simple two-agent conversation
                workflow_data = {
                    "config": config,
                    "agents": agents,
                    "groupchat": None,
                    "manager": None,
                    "created_at": datetime.now(timezone.utc)
                }
            
            self.workflows[config.workflow_id] = workflow_data
            logger.info(f"Created workflow '{config.workflow_id}' with {len(agents)} agents")
            
            return config.workflow_id
            
        except Exception as e:
            logger.error(f"Error creating workflow '{config.workflow_id}': {e}")
            raise
    
    async def execute_workflow(self, workflow_id: str, initial_message: str, 
                             session_id: Optional[str] = None) -> Dict[str, Any]:
        """Execute multi-agent workflow"""
        
        if workflow_id not in self.workflows:
            return {"error": f"Workflow '{workflow_id}' not found"}
        
        if session_id is None:
            session_id = str(uuid.uuid4())
        
        workflow_data = self.workflows[workflow_id]
        config = workflow_data["config"]
        agents = workflow_data["agents"]
        groupchat = workflow_data["groupchat"]
        manager = workflow_data["manager"]
        
        start_time = time.time()
        
        try:
            if groupchat and manager:
                # Multi-agent group conversation
                
                # Initialize conversation
                user_proxy = agents[0]  # Assume first agent can initiate
                
                # Start conversation
                conversation_result = user_proxy.initiate_chat(
                    manager,
                    message=initial_message,
                    clear_history=True
                )
                
                # Extract results
                messages = groupchat.messages
                performance_metrics = manager.get_performance_metrics()
                
            else:
                # Two-agent conversation
                initiator = agents[0]
                recipient = agents[1]
                
                conversation_result = initiator.initiate_chat(
                    recipient,
                    message=initial_message,
                    clear_history=True,
                    max_turns=config.max_rounds
                )
                
                messages = conversation_result.chat_history if hasattr(conversation_result, 'chat_history') else []
                performance_metrics = {
                    "total_messages": len(messages),
                    "conversation_duration": time.time() - start_time
                }
            
            # Process results
            execution_time = time.time() - start_time
            
            result = {
                "session_id": session_id,
                "workflow_id": workflow_id,
                "status": WorkflowStatus.COMPLETED.value,
                "execution_time": execution_time,
                "message_count": len(messages),
                "messages": [
                    {
                        "sender": msg.get("name", "unknown"),
                        "content": msg.get("content", ""),
                        "role": msg.get("role", "")
                    } for msg in messages
                ],
                "performance_metrics": performance_metrics,
                "final_result": messages[-1].get("content", "") if messages else "No result",
                "timestamp": datetime.now(timezone.utc)
            }
            
            # Store session
            self.active_sessions[session_id] = result
            self.execution_history.append(result)
            
            logger.info(f"Workflow '{workflow_id}' completed in {execution_time:.2f}s with {len(messages)} messages")
            return result
            
        except Exception as e:
            logger.error(f"Workflow execution error: {e}")
            
            error_result = {
                "session_id": session_id,
                "workflow_id": workflow_id,
                "status": WorkflowStatus.FAILED.value,
                "error": str(e),
                "execution_time": time.time() - start_time,
                "timestamp": datetime.now(timezone.utc)
            }
            
            self.execution_history.append(error_result)
            return error_result
    
    def get_workflow_info(self, workflow_id: str) -> Dict[str, Any]:
        """Get workflow information"""
        if workflow_id not in self.workflows:
            return {"error": "Workflow not found"}
        
        workflow_data = self.workflows[workflow_id]
        config = workflow_data["config"]
        
        return {
            "workflow_id": config.workflow_id,
            "name": config.name,
            "description": config.description,
            "agent_count": len(config.agents),
            "conversation_pattern": config.conversation_pattern.value,
            "max_rounds": config.max_rounds,
            "agents": [
                {
                    "name": agent_config.name,
                    "role": agent_config.role.value,
                    "tools": agent_config.tools,
                    "code_execution": agent_config.code_execution_config is not None
                }
                for agent_config in config.agents
            ],
            "created_at": workflow_data["created_at"]
        }
    
    def list_workflows(self) -> List[Dict[str, Any]]:
        """List all workflows"""
        return [
            {
                "workflow_id": workflow_id,
                "name": data["config"].name,
                "agent_count": len(data["config"].agents),
                "created_at": data["created_at"]
            }
            for workflow_id, data in self.workflows.items()
        ]
    
    def get_execution_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get execution history"""
        return self.execution_history[-limit:]

class OpenAIOperatorAlternative:
    """Alternative implementation to OpenAI Operator"""
    
    def __init__(self, workflow_engine: AutogenWorkflowEngine):
        self.workflow_engine = workflow_engine
        self.operators = {}
        self.task_queue = []
        self.execution_pool = ThreadPoolExecutor(max_workers=4)
        self.monitoring_data = {
            "tasks_processed": 0,
            "successful_tasks": 0,
            "failed_tasks": 0,
            "average_execution_time": 0.0
        }
    
    def register_operator(self, name: str, workflow_id: str, trigger_keywords: List[str]):
        """Register an operator with workflow"""
        
        self.operators[name] = {
            "workflow_id": workflow_id,
            "trigger_keywords": trigger_keywords,
            "created_at": datetime.now(timezone.utc),
            "execution_count": 0,
            "last_execution": None
        }
        
        logger.info(f"Registered operator '{name}' with workflow '{workflow_id}'")
    
    async def process_task(self, task_description: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Process task using appropriate operator"""
        
        start_time = time.time()
        self.monitoring_data["tasks_processed"] += 1
        
        try:
            # Find matching operator
            selected_operator = self._select_operator(task_description)
            
            if not selected_operator:
                return {
                    "status": "error",
                    "message": "No suitable operator found for task",
                    "task": task_description
                }
            
            operator_name, operator_data = selected_operator
            workflow_id = operator_data["workflow_id"]
            
            # Prepare enhanced message with context
            enhanced_message = task_description
            if context:
                enhanced_message += f"\n\nAdditional context: {json.dumps(context, indent=2)}"
            
            # Execute workflow
            result = await self.workflow_engine.execute_workflow(
                workflow_id=workflow_id,
                initial_message=enhanced_message
            )
            
            # Update operator statistics
            operator_data["execution_count"] += 1
            operator_data["last_execution"] = datetime.now(timezone.utc)
            
            # Update monitoring
            execution_time = time.time() - start_time
            
            if result.get("status") == WorkflowStatus.COMPLETED.value:
                self.monitoring_data["successful_tasks"] += 1
            else:
                self.monitoring_data["failed_tasks"] += 1
            
            # Update average execution time
            total_tasks = self.monitoring_data["tasks_processed"]
            current_avg = self.monitoring_data["average_execution_time"]
            self.monitoring_data["average_execution_time"] = (
                (current_avg * (total_tasks - 1) + execution_time) / total_tasks
            )
            
            return {
                "status": "success",
                "operator_used": operator_name,
                "workflow_result": result,
                "execution_time": execution_time,
                "task": task_description
            }
            
        except Exception as e:
            self.monitoring_data["failed_tasks"] += 1
            logger.error(f"Task processing error: {e}")
            
            return {
                "status": "error",
                "message": str(e),
                "execution_time": time.time() - start_time,
                "task": task_description
            }
    
    def _select_operator(self, task_description: str) -> Optional[Tuple[str, Dict[str, Any]]]:
        """Select appropriate operator for task"""
        
        task_lower = task_description.lower()
        
        # Find operators with matching keywords
        matches = []
        for name, data in self.operators.items():
            keyword_matches = sum(1 for keyword in data["trigger_keywords"] if keyword.lower() in task_lower)
            if keyword_matches > 0:
                matches.append((name, data, keyword_matches))
        
        if not matches:
            return None
        
        # Return operator with most keyword matches
        matches.sort(key=lambda x: x[2], reverse=True)
        return matches[0][0], matches[0][1]
    
    def queue_task(self, task_description: str, context: Dict[str, Any] = None, priority: int = 1):
        """Queue task for asynchronous processing"""
        
        task = {
            "id": str(uuid.uuid4()),
            "description": task_description,
            "context": context or {},
            "priority": priority,
            "created_at": datetime.now(timezone.utc),
            "status": "queued"
        }
        
        self.task_queue.append(task)
        self.task_queue.sort(key=lambda x: x["priority"], reverse=True)
        
        logger.info(f"Queued task '{task['id']}' with priority {priority}")
        return task["id"]
    
    async def process_queue(self, max_concurrent: int = 2):
        """Process task queue"""
        
        if not self.task_queue:
            return {"message": "No tasks in queue"}
        
        # Process tasks in batches
        processed_tasks = []
        
        while self.task_queue and len(processed_tasks) < max_concurrent:
            task = self.task_queue.pop(0)
            task["status"] = "processing"
            
            try:
                result = await self.process_task(task["description"], task["context"])
                task["result"] = result
                task["status"] = "completed"
                
            except Exception as e:
                task["result"] = {"status": "error", "message": str(e)}
                task["status"] = "failed"
            
            processed_tasks.append(task)
        
        return {
            "processed_count": len(processed_tasks),
            "remaining_queue": len(self.task_queue),
            "tasks": processed_tasks
        }
    
    def get_monitoring_data(self) -> Dict[str, Any]:
        """Get monitoring and performance data"""
        
        return {
            "monitoring_metrics": self.monitoring_data.copy(),
            "operators": {
                name: {
                    "workflow_id": data["workflow_id"],
                    "trigger_keywords": data["trigger_keywords"],
                    "execution_count": data["execution_count"],
                    "last_execution": data["last_execution"]
                }
                for name, data in self.operators.items()
            },
            "queue_status": {
                "pending_tasks": len(self.task_queue),
                "next_task_priority": self.task_queue[0]["priority"] if self.task_queue else None
            }
        }

# Comprehensive demonstration
async def demonstrate_autogen_framework():
    """Comprehensive demonstration of Autogen framework"""
    
    logger.info("=== Autogen Advanced Multi-Agent Framework Demonstration ===")
    
    # Check for OpenAI API key
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        logger.error("OpenAI API key not found. Please set OPENAI_API_KEY environment variable.")
        return
    
    # Initialize workflow engine
    workflow_engine = AutogenWorkflowEngine()
    
    # 1. Create Software Development Workflow
    logger.info("\n1. Creating Software Development Team Workflow")
    
    # Product Manager Agent
    pm_config = AgentConfig(
        name="product_manager",
        role=AgentRole.MANAGER,
        system_message="""
        You are a Product Manager responsible for defining requirements and managing the development process.
        Your role is to:
        - Clarify requirements and user stories
        - Coordinate between team members
        - Ensure project scope and timeline alignment
        - Make product decisions and trade-offs
        
        Be clear, decisive, and focus on user value and business objectives.
        """,
        model_config={"model": "gpt-4", "temperature": 0.3},
        tools=["api_request", "file_operations"]
    )
    
    # Software Developer Agent
    dev_config = AgentConfig(
        name="developer",
        role=AgentRole.DEVELOPER,
        system_message="""
        You are a Senior Software Developer responsible for implementing solutions.
        Your role is to:
        - Write clean, efficient, and maintainable code
        - Propose technical solutions and architectures
        - Implement features according to requirements
        - Perform code reviews and suggest improvements
        
        Focus on best practices, performance, and scalability.
        """,
        model_config={"model": "gpt-4", "temperature": 0.2},
        code_execution_config={
            "work_dir": "development_workspace",
            "use_docker": False,
            "timeout": 120
        },
        tools=["file_operations", "database_query"]
    )
    
    # QA Engineer Agent
    qa_config = AgentConfig(
        name="qa_engineer",
        role=AgentRole.REVIEWER,
        system_message="""
        You are a QA Engineer responsible for testing and quality assurance.
        Your role is to:
        - Design and execute test cases
        - Identify bugs and quality issues
        - Validate requirements implementation
        - Ensure code quality and standards compliance
        
        Be thorough, detail-oriented, and focus on user experience and reliability.
        """,
        model_config={"model": "gpt-4", "temperature": 0.4},
        tools=["file_operations", "web_scraper"]
    )
    
    # Create development workflow
    dev_workflow_config = WorkflowConfig(
        workflow_id="software_development_team",
        name="Software Development Team",
        description="Collaborative software development with PM, Developer, and QA",
        agents=[pm_config, dev_config, qa_config],
        conversation_pattern=ConversationPattern.ROUND_ROBIN,
        max_rounds=15,
        enable_code_execution=True
    )
    
    dev_workflow_id = workflow_engine.create_workflow(dev_workflow_config)
    
    # 2. Create Data Analysis Workflow
    logger.info("\n2. Creating Data Analysis Team Workflow")
    
    # Data Analyst Agent
    analyst_config = AgentConfig(
        name="data_analyst",
        role=AgentRole.ANALYST,
        system_message="""
        You are a Data Analyst responsible for analyzing data and generating insights.
        Your role is to:
        - Analyze datasets and identify patterns
        - Create visualizations and reports
        - Provide statistical analysis and insights
        - Recommend data-driven decisions
        
        Focus on accuracy, statistical rigor, and clear communication of findings.
        """,
        model_config={"model": "gpt-4", "temperature": 0.3},
        code_execution_config={
            "work_dir": "analysis_workspace",
            "use_docker": False,
            "timeout": 180
        },
        tools=["stock_data", "database_query", "file_operations"]
    )
    
    # Research Specialist Agent
    researcher_config = AgentConfig(
        name="researcher",
        role=AgentRole.RESEARCHER,
        system_message="""
        You are a Research Specialist responsible for gathering and synthesizing information.
        Your role is to:
        - Conduct thorough research on topics
        - Gather data from multiple sources
        - Synthesize findings into comprehensive reports
        - Identify trends and market insights
        
        Be thorough, accurate, and provide well-sourced information.
        """,
        model_config={"model": "gpt-3.5-turbo", "temperature": 0.4},
        tools=["web_scraper", "api_request", "stock_data"]
    )
    
    # Create analysis workflow
    analysis_workflow_config = WorkflowConfig(
        workflow_id="data_analysis_team",
        name="Data Analysis Team",
        description="Collaborative data analysis with analyst and researcher",
        agents=[analyst_config, researcher_config],
        conversation_pattern=ConversationPattern.SEQUENTIAL,
        max_rounds=10
    )
    
    analysis_workflow_id = workflow_engine.create_workflow(analysis_workflow_config)
    
    # 3. Execute Software Development Workflow
    logger.info("\n3. Executing Software Development Workflow")
    
    dev_task = """
    We need to develop a simple REST API for a task management system.
    
    Requirements:
    - CRUD operations for tasks (create, read, update, delete)
    - Each task should have: id, title, description, status, created_date, due_date
    - Use Python Flask framework
    - Include basic error handling and validation
    - Provide simple test cases
    
    Please work together to:
    1. Define detailed requirements and API specification
    2. Implement the solution with clean, documented code
    3. Create test cases and validate the implementation
    
    Coordinate as a team and ensure high-quality deliverables.
    """
    
    try:
        dev_result = await workflow_engine.execute_workflow(
            workflow_id=dev_workflow_id,
            initial_message=dev_task
        )
        
        logger.info(f"Development Workflow Status: {dev_result['status']}")
        logger.info(f"Execution Time: {dev_result['execution_time']:.2f} seconds")
        logger.info(f"Messages Exchanged: {dev_result['message_count']}")
        
        if dev_result['status'] == WorkflowStatus.COMPLETED.value:
            logger.info("Development workflow completed successfully")
            logger.info(f"Final Result: {dev_result['final_result'][:300]}...")
        
    except Exception as e:
        logger.error(f"Development workflow error: {e}")
    
    # 4. Execute Data Analysis Workflow
    logger.info("\n4. Executing Data Analysis Workflow")
    
    analysis_task = """
    Please conduct a comprehensive analysis of Tesla (TSLA) stock performance and market trends.
    
    The analysis should include:
    1. Current stock price, volume, and recent performance metrics
    2. Research on recent Tesla news, developments, and market sentiment
    3. Technical analysis of price trends and patterns
    4. Market comparison with other EV companies
    5. Investment recommendations based on findings
    
    Work together to provide a thorough, data-driven analysis with clear insights and recommendations.
    """
    
    try:
        analysis_result = await workflow_engine.execute_workflow(
            workflow_id=analysis_workflow_id,
            initial_message=analysis_task
        )
        
        logger.info(f"Analysis Workflow Status: {analysis_result['status']}")
        logger.info(f"Execution Time: {analysis_result['execution_time']:.2f} seconds")
        logger.info(f"Messages Exchanged: {analysis_result['message_count']}")
        
        if analysis_result['status'] == WorkflowStatus.COMPLETED.value:
            logger.info("Analysis workflow completed successfully")
            logger.info(f"Final Result: {analysis_result['final_result'][:300]}...")
        
    except Exception as e:
        logger.error(f"Analysis workflow error: {e}")
    
    # 5. Implement OpenAI Operator Alternative
    logger.info("\n5. Implementing OpenAI Operator Alternative")
    
    operator_alternative = OpenAIOperatorAlternative(workflow_engine)
    
    # Register operators
    operator_alternative.register_operator(
        name="development_operator",
        workflow_id=dev_workflow_id,
        trigger_keywords=["develop", "code", "implement", "build", "create", "software", "API", "application"]
    )
    
    operator_alternative.register_operator(
        name="analysis_operator",
        workflow_id=analysis_workflow_id,
        trigger_keywords=["analyze", "research", "data", "stock", "market", "trends", "insights"]
    )
    
    # Test operator with various tasks
    test_tasks = [
        {
            "description": "Develop a Python script to calculate compound interest",
            "context": {"priority": "high", "deadline": "2024-01-15"}
        },
        {
            "description": "Analyze the performance of Apple stock over the last month",
            "context": {"priority": "medium", "report_type": "executive_summary"}
        },
        {
            "description": "Build a simple web scraper for news articles",
            "context": {"priority": "low", "target_sites": ["bbc.com", "reuters.com"]}
        }
    ]
    
    operator_results = []
    for task in test_tasks:
        try:
            result = await operator_alternative.process_task(
                task["description"], 
                task["context"]
            )
            operator_results.append(result)
            logger.info(f"Operator Task: {task['description'][:50]}...")
            logger.info(f"Status: {result['status']}, Operator: {result.get('operator_used', 'None')}")
            
        except Exception as e:
            logger.error(f"Operator task error: {e}")
    
    # 6. Test Queue Processing
    logger.info("\n6. Testing Queue Processing")
    
    # Queue multiple tasks
    queued_tasks = [
        "Create a database schema for an e-commerce platform",
        "Research machine learning trends in healthcare",
        "Implement a binary search algorithm in Python",
        "Analyze cryptocurrency market volatility"
    ]
    
    task_ids = []
    for i, task in enumerate(queued_tasks):
        task_id = operator_alternative.queue_task(
            task, 
            {"batch": "demo", "index": i}, 
            priority=len(queued_tasks) - i  # Higher priority for earlier tasks
        )
        task_ids.append(task_id)
    
    # Process queue
    queue_result = await operator_alternative.process_queue(max_concurrent=2)
    logger.info(f"Queue Processing: {queue_result['processed_count']} tasks processed")
    logger.info(f"Remaining in queue: {queue_result['remaining_queue']}")
    
    # 7. Performance Analysis and Monitoring
    logger.info("\n7. Performance Analysis and Monitoring")
    
    # Workflow performance
    workflow_history = workflow_engine.get_execution_history()
    operator_monitoring = operator_alternative.get_monitoring_data()
    
    logger.info("Workflow Performance:")
    for execution in workflow_history:
        logger.info(f"  {execution['workflow_id']}: {execution['status']} in {execution['execution_time']:.2f}s")
    
    logger.info("Operator Performance:")
    logger.info(f"  Tasks Processed: {operator_monitoring['monitoring_metrics']['tasks_processed']}")
    logger.info(f"  Success Rate: {operator_monitoring['monitoring_metrics']['successful_tasks'] / max(operator_monitoring['monitoring_metrics']['tasks_processed'], 1):.2%}")
    logger.info(f"  Average Execution Time: {operator_monitoring['monitoring_metrics']['average_execution_time']:.2f}s")
    
    # Create performance visualization
    try:
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Workflow execution times
        workflow_names = [exec['workflow_id'] for exec in workflow_history[-5:]]
        execution_times = [exec['execution_time'] for exec in workflow_history[-5:]]
        
        if workflow_names:
            axes[0, 0].bar(range(len(workflow_names)), execution_times)
            axes[0, 0].set_title('Workflow Execution Times')
            axes[0, 0].set_ylabel('Time (seconds)')
            axes[0, 0].set_xticks(range(len(workflow_names)))
            axes[0, 0].set_xticklabels([name[:15] + '...' if len(name) > 15 else name for name in workflow_names], rotation=45)
        
        # Message counts
        message_counts = [exec['message_count'] for exec in workflow_history[-5:]]
        
        if message_counts:
            axes[0, 1].bar(range(len(workflow_names)), message_counts)
            axes[0, 1].set_title('Messages per Workflow')
            axes[0, 1].set_ylabel('Message Count')
            axes[0, 1].set_xticks(range(len(workflow_names)))
            axes[0, 1].set_xticklabels([name[:15] + '...' if len(name) > 15 else name for name in workflow_names], rotation=45)
        
        # Operator performance
        operator_metrics = operator_monitoring['monitoring_metrics']
        metrics_names = ['Tasks Processed', 'Successful', 'Failed']
        metrics_values = [
            operator_metrics['tasks_processed'],
            operator_metrics['successful_tasks'],
            operator_metrics['failed_tasks']
        ]
        
        axes[1, 0].bar(metrics_names, metrics_values)
        axes[1, 0].set_title('Operator Task Statistics')
        axes[1, 0].set_ylabel('Count')
        
        # Queue processing status
        queue_data = operator_monitoring['queue_status']
        queue_labels = ['Pending Tasks']
        queue_values = [queue_data['pending_tasks']]
        
        axes[1, 1].bar(queue_labels, queue_values)
        axes[1, 1].set_title('Task Queue Status')
        axes[1, 1].set_ylabel('Count')
        
        plt.tight_layout()
        plt.savefig('autogen_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info("Performance visualization saved")
        
    except Exception as e:
        logger.warning(f"Error creating visualizations: {e}")
    
    # 8. Generate Comprehensive Report
    comprehensive_report = {
        "demonstration_summary": {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "workflows_created": len(workflow_engine.workflows),
            "total_executions": len(workflow_engine.execution_history),
            "successful_executions": len([e for e in workflow_engine.execution_history if e['status'] == WorkflowStatus.COMPLETED.value]),
            "operator_tasks_processed": operator_monitoring['monitoring_metrics']['tasks_processed'],
            "operator_success_rate": operator_monitoring['monitoring_metrics']['successful_tasks'] / max(operator_monitoring['monitoring_metrics']['tasks_processed'], 1)
        },
        
        "workflow_configurations": [
            workflow_engine.get_workflow_info(wf_id) for wf_id in workflow_engine.workflows.keys()
        ],
        
        "execution_results": {
            "development_workflow": {
                "status": dev_result.get('status', 'unknown'),
                "execution_time": dev_result.get('execution_time', 0),
                "message_count": dev_result.get('message_count', 0),
                "final_result_length": len(dev_result.get('final_result', ''))
            },
            "analysis_workflow": {
                "status": analysis_result.get('status', 'unknown'),
                "execution_time": analysis_result.get('execution_time', 0),
                "message_count": analysis_result.get('message_count', 0),
                "final_result_length": len(analysis_result.get('final_result', ''))
            }
        },
        
        "operator_performance": operator_monitoring,
        
        "external_tools_used": workflow_engine.tool_integrator.list_tools(),
        
        "features_demonstrated": [
            "Multi-agent conversational workflows",
            "Role-based agent specialization",
            "Code execution in secure environments",
            "External tool integration",
            "Group chat management and orchestration",
            "OpenAI Operator alternative implementation",
            "Task queue processing",
            "Performance monitoring and analytics",
            "Workflow pattern implementations",
            "Real-world use case scenarios"
        ],
        
        "autogen_capabilities": [
            "Conversational multi-agent systems",
            "Human-in-the-loop interactions",
            "Code execution and validation",
            "Retrieval-augmented generation",
            "Group chat orchestration",
            "Speaker selection algorithms",
            "Termination condition management",
            "Message history tracking",
            "Error handling and recovery",
            "Scalable agent coordination"
        ],
        
        "best_practices": [
            "Design agents with clear, specific roles",
            "Use appropriate conversation patterns for tasks",
            "Implement proper termination conditions",
            "Enable code execution for technical tasks",
            "Integrate external tools for enhanced capabilities",
            "Monitor performance and conversation flow",
            "Use human-in-the-loop for critical decisions",
            "Implement proper error handling and recovery",
            "Design workflows with clear objectives",
            "Use group chat managers for complex coordination"
        ],
        
        "recommendations": [
            "Start with simple two-agent conversations",
            "Use AutogenStudio for visual workflow design",
            "Implement proper security for code execution",
            "Monitor conversation length and costs",
            "Use retrieval-augmented agents for knowledge tasks",
            "Implement queue processing for scalability",
            "Design operators for common task patterns",
            "Use performance metrics for optimization",
            "Implement proper logging and observability",
            "Consider human oversight for production systems"
        ]
    }
    
    # Save comprehensive report
    with open("autogen_comprehensive_report.json", "w") as f:
        json.dump(comprehensive_report, f, indent=2, default=str)
    
    logger.info("Autogen framework demonstration completed!")
    logger.info("Check 'autogen_comprehensive_report.json' for detailed results")
    
    return comprehensive_report

# Main execution
async def main():
    """Main execution for Autogen demonstration"""
    try:
        report = await demonstrate_autogen_framework()
        
        # Display key results
        logger.info("\n=== Autogen Framework Summary ===")
        logger.info(f"Workflows created: {report['demonstration_summary']['workflows_created']}")
        logger.info(f"Total executions: {report['demonstration_summary']['total_executions']}")
        logger.info(f"Successful executions: {report['demonstration_summary']['successful_executions']}")
        logger.info(f"Operator tasks processed: {report['demonstration_summary']['operator_tasks_processed']}")
        logger.info(f"Operator success rate: {report['demonstration_summary']['operator_success_rate']:.2%}")
        
        # Display workflow results
        for workflow_name, workflow_data in report["execution_results"].items():
            logger.info(f"{workflow_name}: {workflow_data['status']} in {workflow_data['execution_time']:.2f}s")
        
    except Exception as e:
        logger.error(f"Autogen demonstration failed: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    asyncio.run(main())
````

## Conclusion

The comprehensive Autogen framework implementation demonstrates the revolutionary potential of conversational multi-agent systems, establishing sophisticated patterns for collaborative AI that mirror natural human team dynamics while providing unprecedented automation capabilities. This advanced framework represents the cutting edge of multi-agent orchestration technology.

**Conversational AI Excellence** through natural language interactions between specialized agents enables intuitive collaboration patterns that require minimal orchestration overhead while producing emergent behaviors and sophisticated problem-solving capabilities that exceed individual agent performance.

**Advanced Agent Specialization** via role-based design patterns allows for the creation of expert agents with domain-specific knowledge, tools, and communication styles, enabling the formation of virtual teams that can tackle complex, multi-disciplinary challenges with human-like coordination and expertise.

**Sophisticated Orchestration Mechanisms** including group chat management, dynamic speaker selection, and conversation flow control provide intelligent coordination that adapts to task requirements while maintaining productive collaboration and preventing conversational deadlocks or inefficiencies.

**External Tool Integration Architecture** enables agents to interact with real-world systems, APIs, databases, and services, transforming theoretical AI conversations into practical automation solutions that can perform concrete actions and access external information sources.

**OpenAI Operator Alternative Implementation** showcases how Autogen can serve as a foundation for building enterprise-grade automation platforms that intelligently route tasks to appropriate agent teams based on content analysis and predefined workflows.

**Code Execution Capabilities** through secure, sandboxed environments allow agents to write, test, and validate code collaboratively, enabling software development teams that can implement solutions from requirements through testing with minimal human intervention.

**Production-Ready Infrastructure** including performance monitoring, error handling, queue processing, and scalability features ensures that Autogen-based systems can be deployed reliably in enterprise environments with appropriate governance and observability.

**Human-in-the-Loop Integration** provides seamless mechanisms for incorporating human oversight, approval workflows, and expert input when needed, enabling hybrid human-AI collaboration that leverages the strengths of both artificial and human intelligence.

This advanced Autogen framework establishes the foundation for building intelligent automation systems that can handle complex, multi-step tasks through natural conversation patterns, providing a glimpse into the future of AI-powered collaboration where artificial agents work together as effectively as human teams while operating at unprecedented scale and speed.