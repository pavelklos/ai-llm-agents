<small>Claude Sonnet 4</small>
# 02. Databases for Agents

## Key Terms

**Vector Databases**: Specialized database systems designed to store, index, and query high-dimensional vector embeddings efficiently, enabling semantic search and similarity matching crucial for AI applications like RAG (Retrieval-Augmented Generation).

**Embeddings**: Dense numerical vector representations of text, images, or other data types that capture semantic meaning, allowing machines to understand and compare content based on contextual similarity rather than exact matches.

**Semantic Search**: A search methodology that understands the intent and contextual meaning of search queries, using vector embeddings to find semantically similar content rather than relying solely on keyword matching.

**Knowledge Base**: A structured repository of information that serves as a source of truth for AI agents, containing domain-specific knowledge that can be retrieved and utilized for decision-making and response generation.

**ACID Properties**: Database transaction properties (Atomicity, Consistency, Isolation, Durability) that ensure reliable processing of database transactions, particularly important for maintaining data integrity in agent operations.

**Document Store**: A type of NoSQL database that stores data in document format (typically JSON), providing flexible schema design suitable for storing unstructured or semi-structured data common in AI workflows.

**Full-Text Search**: Database capability to search within text content of documents, providing relevance scoring and advanced query features essential for content retrieval in knowledge-based systems.

**Connection Pooling**: Database connection management technique that maintains a pool of reusable connections, optimizing performance and resource utilization in high-throughput agent applications.

## Database Integration for AI Agents

The integration of diverse database technologies creates a robust foundation for AI agents, enabling efficient data storage, retrieval, and management across structured, unstructured, and vector data types. Modern agent architectures require sophisticated data layers that can handle real-time queries, semantic search, and complex relationships.

### Comprehensive Database Integration Framework

````python
import os
import asyncio
import json
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
import numpy as np
from contextlib import asynccontextmanager

# SQL Database imports
import pyodbc
import asyncpg
import sqlalchemy as sa
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.dialects.mssql import UNIQUEIDENTIFIER
from sqlalchemy import Column, Integer, String, DateTime, Text, JSON, Float

# NoSQL Database imports
import motor.motor_asyncio
from pymongo import MongoClient
import pymongo.errors

# Vector Database imports
import chromadb
from chromadb.config import Settings
import elasticsearch
from elasticsearch import AsyncElasticsearch

# Embedding and ML imports
from sentence_transformers import SentenceTransformer
import openai
from openai import AsyncOpenAI
import tiktoken

from dotenv import load_dotenv

load_dotenv()

@dataclass
class DatabaseConfig:
    """Configuration for database connections"""
    connection_string: str
    max_connections: int = 10
    timeout: int = 30
    retry_attempts: int = 3
    pool_size: int = 5
    overflow_size: int = 10

@dataclass
class QueryResult:
    """Standardized query result format"""
    data: List[Dict[str, Any]]
    metadata: Dict[str, Any]
    execution_time: float
    source_database: str
    query_type: str

class DatabaseInterface(ABC):
    """Abstract base class for database providers"""
    
    def __init__(self, config: DatabaseConfig):
        self.config = config
        self.connection = None
        self.logger = logging.getLogger(self.__class__.__name__)
    
    @abstractmethod
    async def connect(self) -> bool:
        """Establish database connection"""
        pass
    
    @abstractmethod
    async def disconnect(self) -> bool:
        """Close database connection"""
        pass
    
    @abstractmethod
    async def execute_query(self, query: str, params: Dict[str, Any] = None) -> QueryResult:
        """Execute database query"""
        pass
    
    @abstractmethod
    async def health_check(self) -> bool:
        """Check database health"""
        pass

class SQLServerManager(DatabaseInterface):
    """Microsoft SQL Server database manager"""
    
    def __init__(self, config: DatabaseConfig):
        super().__init__(config)
        self.engine = None
        self.session_maker = None
        
        # Define SQLAlchemy models
        self.Base = declarative_base()
        self._create_models()
    
    def _create_models(self):
        """Create SQLAlchemy ORM models"""
        
        class AgentSession(self.Base):
            __tablename__ = 'agent_sessions'
            
            id = Column(UNIQUEIDENTIFIER, primary_key=True, server_default=sa.text("NEWID()"))
            agent_id = Column(String(100), nullable=False)
            session_start = Column(DateTime, nullable=False, default=datetime.utcnow)
            session_end = Column(DateTime)
            metadata = Column(JSON)
            status = Column(String(20), default='active')
            
        class AgentInteraction(self.Base):
            __tablename__ = 'agent_interactions'
            
            id = Column(UNIQUEIDENTIFIER, primary_key=True, server_default=sa.text("NEWID()"))
            session_id = Column(UNIQUEIDENTIFIER, nullable=False)
            interaction_type = Column(String(50), nullable=False)
            input_data = Column(Text)
            output_data = Column(Text)
            timestamp = Column(DateTime, default=datetime.utcnow)
            processing_time = Column(Float)
            success = Column(sa.Boolean, default=True)
            error_message = Column(Text)
            
        class KnowledgeEntry(self.Base):
            __tablename__ = 'knowledge_entries'
            
            id = Column(UNIQUEIDENTIFIER, primary_key=True, server_default=sa.text("NEWID()"))
            title = Column(String(500), nullable=False)
            content = Column(Text, nullable=False)
            category = Column(String(100))
            tags = Column(JSON)
            created_at = Column(DateTime, default=datetime.utcnow)
            updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
            version = Column(Integer, default=1)
            embedding_id = Column(String(100))  # Reference to vector embedding
            
        self.AgentSession = AgentSession
        self.AgentInteraction = AgentInteraction
        self.KnowledgeEntry = KnowledgeEntry
    
    async def connect(self) -> bool:
        """Establish SQL Server connection"""
        try:
            self.engine = create_async_engine(
                self.config.connection_string,
                pool_size=self.config.pool_size,
                max_overflow=self.config.overflow_size,
                pool_timeout=self.config.timeout,
                echo=False
            )
            
            self.session_maker = sessionmaker(
                self.engine,
                class_=AsyncSession,
                expire_on_commit=False
            )
            
            # Create tables if they don't exist
            async with self.engine.begin() as conn:
                await conn.run_sync(self.Base.metadata.create_all)
            
            self.logger.info("SQL Server connection established")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to connect to SQL Server: {e}")
            return False
    
    async def disconnect(self) -> bool:
        """Close SQL Server connection"""
        try:
            if self.engine:
                await self.engine.dispose()
            self.logger.info("SQL Server connection closed")
            return True
        except Exception as e:
            self.logger.error(f"Error closing SQL Server connection: {e}")
            return False
    
    async def execute_query(self, query: str, params: Dict[str, Any] = None) -> QueryResult:
        """Execute SQL query"""
        start_time = asyncio.get_event_loop().time()
        
        try:
            async with self.session_maker() as session:
                if params:
                    result = await session.execute(sa.text(query), params)
                else:
                    result = await session.execute(sa.text(query))
                
                # Handle different result types
                if result.returns_rows:
                    rows = result.fetchall()
                    data = [dict(row._mapping) for row in rows]
                else:
                    data = []
                    await session.commit()
                
                execution_time = asyncio.get_event_loop().time() - start_time
                
                return QueryResult(
                    data=data,
                    metadata={"row_count": len(data), "columns": list(result.keys()) if result.returns_rows else []},
                    execution_time=execution_time,
                    source_database="mssql",
                    query_type="sql"
                )
                
        except Exception as e:
            execution_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"SQL query failed: {e}")
            return QueryResult(
                data=[],
                metadata={"error": str(e)},
                execution_time=execution_time,
                source_database="mssql",
                query_type="sql"
            )
    
    async def create_agent_session(self, agent_id: str, metadata: Dict[str, Any] = None) -> str:
        """Create new agent session"""
        try:
            async with self.session_maker() as session:
                new_session = self.AgentSession(
                    agent_id=agent_id,
                    metadata=metadata or {}
                )
                session.add(new_session)
                await session.commit()
                await session.refresh(new_session)
                return str(new_session.id)
        except Exception as e:
            self.logger.error(f"Failed to create agent session: {e}")
            return None
    
    async def log_interaction(self, session_id: str, interaction_type: str, 
                            input_data: str, output_data: str, 
                            processing_time: float, success: bool = True,
                            error_message: str = None) -> bool:
        """Log agent interaction"""
        try:
            async with self.session_maker() as session:
                interaction = self.AgentInteraction(
                    session_id=session_id,
                    interaction_type=interaction_type,
                    input_data=input_data,
                    output_data=output_data,
                    processing_time=processing_time,
                    success=success,
                    error_message=error_message
                )
                session.add(interaction)
                await session.commit()
                return True
        except Exception as e:
            self.logger.error(f"Failed to log interaction: {e}")
            return False
    
    async def store_knowledge_entry(self, title: str, content: str, 
                                  category: str = None, tags: List[str] = None,
                                  embedding_id: str = None) -> str:
        """Store knowledge entry"""
        try:
            async with self.session_maker() as session:
                entry = self.KnowledgeEntry(
                    title=title,
                    content=content,
                    category=category,
                    tags=tags or [],
                    embedding_id=embedding_id
                )
                session.add(entry)
                await session.commit()
                await session.refresh(entry)
                return str(entry.id)
        except Exception as e:
            self.logger.error(f"Failed to store knowledge entry: {e}")
            return None
    
    async def health_check(self) -> bool:
        """Check SQL Server health"""
        try:
            result = await self.execute_query("SELECT 1 as health_check")
            return len(result.data) == 1
        except Exception:
            return False

class MongoDBManager(DatabaseInterface):
    """MongoDB database manager"""
    
    def __init__(self, config: DatabaseConfig, database_name: str = "agent_db"):
        super().__init__(config)
        self.database_name = database_name
        self.client = None
        self.database = None
    
    async def connect(self) -> bool:
        """Establish MongoDB connection"""
        try:
            self.client = motor.motor_asyncio.AsyncIOMotorClient(
                self.config.connection_string,
                maxPoolSize=self.config.max_connections,
                serverSelectionTimeoutMS=self.config.timeout * 1000
            )
            
            self.database = self.client[self.database_name]
            
            # Test connection
            await self.client.admin.command('ping')
            
            # Create indexes for better performance
            await self._create_indexes()
            
            self.logger.info("MongoDB connection established")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to connect to MongoDB: {e}")
            return False
    
    async def disconnect(self) -> bool:
        """Close MongoDB connection"""
        try:
            if self.client:
                self.client.close()
            self.logger.info("MongoDB connection closed")
            return True
        except Exception as e:
            self.logger.error(f"Error closing MongoDB connection: {e}")
            return False
    
    async def _create_indexes(self):
        """Create database indexes for optimization"""
        collections_indexes = {
            'conversations': [
                [('agent_id', 1), ('timestamp', -1)],
                [('session_id', 1)],
                [('user_id', 1)]
            ],
            'agent_states': [
                [('agent_id', 1), ('timestamp', -1)],
                [('state_type', 1)]
            ],
            'knowledge_documents': [
                [('category', 1)],
                [('tags', 1)],
                [('created_at', -1)],
                [('title', 'text'), ('content', 'text')]  # Text index for search
            ]
        }
        
        for collection_name, indexes in collections_indexes.items():
            collection = self.database[collection_name]
            for index in indexes:
                try:
                    await collection.create_index(index)
                except Exception as e:
                    self.logger.warning(f"Failed to create index {index} on {collection_name}: {e}")
    
    async def execute_query(self, query: Dict[str, Any], collection: str, 
                          operation: str = "find", params: Dict[str, Any] = None) -> QueryResult:
        """Execute MongoDB query"""
        start_time = asyncio.get_event_loop().time()
        
        try:
            coll = self.database[collection]
            data = []
            
            if operation == "find":
                cursor = coll.find(query, params or {})
                data = await cursor.to_list(length=None)
            elif operation == "find_one":
                result = await coll.find_one(query, params or {})
                data = [result] if result else []
            elif operation == "insert_one":
                result = await coll.insert_one(query)
                data = [{"inserted_id": str(result.inserted_id)}]
            elif operation == "insert_many":
                result = await coll.insert_many(query)
                data = [{"inserted_ids": [str(id) for id in result.inserted_ids]}]
            elif operation == "update_one":
                result = await coll.update_one(query, params or {})
                data = [{"modified_count": result.modified_count}]
            elif operation == "update_many":
                result = await coll.update_many(query, params or {})
                data = [{"modified_count": result.modified_count}]
            elif operation == "delete_one":
                result = await coll.delete_one(query)
                data = [{"deleted_count": result.deleted_count}]
            elif operation == "delete_many":
                result = await coll.delete_many(query)
                data = [{"deleted_count": result.deleted_count}]
            elif operation == "aggregate":
                cursor = coll.aggregate(query)
                data = await cursor.to_list(length=None)
            
            execution_time = asyncio.get_event_loop().time() - start_time
            
            # Convert ObjectId to string for JSON serialization
            for item in data:
                if isinstance(item, dict) and '_id' in item:
                    item['_id'] = str(item['_id'])
            
            return QueryResult(
                data=data,
                metadata={"collection": collection, "operation": operation, "count": len(data)},
                execution_time=execution_time,
                source_database="mongodb",
                query_type="nosql"
            )
            
        except Exception as e:
            execution_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"MongoDB query failed: {e}")
            return QueryResult(
                data=[],
                metadata={"error": str(e), "collection": collection, "operation": operation},
                execution_time=execution_time,
                source_database="mongodb",
                query_type="nosql"
            )
    
    async def store_conversation(self, agent_id: str, session_id: str, user_id: str,
                               message: str, response: str, metadata: Dict[str, Any] = None) -> str:
        """Store conversation data"""
        conversation_doc = {
            "agent_id": agent_id,
            "session_id": session_id,
            "user_id": user_id,
            "message": message,
            "response": response,
            "timestamp": datetime.utcnow(),
            "metadata": metadata or {}
        }
        
        result = await self.execute_query(
            conversation_doc, 
            "conversations", 
            "insert_one"
        )
        
        return result.data[0]["inserted_id"] if result.data else None
    
    async def store_agent_state(self, agent_id: str, state_type: str, 
                              state_data: Dict[str, Any]) -> str:
        """Store agent state"""
        state_doc = {
            "agent_id": agent_id,
            "state_type": state_type,
            "state_data": state_data,
            "timestamp": datetime.utcnow()
        }
        
        result = await self.execute_query(
            state_doc,
            "agent_states",
            "insert_one"
        )
        
        return result.data[0]["inserted_id"] if result.data else None
    
    async def get_conversation_history(self, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """Get conversation history"""
        query = {"session_id": session_id}
        result = await self.execute_query(
            query,
            "conversations",
            "find",
            {"sort": [("timestamp", -1)], "limit": limit}
        )
        
        return result.data
    
    async def search_knowledge_documents(self, search_term: str, category: str = None) -> List[Dict[str, Any]]:
        """Search knowledge documents using text search"""
        query = {"$text": {"$search": search_term}}
        
        if category:
            query["category"] = category
        
        result = await self.execute_query(
            query,
            "knowledge_documents",
            "find",
            {"score": {"$meta": "textScore"}, "sort": [("score", {"$meta": "textScore"})]}
        )
        
        return result.data
    
    async def health_check(self) -> bool:
        """Check MongoDB health"""
        try:
            await self.client.admin.command('ping')
            return True
        except Exception:
            return False

class ChromaDBManager:
    """ChromaDB vector database manager"""
    
    def __init__(self, persist_directory: str = "./chroma_db", collection_name: str = "agent_knowledge"):
        self.persist_directory = persist_directory
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.logger = logging.getLogger(self.__class__.__name__)
    
    async def connect(self) -> bool:
        """Initialize ChromaDB client"""
        try:
            self.client = chromadb.PersistentClient(
                path=self.persist_directory,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # Get or create collection
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "Agent knowledge base embeddings"}
            )
            
            self.logger.info(f"ChromaDB initialized with collection: {self.collection_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to initialize ChromaDB: {e}")
            return False
    
    async def add_documents(self, documents: List[str], metadatas: List[Dict[str, Any]] = None,
                          ids: List[str] = None) -> bool:
        """Add documents to vector database"""
        try:
            if not ids:
                ids = [f"doc_{i}_{datetime.utcnow().timestamp()}" for i in range(len(documents))]
            
            if not metadatas:
                metadatas = [{"source": "agent_upload"} for _ in documents]
            
            # Generate embeddings
            embeddings = await asyncio.to_thread(
                self.embedding_model.encode,
                documents,
                convert_to_tensor=False
            )
            
            # Add to collection
            await asyncio.to_thread(
                self.collection.add,
                embeddings=embeddings.tolist(),
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            self.logger.info(f"Added {len(documents)} documents to ChromaDB")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to add documents to ChromaDB: {e}")
            return False
    
    async def similarity_search(self, query: str, n_results: int = 5, 
                              where: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Perform similarity search"""
        try:
            # Generate query embedding
            query_embedding = await asyncio.to_thread(
                self.embedding_model.encode,
                [query],
                convert_to_tensor=False
            )
            
            # Search collection
            results = await asyncio.to_thread(
                self.collection.query,
                query_embeddings=query_embedding.tolist(),
                n_results=n_results,
                where=where,
                include=["documents", "metadatas", "distances"]
            )
            
            # Format results
            formatted_results = []
            for i in range(len(results["documents"][0])):
                formatted_results.append({
                    "document": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "distance": results["distances"][0][i],
                    "similarity": 1 - results["distances"][0][i]  # Convert distance to similarity
                })
            
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"Similarity search failed: {e}")
            return []
    
    async def delete_documents(self, ids: List[str]) -> bool:
        """Delete documents by IDs"""
        try:
            await asyncio.to_thread(self.collection.delete, ids=ids)
            self.logger.info(f"Deleted {len(ids)} documents from ChromaDB")
            return True
        except Exception as e:
            self.logger.error(f"Failed to delete documents: {e}")
            return False
    
    async def get_collection_stats(self) -> Dict[str, Any]:
        """Get collection statistics"""
        try:
            count = await asyncio.to_thread(self.collection.count)
            return {
                "document_count": count,
                "collection_name": self.collection_name,
                "embedding_model": self.embedding_model.get_sentence_embedding_dimension()
            }
        except Exception as e:
            self.logger.error(f"Failed to get collection stats: {e}")
            return {}

class ElasticsearchManager:
    """Elasticsearch full-text search and analytics manager"""
    
    def __init__(self, config: DatabaseConfig, index_prefix: str = "agent"):
        self.config = config
        self.index_prefix = index_prefix
        self.client = None
        self.logger = logging.getLogger(self.__class__.__name__)
    
    async def connect(self) -> bool:
        """Connect to Elasticsearch"""
        try:
            # Parse connection string for Elasticsearch
            if self.config.connection_string.startswith("https://"):
                # Cloud deployment
                self.client = AsyncElasticsearch(
                    [self.config.connection_string],
                    timeout=self.config.timeout,
                    max_retries=self.config.retry_attempts
                )
            else:
                # Local deployment
                host, port = self.config.connection_string.split(":")
                self.client = AsyncElasticsearch(
                    [{"host": host, "port": int(port)}],
                    timeout=self.config.timeout,
                    max_retries=self.config.retry_attempts
                )
            
            # Test connection
            await self.client.ping()
            
            # Create index templates
            await self._create_index_templates()
            
            self.logger.info("Elasticsearch connection established")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to connect to Elasticsearch: {e}")
            return False
    
    async def disconnect(self) -> bool:
        """Close Elasticsearch connection"""
        try:
            if self.client:
                await self.client.close()
            self.logger.info("Elasticsearch connection closed")
            return True
        except Exception as e:
            self.logger.error(f"Error closing Elasticsearch connection: {e}")
            return False
    
    async def _create_index_templates(self):
        """Create index templates for agent data"""
        
        # Conversation logs template
        conversation_template = {
            "index_patterns": [f"{self.index_prefix}-conversations-*"],
            "template": {
                "mappings": {
                    "properties": {
                        "agent_id": {"type": "keyword"},
                        "session_id": {"type": "keyword"},
                        "user_id": {"type": "keyword"},
                        "message": {"type": "text", "analyzer": "standard"},
                        "response": {"type": "text", "analyzer": "standard"},
                        "timestamp": {"type": "date"},
                        "processing_time": {"type": "float"},
                        "intent": {"type": "keyword"},
                        "sentiment": {"type": "keyword"},
                        "metadata": {"type": "object", "dynamic": True}
                    }
                },
                "settings": {
                    "number_of_shards": 1,
                    "number_of_replicas": 0,
                    "refresh_interval": "1s"
                }
            }
        }
        
        # Knowledge base template
        knowledge_template = {
            "index_patterns": [f"{self.index_prefix}-knowledge-*"],
            "template": {
                "mappings": {
                    "properties": {
                        "title": {"type": "text", "analyzer": "standard"},
                        "content": {"type": "text", "analyzer": "standard"},
                        "category": {"type": "keyword"},
                        "tags": {"type": "keyword"},
                        "created_at": {"type": "date"},
                        "updated_at": {"type": "date"},
                        "source": {"type": "keyword"},
                        "relevance_score": {"type": "float"},
                        "embedding_id": {"type": "keyword"}
                    }
                },
                "settings": {
                    "number_of_shards": 1,
                    "number_of_replicas": 0
                }
            }
        }
        
        try:
            await self.client.indices.put_index_template(
                name=f"{self.index_prefix}-conversations",
                body=conversation_template
            )
            
            await self.client.indices.put_index_template(
                name=f"{self.index_prefix}-knowledge",
                body=knowledge_template
            )
            
            self.logger.info("Index templates created successfully")
            
        except Exception as e:
            self.logger.warning(f"Failed to create index templates: {e}")
    
    async def index_document(self, index_suffix: str, document: Dict[str, Any], 
                           doc_id: str = None) -> bool:
        """Index a single document"""
        try:
            index_name = f"{self.index_prefix}-{index_suffix}"
            
            if doc_id:
                await self.client.index(
                    index=index_name,
                    id=doc_id,
                    body=document
                )
            else:
                await self.client.index(
                    index=index_name,
                    body=document
                )
            
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to index document: {e}")
            return False
    
    async def search_documents(self, index_suffix: str, query: Dict[str, Any], 
                             size: int = 10) -> List[Dict[str, Any]]:
        """Search documents using Elasticsearch query DSL"""
        try:
            index_name = f"{self.index_prefix}-{index_suffix}"
            
            response = await self.client.search(
                index=index_name,
                body=query,
                size=size
            )
            
            results = []
            for hit in response["hits"]["hits"]:
                result = {
                    "id": hit["_id"],
                    "score": hit["_score"],
                    "source": hit["_source"]
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            self.logger.error(f"Search failed: {e}")
            return []
    
    async def full_text_search(self, index_suffix: str, search_text: str, 
                             fields: List[str] = None, size: int = 10) -> List[Dict[str, Any]]:
        """Perform full-text search"""
        fields = fields or ["title^2", "content"]  # Boost title matches
        
        query = {
            "query": {
                "multi_match": {
                    "query": search_text,
                    "fields": fields,
                    "type": "best_fields",
                    "fuzziness": "AUTO"
                }
            },
            "highlight": {
                "fields": {
                    "title": {},
                    "content": {"fragment_size": 150, "number_of_fragments": 3}
                }
            }
        }
        
        return await self.search_documents(index_suffix, query, size)
    
    async def aggregate_data(self, index_suffix: str, aggregation: Dict[str, Any]) -> Dict[str, Any]:
        """Perform data aggregation"""
        try:
            index_name = f"{self.index_prefix}-{index_suffix}"
            
            response = await self.client.search(
                index=index_name,
                body={"aggs": aggregation, "size": 0}
            )
            
            return response.get("aggregations", {})
            
        except Exception as e:
            self.logger.error(f"Aggregation failed: {e}")
            return {}
    
    async def health_check(self) -> bool:
        """Check Elasticsearch health"""
        try:
            health = await self.client.cluster.health()
            return health["status"] in ["green", "yellow"]
        except Exception:
            return False

class UnifiedDatabaseManager:
    """Unified manager for all database types"""
    
    def __init__(self):
        self.sql_manager = None
        self.mongo_manager = None
        self.chroma_manager = None
        self.elasticsearch_manager = None
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # OpenAI client for embeddings
        self.openai_client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    async def initialize_databases(self, configs: Dict[str, Any]) -> Dict[str, bool]:
        """Initialize all configured databases"""
        results = {}
        
        # Initialize SQL Server
        if "mssql" in configs:
            self.sql_manager = SQLServerManager(configs["mssql"])
            results["mssql"] = await self.sql_manager.connect()
        
        # Initialize MongoDB
        if "mongodb" in configs:
            self.mongo_manager = MongoDBManager(
                configs["mongodb"],
                configs.get("mongodb_database", "agent_db")
            )
            results["mongodb"] = await self.mongo_manager.connect()
        
        # Initialize ChromaDB
        if "chromadb" in configs:
            self.chroma_manager = ChromaDBManager(
                configs["chromadb"].get("persist_directory", "./chroma_db"),
                configs["chromadb"].get("collection_name", "agent_knowledge")
            )
            results["chromadb"] = await self.chroma_manager.connect()
        
        # Initialize Elasticsearch
        if "elasticsearch" in configs:
            self.elasticsearch_manager = ElasticsearchManager(
                configs["elasticsearch"],
                configs.get("es_index_prefix", "agent")
            )
            results["elasticsearch"] = await self.elasticsearch_manager.connect()
        
        return results
    
    async def store_knowledge_with_embeddings(self, title: str, content: str, 
                                            category: str = None, tags: List[str] = None) -> Dict[str, Any]:
        """Store knowledge across multiple databases with embeddings"""
        
        results = {"success": False, "stored_in": []}
        
        try:
            # Generate embedding using OpenAI
            embedding_response = await self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=f"{title}\n\n{content}"
            )
            embedding_vector = embedding_response.data[0].embedding
            
            # Store in SQL Server (structured metadata)
            if self.sql_manager:
                embedding_id = f"embedding_{datetime.utcnow().timestamp()}"
                sql_id = await self.sql_manager.store_knowledge_entry(
                    title, content, category, tags, embedding_id
                )
                if sql_id:
                    results["stored_in"].append("mssql")
                    results["sql_id"] = sql_id
            
            # Store in MongoDB (flexible document storage)
            if self.mongo_manager:
                mongo_doc = {
                    "title": title,
                    "content": content,
                    "category": category,
                    "tags": tags or [],
                    "created_at": datetime.utcnow(),
                    "embedding_vector": embedding_vector,
                    "sql_reference": results.get("sql_id")
                }
                
                mongo_result = await self.mongo_manager.execute_query(
                    mongo_doc, "knowledge_documents", "insert_one"
                )
                
                if mongo_result.data:
                    results["stored_in"].append("mongodb")
                    results["mongo_id"] = mongo_result.data[0]["inserted_id"]
            
            # Store in ChromaDB (vector search)
            if self.chroma_manager:
                chroma_success = await self.chroma_manager.add_documents(
                    documents=[f"{title}\n\n{content}"],
                    metadatas=[{
                        "title": title,
                        "category": category or "general",
                        "tags": ",".join(tags) if tags else "",
                        "sql_id": results.get("sql_id", ""),
                        "mongo_id": results.get("mongo_id", "")
                    }],
                    ids=[f"knowledge_{datetime.utcnow().timestamp()}"]
                )
                
                if chroma_success:
                    results["stored_in"].append("chromadb")
            
            # Store in Elasticsearch (full-text search)
            if self.elasticsearch_manager:
                es_doc = {
                    "title": title,
                    "content": content,
                    "category": category,
                    "tags": tags or [],
                    "created_at": datetime.utcnow().isoformat(),
                    "relevance_score": 1.0,
                    "sql_reference": results.get("sql_id"),
                    "mongo_reference": results.get("mongo_id")
                }
                
                es_success = await self.elasticsearch_manager.index_document(
                    "knowledge", es_doc, f"knowledge_{datetime.utcnow().timestamp()}"
                )
                
                if es_success:
                    results["stored_in"].append("elasticsearch")
            
            results["success"] = len(results["stored_in"]) > 0
            
        except Exception as e:
            self.logger.error(f"Failed to store knowledge with embeddings: {e}")
            results["error"] = str(e)
        
        return results
    
    async def intelligent_search(self, query: str, search_type: str = "hybrid", 
                               limit: int = 10) -> Dict[str, Any]:
        """Perform intelligent search across multiple databases"""
        
        results = {
            "query": query,
            "search_type": search_type,
            "results": [],
            "sources": []
        }
        
        try:
            if search_type in ["semantic", "hybrid"] and self.chroma_manager:
                # Vector similarity search
                vector_results = await self.chroma_manager.similarity_search(
                    query, n_results=limit
                )
                
                for result in vector_results:
                    results["results"].append({
                        "source": "chromadb",
                        "type": "semantic",
                        "content": result["document"],
                        "metadata": result["metadata"],
                        "score": result["similarity"]
                    })
                
                results["sources"].append("chromadb")
            
            if search_type in ["fulltext", "hybrid"] and self.elasticsearch_manager:
                # Full-text search
                es_results = await self.elasticsearch_manager.full_text_search(
                    "knowledge", query, size=limit
                )
                
                for result in es_results:
                    results["results"].append({
                        "source": "elasticsearch",
                        "type": "fulltext",
                        "content": result["source"],
                        "score": result["score"] / 100,  # Normalize ES scores
                        "highlights": result.get("highlight", {})
                    })
                
                results["sources"].append("elasticsearch")
            
            if search_type in ["structured", "hybrid"] and self.mongo_manager:
                # MongoDB text search
                mongo_results = await self.mongo_manager.search_knowledge_documents(
                    query
                )
                
                for result in mongo_results[:limit]:
                    results["results"].append({
                        "source": "mongodb",
                        "type": "structured",
                        "content": result,
                        "score": result.get("score", 0.5)
                    })
                
                results["sources"].append("mongodb")
            
            # Sort results by score
            results["results"] = sorted(
                results["results"], 
                key=lambda x: x["score"], 
                reverse=True
            )[:limit]
            
        except Exception as e:
            self.logger.error(f"Intelligent search failed: {e}")
            results["error"] = str(e)
        
        return results
    
    async def get_agent_analytics(self, agent_id: str, days: int = 7) -> Dict[str, Any]:
        """Get comprehensive agent analytics"""
        
        analytics = {
            "agent_id": agent_id,
            "period_days": days,
            "sql_analytics": {},
            "mongo_analytics": {},
            "elasticsearch_analytics": {}
        }
        
        try:
            start_date = datetime.utcnow() - timedelta(days=days)
            
            # SQL Server analytics
            if self.sql_manager:
                sql_query = """
                SELECT 
                    COUNT(*) as total_interactions,
                    AVG(processing_time) as avg_processing_time,
                    SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successful_interactions,
                    COUNT(DISTINCT session_id) as unique_sessions
                FROM agent_interactions 
                WHERE session_id IN (
                    SELECT id FROM agent_sessions 
                    WHERE agent_id = :agent_id AND session_start >= :start_date
                )
                """
                
                sql_result = await self.sql_manager.execute_query(
                    sql_query, 
                    {"agent_id": agent_id, "start_date": start_date}
                )
                
                if sql_result.data:
                    analytics["sql_analytics"] = sql_result.data[0]
            
            # MongoDB analytics
            if self.mongo_manager:
                mongo_pipeline = [
                    {"$match": {
                        "agent_id": agent_id,
                        "timestamp": {"$gte": start_date}
                    }},
                    {"$group": {
                        "_id": None,
                        "total_conversations": {"$sum": 1},
                        "unique_users": {"$addToSet": "$user_id"},
                        "avg_response_length": {"$avg": {"$strLenCP": "$response"}}
                    }},
                    {"$project": {
                        "total_conversations": 1,
                        "unique_users": {"$size": "$unique_users"},
                        "avg_response_length": 1
                    }}
                ]
                
                mongo_result = await self.mongo_manager.execute_query(
                    mongo_pipeline, "conversations", "aggregate"
                )
                
                if mongo_result.data:
                    analytics["mongo_analytics"] = mongo_result.data[0]
            
            # Elasticsearch analytics
            if self.elasticsearch_manager:
                es_aggregation = {
                    "date_histogram": {
                        "field": "timestamp",
                        "calendar_interval": "day"
                    },
                    "aggs": {
                        "avg_processing_time": {
                            "avg": {"field": "processing_time"}
                        },
                        "intent_distribution": {
                            "terms": {"field": "intent"}
                        }
                    }
                }
                
                es_result = await self.elasticsearch_manager.aggregate_data(
                    "conversations", es_aggregation
                )
                
                analytics["elasticsearch_analytics"] = es_result
            
        except Exception as e:
            self.logger.error(f"Analytics generation failed: {e}")
            analytics["error"] = str(e)
        
        return analytics
    
    async def health_check_all(self) -> Dict[str, bool]:
        """Check health of all connected databases"""
        health_status = {}
        
        if self.sql_manager:
            health_status["mssql"] = await self.sql_manager.health_check()
        
        if self.mongo_manager:
            health_status["mongodb"] = await self.mongo_manager.health_check()
        
        if self.chroma_manager:
            try:
                stats = await self.chroma_manager.get_collection_stats()
                health_status["chromadb"] = bool(stats)
            except:
                health_status["chromadb"] = False
        
        if self.elasticsearch_manager:
            health_status["elasticsearch"] = await self.elasticsearch_manager.health_check()
        
        return health_status
    
    async def cleanup_and_close(self):
        """Clean up and close all database connections"""
        if self.sql_manager:
            await self.sql_manager.disconnect()
        
        if self.mongo_manager:
            await self.mongo_manager.disconnect()
        
        if self.elasticsearch_manager:
            await self.elasticsearch_manager.disconnect()

# Usage example and testing
async def main():
    """Example usage of the unified database manager"""
    
    # Database configurations
    configs = {
        "mssql": DatabaseConfig(
            connection_string=os.getenv('MSSQL_CONNECTION_STRING', 
                'mssql+aiodbc://username:password@server/database?driver=ODBC+Driver+17+for+SQL+Server')
        ),
        "mongodb": DatabaseConfig(
            connection_string=os.getenv('MONGODB_CONNECTION_STRING', 
                'mongodb://localhost:27017/')
        ),
        "chromadb": {
            "persist_directory": "./agent_chroma_db",
            "collection_name": "agent_knowledge_base"
        },
        "elasticsearch": DatabaseConfig(
            connection_string=os.getenv('ELASTICSEARCH_URL', 'localhost:9200')
        )
    }
    
    # Initialize unified manager
    db_manager = UnifiedDatabaseManager()
    
    print("Initializing databases...")
    init_results = await db_manager.initialize_databases(configs)
    print(f"Database initialization results: {init_results}")
    
    # Test knowledge storage
    print("\nStoring knowledge with embeddings...")
    knowledge_result = await db_manager.store_knowledge_with_embeddings(
        title="Python Programming Best Practices",
        content="Python is a versatile programming language. Best practices include using virtual environments, following PEP 8 style guide, writing unit tests, and using type hints for better code documentation.",
        category="programming",
        tags=["python", "best-practices", "coding"]
    )
    print(f"Knowledge storage result: {knowledge_result}")
    
    # Test intelligent search
    print("\nPerforming intelligent search...")
    search_results = await db_manager.intelligent_search(
        "Python programming best practices",
        search_type="hybrid",
        limit=5
    )
    print(f"Search results: {len(search_results['results'])} found")
    for result in search_results['results']:
        print(f"  - Source: {result['source']}, Score: {result['score']:.3f}")
    
    # Test analytics
    print("\nGenerating agent analytics...")
    analytics = await db_manager.get_agent_analytics("test_agent_001")
    print(f"Analytics: {analytics}")
    
    # Health check
    print("\nPerforming health check...")
    health_status = await db_manager.health_check_all()
    print(f"Health status: {health_status}")
    
    # Cleanup
    await db_manager.cleanup_and_close()
    print("Database connections closed")

if __name__ == "__main__":
    asyncio.run(main())
````

## Conclusion

The comprehensive database integration framework demonstrates the sophisticated data layer required for modern AI agents, seamlessly combining SQL, NoSQL, vector, and search databases to create a robust knowledge and interaction management system.

**Multi-Database Architecture** enables agents to leverage the strengths of different database technologies - SQL Server for structured transactions, MongoDB for flexible document storage, ChromaDB for semantic vector search, and Elasticsearch for full-text search and analytics. This polyglot persistence approach optimizes performance and capabilities for diverse data types and access patterns.

**Vector Database Integration** represents a crucial advancement for AI agents, enabling semantic search and similarity matching that goes beyond traditional keyword-based queries. The integration of ChromaDB with embedding generation creates a powerful knowledge retrieval system that understands context and meaning.

**Unified Management Layer** abstracts the complexity of multiple database systems while maintaining their individual strengths. The standardized interface enables agents to work with heterogeneous data sources without requiring database-specific knowledge, facilitating development and maintenance.

**Advanced Query Capabilities** combine structured queries, document searches, vector similarity matching, and full-text search to provide comprehensive data retrieval options. The intelligent search functionality automatically leverages multiple databases to deliver the most relevant results.

**Performance Optimization** through connection pooling, async operations, indexing strategies, and query optimization ensures scalable performance under high-load conditions. The framework supports both development and production environments with appropriate configuration options.

**Analytics and Monitoring** capabilities provide insights into agent behavior, performance metrics, and usage patterns across all database systems. This telemetry enables optimization and troubleshooting while supporting compliance and audit requirements.

**Production Considerations** include robust error handling, health monitoring, backup strategies, and security measures. The framework provides a foundation for enterprise-grade agent deployments while maintaining flexibility for experimentation and rapid prototyping.

This integrated approach creates a powerful data foundation that enables AI agents to maintain context, learn from interactions, and access relevant knowledge efficiently, forming the backbone of sophisticated agent-based applications and services.