<small>Claude 3.7 Sonnet Thinking</small>
# 02. Databases for Agents

## Key Terms

- **SQL Databases**: Relational database systems that use Structured Query Language for managing data in tables with predefined schemas.
- **NoSQL Databases**: Non-relational databases designed for flexible schemas, horizontal scaling, and specialized data models.
- **Vector Databases**: Databases optimized for storing and querying high-dimensional vector embeddings used in AI applications.
- **Embeddings**: High-dimensional vector representations that capture semantic meaning of text, images, or other data.
- **Knowledge Base**: Structured repository of information that AI agents can query to retrieve facts and context.
- **RAG (Retrieval-Augmented Generation)**: Technique combining retrieval mechanisms with generative AI to improve responses with external knowledge.
- **Semantic Search**: Search methodology that understands intent and contextual meaning rather than exact keyword matching.
- **Index**: Data structure to optimize search operations on database fields.

## Database Types in AI Context

AI agents require different data storage solutions depending on use cases, performance needs, and data types. Understanding the strengths and limitations of each database type is essential for building effective agent systems.

### SQL Databases for AI Agents

Relational databases provide structured storage with ACID compliance and are ideal for transactional data and complex relationships between entities.

```python
import os
import pyodbc
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

class SQLAgentDataStore:
    """MS SQL database integration for AI agents"""
    
    def __init__(self):
        """Initialize SQL connection from environment variables"""
        self.conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={os.getenv('SQL_SERVER')};"
            f"DATABASE={os.getenv('SQL_DATABASE')};"
            f"UID={os.getenv('SQL_USERNAME')};"
            f"PWD={os.getenv('SQL_PASSWORD')};"
        )
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
    def connect(self):
        """Establish database connection"""
        try:
            return pyodbc.connect(self.conn_str)
        except pyodbc.Error as e:
            print(f"Connection error: {e}")
            return None
            
    def execute_query(self, query, params=None):
        """Execute SQL query and return results"""
        conn = self.connect()
        if not conn:
            return None
            
        try:
            df = pd.read_sql(query, conn, params=params)
            return df
        except Exception as e:
            print(f"Query execution error: {e}")
            return None
        finally:
            conn.close()
            
    def get_schema_info(self):
        """Extract database schema for context building"""
        tables_query = """
        SELECT 
            t.name AS table_name,
            c.name AS column_name,
            ty.name AS data_type,
            c.max_length,
            c.is_nullable,
            CASE WHEN pk.column_id IS NOT NULL THEN 1 ELSE 0 END AS is_primary_key
        FROM 
            sys.tables t
            INNER JOIN sys.columns c ON t.object_id = c.object_id
            INNER JOIN sys.types ty ON c.user_type_id = ty.user_type_id
            LEFT JOIN sys.index_columns pk ON 
                c.object_id = pk.object_id AND 
                c.column_id = pk.column_id AND
                pk.index_id = 1
        ORDER BY 
            t.name, c.column_id;
        """
        
        return self.execute_query(tables_query)
        
    def generate_sql_from_question(self, question, schema_context=None):
        """Use LLM to generate SQL from natural language question"""
        if not schema_context:
            schema_df = self.get_schema_info()
            schema_context = schema_df.to_string(index=False) if schema_df is not None else ""
        
        prompt = f"""
        Database Schema:
        {schema_context}
        
        Based on the database schema above, write a SQL query to answer this question:
        "{question}"
        
        Return only the SQL query without explanation.
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a SQL expert. Write correct SQL queries based on the given database schema."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        
        return response.choices[0].message.content.strip()
    
    def answer_question(self, question):
        """End-to-end process to answer questions using the database"""
        # Get schema information
        schema_df = self.get_schema_info()
        schema_context = schema_df.to_string(index=False) if schema_df is not None else ""
        
        # Generate SQL query
        sql_query = self.generate_sql_from_question(question, schema_context)
        
        try:
            # Execute the query
            results = self.execute_query(sql_query)
            
            if results is None or results.empty:
                return "No results found for this query."
                
            # Format the results
            result_str = results.to_string(index=False)
            
            # Use LLM to interpret results
            prompt = f"""
            Question: {question}
            
            SQL Query: {sql_query}
            
            Query Results:
            {result_str}
            
            Based on the query results above, please provide a clear answer to the question.
            """
            
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant who explains database query results."},
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"Error executing query: {str(e)}"

# Example usage
if __name__ == "__main__":
    agent = SQLAgentDataStore()
    
    # Example question
    question = "What are the top 5 customers by total order value?"
    print(f"Question: {question}")
    
    answer = agent.answer_question(question)
    print(f"Answer: {answer}")
```

### NoSQL Databases with MongoDB

MongoDB offers flexibility for storing semi-structured data, document-oriented storage, and horizontal scalability, which is valuable for agents that need to persist varied data types.

```python
import os
from typing import Dict, List, Any, Optional
from pymongo import MongoClient
from pymongo.collection import Collection
from dotenv import load_dotenv
from datetime import datetime

# Load environment variables
load_dotenv()

class MongoAgentStore:
    """MongoDB integration for AI agent data storage"""
    
    def __init__(self, db_name: str = "agent_db"):
        """Initialize MongoDB connection from environment variables"""
        mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
        self.client = MongoClient(mongo_uri)
        self.db = self.client[db_name]
        
    def get_collection(self, collection_name: str) -> Collection:
        """Get or create a collection"""
        return self.db[collection_name]
        
    def store_conversation(self, user_id: str, messages: List[Dict[str, Any]]) -> str:
        """Store conversation history"""
        conversations = self.get_collection("conversations")
        
        # Create a new conversation document
        conversation_doc = {
            "user_id": user_id,
            "messages": messages,
            "created_at": datetime.now(),
            "updated_at": datetime.now()
        }
        
        result = conversations.insert_one(conversation_doc)
        return str(result.inserted_id)
        
    def update_conversation(self, conversation_id: str, messages: List[Dict[str, Any]]) -> bool:
        """Update an existing conversation with new messages"""
        conversations = self.get_collection("conversations")
        
        result = conversations.update_one(
            {"_id": conversation_id},
            {
                "$set": {
                    "messages": messages,
                    "updated_at": datetime.now()
                }
            }
        )
        
        return result.modified_count > 0
        
    def get_conversation(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve a conversation by ID"""
        conversations = self.get_collection("conversations")
        return conversations.find_one({"_id": conversation_id})
        
    def get_user_conversations(self, user_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent conversations for a user"""
        conversations = self.get_collection("conversations")
        return list(
            conversations.find(
                {"user_id": user_id}
            ).sort("updated_at", -1).limit(limit)
        )
        
    def store_agent_state(self, agent_id: str, state: Dict[str, Any]) -> bool:
        """Store or update agent state"""
        agents = self.get_collection("agent_states")
        
        # Upsert agent state
        result = agents.update_one(
            {"agent_id": agent_id},
            {"$set": {**state, "updated_at": datetime.now()}},
            upsert=True
        )
        
        return result.acknowledged
        
    def get_agent_state(self, agent_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve agent state by ID"""
        agents = self.get_collection("agent_states")
        return agents.find_one({"agent_id": agent_id})
        
    def store_tool_execution(self, 
                            agent_id: str,
                            tool_name: str,
                            inputs: Dict[str, Any],
                            outputs: Dict[str, Any],
                            status: str,
                            error: Optional[str] = None) -> str:
        """Log tool execution for auditing and improvement"""
        tool_logs = self.get_collection("tool_executions")
        
        log_entry = {
            "agent_id": agent_id,
            "tool_name": tool_name,
            "inputs": inputs,
            "outputs": outputs,
            "status": status,
            "error": error,
            "timestamp": datetime.now()
        }
        
        result = tool_logs.insert_one(log_entry)
        return str(result.inserted_id)
        
    def store_feedback(self, conversation_id: str, rating: int, feedback: Optional[str] = None) -> str:
        """Store user feedback for a conversation"""
        feedbacks = self.get_collection("feedback")
        
        feedback_doc = {
            "conversation_id": conversation_id,
            "rating": rating,
            "feedback": feedback,
            "timestamp": datetime.now()
        }
        
        result = feedbacks.insert_one(feedback_doc)
        return str(result.inserted_id)

    def aggregate_feedback_stats(self) -> Dict[str, Any]:
        """Aggregate feedback statistics"""
        feedbacks = self.get_collection("feedback")
        
        pipeline = [
            {
                "$group": {
                    "_id": None,
                    "avg_rating": {"$avg": "$rating"},
                    "count": {"$sum": 1},
                    "ratings": {
                        "$push": "$rating"
                    }
                }
            },
            {
                "$project": {
                    "_id": 0,
                    "avg_rating": 1,
                    "count": 1,
                    "distribution": {
                        "1": {"$size": {"$filter": {"input": "$ratings", "cond": {"$eq": ["$$this", 1]}}}},
                        "2": {"$size": {"$filter": {"input": "$ratings", "cond": {"$eq": ["$$this", 2]}}}},
                        "3": {"$size": {"$filter": {"input": "$ratings", "cond": {"$eq": ["$$this", 3]}}}},
                        "4": {"$size": {"$filter": {"input": "$ratings", "cond": {"$eq": ["$$this", 4]}}}},
                        "5": {"$size": {"$filter": {"input": "$ratings", "cond": {"$eq": ["$$this", 5]}}}}
                    }
                }
            }
        ]
        
        results = list(feedbacks.aggregate(pipeline))
        return results[0] if results else {"avg_rating": 0, "count": 0, "distribution": {}}

# Example usage
if __name__ == "__main__":
    store = MongoAgentStore()
    
    # Example storing a conversation
    user_id = "user123"
    messages = [
        {"role": "user", "content": "Can you help me analyze my sales data?"},
        {"role": "assistant", "content": "I'd be happy to help analyze your sales data. What specific information are you looking for?"}
    ]
    
    conversation_id = store.store_conversation(user_id, messages)
    print(f"Stored conversation with ID: {conversation_id}")
    
    # Example storing agent state
    agent_id = "sales_analysis_agent"
    state = {
        "current_task": "data_analysis",
        "datasets_loaded": ["sales_2023", "inventory_2023"],
        "analysis_stage": "correlation_analysis",
        "user_preferences": {
            "chart_type": "bar",
            "time_period": "quarterly"
        }
    }
    
    store.store_agent_state(agent_id, state)
    print(f"Stored state for agent: {agent_id}")
    
    # Example logging tool execution
    tool_execution_id = store.store_tool_execution(
        agent_id=agent_id,
        tool_name="data_analyzer",
        inputs={"dataset": "sales_2023", "analysis_type": "trend"},
        outputs={"trend": "upward", "confidence": 0.87},
        status="success"
    )
    print(f"Logged tool execution: {tool_execution_id}")
```

### Vector Databases with Chroma

Vector databases are essential for storing embeddings used in semantic search and RAG systems, enabling AI agents to retrieve relevant information based on meaning rather than just keywords.

```python
import os
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions
import openai
import uuid
import pandas as pd
from tqdm import tqdm
import numpy as np

# Load environment variables
load_dotenv()

class VectorKnowledgeBase:
    """Vector database integration for AI agent knowledge retrieval"""
    
    def __init__(self, collection_name: str = "agent_knowledge"):
        """Initialize ChromaDB and embedding function"""
        # Set up OpenAI client
        openai.api_key = os.getenv("OPENAI_API_KEY")
        
        # Set up embedding function
        self.ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name="text-embedding-3-small"
        )
        
        # Initialize ChromaDB
        self.client = chromadb.PersistentClient(path="./chroma_db")
        
        # Get or create collection
        try:
            self.collection = self.client.get_collection(
                name=collection_name,
                embedding_function=self.ef
            )
        except ValueError:
            self.collection = self.client.create_collection(
                name=collection_name,
                embedding_function=self.ef
            )
    
    def add_documents(self, documents: List[Dict[str, Any]]) -> List[str]:
        """
        Add documents to the vector store
        
        Each document should have:
        - content: str - The text content
        - metadata: dict - Additional metadata like source, date, etc.
        """
        ids = [str(uuid.uuid4()) for _ in range(len(documents))]
        
        contents = [doc["content"] for doc in documents]
        metadatas = [doc.get("metadata", {}) for doc in documents]
        
        self.collection.add(
            documents=contents,
            metadatas=metadatas,
            ids=ids
        )
        
        return ids
    
    def add_document_batch(self, 
                          documents: List[Dict[str, Any]], 
                          batch_size: int = 100) -> List[str]:
        """Add documents in batches to avoid memory issues"""
        all_ids = []
        
        for i in tqdm(range(0, len(documents), batch_size)):
            batch = documents[i:i + batch_size]
            ids = self.add_documents(batch)
            all_ids.extend(ids)
            
        return all_ids
    
    def import_from_csv(self, 
                       filepath: str, 
                       content_column: str,
                       chunk_size: int = 1000, 
                       batch_size: int = 100) -> int:
        """Import documents from a CSV file"""
        df = pd.read_csv(filepath)
        total_docs = 0
        
        # Process in chunks to handle large files
        for chunk_start in range(0, len(df), chunk_size):
            chunk_end = min(chunk_start + chunk_size, len(df))
            chunk = df.iloc[chunk_start:chunk_end]
            
            documents = []
            for _, row in chunk.iterrows():
                content = row[content_column]
                # Skip if content is not a string or is empty
                if not isinstance(content, str) or not content.strip():
                    continue
                    
                # Create metadata from other columns
                metadata = {}
                for col in df.columns:
                    if col != content_column and pd.notna(row[col]):
                        val = row[col]
                        # Convert numpy/pandas types to Python native types
                        if isinstance(val, (np.integer, np.floating)):
                            val = val.item()
                        elif isinstance(val, (pd.Timestamp)):
                            val = val.isoformat()
                        metadata[col] = str(val)
                
                documents.append({
                    "content": content,
                    "metadata": metadata
                })
            
            # Add batch of documents
            if documents:
                self.add_document_batch(documents, batch_size=batch_size)
                total_docs += len(documents)
        
        return total_docs
    
    def query(self, 
             query_text: str, 
             n_results: int = 5, 
             metadata_filter: Optional[Dict] = None) -> List[Dict]:
        """
        Query the vector store for semantically similar documents
        
        Args:
            query_text: The query string
            n_results: Number of results to return
            metadata_filter: Filter results by metadata fields
        
        Returns:
            List of matching documents with content and metadata
        """
        where_document = metadata_filter or {}
        
        results = self.collection.query(
            query_texts=[query_text],
            n_results=n_results,
            where=where_document
        )
        
        documents = []
        for i, doc in enumerate(results["documents"][0]):
            documents.append({
                "content": doc,
                "metadata": results["metadatas"][0][i] if results["metadatas"] else {},
                "distance": results["distances"][0][i] if "distances" in results else None
            })
        
        return documents
    
    def delete_document(self, document_id: str) -> bool:
        """Delete a document by ID"""
        try:
            self.collection.delete(ids=[document_id])
            return True
        except Exception as e:
            print(f"Error deleting document {document_id}: {e}")
            return False
            
    def update_document(self, document_id: str, content: str, metadata: Optional[Dict] = None) -> bool:
        """Update an existing document"""
        try:
            self.collection.update(
                ids=[document_id],
                documents=[content],
                metadatas=[metadata] if metadata else None
            )
            return True
        except Exception as e:
            print(f"Error updating document {document_id}: {e}")
            return False
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """Get statistics about the collection"""
        count = self.collection.count()
        
        # Sample a few embeddings to get dimensions
        sample = self.collection.get(limit=1)
        dimensions = len(self.ef(["Sample text"])[0]) if sample["ids"] else 0
        
        return {
            "document_count": count,
            "embedding_dimensions": dimensions,
            "collection_name": self.collection.name
        }

class RAGAgent:
    """Retrieval-Augmented Generation agent using vector database"""
    
    def __init__(self, kb: VectorKnowledgeBase):
        """Initialize the RAG agent with a knowledge base"""
        self.kb = kb
        self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
    def answer_question(self, 
                       question: str, 
                       n_docs: int = 3,
                       metadata_filter: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Answer questions using RAG approach
        
        Args:
            question: The user's question
            n_docs: Number of documents to retrieve
            metadata_filter: Filter for document retrieval
            
        Returns:
            Dict with answer and retrieved context
        """
        # Retrieve relevant documents
        docs = self.kb.query(question, n_results=n_docs, metadata_filter=metadata_filter)
        
        if not docs:
            return {
                "answer": "I don't have enough information to answer this question.",
                "sources": []
            }
        
        # Format context from retrieved documents
        context = "\n\n---\n\n".join([doc["content"] for doc in docs])
        
        # Create prompt with retrieved context
        prompt = f"""
        Answer the question based on the following context. If the context doesn't contain
        relevant information, just say you don't know the answer based on the available information.
        
        Context:
        {context}
        
        Question: {question}
        """
        
        # Generate answer using OpenAI
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a knowledgeable assistant that answers questions based only on the provided context."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        answer = response.choices[0].message.content
        
        # Format sources for citation
        sources = []
        for doc in docs:
            source = {
                "content_preview": doc["content"][:150] + "..." if len(doc["content"]) > 150 else doc["content"],
                "metadata": doc["metadata"]
            }
            sources.append(source)
        
        return {
            "answer": answer,
            "sources": sources
        }
    
    def improve_knowledge_base(self, question: str, feedback: str) -> str:
        """Add new knowledge to the KB based on user feedback"""
        prompt = f"""
        The user asked: "{question}"
        
        The user provided this feedback or additional information: "{feedback}"
        
        Please format this into a concise, informative document that can be added to a knowledge base.
        Focus on factual information and make it useful for future similar questions.
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a knowledge base curator that creates high-quality reference documents."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        new_document = response.choices[0].message.content
        
        # Add to knowledge base
        doc_ids = self.kb.add_documents([
            {
                "content": new_document,
                "metadata": {
                    "source": "user_feedback",
                    "question": question,
                    "date_added": pd.Timestamp.now().isoformat()
                }
            }
        ])
        
        return doc_ids[0] if doc_ids else None

# Example usage
if __name__ == "__main__":
    # Initialize knowledge base
    kb = VectorKnowledgeBase(collection_name="company_knowledge")
    
    # Sample documents
    documents = [
        {
            "content": "Our company was founded in 2010 by Jane Smith. The headquarters is located in Boston, MA.",
            "metadata": {"category": "company_info", "confidence": "high"}
        },
        {
            "content": "The flagship product XYZ-1000 was launched in 2015. It features AI-powered analytics and real-time monitoring.",
            "metadata": {"category": "product_info", "product_id": "XYZ-1000"}
        },
        {
            "content": "Customer support is available 24/7 via email at support@example.com or by phone at 1-800-555-1234.",
            "metadata": {"category": "support", "department": "customer_service"}
        }
    ]
    
    # Add documents to knowledge base
    kb.add_documents(documents)
    
    # Initialize RAG agent
    agent = RAGAgent(kb)
    
    # Test with a question
    question = "When was the company founded and who is the founder?"
    result = agent.answer_question(question)
    
    print(f"Question: {question}")
    print(f"Answer: {result['answer']}")
    print("\nSources:")
    for i, source in enumerate(result['sources'], 1):
        print(f"{i}. {source['content_preview']} - {source['metadata']}")
```

### Elasticsearch for AI Agents

Elasticsearch provides powerful search capabilities with support for semantic search, keyword search, and aggregations, making it suitable for complex knowledge retrieval tasks.

```python
import os
from typing import List, Dict, Any, Optional
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
from dotenv import load_dotenv
import openai
import uuid
from datetime import datetime
import hashlib

# Load environment variables
load_dotenv()

class ElasticsearchAgentStore:
    """Elasticsearch integration for AI agent knowledge and search"""
    
    def __init__(self, index_prefix: str = "agent"):
        """Initialize Elasticsearch connection from environment variables"""
        es_cloud_id = os.getenv("ELASTICSEARCH_CLOUD_ID")
        es_user = os.getenv("ELASTICSEARCH_USER")
        es_password = os.getenv("ELASTICSEARCH_PASSWORD")
        
        if es_cloud_id:
            # Cloud configuration
            self.es = Elasticsearch(
                cloud_id=es_cloud_id,
                basic_auth=(es_user, es_password)
            )
        else:
            # Local configuration
            es_host = os.getenv("ELASTICSEARCH_HOST", "http://localhost:9200")
            self.es = Elasticsearch(es_host)
            
        # Set up index names
        self.knowledge_index = f"{index_prefix}_knowledge"
        self.log_index = f"{index_prefix}_logs"
        self.conversation_index = f"{index_prefix}_conversations"
        
        # Initialize OpenAI client for embeddings
        openai.api_key = os.getenv("OPENAI_API_KEY")
        
        # Ensure indexes exist
        self._ensure_indexes()
        
    def _ensure_indexes(self):
        """Create required indexes if they don't exist"""
        # Knowledge index with vector search
        if not self.es.indices.exists(index=self.knowledge_index):
            self.es.indices.create(
                index=self.knowledge_index,
                body={
                    "mappings": {
                        "properties": {
                            "content": {"type": "text"},
                            "embedding": {
                                "type": "dense_vector",
                                "dims": 1536,  # OpenAI embedding dimensions
                                "index": True,
                                "similarity": "cosine"
                            },
                            "metadata": {
                                "type": "object",
                                "dynamic": True
                            },
                            "source": {"type": "keyword"},
                            "created_at": {"type": "date"},
                            "updated_at": {"type": "date"}
                        }
                    }
                }
            )
        
        # Log index
        if not self.es.indices.exists(index=self.log_index):
            self.es.indices.create(
                index=self.log_index,
                body={
                    "mappings": {
                        "properties": {
                            "agent_id": {"type": "keyword"},
                            "level": {"type": "keyword"},
                            "message": {"type": "text"},
                            "metadata": {"type": "object"},
                            "timestamp": {"type": "date"}
                        }
                    }
                }
            )
            
        # Conversation index
        if not self.es.indices.exists(index=self.conversation_index):
            self.es.indices.create(
                index=self.conversation_index,
                body={
                    "mappings": {
                        "properties": {
                            "user_id": {"type": "keyword"},
                            "messages": {
                                "type": "nested",
                                "properties": {
                                    "role": {"type": "keyword"},
                                    "content": {"type": "text"},
                                    "timestamp": {"type": "date"}
                                }
                            },
                            "metadata": {"type": "object"},
                            "created_at": {"type": "date"},
                            "updated_at": {"type": "date"}
                        }
                    }
                }
            )
    
    def create_embedding(self, text: str) -> List[float]:
        """Create embedding vector for text using OpenAI API"""
        response = openai.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def add_knowledge(self, 
                     content: str, 
                     metadata: Optional[Dict[str, Any]] = None, 
                     source: str = "manual") -> str:
        """Add a knowledge document with vector embedding"""
        doc_id = str(uuid.uuid4())
        embedding = self.create_embedding(content)
        
        doc = {
            "content": content,
            "embedding": embedding,
            "metadata": metadata or {},
            "source": source,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        self.es.index(
            index=self.knowledge_index,
            id=doc_id,
            document=doc
        )
        
        return doc_id
        
    def add_knowledge_batch(self, documents: List[Dict[str, Any]]) -> List[str]:
        """Add multiple knowledge documents in bulk"""
        actions = []
        doc_ids = []
        
        for doc in documents:
            doc_id = str(uuid.uuid4())
            doc_ids.append(doc_id)
            
            content = doc["content"]
            metadata = doc.get("metadata", {})
            source = doc.get("source", "batch")
            
            embedding = self.create_embedding(content)
            
            action = {
                "_index": self.knowledge_index,
                "_id": doc_id,
                "_source": {
                    "content": content,
                    "embedding": embedding,
                    "metadata": metadata,
                    "source": source,
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat()
                }
            }
            
            actions.append(action)
        
        bulk(self.es, actions)
        return doc_ids
    
    def semantic_search(self, 
                       query: str, 
                       k: int = 5, 
                       metadata_filter: Optional[Dict] = None) -> List[Dict]:
        """Perform semantic search using vector similarity"""
        query_embedding = self.create_embedding(query)
        
        must_conditions = []
        if metadata_filter:
            for key, value in metadata_filter.items():
                must_conditions.append({"match": {f"metadata.{key}": value}})
        
        body = {
            "query": {
                "script_score": {
                    "query": {
                        "bool": {
                            "must": must_conditions if must_conditions else {"match_all": {}}
                        }
                    },
                    "script": {
                        "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                        "params": {"query_vector": query_embedding}
                    }
                }
            },
            "size": k
        }
        
        response = self.es.search(
            index=self.knowledge_index,
            body=body
        )
        
        results = []
        for hit in response["hits"]["hits"]:
            results.append({
                "id": hit["_id"],
                "content": hit["_source"]["content"],
                "metadata": hit["_source"]["metadata"],
                "score": hit["_score"] - 1.0,  # Convert back to cosine similarity
                "source": hit["_source"]["source"]
            })
            
        return results
    
    def hybrid_search(self, 
                     query: str, 
                     k: int = 5,
                     semantic_weight: float = 0.7, 
                     metadata_filter: Optional[Dict] = None) -> List[Dict]:
        """Hybrid search combining semantic and keyword matching"""
        query_embedding = self.create_embedding(query)
        
        must_conditions = []
        if metadata_filter:
            for key, value in metadata_filter.items():
                must_conditions.append({"match": {f"metadata.{key}": value}})
        
        body = {
            "query": {
                "script_score": {
                    "query": {
                        "bool": {
                            "must": must_conditions if must_conditions else {"match_all": {}},
                            "should": [
                                {"match": {"content": {"query": query, "boost": 1.0}}}
                            ]
                        }
                    },
                    "script": {
                        "source": f"cosineSimilarity(params.query_vector, 'embedding') * {semantic_weight} + _score * (1.0 - {semantic_weight})",
                        "params": {"query_vector": query_embedding}
                    }
                }
            },
            "size": k
        }
        
        response = self.es.search(
            index=self.knowledge_index,
            body=body
        )
        
        results = []
        for hit in response["hits"]["hits"]:
            results.append({
                "id": hit["_id"],
                "content": hit["_source"]["content"],
                "metadata": hit["_source"]["metadata"],
                "score": hit["_score"],
                "source": hit["_source"]["source"]
            })
            
        return results
    
    def log_event(self, 
                 agent_id: str, 
                 message: str, 
                 level: str = "info", 
                 metadata: Optional[Dict[str, Any]] = None) -> str:
        """Log an agent event"""
        log_id = hashlib.md5(f"{agent_id}:{datetime.now().isoformat()}".encode()).hexdigest()
        
        doc = {
            "agent_id": agent_id,
            "level": level,
            "message": message,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat()
        }
        
        self.es.index(
            index=self.log_index,
            id=log_id,
            document=doc
        )
        
        return log_id
    
    def store_conversation(self, 
                         user_id: str, 
                         messages: List[Dict[str, Any]], 
                         metadata: Optional[Dict[str, Any]] = None) -> str:
        """Store a conversation history"""
        conversation_id = str(uuid.uuid4())
        
        # Ensure messages have timestamps
        for message in messages:
            if "timestamp" not in message:
                message["timestamp"] = datetime.now().isoformat()
        
        doc = {
            "user_id": user_id,
            "messages": messages,
            "metadata": metadata or {},
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        self.es.index(
            index=self.conversation_index,
            id=conversation_id,
            document=doc
        )
        
        return conversation_id
    
    def get_conversations(self, 
                        user_id: Optional[str] = None, 
                        limit: int = 10, 
                        offset: int = 0) -> Dict[str, Any]:
        """Retrieve conversations with pagination"""
        query = {"match_all": {}}
        
        if user_id:
            query = {"match": {"user_id": user_id}}
        
        body = {
            "query": query,
            "sort": [{"created_at": {"order": "desc"}}],
            "from": offset,
            "size": limit
        }
        
        response = self.es.search(
            index=self.conversation_index,
            body=body
        )
        
        conversations = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            conversations.append({
                "id": hit["_id"],
                "user_id": source["user_id"],
                "messages": source["messages"],
                "metadata": source["metadata"],
                "created_at": source["created_at"],
                "updated_at": source["updated_at"]
            })
        
        return {
            "total": response["hits"]["total"]["value"],
            "conversations": conversations
        }
    
    def search_logs(self, 
                  agent_id: Optional[str] = None,
                  level: Optional[str] = None,
                  query: Optional[str] = None,
                  start_time: Optional[str] = None,
                  end_time: Optional[str] = None,
                  limit: int = 50) -> List[Dict[str, Any]]:
        """Search agent logs with filters"""
        must_conditions = []
        
        if agent_id:
            must_conditions.append({"match": {"agent_id": agent_id}})
            
        if level:
            must_conditions.append({"match": {"level": level}})
            
        if query:
            must_conditions.append({"match": {"message": query}})
            
        time_range = {}
        if start_time:
            time_range["gte"] = start_time
            
        if end_time:
            time_range["lte"] = end_time
            
        if time_range:
            must_conditions.append({"range": {"timestamp": time_range}})
        
        body = {
            "query": {
                "bool": {
                    "must": must_conditions if must_conditions else {"match_all": {}}
                }
            },
            "sort": [{"timestamp": {"order": "desc"}}],
            "size": limit
        }
        
        response = self.es.search(
            index=self.log_index,
            body=body
        )
        
        logs = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            logs.append({
                "id": hit["_id"],
                "agent_id": source["agent_id"],
                "level": source["level"],
                "message": source["message"],
                "metadata": source["metadata"],
                "timestamp": source["timestamp"]
            })
            
        return logs

# Example usage
if __name__ == "__main__":
    store = ElasticsearchAgentStore()
    
    # Add knowledge examples
    doc_id = store.add_knowledge(
        content="Elasticsearch is a distributed, RESTful search and analytics engine. "
                "It provides a distributed, multitenant-capable full-text search engine with "
                "an HTTP web interface and schema-free JSON documents.",
        metadata={"category": "technology", "type": "database"},
        source="documentation"
    )
    
    print(f"Added knowledge document with ID: {doc_id}")
    
    # Log an event
    log_id = store.log_event(
        agent_id="search_agent_001",
        message="Initialized agent with default configuration",
        level="info",
        metadata={"config_version": "1.2.3"}
    )
    
    print(f"Added log entry with ID: {log_id}")
    
    # Store a conversation
    conversation_id = store.store_conversation(
        user_id="user123",
        messages=[
            {"role": "user", "content": "How does Elasticsearch handle vector search?"},
            {"role": "assistant", "content": "Elasticsearch supports vector search through dense_vector fields..."}
        ],
        metadata={"session_id": "abc123", "source": "web_interface"}
    )
    
    print(f"Stored conversation with ID: {conversation_id}")
    
    # Perform semantic search
    results = store.semantic_search(
        query="How do I use Elasticsearch for full-text search?",
        k=3
    )
    
    print("\nSemantic search results:")
    for result in results:
        print(f"- Score: {result['score']:.4f}, Content: {result['content'][:50]}...")
```

## Building Knowledge Bases for AI Agents

A knowledge base combines structured data from various sources to provide agents with domain-specific information. Here's how to build a unified knowledge system that integrates multiple database types:

```python
import os
from typing import List, Dict, Any, Optional, Union, Tuple
from dotenv import load_dotenv
import openai
from pymongo import MongoClient
import pyodbc
import pandas as pd
from datetime import datetime
import chromadb
from chromadb.utils import embedding_functions
import json
import uuid
from tqdm import tqdm
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

class UnifiedKnowledgeSystem:
    """Unified knowledge system integrating SQL, NoSQL and vector databases"""
    
    def __init__(self):
        """Initialize connections to all database systems"""
        self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Initialize SQL connection
        self.sql_conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={os.getenv('SQL_SERVER')};"
            f"DATABASE={os.getenv('SQL_DATABASE')};"
            f"UID={os.getenv('SQL_USERNAME')};"
            f"PWD={os.getenv('SQL_PASSWORD')};"
        )
        
        # Initialize MongoDB
        mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
        self.mongo_client = MongoClient(mongo_uri)
        self.mongo_db = self.mongo_client[os.getenv("MONGODB_DB", "agent_knowledge")]
        
        # Initialize ChromaDB for vector storage
        self.ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name="text-embedding-3-small"
        )
        
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.chroma_collection = self._get_or_create_collection("unified_knowledge")
        
        logger.info("Unified Knowledge System initialized")
    
    def _get_or_create_collection(self, collection_name: str):
        """Get or create a ChromaDB collection"""
        try:
            return self.chroma_client.get_collection(
                name=collection_name,
                embedding_function=self.ef
            )
        except ValueError:
            return self.chroma_client.create_collection(
                name=collection_name,
                embedding_function=self.ef
            )
    
    def _get_sql_connection(self):
        """Get a SQL connection"""
        try:
            return pyodbc.connect(self.sql_conn_str)
        except pyodbc.Error as e:
            logger.error(f"SQL connection error: {e}")
            return None
    
    def execute_sql_query(self, query: str, params: Optional[List] = None) -> pd.DataFrame:
        """Execute a SQL query and return results as a DataFrame"""
        conn = self._get_sql_connection()
        if not conn:
            return pd.DataFrame()
            
        try:
            return pd.read_sql(query, conn, params=params)
        except Exception as e:
            logger.error(f"SQL query execution error: {e}")
            return pd.DataFrame()
        finally:
            conn.close()
    
    def ingest_from_sql(self, 
                       query: str, 
                       text_columns: List[str], 
                       metadata_columns: Optional[List[str]] = None) -> int:
        """Ingest data from SQL into the vector store"""
        df = self.execute_sql_query(query)
        if df.empty:
            logger.warning("No data returned from SQL query")
            return 0
            
        metadata_columns = metadata_columns or []
        count = 0
        
        for _, row in tqdm(df.iterrows(), total=len(df)):
            # Combine text columns into a single content string
            content_parts = []
            for col in text_columns:
                if col in row and pd.notna(row[col]) and row[col]:
                    content_parts.append(f"{col}: {row[col]}")
                    
            if not content_parts:
                continue
                
            content = "\n".join(content_parts)
            
            # Extract metadata
            metadata = {}
            for col in metadata_columns:
                if col in row and pd.notna(row[col]):
                    val = row[col]
                    # Convert to serializable type
                    if isinstance(val, pd.Timestamp):
                        val = val.isoformat()
                    elif hasattr(val, 'item'):
                        val = val.item()  # Convert numpy types
                    metadata[col] = val
                    
            # Add source information
            metadata["source"] = "sql_database"
            metadata["ingestion_timestamp"] = datetime.now().isoformat()
            
            # Add to vector store
            self._add_to_vector_store(content, metadata)
            
            # Store structured data in MongoDB for additional querying
            self._store_in_mongodb(content, metadata, "sql_imports")
            
            count += 1
            
        logger.info(f"Ingested {count} records from SQL")
        return count
    
    def _add_to_vector_store(self, content: str, metadata: Dict[str, Any]) -> str:
        """Add content to the vector store"""
        doc_id = str(uuid.uuid4())
        
        self.chroma_collection.add(
            documents=[content],
            metadatas=[metadata],
            ids=[doc_id]
        )
        
        return doc_id
    
    def _store_in_mongodb(self, 
                         content: str, 
                         metadata: Dict[str, Any],
                         collection_name: str) -> str:
        """Store data in MongoDB"""
        mongo_collection = self.mongo_db[collection_name]
        
        doc = {
            "content": content,
            "metadata": metadata,
            "created_at": datetime.now()
        }
        
        result = mongo_collection.insert_one(doc)
        return str(result.inserted_id)
    
    def ingest_document(self, 
                       content: str, 
                       metadata: Dict[str, Any],
                       chunks: bool = True,
                       chunk_size: int = 1000,
                       chunk_overlap: int = 200) -> List[str]:
        """Ingest a document, optionally chunking it for better retrieval"""
        doc_ids = []
        
        if not chunks or len(content) <= chunk_size:
            # Store as a single document
            vector_id = self._add_to_vector_store(content, metadata)
            mongo_id = self._store_in_mongodb(content, metadata, "documents")
            doc_ids.append(vector_id)
        else:
            # Chunk the document
            chunks = self._chunk_text(content, chunk_size, chunk_overlap)
            
            for i, chunk in enumerate(chunks):
                chunk_metadata = metadata.copy()
                chunk_metadata["chunk_index"] = i
                chunk_metadata["total_chunks"] = len(chunks)
                
                vector_id = self._add_to_vector_store(chunk, chunk_metadata)
                mongo_id = self._store_in_mongodb(chunk, chunk_metadata, "document_chunks")
                doc_ids.append(vector_id)
        
        return doc_ids
    
    def _chunk_text(self, text: str, chunk_size: int, chunk_overlap: int) -> List[str]:
        """Split text into overlapping chunks"""
        if len(text) <= chunk_size:
            return [text]
            
        chunks = []
        start = 0
        
        while start < len(text):
            # Find the end of the chunk
            end = start + chunk_size
            
            if end >= len(text):
                # Last chunk
                chunks.append(text[start:])
                break
                
            # Try to find a good breaking point (newline or period)
            # Look backward from the end to find a good break
            break_point = end
            
            # Look for paragraph break first
            para_break = text.rfind('\n\n', start, end)
            if para_break != -1 and para_break > start + chunk_size // 2:
                break_point = para_break + 2
            else:
                # Look for a single newline
                nl_break = text.rfind('\n', start, end)
                if nl_break != -1 and nl_break > start + chunk_size // 2:
                    break_point = nl_break + 1
                else:
                    # Look for sentence end
                    for punct in ['. ', '! ', '? ']:
                        sentence_end = text.rfind(punct, start, end)
                        if sentence_end != -1 and sentence_end > start + chunk_size // 2:
                            break_point = sentence_end + 2
                            break
            
            # Add the chunk
            chunks.append(text[start:break_point])
            
            # Move start position, ensuring overlap
            start = break_point - chunk_overlap
            
            # Make sure we're making forward progress
            if start <= 0 or start <= chunks[-1].find('\n'):
                start = break_point
                
        return chunks
    
    def query_knowledge(self, 
                      query: str, 
                      n_results: int = 5, 
                      metadata_filter: Optional[Dict] = None) -> List[Dict]:
        """Query the vector database for relevant knowledge"""
        # Query the vector store
        results = self.chroma_collection.query(
            query_texts=[query],
            n_results=n_results,
            where=metadata_filter
        )
        
        documents = []
        for i, doc in enumerate(results["documents"][0]):
            documents.append({
                "content": doc,
                "metadata": results["metadatas"][0][i] if results["metadatas"] else {},
                "id": results["ids"][0][i],
                "distance": results["distances"][0][i] if "distances" in results else None
            })
        
        return documents
    
    def answer_question(self, 
                      question: str,
                      n_docs: int = 5,
                      metadata_filter: Optional[Dict] = None,
                      model: str = "gpt-4") -> Dict[str, Any]:
        """Answer a question using RAG approach"""
        # Retrieve relevant documents
        docs = self.query_knowledge(question, n_results=n_docs, metadata_filter=metadata_filter)
        
        if not docs:
            return {
                "answer": "I don't have enough information to answer this question.",
                "sources": []
            }
        
        # Format context
        context_parts = []
        for i, doc in enumerate(docs):
            context_parts.append(f"Document {i+1}:\n{doc['content']}")
            
        context = "\n\n".join(context_parts)
        
        # Create prompt with retrieved context
        prompt = f"""
        Use the following documents to answer the question. If the documents don't contain
        the information needed, just indicate that you don't know based on the available information.
        
        Question: {question}
        
        Documents:
        {context}
        """
        
        # Generate answer using LLM
        response = self.client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a knowledgeable assistant that answers questions based on provided documents."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        answer = response.choices[0].message.content
        
        # Log this interaction in MongoDB
        self.mongo_db["question_logs"].insert_one({
            "question": question,
            "retrieved_docs": [{"id": doc["id"], "content_preview": doc["content"][:100]} for doc in docs],
            "answer": answer,
            "timestamp": datetime.now()
        })
        
        return {
            "answer": answer,
            "sources": [{"id": doc["id"], "metadata": doc["metadata"]} for doc in docs]
        }
    
    def generate_sql_query(self, question: str) -> Tuple[str, str]:
        """Generate SQL query from natural language question"""
        # Get database schema
        schema_query = """
        SELECT 
            t.name AS table_name,
            c.name AS column_name,
            ty.name AS data_type
        FROM 
            sys.tables t
            INNER JOIN sys.columns c ON t.object_id = c.object_id
            INNER JOIN sys.types ty ON c.user_type_id = ty.user_type_id
        ORDER BY 
            t.name, c.column_id;
        """
        
        schema_df = self.execute_sql_query(schema_query)
        schema_str = schema_df.to_string(index=False) if not schema_df.empty else "Schema unavailable"
        
        # Generate SQL query using LLM
        prompt = f"""
        Given the following database schema:
        
        {schema_str}
        
        Write a SQL query to answer this question: "{question}"
        
        Return only the SQL query without any explanation.
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert SQL developer."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        
        sql_query = response.choices[0].message.content.strip()
        
        # Execute the query and generate a response
        try:
            results = self.execute_sql_query(sql_query)
            
            if results.empty:
                return sql_query, "The query returned no results."
                
            # Convert results to a readable format
            results_str = results.to_string(index=False)
            
            # Generate natural language response
            nl_prompt = f"""
            Question: {question}
            
            SQL Query: {sql_query}
            
            Query Results:
            {results_str}
            
            Please interpret these results to answer the original question.
            """
            
            nl_response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a data analyst explaining query results."},
                    {"role": "user", "content": nl_prompt}
                ]
            )
            
            return sql_query, nl_response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error executing generated SQL: {e}")
            return sql_query, f"Error executing the query: {str(e)}"
    
    def search_mongodb(self, query: Dict, collection_name: str) -> List[Dict]:
        """Search MongoDB collection"""
        collection = self.mongo_db[collection_name]
        return list(collection.find(query))
    
    def search_hybrid(self, 
                    query: str, 
                    collections: List[str] = None, 
                    n_results: int = 5) -> Dict[str, List[Dict]]:
        """Perform hybrid search across MongoDB and vector store"""
        # Get semantic results from vector store
        vector_results = self.query_knowledge(query, n_results=n_results)
        
        # Extract keywords for MongoDB text search
        keyword_prompt = f"Extract 3-5 key search terms from this query: '{query}'"
        keyword_response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Extract key search terms from queries."},
                {"role": "user", "content": keyword_prompt}
            ]
        )
        
        keywords = keyword_response.choices[0].message.content.strip().split('\n')
        keywords = [k.strip().lower() for k in ' '.join(keywords).split() if len(k.strip()) > 2]
        
        # Perform MongoDB text searches
        mongo_results = {}
        collections = collections or ["documents", "document_chunks", "sql_imports"]
        
        for collection_name in collections:
            collection = self.mongo_db[collection_name]
            
            # Build a text search query
            search_conditions = []
            for keyword in keywords:
                search_conditions.append({"$text": {"$search": keyword}})
                search_conditions.append({"content": {"$regex": keyword, "$options": "i"}})
            
            results = list(collection.find(
                {"$or": search_conditions},
                {"score": {"$meta": "textScore"}}
            ).sort([("score", {"$meta": "textScore"})]).limit(n_results))
            
            mongo_results[collection_name] = results
        
        return {
            "vector_results": vector_results,
            "mongodb_results": mongo_results
        }

# Example usage
if __name__ == "__main__":
    knowledge_system = UnifiedKnowledgeSystem()
    
    # Example: Ingest from SQL
    sql_query = "SELECT TOP 100 * FROM products"
    knowledge_system.ingest_from_sql(
        query=sql_query,
        text_columns=["name", "description"],
        metadata_columns=["category", "price", "id"]
    )
    
    # Example: Ingest a document
    document = """
    # Product Manual: XYZ-1000
    
    ## Overview
    The XYZ-1000 is our flagship product designed for enterprise data analytics.
    
    ## Features
    - Real-time data processing
    - AI-powered insights
    - Cloud integration
    - Custom dashboards
    
    ## Technical Specifications
    - Processing speed: 10TB/hour
    - Storage: 50PB
    - API endpoints: REST, GraphQL
    """
    
    metadata = {
        "title": "XYZ-1000 Product Manual",
        "type": "documentation",
        "product_id": "XYZ-1000",
        "version": "1.0"
    }
    
    doc_ids = knowledge_system.ingest_document(document, metadata)
    print(f"Ingested document with IDs: {doc_ids}")
    
    # Example: Query knowledge
    question = "What are the main features of the XYZ-1000 product?"
    answer = knowledge_system.answer_question(question)
    
    print(f"\nQuestion: {question}")
    print(f"Answer: {answer['answer']}")
    print("\nSources:")
    for i, source in enumerate(answer['sources']):
        print(f"  {i+1}. ID: {source['id']}")
        for k, v in source['metadata'].items():
            print(f"     {k}: {v}")
```

## Conclusion

Databases are foundational components for building effective AI agents. Through this comprehensive exploration, we've seen how different database technologies serve distinct roles in the AI agent ecosystem:

- **SQL Databases** provide structured storage with powerful querying capabilities, ideal for handling relational data models and transactional operations.
- **NoSQL Databases** like MongoDB offer flexible schema design and horizontal scaling for storing diverse agent data including conversations, states, and tool executions.
- **Vector Databases** like Chroma enable semantic search through embeddings, allowing agents to retrieve contextually relevant information beyond keyword matching.
- **Elasticsearch** combines full-text search with vector capabilities, offering hybrid retrieval systems that leverage both semantic similarity and keyword relevance.

The unified knowledge system implementation demonstrates how these technologies can be integrated to create a comprehensive data layer for AI agents. This approach enables agents to:

1. Access structured data through SQL queries
2. Maintain state and history in flexible NoSQL collections
3. Perform semantic search using vector embeddings
4. Implement hybrid search for optimal information retrieval

When implementing database systems for AI agents, consider the following best practices:
- Store credentials securely in environment variables
- Implement proper error handling for database operations
- Use connection pooling for efficiency
- Design schemas that accommodate both agent needs and future expansion
- Consider chunking strategies for optimal retrieval performance
- Implement logging and monitoring for database operations

A well-designed database system empowers AI agents with memory, knowledge, and the ability to learn from interactions, making it a critical foundation for building sophisticated agent systems.