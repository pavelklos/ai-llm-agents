{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accbde67-9c7e-41b0-9329-8052e2ef365b",
   "metadata": {},
   "source": [
    "# AG2: Orchestrating agents (Ending a chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb42466-306d-49b1-b814-6674b60451e4",
   "metadata": {},
   "source": [
    "- Orchestrating agents<br>\n",
    "  - https://docs.ag2.ai/docs/user-guide/basic-concepts/orchestration/orchestrations\n",
    "- Ending a chat<br>\n",
    "  - https://docs.ag2.ai/docs/user-guide/basic-concepts/orchestration/ending-a-chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52efea-a524-4edd-89e0-35bf8ed2a4a1",
   "metadata": {},
   "source": [
    "## Orchestrating agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9a36a-a02d-45f1-9fe9-d1d096e790d5",
   "metadata": {},
   "source": [
    "- **Two-agent chat**: The simplest form of conversation pattern where two agents chat back-and-forth with each other. This has been demonstrated in the previous examples.\n",
    "- **Sequential chat**: A sequence of chats, each between two agents, chained together by a carryover mechanism (which brings the summary of the previous chat to the context of the next chat). Useful for simple sequential workflows.\n",
    "- **Group chat**: A chat with more than two agents with options on how agents are selected. See GroupChat Overview for further details.\n",
    "- **Nested chat**: A mechanism to package a workflow into a single agent/chat for reuse in a workflow.\n",
    "- **Swarm**: A pattern based on agents with handoffs. There’s a shared context and each agent has tools and the ability to transfer control to other agents. The original swarm concept was created by OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1039ae-8255-4ec0-8c3a-2757a8f0ae95",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce6eafa-f6ef-4ff1-8d54-17b4fcb71612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable or add it to a .env file\")\n",
    "\n",
    "# Define the model to use\n",
    "MODEL_GPT = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8123d-e0da-466f-8a02-8ac8dd3aa56a",
   "metadata": {},
   "source": [
    "## Ending a chat\n",
    "There are a number of ways a chat can end:\n",
    "1. The maximum number of turns in a chat is reached\n",
    "2. An agent’s termination function passes on a received message\n",
    "3. An agent automatically replies a maximum number of times\n",
    "4. A human replies with ‘exit’ when prompted\n",
    "5. In a group chat, there’s no next agent\n",
    "6. In a swarm, transitioning to AfterWorkOption.TERMINATE\n",
    "7. Custom reply functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d67df-fae3-420b-8bf7-5f39b15250f6",
   "metadata": {},
   "source": [
    "### 1. Maximum turns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb425a7-e184-45f5-b9ae-d5f604076a35",
   "metadata": {},
   "source": [
    "```python\n",
    "# GroupChat with a maximum of 5 rounds\n",
    "groupchat = GroupChat(\n",
    "    agents=[agent_a, agent_b, agent_c],\n",
    "    speaker_selection_method=\"round_robin\",\n",
    "    max_round=5,\n",
    "    ...\n",
    ")\n",
    "gcm = GroupChatManager(\n",
    "    ...\n",
    ")\n",
    "agent_a.initiate_chat(gcm, \"first message\")\n",
    "# 1. agent_a with \"first message\" > 2. agent_b > 3. agent_c > 4. agent_a > 5. agent_b > end\n",
    "\n",
    "# Swarm with a maximum of 5 rounds\n",
    "initiate_swarm_chat(\n",
    "    agents=[agent_a, agent_b, agent_c],\n",
    "    max_round=5,\n",
    "    messages=\"first message\"\n",
    "    ...\n",
    ")\n",
    "# When initial agent is set to agent_a and agents hand off to the next agent.\n",
    "# 1. User with \"first message\" > 2. agent_a > 3. agent_b > 4. agent_c > 5. agent_a > end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede1f3f-8c85-4535-a2ce-f325d660f5ad",
   "metadata": {},
   "source": [
    "```python\n",
    "# initiate_chat with a maximum of 2 turns across the 2 agents (effectively 4 steps)\n",
    "agent_a.initiate_chat(\n",
    "    recipient=agent_b,\n",
    "    max_turns=2,\n",
    "    message=\"first message\"\n",
    ")\n",
    "# 1. agent_a with \"first message\" > 1. agent_b > 2. agent_a > 2. agent_b > end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447386c8-0847-4444-8a11-4357ce77479f",
   "metadata": {},
   "source": [
    "### 2. Terminating message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48bd7f-82fd-45d2-bdf0-21744dd10a6c",
   "metadata": {},
   "source": [
    "```python\n",
    "agent_a = ConversableAgent(\n",
    "    system_message=\"You're a helpful AI assistant, end your responses with 'DONE!'\"\n",
    "    ...\n",
    ")\n",
    "\n",
    "# Terminates when the agent receives a message with \"DONE!\" in it.\n",
    "agent_b = ConversableAgent(\n",
    "    is_termination_msg=lambda x: \"DONE!\" in (x.get(\"content\", \"\") or \"\").upper()\n",
    "    ...\n",
    ")\n",
    "\n",
    "# agent_b > agent_a replies with message \"... DONE!\" > agent_b ends before replying\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba53d97-c6aa-4e51-9f49-522750a92c6a",
   "metadata": {},
   "source": [
    "### 3. Number of automatic replies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea832972-16c3-4fc5-b139-61064162a768",
   "metadata": {},
   "source": [
    "```python\n",
    "agent_a = ConversableAgent(\n",
    "    max_consecutive_auto_reply=2\n",
    "    ...\n",
    ")\n",
    "\n",
    "agent_b = ConversableAgent(\n",
    "    ...\n",
    ")\n",
    "\n",
    "agent_a.initiate_chat(agent_b, ...)\n",
    "\n",
    "# agent_a > agent_b > agent_a with first auto reply > agent_b > agent_a with second auto reply > agent_b > agent_a ends before replying\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e36516-59b0-49de-838d-3dbad94d0ea3",
   "metadata": {},
   "source": [
    "### 4. Human replies with ‘exit’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b715-d94d-4f7b-a7ef-60941353daa1",
   "metadata": {},
   "source": [
    "Please give feedback to agent_a. Press enter to skip and use auto-reply, or type **'exit'** to stop the conversation: **exit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed759f-dc1d-4015-ad02-3cc435d8a026",
   "metadata": {},
   "source": [
    "### 5. GroupChat, no next agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483ab60-c0d8-4e31-a646-ca17a8c2b6e0",
   "metadata": {},
   "source": [
    "If the next agent in a GroupChat can’t be determined the chat will end.<br>\n",
    "If you are customizing the speaker selection method with a Callable, return None to end the chat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebce413-ee2d-4381-bf6e-df366da1af19",
   "metadata": {},
   "source": [
    "### 6. Swarm, transitioning to end the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d947329-9124-4323-8e35-cdbf507d6361",
   "metadata": {},
   "source": [
    "In a swarm, if you transition to AfterWorkOption.TERMINATE it will end the swarm. The default swarm-level AfterWork option is AfterWorkOption.TERMINATE and this will apply to any agent in the swarm that doesn’t have an AfterWork hand-off specified.<br>\n",
    "Additionally, if you transition to AfterWorkOption.REVERT_TO_USER but have not specified a user_agent in initiate_swarm_chat then it will end the swarm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb765a6-c113-40d4-8322-5b18c1a25c7e",
   "metadata": {},
   "source": [
    "### 7. Reply functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec2307-e2c5-4c59-9fab-363201a915a9",
   "metadata": {},
   "source": [
    "```python\n",
    "agent_a = ConversableAgent(\n",
    "    ...\n",
    ")\n",
    "\n",
    "agent_b = ConversableAgent(\n",
    "    ...\n",
    ")\n",
    "\n",
    "def my_reply_func(\n",
    "    recipient: ConversableAgent,\n",
    "    messages: Optional[List[Dict]] = None,\n",
    "    sender: Optional[Agent] = None,\n",
    "    config: Optional[Any] = None,\n",
    ") -> Tuple[bool, Union[str, Dict, None]]:\n",
    "    return True, None # Indicates termination\n",
    "\n",
    "# Register the reply function as the agent_a's first reply function\n",
    "agent_a.register_reply(\n",
    "    trigger=[Agent, None],\n",
    "    reply_func=my_reply_func,\n",
    "    position=0\n",
    "\n",
    ")\n",
    "\n",
    "agent_a.initiate_chat(agent_b, ...)\n",
    "\n",
    "# agent_a > agent_b > agent_a ends with first custom reply function\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
