{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accbde67-9c7e-41b0-9329-8052e2ef365b",
   "metadata": {},
   "source": [
    "# LlamaIndex: QA over Structured Data (Text-to-Pandas Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb42466-306d-49b1-b814-6674b60451e4",
   "metadata": {},
   "source": [
    "- Question-Answering (RAG)\n",
    "  - https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/\n",
    "- QA over Structured Data (Text-to-Pandas Guide)<br>\n",
    "  - **[Text-to-SQL Guide (Query Engine + Retriever)](https://docs.llamaindex.ai/en/stable/examples/query_engine/pandas_query_engine/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1039ae-8255-4ec0-8c3a-2757a8f0ae95",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce6eafa-f6ef-4ff1-8d54-17b4fcb71612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable or add it to a .env file\")\n",
    "\n",
    "# Define the model to use\n",
    "MODEL_GPT = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0e29c-7766-4b00-adb0-12c09cd720e0",
   "metadata": {},
   "source": [
    "## SETUP (LlamaIndex)\n",
    "### Pandas Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7603a30c-d9e9-49c1-83f0-72afe36062f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5560771-22b0-4e63-af81-6cb50e3490b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7735813f-79fd-4fb9-bf6a-8e92a0222032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6dd3f-051e-4d22-bce4-7528a4fe58ec",
   "metadata": {},
   "source": [
    "## Let's start on a Toy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ff3b71-b478-4746-b7dc-89b8b27b2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some sample data\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"city\": [\"Toronto\", \"Tokyo\", \"Berlin\"],\n",
    "        \"population\": [2930000, 13960000, 3645000],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d702cc-6ea3-4812-a2d2-119fadd2d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f0a6bf-d6d7-4697-9a2b-084e01eb5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.ollama import Ollama\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import Settings\n",
    "\n",
    "# Settings.llm = Ollama(model=\"llama2\", request_timeout=120.0)\n",
    "# Settings.embed_model = HuggingFaceEmbedding(\n",
    "#     model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "# )\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4o-mini\")\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee519b5b-a079-4c66-9d0a-8355b712a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['population'].idxmax(), 'city']\n",
      "```\n",
      "> Pandas Output: Tokyo\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the city with the highest population?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4b9c69-fecf-4425-88bc-96d28eac5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.loc[df['population'].idxmax(), 'city']\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b47b90-d464-4260-a425-f05a4e713fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['population'].idxmax()]\n",
      "```\n",
      "> Pandas Output: city             Tokyo\n",
      "population    13960000\n",
      "Name: 1, dtype: object\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The city with the highest population is Tokyo, with a population of 13,960,000.\n"
     ]
    }
   ],
   "source": [
    "query_engine = PandasQueryEngine(df=df, verbose=True, synthesize_response=True)\n",
    "response = query_engine.query(\n",
    "    \"What is the city with the highest population? Give both the city and population\",\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5114e2-4ec3-4aba-99d6-c9b48ad29575",
   "metadata": {},
   "source": [
    "## Analyzing the Titanic Dataset\n",
    "The Titanic dataset is one of the most popular tabular datasets in introductory machine learning<br>\n",
    "- https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7efc05-9274-4b6e-8373-f1b8f7404b15",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "841ec862-5ff8-4650-91f4-73fa5b004ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c31e97-f1c9-41fc-860e-361191b8442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./titanic_train.csv\")\n",
    "df = pd.read_csv(\"./data/titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ae30366-e721-45b0-baac-179e853224c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b26783-ee02-4233-8117-ba8378cf0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df['survived'].corr(df['age'])\n",
      "```\n",
      "> Pandas Output: -0.07722109457217755\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the correlation between survival and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3259ffd5-bce1-4c5b-8ba4-5d9cc77a7b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>-0.07722109457217755</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114eef8b-13cc-4528-9d79-b835ede3192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['survived'].corr(df['age'])\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2088b-80a3-4787-8544-3ee929814ac8",
   "metadata": {},
   "source": [
    "## Additional Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c590550-7c04-4641-8f16-cfdec593a049",
   "metadata": {},
   "source": [
    "### Analyzing / Modifying prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f368dd4-0ee4-4f21-8834-a2ea66f01588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f88901-b82b-41a7-8de2-80d7c875c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "{df_str}\n",
      "\n",
      "Follow these instructions:\n",
      "{instruction_str}\n",
      "Query: {query_str}\n",
      "\n",
      "Expression:\n"
     ]
    }
   ],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)\n",
    "prompts = query_engine.get_prompts()\n",
    "print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f4fd0e-7564-4af5-82d9-2f73ecfd7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, synthesize a response from the query results.\n",
      "Query: {query_str}\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "{pandas_instructions}\n",
      "\n",
      "Pandas Output: {pandas_output}\n",
      "\n",
      "Response: \n"
     ]
    }
   ],
   "source": [
    "print(prompts[\"response_synthesis_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62fca78a-770f-4e60-a936-b23f23091a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "You are working with a pandas dataframe in Python.\n",
    "The name of the dataframe is `df`.\n",
    "This is the result of `print(df.head())`:\n",
    "{df_str}\n",
    "\n",
    "Follow these instructions:\n",
    "{instruction_str}\n",
    "Query: {query_str}\n",
    "\n",
    "Expression: \"\"\"\n",
    ")\n",
    "\n",
    "query_engine.update_prompts({\"pandas_prompt\": new_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1af0f6e-2baa-4482-b0a1-3820c71f6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = \"\"\"\\\n",
    "1. Convert the query to executable Python code using Pandas.\n",
    "2. The final line of code should be a Python expression that can be called with the `eval()` function.\n",
    "3. The code should represent a solution to the query.\n",
    "4. PRINT ONLY THE EXPRESSION.\n",
    "5. Do not quote the expression.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d8bf2f3-7e78-4359-8495-e7118989d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].loc[df['age'] == df['age'].max(), 'name'].values[0]\n",
      "```\n",
      "> Pandas Output: Barkworth, Mr. Algernon Henry Wilson\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "621ff557-8be0-4444-9517-b8a968f8d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].loc[df['age'] == df.loc[df['survived'] == 1, 'age'].max(), ['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                      name   age\n",
      "630  Barkworth, Mr. Algernon Henry Wilson  80.0\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e58119bc-8473-4059-a6fa-8afcfdc1237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].nsmallest(1, 'age')[['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                 name   age\n",
      "803  Thomas, Master. Assad Alexander  0.42\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the youngest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f459b92-1398-4a3f-80d0-19a5245bb216",
   "metadata": {},
   "source": [
    "# Implementing Query Engine using Query Pipeline Syntax\n",
    "**Query Pipeline over Pandas DataFrames**\n",
    "- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecba0bc-bfc5-40b2-82c3-daa293aa9533",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a133be58-e068-477a-a058-938a0668efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable or add it to a .env file\")\n",
    "\n",
    "# Define the model to use\n",
    "MODEL_GPT = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e18a2-0b06-4580-9d25-36d3f3c85daa",
   "metadata": {},
   "source": [
    "## SETUP (LlamaIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebebdfe6-c03a-435e-9d59-31717d95d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-llms-openai llama-index-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f71f6f63-b664-4c7b-a314-ccc2f0fbcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52fa4e-c052-4156-90e3-438d06c8bc71",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "447be699-eab7-42df-b352-95f630d71987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd1aea7-4565-4429-a8f5-366b14433fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"./titanic_train.csv\")\n",
    "df = pd.read_csv(\"./data/titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e6ff7f9-7bb6-4864-8aae-e0e34e76301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   survived  891 non-null    int64  \n",
      " 1   pclass    891 non-null    int64  \n",
      " 2   name      891 non-null    object \n",
      " 3   sex       891 non-null    object \n",
      " 4   age       714 non-null    float64\n",
      " 5   sibsp     891 non-null    int64  \n",
      " 6   parch     891 non-null    int64  \n",
      " 7   ticket    891 non-null    object \n",
      " 8   fare      891 non-null    float64\n",
      " 9   cabin     204 non-null    object \n",
      " 10  embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0c3198c-626b-4e5d-96bc-141e20398f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c182097-fa68-4f44-83dd-6e3d92b0366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass                                               name  \\\n",
       "0           0       3                            Braund, Mr. Owen Harris   \n",
       "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2           1       3                             Heikkinen, Miss. Laina   \n",
       "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4           0       3                           Allen, Mr. William Henry   \n",
       "..        ...     ...                                                ...   \n",
       "886         0       2                              Montvila, Rev. Juozas   \n",
       "887         1       1                       Graham, Miss. Margaret Edith   \n",
       "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889         1       1                              Behr, Mr. Karl Howell   \n",
       "890         0       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        sex   age  sibsp  parch            ticket     fare cabin embarked  \n",
       "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1    female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
       "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
       "887  female  19.0      0      0            112053  30.0000   B42        S  \n",
       "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889    male  26.0      0      0            111369  30.0000  C148        C  \n",
       "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9adff-070e-4568-9bc9-919b0c717cf1",
   "metadata": {},
   "source": [
    "## Define Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45e36490-1bee-4ccd-be80-df91e75d91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=df.head(5)\n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df8773-67ea-432c-93f0-9697da14c495",
   "metadata": {},
   "source": [
    "## Build Query Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa7b5534-3a52-4d11-b01d-5dfcd0dffa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc0ab9-8fb4-4082-8c64-18c6603906fe",
   "metadata": {},
   "source": [
    "## Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bd1ab86-8d4a-4c6c-97d1-af6265fb7eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "   survived  pclass                                               name  ...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['survived'].corr(df['age'])\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "pandas_instructions: assistant: df['survived'].corr(df['age'])\n",
      "pandas_output: -0.07722109457217755\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: What is the correlation between survival and age?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['survived'].corr(df['age'])\n",
      "\n",
      "Pandas ...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query_str=\"What is the correlation between survival and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e05c2f3b-5d12-48dc-816d-b638bba31fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between survival and age is approximately -0.077. This indicates a very weak negative correlation, suggesting that there is little to no relationship between age and survival rates in the dataset analyzed.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47e800cc-a3ce-4bd2-90bc-4291a54423fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df[df['survived'] == 1].loc[df['age'].idxmax(), 'name']\n",
      "```\n",
      "> Pandas Output: Barkworth, Mr. Algernon Henry Wilson\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d837a6bc-81ff-4a7b-8e3c-f1a98d5d70ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Barkworth, Mr. Algernon Henry Wilson</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe6a477-2a20-41db-b2a1-b49f95e7efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].loc[df['age'] == df['age'].max(), ['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                      name   age\n",
      "630  Barkworth, Mr. Algernon Henry Wilson  80.0\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c51a5d2f-7275-4f75-b57d-76ec21a3ca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>                                     name   age\n",
       "630  Barkworth, Mr. Algernon Henry Wilson  80.0</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47ea6b03-0c95-4446-9c11-352575b21ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].nsmallest(1, 'age')[['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                 name   age\n",
      "803  Thomas, Master. Assad Alexander  0.42\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the youngest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5afa7b23-75ef-49a4-b06f-58834d39e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>                                name   age\n",
       "803  Thomas, Master. Assad Alexander  0.42</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
