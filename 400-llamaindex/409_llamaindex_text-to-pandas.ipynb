{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accbde67-9c7e-41b0-9329-8052e2ef365b",
   "metadata": {},
   "source": [
    "# LlamaIndex: QA over Structured Data (Text-to-Pandas Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb42466-306d-49b1-b814-6674b60451e4",
   "metadata": {},
   "source": [
    "- Question-Answering (RAG)\n",
    "  - https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/\n",
    "- QA over Structured Data (Text-to-Pandas Guide)<br>\n",
    "  - **[Text-to-SQL Guide (Query Engine + Retriever)](https://docs.llamaindex.ai/en/stable/examples/query_engine/pandas_query_engine/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1039ae-8255-4ec0-8c3a-2757a8f0ae95",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce6eafa-f6ef-4ff1-8d54-17b4fcb71612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable or add it to a .env file\")\n",
    "\n",
    "# Define the model to use\n",
    "MODEL_GPT = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0e29c-7766-4b00-adb0-12c09cd720e0",
   "metadata": {},
   "source": [
    "## SETUP (LlamaIndex)\n",
    "### Pandas Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7603a30c-d9e9-49c1-83f0-72afe36062f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5560771-22b0-4e63-af81-6cb50e3490b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7735813f-79fd-4fb9-bf6a-8e92a0222032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6dd3f-051e-4d22-bce4-7528a4fe58ec",
   "metadata": {},
   "source": [
    "## Let's start on a Toy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ff3b71-b478-4746-b7dc-89b8b27b2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some sample data\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"city\": [\"Toronto\", \"Tokyo\", \"Berlin\"],\n",
    "        \"population\": [2930000, 13960000, 3645000],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d702cc-6ea3-4812-a2d2-119fadd2d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f0a6bf-d6d7-4697-9a2b-084e01eb5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.ollama import Ollama\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import Settings\n",
    "\n",
    "# Settings.llm = Ollama(model=\"llama2\", request_timeout=120.0)\n",
    "# Settings.embed_model = HuggingFaceEmbedding(\n",
    "#     model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "# )\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4o-mini\")\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee519b5b-a079-4c66-9d0a-8355b712a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['population'].idxmax(), 'city']\n",
      "```\n",
      "> Pandas Output: Tokyo\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the city with the highest population?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4b9c69-fecf-4425-88bc-96d28eac5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.loc[df['population'].idxmax(), 'city']\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b47b90-d464-4260-a425-f05a4e713fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['population'].idxmax()]\n",
      "```\n",
      "> Pandas Output: city             Tokyo\n",
      "population    13960000\n",
      "Name: 1, dtype: object\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The city with the highest population is Tokyo, with a population of 13,960,000.\n"
     ]
    }
   ],
   "source": [
    "query_engine = PandasQueryEngine(df=df, verbose=True, synthesize_response=True)\n",
    "response = query_engine.query(\n",
    "    \"What is the city with the highest population? Give both the city and population\",\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5114e2-4ec3-4aba-99d6-c9b48ad29575",
   "metadata": {},
   "source": [
    "## Analyzing the Titanic Dataset\n",
    "The Titanic dataset is one of the most popular tabular datasets in introductory machine learning<br>\n",
    "- https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7efc05-9274-4b6e-8373-f1b8f7404b15",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "841ec862-5ff8-4650-91f4-73fa5b004ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c31e97-f1c9-41fc-860e-361191b8442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./titanic_train.csv\")\n",
    "df = pd.read_csv(\"./data/titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ae30366-e721-45b0-baac-179e853224c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b26783-ee02-4233-8117-ba8378cf0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df['survived'].corr(df['age'])\n",
      "```\n",
      "> Pandas Output: -0.07722109457217755\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the correlation between survival and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3259ffd5-bce1-4c5b-8ba4-5d9cc77a7b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>-0.07722109457217755</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114eef8b-13cc-4528-9d79-b835ede3192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['survived'].corr(df['age'])\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2088b-80a3-4787-8544-3ee929814ac8",
   "metadata": {},
   "source": [
    "## Additional Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c590550-7c04-4641-8f16-cfdec593a049",
   "metadata": {},
   "source": [
    "### Analyzing / Modifying prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f368dd4-0ee4-4f21-8834-a2ea66f01588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f88901-b82b-41a7-8de2-80d7c875c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "{df_str}\n",
      "\n",
      "Follow these instructions:\n",
      "{instruction_str}\n",
      "Query: {query_str}\n",
      "\n",
      "Expression:\n"
     ]
    }
   ],
   "source": [
    "# query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "query_engine = PandasQueryEngine(df=df, verbose=True, llm=llm)\n",
    "prompts = query_engine.get_prompts()\n",
    "print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f4fd0e-7564-4af5-82d9-2f73ecfd7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, synthesize a response from the query results.\n",
      "Query: {query_str}\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "{pandas_instructions}\n",
      "\n",
      "Pandas Output: {pandas_output}\n",
      "\n",
      "Response: \n"
     ]
    }
   ],
   "source": [
    "print(prompts[\"response_synthesis_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62fca78a-770f-4e60-a936-b23f23091a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "You are working with a pandas dataframe in Python.\n",
    "The name of the dataframe is `df`.\n",
    "This is the result of `print(df.head())`:\n",
    "{df_str}\n",
    "\n",
    "Follow these instructions:\n",
    "{instruction_str}\n",
    "Query: {query_str}\n",
    "\n",
    "Expression: \"\"\"\n",
    ")\n",
    "\n",
    "query_engine.update_prompts({\"pandas_prompt\": new_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1af0f6e-2baa-4482-b0a1-3820c71f6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = \"\"\"\\\n",
    "1. Convert the query to executable Python code using Pandas.\n",
    "2. The final line of code should be a Python expression that can be called with the `eval()` function.\n",
    "3. The code should represent a solution to the query.\n",
    "4. PRINT ONLY THE EXPRESSION.\n",
    "5. Do not quote the expression.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d8bf2f3-7e78-4359-8495-e7118989d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].loc[df['age'] == df['age'].max(), 'name'].values[0]\n",
      "```\n",
      "> Pandas Output: Barkworth, Mr. Algernon Henry Wilson\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "621ff557-8be0-4444-9517-b8a968f8d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].loc[df['age'] == df.loc[df['survived'] == 1, 'age'].max(), ['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                      name   age\n",
      "630  Barkworth, Mr. Algernon Henry Wilson  80.0\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the oldest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e58119bc-8473-4059-a6fa-8afcfdc1237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.loc[df['survived'] == 1].nsmallest(1, 'age')[['name', 'age']]\n",
      "```\n",
      "> Pandas Output:                                 name   age\n",
      "803  Thomas, Master. Assad Alexander  0.42\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the youngest survival by age. Give both the survival name and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f459b92-1398-4a3f-80d0-19a5245bb216",
   "metadata": {},
   "source": [
    "### Implementing Query Engine using Query Pipeline Syntax\n",
    "**Query Pipeline over Pandas DataFrames**\n",
    "- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
