{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d820eca0-3694-4463-8382-52901b904534",
   "metadata": {},
   "source": [
    "# AI Vector Store with LangChain and Pinecone\n",
    "\n",
    "This guide demonstrates how to create a vector store using LangChain and the Pinecone package (not the deprecated pinecone-client) with specific document files: a text file (Alice in Wonderland), a markdown file (Flask documentation), and a PDF file (Attention Is All You Need research paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de407e58-28d2-47ee-bfd4-b325dd2cbc68",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install all necessary dependencies with the updated Pinecone package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06a3fa5-3ba0-4bba-a0b4-f293f9d6a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages with the new Pinecone package\n",
    "# !pip install langchain langchain_openai pinecone pypdf tiktoken requests unstructured markdown faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54253a6-3c68-419a-bd89-c262d9d839ed",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Let's set up our environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7458fd-61ab-4fb5-bc6f-a1d36e16d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Load environment variables from .env file (if you have one)\n",
    "load_dotenv()\n",
    "\n",
    "# Set your API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT') # region\n",
    "# print(os.environ[\"OPENAI_API_KEY\"])\n",
    "# print(PINECONE_API_KEY)\n",
    "# print(PINECONE_ENVIRONMENT)\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini' # 'gpt-3.5-turbo'\n",
    "PINECONE_INDEX_NAME = \"mixed-document-types\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3aa402-4a31-4211-a98c-8caf4b81f0fd",
   "metadata": {},
   "source": [
    "## Download Specific Files\n",
    "\n",
    "We'll download the three specific files you mentioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec36a8c5-ac7f-4ea0-a731-21d05bbed3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file(url, path):\n",
    "    \"\"\"Download a file from a URL to a specific path.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {path.name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68752f30-891b-4073-95bc-245a833ec783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded alice_in_wonderland.txt\n"
     ]
    }
   ],
   "source": [
    "# Download Alice in Wonderland (txt)\n",
    "alice_url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
    "alice_path = data_dir / \"alice_in_wonderland.txt\"\n",
    "if not alice_path.exists():\n",
    "    download_file(alice_url, alice_path)\n",
    "else:\n",
    "    print(f\"{alice_path.name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2bc8e4-b7d4-4de0-9a9d-56b889eacdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded flask_docs.md\n"
     ]
    }
   ],
   "source": [
    "# Download Flask documentation (markdown)\n",
    "flask_docs_url = \"https://raw.githubusercontent.com/pallets/flask/main/README.md\"\n",
    "flask_docs_path = data_dir / \"flask_docs.md\"\n",
    "if not flask_docs_path.exists():\n",
    "    download_file(flask_docs_url, flask_docs_path)\n",
    "else:\n",
    "    print(f\"{flask_docs_path.name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a55fd0-854f-4ca6-b8bc-413ecf38d62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded attention_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# Download a research paper (PDF)\n",
    "research_paper_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "research_paper_path = data_dir / \"attention_paper.pdf\"\n",
    "if not research_paper_path.exists():\n",
    "    download_file(research_paper_url, research_paper_path)\n",
    "else:\n",
    "    print(f\"{research_paper_path.name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a4081a-253a-4da5-a8b8-224080f5bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\alice_in_wonderland.txt\n",
      "data\\flask_docs.md\n",
      "data\\attention_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "print(alice_path)\n",
    "print(flask_docs_path)\n",
    "print(research_paper_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677abc65-a45b-4fcb-aa21-573aa3d4e1b3",
   "metadata": {},
   "source": [
    "## Load and Process Different File Types\n",
    "\n",
    "Now we'll load the documents using the appropriate loaders for each file type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dea76c6-aaec-40fc-aa93-1ce55b7961f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading alice_in_wonderland.txt...\n",
      "Loading flask_docs.md...\n",
      "Loading attention_paper.pdf...\n",
      "Loaded 17 documents\n",
      "Split into 245 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, UnstructuredMarkdownLoader\n",
    "\n",
    "# Create a list to store all documents\n",
    "all_documents = []\n",
    "\n",
    "# Load TXT file - Alice in Wonderland\n",
    "print(f\"Loading {alice_path.name}...\")\n",
    "# text_loader = TextLoader(alice_path)\n",
    "text_loader = TextLoader(str(alice_path), encoding='utf-8')\n",
    "all_documents.extend(text_loader.load())\n",
    "\n",
    "# Load Markdown file - Flask docs\n",
    "print(f\"Loading {flask_docs_path.name}...\")\n",
    "# md_loader = UnstructuredMarkdownLoader(flask_docs_path)\n",
    "md_loader = UnstructuredMarkdownLoader(str(flask_docs_path))\n",
    "all_documents.extend(md_loader.load())\n",
    "\n",
    "# Load PDF file - Research paper\n",
    "print(f\"Loading {research_paper_path.name}...\")\n",
    "# pdf_loader = PyPDFLoader(research_paper_path)\n",
    "pdf_loader = PyPDFLoader(str(research_paper_path))\n",
    "all_documents.extend(pdf_loader.load())\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} documents\")\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d23fb-6aa1-4a35-8cf0-b9236f6ddccf",
   "metadata": {},
   "source": [
    "## Create Embeddings\n",
    "\n",
    "We'll use OpenAI embeddings to vectorize our document chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc467148-8f6f-4dd1-9e82-2403da2788af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Test embedding a sample text\n",
    "sample_text = \"This is a test document for embeddings.\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "print(f\"Embedding dimension: {len(sample_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96ff52-f854-49b6-b469-3ab21755a747",
   "metadata": {},
   "source": [
    "## Create Vector Store with Pinecone\n",
    "\n",
    "Now let's initialize Pinecone and create our vector store using the updated Pinecone package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d42b4a7-c6ad-48f1-a772-bc0771877246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new Pinecone index: mixed-document-types\n",
      "Documents loaded into Pinecone successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Pinecone client\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Set index name with a unique identifier\n",
    "# index_name = \"mixed-document-types\"\n",
    "index_name = PINECONE_INDEX_NAME\n",
    "\n",
    "# Check if index already exists, if not create it\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "    # Determine dimension from the OpenAI embeddings\n",
    "    dimension = len(sample_embedding)\n",
    "    # Create the index with the Pinecone API\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            # region=\"us-west-2\"\n",
    "            region=PINECONE_ENVIRONMENT\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created new Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "else:\n",
    "    print(f\"Using existing Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "\n",
    "# Connect to the index with Pinecone API\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# Create Pinecone vector store with LangChain\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=PINECONE_INDEX_NAME\n",
    ")\n",
    "\n",
    "print(\"Documents loaded into Pinecone successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3cfe52-1165-4272-96cb-214228e28a66",
   "metadata": {},
   "source": [
    "## Create Retrieval System\n",
    "\n",
    "Let's set up our retrieval system with LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eee67f6-bf47-4177-97b4-902453295d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "llm = ChatOpenAI(model_name=MODEL_GPT)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536a280-1254-4189-ad93-9a9823a7334e",
   "metadata": {},
   "source": [
    "## Test with Questions About the Documents\n",
    "\n",
    "Let's test our system with five questions about our specific documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f6308b-239e-474e-a2fb-4c5a1ce6a01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: What happens to Alice when she drinks from the bottle?\n",
      "--------------------------------------------------\n",
      "Answer:\n",
      "When Alice drinks from the bottle labeled \"DRINK ME,\" she finds it very nice and finishes it off. The context suggests that drinking from the bottle likely causes her to change in size, although the specific effect of that particular drink on her size is not detailed in the provided text.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "Document 1:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: There seemed to be no use in waiting by the little door, so she went\n",
      "back to the table, half hoping she might find another key on it, or at\n",
      "any rate a book of rules for shutting people up like telesco...\n",
      "\n",
      "Document 2:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: It was all very well to say “Drink me,” but the wise little Alice was\n",
      "not going to do _that_ in a hurry. “No, I’ll look first,” she said,\n",
      "“and see whether it’s marked ‘_poison_’ or not”; for she had r...\n",
      "\n",
      "Document 3:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: By this time she had found her way into a tidy little room with a table\n",
      "in the window, and on it (as she had hoped) a fan and two or three\n",
      "pairs of tiny white kid gloves: she took up the fan and a pai...\n",
      "\n",
      "Document 4:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: Soon her eye fell on a little glass box that was lying under the table:\n",
      "she opened it, and found in it a very small cake, on which the words\n",
      "“EAT ME” were beautifully marked in currants. “Well, I’ll e...\n",
      "\n",
      "\n",
      "Question: What are the key features of Flask framework?\n",
      "--------------------------------------------------\n",
      "Answer:\n",
      "The key features of the Flask framework include:\n",
      "\n",
      "1. **Lightweight and Flexible**: Flask is a lightweight WSGI web application framework that is designed to be simple and easy to use, allowing developers to quickly get started.\n",
      "\n",
      "2. **Modular Design**: Flask does not enforce any dependencies or project layout. Developers have the freedom to choose their own tools and libraries.\n",
      "\n",
      "3. **Built-in Development Server**: Flask includes a built-in development server, making it easy to run and test applications during development.\n",
      "\n",
      "4. **Routing**: Flask provides a simple and intuitive routing system for mapping URLs to Python functions.\n",
      "\n",
      "5. **Template Engine**: Flask integrates with Jinja, a powerful template engine for rendering dynamic HTML pages.\n",
      "\n",
      "6. **Extensible**: There are many community-provided extensions that make it easy to add new functionalities, such as form handling, authentication, and database integration.\n",
      "\n",
      "7. **RESTful Request Dispatching**: Flask supports RESTful request dispatching which is helpful in building REST APIs.\n",
      "\n",
      "8. **Session Management**: Flask includes built-in support for handling user sessions.\n",
      "\n",
      "9. **Testing Support**: Flask provides tools and features for unit testing and debugging applications.\n",
      "\n",
      "10. **Community Support**: Flask is maintained by the Pallets organization and has a large and active community, contributing to extensive documentation and resources.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "Document 1:\n",
      "Source: Flask Documentation (data\\flask_docs.md)\n",
      "Content: Flask\n",
      "\n",
      "Flask is a lightweight WSGI web application framework. It is designed to make getting started quick and easy, with the ability to scale up to complex applications. It began as a simple wrapper ...\n",
      "\n",
      "Document 2:\n",
      "Source: Flask Documentation (data\\flask_docs.md)\n",
      "Content: from flask import Flask\n",
      "\n",
      "app = Flask(name)\n",
      "\n",
      "@app.route(\"/\") def hello(): return \"Hello, World!\" ```\n",
      "\n",
      "$ flask run * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "\n",
      "Donate\n",
      "\n",
      "The Pallets organiz...\n",
      "\n",
      "Document 3:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: Suddenly she came upon a little three-legged table, all made of solid\n",
      "glass; there was nothing on it except a tiny golden key, and Alice’s\n",
      "first thought was that it might belong to one of the doors of...\n",
      "\n",
      "Document 4:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 14.0\n",
      "Content: Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "sh...\n",
      "\n",
      "\n",
      "Question: What is the attention mechanism described in the research paper?\n",
      "--------------------------------------------------\n",
      "Answer:\n",
      "The attention mechanism described in the research paper is a function that maps a query and a set of key-value pairs to an output. In this mechanism, the query, keys, values, and output are all represented as vectors. The output is computed as a weighted sum of the values, where the weights are determined by the relationships between the query and the keys. This allows the model to focus on different parts of the input sequence when making predictions, enabling it to handle dependencies without regard to their distance in the input or output sequences. The attention mechanism is central to the Transformer architecture, which relies entirely on attention and does not use recurrence or convolutions.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "Document 1:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 0.0\n",
      "Content: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "\n",
      "Document 2:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 2.0\n",
      "Content: 3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as ...\n",
      "\n",
      "Document 3:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 1.0\n",
      "Content: sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "...\n",
      "\n",
      "Document 4:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 12.0\n",
      "Content: Attention Visualizations\n",
      "Input-Input Layer5\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS...\n",
      "\n",
      "\n",
      "Question: How does the White Rabbit appear in Alice in Wonderland?\n",
      "--------------------------------------------------\n",
      "Answer:\n",
      "The White Rabbit in \"Alice in Wonderland\" is depicted as a character who is very hurried and anxious. He is described as splendidly dressed, holding a pair of white kid gloves and a large fan. He often mutters to himself about being late, which indicates his frantic nature. His appearance is notable for its anthropomorphism, as he displays human-like qualities such as talking and dressing. He plays a pivotal role in leading Alice into the fantastical world of Wonderland.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "Document 1:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: After a time she heard a little pattering of feet in the distance, and\n",
      "she hastily dried her eyes to see what was coming. It was the White\n",
      "Rabbit returning, splendidly dressed, with a pair of white ki...\n",
      "\n",
      "Document 2:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: Alice was not a bit hurt, and she jumped up on to her feet in a moment:\n",
      "she looked up, but it was all dark overhead; before her was another\n",
      "long passage, and the White Rabbit was still in sight, hurry...\n",
      "\n",
      "Document 3:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: “Read them,” said the King.\n",
      "\n",
      "The White Rabbit put on his spectacles. “Where shall I begin, please\n",
      "your Majesty?” he asked.\n",
      "\n",
      "“Begin at the beginning,” the King said gravely, “and go on till you\n",
      "come to...\n",
      "\n",
      "Document 4:\n",
      "Source: Alice in Wonderland (data\\alice_in_wonderland.txt)\n",
      "Content: The long grass rustled at her feet as the White Rabbit hurried by—the\n",
      "frightened Mouse splashed his way through the neighbouring pool—she\n",
      "could hear the rattle of the teacups as the March Hare and his...\n",
      "\n",
      "\n",
      "Question: Compare the self-attention architecture with RNNs according to the paper.\n",
      "--------------------------------------------------\n",
      "Answer:\n",
      "The paper compares self-attention architecture with recurrent neural networks (RNNs) based on several aspects:\n",
      "\n",
      "1. **Computational Complexity**: Self-attention layers have a lower computational complexity compared to RNNs. Specifically, self-attention allows for O(1) operations per layer, while RNNs require O(n) sequential operations, making self-attention faster when processing sequences.\n",
      "\n",
      "2. **Parallelization**: Self-attention layers can parallelize computation more effectively compared to RNNs, which have a minimum number of sequential operations due to their reliance on the previous time steps for the current output. This characteristic of self-attention facilitates more efficient training and inference.\n",
      "\n",
      "3. **Learning Dependencies**: The paper mentions that RNNs can struggle with learning dependencies between distant positions in a sequence. Self-attention mitigates this issue by providing a constant number of operations irrespective of the distance between positions, allowing the model to learn these dependencies more effectively.\n",
      "\n",
      "Overall, the self-attention mechanism offers advantages in speed, parallelization, and the ability to capture long-range dependencies within sequences compared to RNN architectures.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "Document 1:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 5.0\n",
      "Content: executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\n",
      "computational complexity, self-attention layers are faster than recurrent layers when the sequence\n",
      "6...\n",
      "\n",
      "Document 2:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 5.0\n",
      "Content: P Epos.\n",
      "We also experimented with using learned positional embeddings [9] instead, and found that the two\n",
      "versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal vers...\n",
      "\n",
      "Document 3:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 1.0\n",
      "Content: in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "...\n",
      "\n",
      "Document 4:\n",
      "Source: Attention Research Paper (data\\attention_paper.pdf)\n",
      "Page: 10.0\n",
      "Content: 2017.\n",
      "[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\n",
      "In International Conference on Learning Representations, 2017.\n",
      "[20] Diederik Kingma and Jimmy Ba. A...\n"
     ]
    }
   ],
   "source": [
    "# Function to query and display results\n",
    "def ask_question(question):\n",
    "    print(f\"\\n\\nQuestion: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # result = qa_chain({\"query\": question}) # deprecated\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(\"Answer:\")\n",
    "    print(result[\"result\"])\n",
    "    \n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"]):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        if source.endswith('.txt'):\n",
    "            doc_type = \"Alice in Wonderland\"\n",
    "        elif source.endswith('.md'):\n",
    "            doc_type = \"Flask Documentation\"\n",
    "        elif source.endswith('.pdf'):\n",
    "            doc_type = \"Attention Research Paper\"\n",
    "        else:\n",
    "            doc_type = \"Unknown\"\n",
    "            \n",
    "        print(f\"Source: {doc_type} ({source})\")\n",
    "        if 'page' in doc.metadata:\n",
    "            print(f\"Page: {doc.metadata['page']}\")\n",
    "        print(f\"Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "# List of questions about the documents\n",
    "questions = [\n",
    "    \"What happens to Alice when she drinks from the bottle?\",\n",
    "    \"What are the key features of Flask framework?\",\n",
    "    \"What is the attention mechanism described in the research paper?\",\n",
    "    \"How does the White Rabbit appear in Alice in Wonderland?\",\n",
    "    \"Compare the self-attention architecture with RNNs according to the paper.\"\n",
    "]\n",
    "\n",
    "# Ask each question\n",
    "for question in questions:\n",
    "    ask_question(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69bd55-8727-4542-ad8b-85c4617397fe",
   "metadata": {},
   "source": [
    "## Clean Up (Optional)\n",
    "\n",
    "If you want to delete the Pinecone index after you're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7580601-7c09-4089-b363-08622fa082ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index using modern Pinecone API (uncomment if needed)\n",
    "# pc.delete_index(PINECONE_INDEX_NAME)\n",
    "# print(f\"Deleted Pinecone index: {PINECONE_INDEX_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
