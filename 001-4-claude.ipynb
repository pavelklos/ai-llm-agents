{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab3af41-4403-47af-874d-9fad67fb05b7",
   "metadata": {},
   "source": [
    "**by Claude**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3e754-98f4-429e-a4fa-5c41da774503",
   "metadata": {},
   "source": [
    "##  AutoGen AI Agents Example\n",
    "Here's a simple Python application with two different AutoGen agents communicating with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a0805f-c735-4642-bbf8-7fdc3959ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a8d36-529b-45ff-8521-ffeed2bab878",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60634896-a3f4-4f0e-8f64-dc9aaa50b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables \n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set environment variables\n",
    "# os.environ['OPENAI_API_KEY'] = open_api_key\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70572e5-dfa0-4a14-aeec-263fdba46844",
   "metadata": {},
   "source": [
    "### Configure OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917027e1-4993-4d8c-9d99-b6849ee6156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API\n",
    "\n",
    "api_configuration = {\n",
    "    \"model\": MODEL_GPT,\n",
    "    \"api_key\": open_api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82caf1e2-c839-4283-93d3-66c58c5ca30b",
   "metadata": {},
   "source": [
    "### Create a configuration list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef42a0ee-f494-40c1-83dd-b853f535ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration list\n",
    "\n",
    "config_list = [api_configuration]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890c605-4819-41b8-b30e-4f44a27de43b",
   "metadata": {},
   "source": [
    "### Configure the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d251b73-be48-4876-9030-822a392f5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the agents\n",
    "\n",
    "assistant_config = {\n",
    "    \"seed\": 42,  # For reproducibility\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588b3e6-c1dd-4a28-af73-5474566978c7",
   "metadata": {},
   "source": [
    "### Create an assistant agent that can generate code and explain concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f875f3-ac46-466f-b43c-56b35647557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant agent that can generate code and explain concepts\n",
    "\n",
    "# assistant = AssistantAgent(\n",
    "#     name=\"Assistant\",\n",
    "#     system_message=\"You are a helpful AI assistant that specializes in Python programming. You provide clear, concise code with explanations.\",\n",
    "#     llm_config=assistant_config,\n",
    "# )\n",
    "\n",
    "# Create an assistant agent that can generate code and explain concepts\n",
    "# Add termination message\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"\"\"You are a helpful AI assistant that specializes in Python programming. \n",
    "    You provide clear, concise code with explanations. \n",
    "    After you've completed the task, end with the message 'TASK COMPLETED'.\"\"\",\n",
    "    llm_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b345d7-3356-4cf7-a33e-2bf0a8925238",
   "metadata": {},
   "source": [
    "### Create a code executor agent that can run and test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98173c0d-01b7-4311-ae17-76646f870607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code executor agent that can run and test code\n",
    "\n",
    "# executor = UserProxyAgent(\n",
    "#     name=\"Executor\",\n",
    "#     system_message=\"You are a code execution agent. You run code provided by the Assistant and report results or errors.\",\n",
    "#     human_input_mode=\"NEVER\",  # Don't ask for human input\n",
    "#     code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
    "# )\n",
    "\n",
    "# Create a code executor agent that can run and test code\n",
    "\n",
    "executor = UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"\"\"You are a code execution agent. You run code provided by the Assistant and report results or errors.\n",
    "    When you see 'TASK COMPLETED' from the Assistant and the code works correctly, respond with 'CONVERSATION FINISHED' and stop.\"\"\",\n",
    "    human_input_mode=\"NEVER\",  # Don't ask for human input\n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ea6c6-2aa9-4904-87b7-d71253b80be4",
   "metadata": {},
   "source": [
    "### Explicitly register reply functions with termination conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4830ad7-aeb7-4af8-96b2-10d2b10e98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly register reply functions with termination conditions\n",
    "\n",
    "def executor_reply(recipient, messages, sender, config):\n",
    "    \"\"\"Function to determine if the executor should terminate the conversation\"\"\"\n",
    "    if \"TASK COMPLETED\" in messages[-1][\"content\"]:\n",
    "        # Check if the executed code ran successfully before terminating\n",
    "        return \"CONVERSATION FINISHED\"\n",
    "    return False  # Continue the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9b44e-1447-4d1d-a89e-c7a13a1a90b9",
   "metadata": {},
   "source": [
    "### Register the custom reply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75cf0ad-df0c-4f1b-9fcf-d2e2917be30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the custom reply function\n",
    "\n",
    "executor.register_reply(\n",
    "    [assistant],\n",
    "    executor_reply,\n",
    "    config={\"callback\": None}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d1afd-2690-4815-9917-6087894f15e7",
   "metadata": {},
   "source": [
    "### Define how the agents will interact with a max_turns parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600e4bd1-f5ad-42da-89fe-d7a9bde374b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how the agents will interact\n",
    "\n",
    "# def start_task(task_description):\n",
    "#     # Executor initiates the conversation\n",
    "#     executor.initiate_chat(\n",
    "#         assistant,\n",
    "#         message=f\"I need help with the following task: {task_description}. Please provide Python code to accomplish this.\"\n",
    "#     )\n",
    "\n",
    "# Define how the agents will interact with a max_turns parameter\n",
    "\n",
    "def start_task(task_description, max_turns=10):\n",
    "    # Executor initiates the conversation with a maximum number of turns\n",
    "    executor.initiate_chat(\n",
    "        assistant,\n",
    "        message=f\"I need help with the following task: {task_description}. Please provide Python code to accomplish this.\",\n",
    "        max_turns=max_turns\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e7e88-32f7-4d56-ae2f-a00d1f6fe371",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2641e53-fe37-4ade-bead-ac986347b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mExecutor\u001b[0m (to Assistant):\n",
      "\n",
      "I need help with the following task: Create a simple data analysis script that calculates basic statistics (mean, median, mode) for a list of numbers.. Please provide Python code to accomplish this.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAssistant\u001b[0m (to Executor):\n",
      "\n",
      "Certainly! Below is a simple Python script that calculates the mean, median, and mode for a list of numbers using the `statistics` module.\n",
      "\n",
      "```python\n",
      "import statistics\n",
      "\n",
      "def calculate_statistics(numbers):\n",
      "    if not numbers:\n",
      "        return \"The list is empty.\"\n",
      "\n",
      "    mean = statistics.mean(numbers)\n",
      "    median = statistics.median(numbers)\n",
      "    try:\n",
      "        mode = statistics.mode(numbers)\n",
      "    except statistics.StatisticsError:\n",
      "        mode = \"No unique mode found\"\n",
      "\n",
      "    return {\n",
      "        'Mean': mean,\n",
      "        'Median': median,\n",
      "        'Mode': mode\n",
      "    }\n",
      "\n",
      "# Example usage\n",
      "numbers = [1, 2, 2, 3, 4, 4, 4, 5]\n",
      "stats = calculate_statistics(numbers)\n",
      "\n",
      "print(stats)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Import the `statistics` module**: This module provides functions to calculate statistical measures.\n",
      "2. **Define `calculate_statistics` function**: This function takes a list of numbers as input.\n",
      "3. **Check for empty list**: If the list is empty, it returns a message indicating this.\n",
      "4. **Calculate Mean**: Uses `statistics.mean()` to calculate the average of the numbers.\n",
      "5. **Calculate Median**: Uses `statistics.median()` to find the middle value.\n",
      "6. **Calculate Mode**: Uses `statistics.mode()`, wrapped in a try-except block to handle cases where there's no unique mode.\n",
      "7. **Return a dictionary**: The function returns a dictionary containing the mean, median, and mode.\n",
      "8. **Example usage**: A sample list is provided, and the statistics are printed.\n",
      "\n",
      "You can replace the `numbers` list with any other list of numbers to analyze different data.\n",
      "\n",
      "TASK COMPLETED\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m task = \u001b[33m\"\u001b[39m\u001b[33mCreate a simple data analysis script that calculates basic statistics (mean, median, mode) for a list of numbers.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Start the interaction\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# start_task(task)\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Start the interaction with a maximum of 5 turns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mstart_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# You can modify the task description to suit your needs\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# For example:\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# task = \"Build a web scraper to extract headlines from a news website\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# start_task(task, max_turns=5)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mstart_task\u001b[39m\u001b[34m(task_description, max_turns)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart_task\u001b[39m(task_description, max_turns=\u001b[32m10\u001b[39m):\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Executor initiates the conversation with a maximum number of turns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI need help with the following task: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtask_description\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. Please provide Python code to accomplish this.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_turns\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-agents\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1478\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1476\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m   1477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1478\u001b[39m     msg2send = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-agents\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2431\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, **kwargs)\u001b[39m\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2431\u001b[39m     final, reply = reply_func(\u001b[38;5;28mself\u001b[39m, messages=messages, sender=sender, config=reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   2432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2433\u001b[39m         log_event(\n\u001b[32m   2434\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2435\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2439\u001b[39m             reply=reply,\n\u001b[32m   2440\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "# Define a sample task\n",
    "task = \"Create a simple data analysis script that calculates basic statistics (mean, median, mode) for a list of numbers.\"\n",
    "\n",
    "# Start the interaction\n",
    "# start_task(task)\n",
    "\n",
    "# Start the interaction with a maximum of 5 turns\n",
    "start_task(task, max_turns=5)\n",
    "\n",
    "# You can modify the task description to suit your needs\n",
    "# For example:\n",
    "# task = \"Build a web scraper to extract headlines from a news website\"\n",
    "# start_task(task, max_turns=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
